{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7176c0-5ed5-4850-a27a-b820414ff96d",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"40%\" src=\"pics/Universidad Burgos.png\">\n",
    "<img style=\"float:right\" width=\"16%\" src=\"pics/person1_bacteria_2.jpeg\">\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Trabajo Fin de Grado\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">NOMBRE TFG</h2>\n",
    "\n",
    "### Nuria Martínez Queralt\n",
    "\n",
    "### Grado en Ingeniería de la Salud \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33e68c-4e8b-4305-91c2-cff54089bbf4",
   "metadata": {},
   "source": [
    "En este notebook se han llevado a cabo una serie de tareas para la realización del TFG, el cual consiste en la identificación de neumonía a partir de radiografías de tórax empleando una red neuronal. Para esto, se deben probar distintos modelos hasta llegar al modelo más optimo de red neuronal para este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296a9ed-5af7-4b30-91c5-7015aefef326",
   "metadata": {},
   "source": [
    "## Redistribución de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1466b-002c-4d9e-8c11-fe752738fabe",
   "metadata": {},
   "source": [
    "Debido a que la distribución inicial obtenida a partir del dataset descargado de internet: \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\" incluye únicamente 16 imágenes en la carpeta de validación (\"val\") y, esto supone un problema para la obtención de buenos resultados a la hora de construir nuestra red neuronal, antes de empezar a trabajar con las imágenes, se debe crear una función para obtener un nuevo dataset con nuevas carpetas \"train\", \"test\" y \"val\" y una nueva distribución de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607cb8f4-f897-4551-a114-31b2c1dcf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def buscar_imagen(directorio_padre, nombre_imagen):\n",
    "    '''\n",
    "    Función empleada para encontrar una imagen concreta (a partir de su nombre) dentro de cualquiera de las subcarpetas del directorio_padre.\n",
    "    ---------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_padre: ruta donde se encuentra la carpeta principal con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    - nombre_imagen: nombre de la imágen a la que se desea acceder \n",
    "    ----------------------------------------------------------\n",
    "    Return:\n",
    "    - ruta_imagen: ruta completa de la imágen a la que se desea acceder \n",
    "    '''\n",
    "    # Subcarpetas principales en las que buscar\n",
    "    subcarpetas_principales = ['train', 'test', 'val']\n",
    "    # Subcarpetas adicionales en las que buscar dentro de cada subcarpeta principal (donde se encuentran las imágenes)\n",
    "    subcarpetas_adicionales = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Se itera sobre las subcarpetas principales\n",
    "    for subcarpeta_principal in subcarpetas_principales:\n",
    "        # Se itera sobre las subcarpetas adicionales dentro de cada subcarpeta principal\n",
    "        for subcarpeta_adicional in subcarpetas_adicionales:\n",
    "            # Se obtiene la ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(directorio_padre, subcarpeta_principal, subcarpeta_adicional, nombre_imagen)\n",
    "            # verificar si la imagen existe en la subcarpeta actual\n",
    "            if os.path.exists(ruta_imagen):\n",
    "                return ruta_imagen  # devolver la ruta de la imagen si se encuentra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806f2df1-fbcf-46be-bc11-a7a80fd7b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def redestribucion_imagenes(directorio_principal):\n",
    "\n",
    "    '''\n",
    "    Función empleada para redistribuir las imágenes ubicadas en distintas subcarpetas dentro de la carpeta data en una carpeta nueva con las\n",
    "    mismas subcarpetas pero con un porcentaje distinto de imágenes en cada subcarpeta. La distribución quedaría de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    De igual forma, la distribución de las carpetas \"PNEUMONIA\" y \"NORMAL\" también queda de forma proporcional.\n",
    "    --------------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_principal: ruta donde se encuentra la carpeta data con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    -------------------------------------------------------------------\n",
    "    Return: \n",
    "    - nada\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    En primer lugar, se crea un csv con dos columnas nombres_ficheros y clases compuesto por todas las imágenes existentes en el directorio_padre.\n",
    "    En la columna nombres_ficheros debe aparecer el nombre de TODAS las imágenes que existen dentro de cada subcarpeta y en la columna clases debe \n",
    "    aparecer 0 o 1 en función si se trata de una imagen de la carpeta NORMAL o PNEUMONIA respectivamente.\n",
    "    '''\n",
    "\n",
    "    directorio_padre = os.path.join(directorio_principal, 'data') #se accede a la ruta de la carpeta data\n",
    "    \n",
    "    # Listas vacias para almacenar los nombres de las imágenes y las clases (0 o 1 en función de si es normal o neumonía respectivamente)\n",
    "    nombres_ficheros = []\n",
    "    clases = []\n",
    "    \n",
    "    # Se recorren las carpetas de train, test y val\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(directorio_padre, subcarpeta) #ruta a cada una de las subcarpetas\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase) #ruta a cada una de las clases dentro de las subcarpetas\n",
    "            for nombre_fichero in os.listdir(ruta_clase):\n",
    "                nombres_ficheros.append(nombre_fichero)\n",
    "                clases.append(0 if clase == 'NORMAL' else 1)\n",
    "    \n",
    "    # Se crea el DataFrame con los datos\n",
    "    df_todas = pd.DataFrame({'nombre_fichero': nombres_ficheros,'clase': clases})\n",
    "    \n",
    "    # Se guarda el DataFrame en un archivo CSV\n",
    "    ruta_csv = os.path.join(directorio_padre, 'dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    df_todas.to_csv(ruta_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A partir del csv anterior y, con ayuda de la función train_test_split de skitlearn se divide el csv anterior en dos \n",
    "    subgrupos de train y test en proporción 80, 20 para poder usar el 80% de las imágenes para train y el 20% para test.\n",
    "    También se emplea el parámetro stratify para que exista una proporción de clases en cada uno de los grupos, es decir, en ''NORMAL\" y \"PNEUMONIA\".\n",
    "    '''\n",
    "    \n",
    "    # random_state=42 se emplea para que cada vez que se ejecute el código, se obtenga la misma división de datos. El valor 42 es un valor que se usa\n",
    "    # comunmente en este caso pero se puede emplear cualquie otro valor entero.\n",
    "    train_df, test_df = train_test_split(df_todas, test_size=0.2, stratify=df_todas['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_csv = os.path.join(directorio_padre, 'train_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_test_csv = os.path.join(directorio_padre, 'test_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_df.to_csv(ruta_train_csv, index=False)\n",
    "    test_df.to_csv(ruta_test_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A continuación, se coge el conjunto de datos obtenido previamente de train, es decir, el csv \"train_df\" y se repite el mismo\n",
    "    proceso pero, esta vez dividiendo este conjunto de datos para train y val en un 80% y 20% respectivamente.\n",
    "    De tal forma que, finalemnte se obtenga el conjunto de test que represeneta el 20% del total (obtenido previamente), el conjunto de train\n",
    "    que representa el 80% del 80% del total ya que, inicialmente nos hemos quedado con el 80% pero luego, de este 80%, el 20% va destinado al conjunto\n",
    "    de validación. Por lo que, finalmete quedarían distribuidos de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    '''\n",
    "\n",
    "    # Se emplea train_test_split para dividir el conjunto de datos de entrenamiento en train (80%) y val (20%)\n",
    "    train_def_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_final_csv = os.path.join(directorio_padre, 'train_final_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_val_csv = os.path.join(directorio_padre, 'val_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_def_df.to_csv(ruta_train_final_csv, index=False)\n",
    "    val_df.to_csv(ruta_val_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    Finalmente, se crea una nueva carpeta denominada data_nuevo dentro del directorio principal. Dentro de esta carpeta se crean 3 subcarpetas \n",
    "    (\"train\", \"test\" y \"val\") que corresponderian con los dataframes obtenidos hasta hora: train_def_df, val_df y test_df y, dentro de estas 3 \n",
    "    subcarpetas, se crean 2 carpetas \"NORMAL\" y \"PNEUMONIA\" que corresponden con con las clases determinadas en cada dataframe, 0 en caso de \n",
    "    \"NORMAL\" y 1 para \"PNEUMONIA\". Dentro de estas dos carpetas para (\"train\", \"test\" y \"val\") se encontraran las imagenes correspondientes \n",
    "    para cada caso según los dataframes obtenidos.\n",
    "    \n",
    "    La función ''os.makedirs'', verifica si la carpeta ruta_subcarpeta ya existe. Si existe, no se hace nada y el programa continúa su ejecución \n",
    "    sin lanzar un error. Si no existe, la función os.makedirs() la crea junto con cualquier carpeta intermedia necesaria en la ruta especificada.\n",
    "    '''\n",
    "\n",
    "    # Se crea la nueva carpeta dentro del directorio principal\n",
    "    ruta_principal_nueva = os.path.join(directorio_principal, 'data_nuevo') \n",
    "\n",
    "    # Se crean las carpetas 'train', 'test' y 'val' dentro de la nueva carpeta principal\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(ruta_principal_nueva, subcarpeta)\n",
    "        os.makedirs(ruta_subcarpeta, exist_ok=True) \n",
    "        \n",
    "        # Se crean las subcarpetas 'normal' y 'neumonia' dentro de cada subcarpeta ('train', 'test' y 'val')\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            os.makedirs(ruta_clase, exist_ok=True)\n",
    "    \n",
    "                \n",
    "    # Se copian los archivos CSV a las subcarpetas correspondientes\n",
    "    for df, nombre_carpeta in [(train_def_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "        for index, row in df.iterrows(): #se itera sobre cada dataframe fila a fila\n",
    "            clase = 'NORMAL' if row['clase'] == 0 else 'PNEUMONIA'\n",
    "            nombre_archivo = row['nombre_fichero']\n",
    "    \n",
    "            # ruta de origen donde se busca la imagen concreta a partir de la función realizada previamente\n",
    "            # esta ruta se refiere a donde esta la imagen que se desea guardar en la carpeta destino originalmente para poder copiarla\n",
    "            ruta_origen=buscar_imagen(directorio_padre, nombre_archivo)\n",
    "            \n",
    "            # ruta donde se desa guardar (y redestribuir de la forma correcta) las imágenes\n",
    "            ruta_destino = os.path.join(ruta_principal_nueva, nombre_carpeta, clase, nombre_archivo)\n",
    "            \n",
    "            shutil.copyfile(ruta_origen, ruta_destino) # copia las imágenes de la ruta incial a la ruta final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c371aab4-b02f-4ce2-b902-03be9c426b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_principal = 'C:/Users/nuria/Downloads/TFG' #ruta donde se encuentra la carpeta data en mi caso y donde se va a crear la nueva carpeta data_nuevo\n",
    "redestribucion_imagenes(directorio_principal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b4967-0b21-4bea-a7dd-96dfc0bc0206",
   "metadata": {},
   "source": [
    "A partir de aqui, se va a trabajar con la nueva carpeta de imágenes y su nueva distribución para evitar errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f5be-2c05-498e-88e7-da98e1210f1c",
   "metadata": {},
   "source": [
    "## Preparación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd3214-3749-4449-a6ce-2150370b3359",
   "metadata": {},
   "source": [
    "Se prepara el modelo para poder trabajar con las imágenes de train, test y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f44c95-c38d-4885-a5e7-fe86df3e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def preparar_modelo(ruta, batch_size,target_size):\n",
    "\n",
    "    '''\n",
    "    Función que configura los generadores de datos para entrenar, validar y probar un modelo de aprendizaje automático con imágenes.\n",
    "    -----------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo.\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. Este valor deberá coincidir\n",
    "    con el input_shape empleado posteriormente.\n",
    "    ----------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    dir_general = ruta \n",
    "    \n",
    "    dir_train = os.path.join(dir_general, 'train')\n",
    "    dir_validation = os.path.join(dir_general, 'val')\n",
    "    dir_test = os.path.join(dir_general, 'test')\n",
    "    \n",
    "    # Preprocesamiento de imágenes\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de entrenamiento\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dir_train,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size, \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=True) # el conjunto de datos se barajará aleatoriamente para evitar sobreajuste \n",
    "\n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de validación\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        dir_validation,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size, \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False) # el conjunto de datos se barajará aleatoriamente para evitar sobreajuste \n",
    "\n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de prueba\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dir_test,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False) # el conjunto de datos se barajará aleatoriamente para evitar sobreajuste \n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2a919-5a84-4a53-94f1-ad964d37c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=20 #ejemplo de batch size\n",
    "target_size=(340,340) #ejemplo de target_size\n",
    "\n",
    "train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5654c9-4f71-4980-9ade-721a48531aec",
   "metadata": {},
   "source": [
    "## Creación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5c91f-3b3e-403c-820b-56c4cd7ecfa7",
   "metadata": {},
   "source": [
    "Se crea una función para calcular las distintas métricas que servirán para la posterior evaluación de cada modelo que se realice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62f0ad-3bf5-43b6-b2a6-ae64737f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np \n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    '''\n",
    "    Funcicón que calcula distintas métricas para la evaluación del modelo.\n",
    "    -----------------------------------------------------\n",
    "    Parámetros: \n",
    "    - y_test: array de etiquetas verdaderas del conjunto de prueba\n",
    "    - y_pred: array de etiquetas predichas por el modelo\n",
    "    ----------------------------------------\n",
    "    Return: \n",
    "    - accuracy: float que indica la proporción de predicciones correctas\n",
    "    - precision: float que indica la proporción de predicciones positivas correctas\n",
    "    - recall: float que indica la proporción de positivos detectados\n",
    "    - f1: float que indica la media armónica de precisión y exhaustividad para evaluar de una forma más equilibrada el rendimiento del modelo\n",
    "    - specificity: float que indica la proporción de negativos detectados\n",
    "    - fpr: float que indica la tasa de falsos positivos, es decir, la proporción de negativos incorrectamente clasificadas como positivos, \n",
    "    respecto al total de casos negativos reales.\n",
    "    - fnr: float que indica la tasa de falsos negativos, es decir, la proporción de positivos incorrectamente clasificadas como negativos, \n",
    "    respecto al total de casos positivos reales.\n",
    "    - auc: float que se emplea para evaluar la capacidad de distinción entre clases positivas y negativas de un modelo de clasificación \n",
    "    binaria. Un 1 significa que es capaz de distinguir perfectamente entre clases, un 0.5 significa una clasificación aleatoria y un 0 indica \n",
    "    que ninguna clase ha sido correctamente clasificada.\n",
    "    '''\n",
    "    \n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "    \n",
    "    #se obtienen los verdaderos negativos, falsos positivos, falsos negativos y verdaderos positivos a partir de la matriz de confusión \n",
    "    #con .ravel() se convierte la matriz en un array unidimensional\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_bin).ravel() \n",
    "\n",
    "    #se calculan cada una de las métricas empleando su correspondiente fórmula\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn) #tasa de falsos positivos\n",
    "    fnr = fn / (fn + tp) #tasa de falsos negativos\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, specificity, fpr, fnr, auc] #se devuleve como una lista para poder trabajar correctamente con las métricas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e775dc-426e-447b-bc1b-35d52330027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59a0d8-8fe2-4590-b50d-d3e1dd996e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e81a3-d57f-49a8-8307-1f4812bed084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1b32f5-76dc-483e-bb31-8c6e0d468c1f",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c1053-7fc4-4fa8-b4b4-f69100771f5b",
   "metadata": {},
   "source": [
    "Antes de realizar la comparación entre distintas arquitecturas y distintos batch_size, se han establecido diferentes modelos de arquitectura de red neuronal variando las capas, el número de capas, etc a partir de una red neuronal convolucional (CNN) propia realizada a partir del siguinete link: ''https://www.kaggle.com/code/paola311/clasificaci-n-de-im-genes-cnn'', una arquitectura CNN comunmente aplicada como punto de partida para la clasificacion de imagenes y a partir de una CNN basada en AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81631355-c81a-4aa2-9caf-d374da1919c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN propia\n",
    "\n",
    "def establecer_arquitectura_propia(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece tres tipos de modelos de red neuronal convolucional (CNN) a partir de una CNN propia.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(150,150,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y, se sabe de antemano que los resultados no van a ser buenos.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525f7f5-659b-4a79-9b51-b2e5c6d1a826",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN AlexaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c0f380-66aa-4989-a4ef-88253c46d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN alexaNet\n",
    "def establecer_arquitectura_AlexaNet(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) a partir de la CNN de alexNet.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(340,340,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce17fe-abf7-4859-8cbb-4baa86a918c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53a6c14c-63ba-4378-a4bd-4c61b0df546f",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6aca24-eddf-41fd-93ee-bf9dba26ed02",
   "metadata": {},
   "source": [
    "Se crean dos funciones distintas (una para CNN propia y otra para CNN alexNet) para poder realizar una comparación entre distintas arquitecturas y distintos batch_size entrenando y evaluando los modelos generados con distintas arquitecturas y distintos batch sizes. Para realizar la comparación, se emplea la función de obtención de métricas previamente definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1b7f36-6297-43d4-a8a8-93964cc84ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_propia(ruta,epochs,batch_sizes,modelos,target_size, directorio_historico, nombre_historico):\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas arquitecturas de modelo y distintos batch size introducidos como parámetros a partir de \n",
    "    la CNN propia establecida previamente. \n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá ser \n",
    "    (150,150) para coincidir con el input_shape del modelo de CNN propia.\n",
    "    - directorio_historico: str. Ruta general donde se va a crear la carpeta del historico para guardar los csv correspondientes\n",
    "    - nombre_historico: str. Nombre de la carpeta creada para guardar los csv de los historicos de la CNN propia\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_propia(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "            #ENTRENAMIENTO\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) \n",
    "\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            nombre_archivo = f'hist_propia_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los csv donde esta el historico correspondiente\n",
    "            ruta_historico = os.path.join(directorio_historico,nombre_historico) #se guarda dentro de una nueva carpeta \n",
    "            # Crea la carpeta del historico si no existe\n",
    "            os.makedirs(ruta_historico, exist_ok=True)\n",
    "            ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "            historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "            #se calculan las métricas a partir de la función creada previamente\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "        \n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8be533-a397-4df4-8e10-1f131bb07c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 132s 276ms/step - loss: 0.2550 - accuracy: 0.8943 - recall: 0.9535 - auc: 0.9436 - val_loss: 0.1612 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9757\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 128s 273ms/step - loss: 0.1368 - accuracy: 0.9506 - recall: 0.9711 - auc: 0.9837 - val_loss: 0.1533 - val_accuracy: 0.9392 - val_recall: 0.9766 - val_auc: 0.9806\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 127s 271ms/step - loss: 0.1166 - accuracy: 0.9570 - recall: 0.9740 - auc: 0.9874 - val_loss: 0.1883 - val_accuracy: 0.9306 - val_recall: 0.9810 - val_auc: 0.9769\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0902 - accuracy: 0.9666 - recall: 0.9788 - auc: 0.9924 - val_loss: 0.2097 - val_accuracy: 0.9253 - val_recall: 0.9810 - val_auc: 0.9689\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 122s 259ms/step - loss: 0.0742 - accuracy: 0.9738 - recall: 0.9835 - auc: 0.9945 - val_loss: 0.2396 - val_accuracy: 0.9338 - val_recall: 0.9269 - val_auc: 0.9776\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0592 - accuracy: 0.9773 - recall: 0.9857 - auc: 0.9968 - val_loss: 0.1986 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9723\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 124s 263ms/step - loss: 0.0448 - accuracy: 0.9821 - recall: 0.9872 - auc: 0.9980 - val_loss: 0.2237 - val_accuracy: 0.9392 - val_recall: 0.9678 - val_auc: 0.9681\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 123s 261ms/step - loss: 0.0500 - accuracy: 0.9829 - recall: 0.9905 - auc: 0.9978 - val_loss: 0.2481 - val_accuracy: 0.9370 - val_recall: 0.9518 - val_auc: 0.9660\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0237 - accuracy: 0.9925 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.3000 - val_accuracy: 0.9349 - val_recall: 0.9430 - val_auc: 0.9632\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0178 - accuracy: 0.9928 - recall: 0.9949 - auc: 0.9998 - val_loss: 0.2932 - val_accuracy: 0.9317 - val_recall: 0.9430 - val_auc: 0.9615\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0207 - accuracy: 0.9933 - recall: 0.9952 - auc: 0.9992 - val_loss: 0.3537 - val_accuracy: 0.9317 - val_recall: 0.9430 - val_auc: 0.9562\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0142 - accuracy: 0.9952 - recall: 0.9967 - auc: 0.9999 - val_loss: 0.3317 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9583\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.254966  0.894315  0.953548  0.943649  0.161163      0.941302   \n",
      "1   0.136755  0.950627  0.971105  0.983685  0.153286      0.939168   \n",
      "2   0.116592  0.957032  0.974031  0.987410  0.188335      0.930630   \n",
      "3   0.090210  0.966640  0.978786  0.992437  0.209658      0.925294   \n",
      "4   0.074250  0.973846  0.983541  0.994526  0.239587      0.933831   \n",
      "5   0.059241  0.977315  0.985735  0.996798  0.198563      0.940235   \n",
      "6   0.044846  0.982119  0.987198  0.997966  0.223664      0.939168   \n",
      "7   0.049986  0.982920  0.990490  0.997820  0.248072      0.937033   \n",
      "8   0.023701  0.992527  0.995611  0.999610  0.299994      0.934899   \n",
      "9   0.017778  0.992794  0.994879  0.999814  0.293185      0.931697   \n",
      "10  0.020657  0.993328  0.995245  0.999175  0.353679      0.931697   \n",
      "11  0.014151  0.995196  0.996708  0.999878  0.331656      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.960526  0.975663  \n",
      "1     0.976608  0.980578  \n",
      "2     0.980994  0.976943  \n",
      "3     0.980994  0.968882  \n",
      "4     0.926901  0.977599  \n",
      "5     0.961988  0.972329  \n",
      "6     0.967836  0.968111  \n",
      "7     0.951754  0.965996  \n",
      "8     0.942982  0.963182  \n",
      "9     0.942982  0.961451  \n",
      "10    0.942982  0.956187  \n",
      "11    0.954678  0.958322  \n",
      "147/147 [==============================] - 29s 195ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 129s 542ms/step - loss: 0.2337 - accuracy: 0.9061 - recall: 0.9568 - auc: 0.9557 - val_loss: 0.1534 - val_accuracy: 0.9445 - val_recall: 0.9693 - val_auc: 0.9771\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 125s 530ms/step - loss: 0.1450 - accuracy: 0.9474 - recall: 0.9685 - auc: 0.9810 - val_loss: 0.1578 - val_accuracy: 0.9424 - val_recall: 0.9766 - val_auc: 0.9772\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1075 - accuracy: 0.9610 - recall: 0.9777 - auc: 0.9896 - val_loss: 0.1546 - val_accuracy: 0.9456 - val_recall: 0.9576 - val_auc: 0.9807\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 122s 519ms/step - loss: 0.0988 - accuracy: 0.9672 - recall: 0.9810 - auc: 0.9912 - val_loss: 0.1787 - val_accuracy: 0.9338 - val_recall: 0.9357 - val_auc: 0.9790\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 122s 520ms/step - loss: 0.0794 - accuracy: 0.9720 - recall: 0.9832 - auc: 0.9941 - val_loss: 0.1636 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9803\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 122s 521ms/step - loss: 0.0612 - accuracy: 0.9776 - recall: 0.9865 - auc: 0.9964 - val_loss: 0.1980 - val_accuracy: 0.9434 - val_recall: 0.9474 - val_auc: 0.9785\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 121s 515ms/step - loss: 0.0584 - accuracy: 0.9795 - recall: 0.9868 - auc: 0.9967 - val_loss: 0.1859 - val_accuracy: 0.9434 - val_recall: 0.9722 - val_auc: 0.9722\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 122s 517ms/step - loss: 0.0305 - accuracy: 0.9907 - recall: 0.9949 - auc: 0.9988 - val_loss: 0.2916 - val_accuracy: 0.9317 - val_recall: 0.9284 - val_auc: 0.9707\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 121s 513ms/step - loss: 0.0334 - accuracy: 0.9883 - recall: 0.9945 - auc: 0.9991 - val_loss: 0.2256 - val_accuracy: 0.9456 - val_recall: 0.9561 - val_auc: 0.9737\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 121s 516ms/step - loss: 0.0223 - accuracy: 0.9920 - recall: 0.9945 - auc: 0.9992 - val_loss: 0.2643 - val_accuracy: 0.9402 - val_recall: 0.9664 - val_auc: 0.9627\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 122s 519ms/step - loss: 0.0132 - accuracy: 0.9957 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.3003 - val_accuracy: 0.9338 - val_recall: 0.9591 - val_auc: 0.9612\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 122s 520ms/step - loss: 0.0212 - accuracy: 0.9920 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.3627 - val_accuracy: 0.9210 - val_recall: 0.9825 - val_auc: 0.9461\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 123s 523ms/step - loss: 0.0158 - accuracy: 0.9955 - recall: 0.9978 - auc: 0.9997 - val_loss: 0.2948 - val_accuracy: 0.9424 - val_recall: 0.9678 - val_auc: 0.9604\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.233694  0.906058  0.956840  0.955706  0.153361      0.944504   \n",
      "1   0.145013  0.947425  0.968544  0.981019  0.157844      0.942369   \n",
      "2   0.107493  0.961035  0.977688  0.989576  0.154621      0.945571   \n",
      "3   0.098837  0.967174  0.980980  0.991209  0.178688      0.933831   \n",
      "4   0.079431  0.971978  0.983175  0.994139  0.163614      0.948773   \n",
      "5   0.061157  0.977582  0.986467  0.996412  0.198033      0.943437   \n",
      "6   0.058378  0.979450  0.986832  0.996672  0.185851      0.943437   \n",
      "7   0.030511  0.990659  0.994879  0.998753  0.291643      0.931697   \n",
      "8   0.033393  0.988257  0.994514  0.999099  0.225611      0.945571   \n",
      "9   0.022256  0.991994  0.994514  0.999202  0.264304      0.940235   \n",
      "10  0.013185  0.995730  0.997440  0.999892  0.300316      0.933831   \n",
      "11  0.021153  0.991994  0.995245  0.999635  0.362660      0.921025   \n",
      "12  0.015796  0.995463  0.997805  0.999748  0.294762      0.942369   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.969298  0.977062  \n",
      "1     0.976608  0.977189  \n",
      "2     0.957602  0.980697  \n",
      "3     0.935673  0.979015  \n",
      "4     0.960526  0.980278  \n",
      "5     0.947368  0.978530  \n",
      "6     0.972222  0.972216  \n",
      "7     0.928363  0.970691  \n",
      "8     0.956140  0.973678  \n",
      "9     0.966374  0.962714  \n",
      "10    0.959064  0.961194  \n",
      "11    0.982456  0.946123  \n",
      "12    0.967836  0.960393  \n",
      "74/74 [==============================] - 28s 374ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 128s 667ms/step - loss: 0.2687 - accuracy: 0.8850 - recall: 0.9492 - auc: 0.9399 - val_loss: 0.1539 - val_accuracy: 0.9488 - val_recall: 0.9737 - val_auc: 0.9749\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 122s 651ms/step - loss: 0.1336 - accuracy: 0.9536 - recall: 0.9733 - auc: 0.9844 - val_loss: 0.1520 - val_accuracy: 0.9477 - val_recall: 0.9591 - val_auc: 0.9802\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 121s 643ms/step - loss: 0.1254 - accuracy: 0.9536 - recall: 0.9726 - auc: 0.9864 - val_loss: 0.1658 - val_accuracy: 0.9413 - val_recall: 0.9474 - val_auc: 0.9756\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 120s 638ms/step - loss: 0.1049 - accuracy: 0.9634 - recall: 0.9784 - auc: 0.9897 - val_loss: 0.1620 - val_accuracy: 0.9434 - val_recall: 0.9620 - val_auc: 0.9785\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 121s 641ms/step - loss: 0.0861 - accuracy: 0.9701 - recall: 0.9839 - auc: 0.9934 - val_loss: 0.1711 - val_accuracy: 0.9445 - val_recall: 0.9795 - val_auc: 0.9786\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 120s 637ms/step - loss: 0.0833 - accuracy: 0.9704 - recall: 0.9832 - auc: 0.9921 - val_loss: 0.1666 - val_accuracy: 0.9392 - val_recall: 0.9488 - val_auc: 0.9774\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 120s 640ms/step - loss: 0.0586 - accuracy: 0.9789 - recall: 0.9879 - auc: 0.9955 - val_loss: 0.3160 - val_accuracy: 0.9189 - val_recall: 0.9006 - val_auc: 0.9704\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 119s 635ms/step - loss: 0.0548 - accuracy: 0.9819 - recall: 0.9879 - auc: 0.9958 - val_loss: 0.2013 - val_accuracy: 0.9317 - val_recall: 0.9474 - val_auc: 0.9730\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 121s 642ms/step - loss: 0.0447 - accuracy: 0.9867 - recall: 0.9912 - auc: 0.9974 - val_loss: 0.2339 - val_accuracy: 0.9285 - val_recall: 0.9781 - val_auc: 0.9710\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 122s 647ms/step - loss: 0.0309 - accuracy: 0.9891 - recall: 0.9934 - auc: 0.9988 - val_loss: 0.1916 - val_accuracy: 0.9445 - val_recall: 0.9737 - val_auc: 0.9716\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 121s 647ms/step - loss: 0.0403 - accuracy: 0.9856 - recall: 0.9909 - auc: 0.9983 - val_loss: 0.2672 - val_accuracy: 0.9306 - val_recall: 0.9795 - val_auc: 0.9651\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 120s 640ms/step - loss: 0.0224 - accuracy: 0.9931 - recall: 0.9963 - auc: 0.9996 - val_loss: 0.2395 - val_accuracy: 0.9328 - val_recall: 0.9708 - val_auc: 0.9698\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.268661  0.884975  0.949159  0.939918  0.153877      0.948773   \n",
      "1   0.133632  0.953563  0.973299  0.984413  0.151978      0.947705   \n",
      "2   0.125381  0.953563  0.972568  0.986356  0.165765      0.941302   \n",
      "3   0.104866  0.963437  0.978420  0.989664  0.161997      0.943437   \n",
      "4   0.086065  0.970109  0.983906  0.993434  0.171080      0.944504   \n",
      "5   0.083264  0.970376  0.983175  0.992098  0.166648      0.939168   \n",
      "6   0.058640  0.978916  0.987930  0.995539  0.315996      0.918890   \n",
      "7   0.054812  0.981852  0.987930  0.995777  0.201254      0.931697   \n",
      "8   0.044651  0.986656  0.991222  0.997445  0.233852      0.928495   \n",
      "9   0.030866  0.989058  0.993416  0.998779  0.191622      0.944504   \n",
      "10  0.040308  0.985588  0.990856  0.998283  0.267190      0.930630   \n",
      "11  0.022404  0.993061  0.996342  0.999609  0.239474      0.932764   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.973684  0.974877  \n",
      "1     0.959064  0.980171  \n",
      "2     0.947368  0.975574  \n",
      "3     0.961988  0.978541  \n",
      "4     0.979532  0.978558  \n",
      "5     0.948830  0.977432  \n",
      "6     0.900585  0.970405  \n",
      "7     0.947368  0.972959  \n",
      "8     0.978070  0.971023  \n",
      "9     0.973684  0.971641  \n",
      "10    0.979532  0.965071  \n",
      "11    0.970760  0.969761  \n",
      "59/59 [==============================] - 27s 448ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 1969s 17s/step - loss: 0.3697 - accuracy: 0.8308 - recall: 0.9294 - auc: 0.8825 - val_loss: 0.1901 - val_accuracy: 0.9317 - val_recall: 0.9298 - val_auc: 0.9784\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 85s 718ms/step - loss: 0.1711 - accuracy: 0.9359 - recall: 0.9656 - auc: 0.9754 - val_loss: 0.1747 - val_accuracy: 0.9328 - val_recall: 0.9854 - val_auc: 0.9745\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 91s 767ms/step - loss: 0.1297 - accuracy: 0.9512 - recall: 0.9700 - auc: 0.9846 - val_loss: 0.1791 - val_accuracy: 0.9424 - val_recall: 0.9386 - val_auc: 0.9801\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 96s 814ms/step - loss: 0.1158 - accuracy: 0.9605 - recall: 0.9770 - auc: 0.9881 - val_loss: 0.1476 - val_accuracy: 0.9477 - val_recall: 0.9649 - val_auc: 0.9783\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 94s 800ms/step - loss: 0.0953 - accuracy: 0.9653 - recall: 0.9792 - auc: 0.9914 - val_loss: 0.1709 - val_accuracy: 0.9477 - val_recall: 0.9854 - val_auc: 0.9758\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 97s 822ms/step - loss: 0.0903 - accuracy: 0.9688 - recall: 0.9810 - auc: 0.9930 - val_loss: 0.1625 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9782\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 99s 840ms/step - loss: 0.0866 - accuracy: 0.9690 - recall: 0.9813 - auc: 0.9935 - val_loss: 0.1776 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9719\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 101s 852ms/step - loss: 0.0736 - accuracy: 0.9754 - recall: 0.9846 - auc: 0.9944 - val_loss: 0.1616 - val_accuracy: 0.9445 - val_recall: 0.9635 - val_auc: 0.9790\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 100s 849ms/step - loss: 0.0654 - accuracy: 0.9770 - recall: 0.9857 - auc: 0.9960 - val_loss: 0.1748 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9740\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 100s 852ms/step - loss: 0.0531 - accuracy: 0.9827 - recall: 0.9894 - auc: 0.9973 - val_loss: 0.1942 - val_accuracy: 0.9328 - val_recall: 0.9708 - val_auc: 0.9756\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 98s 834ms/step - loss: 0.0427 - accuracy: 0.9835 - recall: 0.9912 - auc: 0.9988 - val_loss: 0.1799 - val_accuracy: 0.9445 - val_recall: 0.9532 - val_auc: 0.9752\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 101s 855ms/step - loss: 0.0347 - accuracy: 0.9875 - recall: 0.9927 - auc: 0.9992 - val_loss: 0.2079 - val_accuracy: 0.9413 - val_recall: 0.9430 - val_auc: 0.9755\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 103s 872ms/step - loss: 0.0300 - accuracy: 0.9907 - recall: 0.9945 - auc: 0.9992 - val_loss: 0.2101 - val_accuracy: 0.9392 - val_recall: 0.9591 - val_auc: 0.9744\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.369716  0.830798  0.929407  0.882521  0.190066      0.931697   \n",
      "1   0.171092  0.935949  0.965618  0.975379  0.174678      0.932764   \n",
      "2   0.129685  0.951161  0.970007  0.984564  0.179082      0.942369   \n",
      "3   0.115828  0.960502  0.976957  0.988061  0.147566      0.947705   \n",
      "4   0.095321  0.965306  0.979151  0.991383  0.170861      0.947705   \n",
      "5   0.090305  0.968775  0.980980  0.992954  0.162546      0.943437   \n",
      "6   0.086604  0.969042  0.981346  0.993471  0.177581      0.937033   \n",
      "7   0.073614  0.975447  0.984638  0.994386  0.161570      0.944504   \n",
      "8   0.065370  0.977048  0.985735  0.996015  0.174773      0.939168   \n",
      "9   0.053092  0.982653  0.989393  0.997280  0.194157      0.932764   \n",
      "10  0.042716  0.983453  0.991222  0.998761  0.179883      0.944504   \n",
      "11  0.034685  0.987457  0.992685  0.999177  0.207929      0.941302   \n",
      "12  0.029978  0.990659  0.994514  0.999200  0.210063      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.929825  0.978405  \n",
      "1     0.985380  0.974525  \n",
      "2     0.938596  0.980070  \n",
      "3     0.964912  0.978304  \n",
      "4     0.985380  0.975759  \n",
      "5     0.957602  0.978209  \n",
      "6     0.979532  0.971916  \n",
      "7     0.963450  0.979006  \n",
      "8     0.957602  0.973959  \n",
      "9     0.970760  0.975556  \n",
      "10    0.953216  0.975242  \n",
      "11    0.942982  0.975487  \n",
      "12    0.959064  0.974395  \n",
      "37/37 [==============================] - 21s 549ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.4250 - accuracy: 0.8118 - recall: 0.9378 - auc: 0.8460 - val_loss: 0.1938 - val_accuracy: 0.9200 - val_recall: 0.9576 - val_auc: 0.9711\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.1638 - accuracy: 0.9367 - recall: 0.9638 - auc: 0.9793 - val_loss: 0.1996 - val_accuracy: 0.9264 - val_recall: 0.9898 - val_auc: 0.9760\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.1258 - accuracy: 0.9528 - recall: 0.9737 - auc: 0.9868 - val_loss: 0.1652 - val_accuracy: 0.9349 - val_recall: 0.9795 - val_auc: 0.9774\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.1071 - accuracy: 0.9597 - recall: 0.9755 - auc: 0.9900 - val_loss: 0.1649 - val_accuracy: 0.9381 - val_recall: 0.9825 - val_auc: 0.9756\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.1089 - accuracy: 0.9573 - recall: 0.9755 - auc: 0.9898 - val_loss: 0.1502 - val_accuracy: 0.9445 - val_recall: 0.9532 - val_auc: 0.9808\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0955 - accuracy: 0.9656 - recall: 0.9799 - auc: 0.9921 - val_loss: 0.1494 - val_accuracy: 0.9466 - val_recall: 0.9693 - val_auc: 0.9788\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0853 - accuracy: 0.9693 - recall: 0.9817 - auc: 0.9927 - val_loss: 0.1523 - val_accuracy: 0.9477 - val_recall: 0.9620 - val_auc: 0.9799\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.1250 - accuracy: 0.9544 - recall: 0.9770 - auc: 0.9871 - val_loss: 0.1830 - val_accuracy: 0.9264 - val_recall: 0.9868 - val_auc: 0.9744\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.0888 - accuracy: 0.9717 - recall: 0.9846 - auc: 0.9926 - val_loss: 0.1476 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9809\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.0668 - accuracy: 0.9778 - recall: 0.9876 - auc: 0.9956 - val_loss: 0.1637 - val_accuracy: 0.9477 - val_recall: 0.9561 - val_auc: 0.9817\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0613 - accuracy: 0.9773 - recall: 0.9868 - auc: 0.9960 - val_loss: 0.1612 - val_accuracy: 0.9498 - val_recall: 0.9620 - val_auc: 0.9785\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0563 - accuracy: 0.9805 - recall: 0.9887 - auc: 0.9967 - val_loss: 0.1615 - val_accuracy: 0.9509 - val_recall: 0.9635 - val_auc: 0.9769\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0551 - accuracy: 0.9816 - recall: 0.9901 - auc: 0.9971 - val_loss: 0.1874 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9749\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0455 - accuracy: 0.9845 - recall: 0.9912 - auc: 0.9976 - val_loss: 0.1635 - val_accuracy: 0.9488 - val_recall: 0.9635 - val_auc: 0.9776\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0361 - accuracy: 0.9901 - recall: 0.9952 - auc: 0.9986 - val_loss: 0.1906 - val_accuracy: 0.9498 - val_recall: 0.9561 - val_auc: 0.9767\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0294 - accuracy: 0.9917 - recall: 0.9960 - auc: 0.9993 - val_loss: 0.1998 - val_accuracy: 0.9456 - val_recall: 0.9444 - val_auc: 0.9767\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.0372 - accuracy: 0.9869 - recall: 0.9923 - auc: 0.9989 - val_loss: 0.2155 - val_accuracy: 0.9402 - val_recall: 0.9766 - val_auc: 0.9713\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 93s 2s/step - loss: 0.0262 - accuracy: 0.9920 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.2006 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9730\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 93s 2s/step - loss: 0.0211 - accuracy: 0.9939 - recall: 0.9963 - auc: 0.9997 - val_loss: 0.2026 - val_accuracy: 0.9466 - val_recall: 0.9605 - val_auc: 0.9744\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0160 - accuracy: 0.9957 - recall: 0.9978 - auc: 0.9999 - val_loss: 0.2235 - val_accuracy: 0.9424 - val_recall: 0.9503 - val_auc: 0.9726\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.424956  0.811849  0.937820  0.846020  0.193828      0.919957   \n",
      "1   0.163797  0.936749  0.963789  0.979322  0.199570      0.926361   \n",
      "2   0.125762  0.952762  0.973665  0.986798  0.165246      0.934899   \n",
      "3   0.107068  0.959701  0.975494  0.989991  0.164894      0.938100   \n",
      "4   0.108850  0.957299  0.975494  0.989769  0.150206      0.944504   \n",
      "5   0.095539  0.965572  0.979883  0.992103  0.149421      0.946638   \n",
      "6   0.085344  0.969309  0.981712  0.992712  0.152297      0.947705   \n",
      "7   0.125005  0.954363  0.976957  0.987059  0.183015      0.926361   \n",
      "8   0.088773  0.971711  0.984638  0.992550  0.147572      0.945571   \n",
      "9   0.066761  0.977849  0.987564  0.995576  0.163730      0.947705   \n",
      "10  0.061270  0.977315  0.986832  0.996002  0.161231      0.949840   \n",
      "11  0.056285  0.980518  0.988661  0.996731  0.161504      0.950907   \n",
      "12  0.055150  0.981585  0.990124  0.997113  0.187390      0.937033   \n",
      "13  0.045539  0.984521  0.991222  0.997581  0.163450      0.948773   \n",
      "14  0.036120  0.990125  0.995245  0.998556  0.190596      0.949840   \n",
      "15  0.029430  0.991727  0.995977  0.999295  0.199841      0.945571   \n",
      "16  0.037180  0.986923  0.992319  0.998945  0.215487      0.940235   \n",
      "17  0.026201  0.991994  0.995245  0.999601  0.200585      0.943437   \n",
      "18  0.021119  0.993862  0.996342  0.999737  0.202591      0.946638   \n",
      "19  0.015992  0.995730  0.997805  0.999861  0.223494      0.942369   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.957602  0.971093  \n",
      "1     0.989766  0.975955  \n",
      "2     0.979532  0.977443  \n",
      "3     0.982456  0.975559  \n",
      "4     0.953216  0.980778  \n",
      "5     0.969298  0.978830  \n",
      "6     0.961988  0.979942  \n",
      "7     0.986842  0.974447  \n",
      "8     0.960526  0.980933  \n",
      "9     0.956140  0.981688  \n",
      "10    0.961988  0.978524  \n",
      "11    0.963450  0.976929  \n",
      "12    0.979532  0.974909  \n",
      "13    0.963450  0.977573  \n",
      "14    0.956140  0.976689  \n",
      "15    0.944444  0.976657  \n",
      "16    0.976608  0.971344  \n",
      "17    0.957602  0.973049  \n",
      "18    0.960526  0.974366  \n",
      "19    0.950292  0.972641  \n",
      "19/19 [==============================] - 19s 973ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 126s 267ms/step - loss: 0.2864 - accuracy: 0.8874 - recall: 0.9433 - auc: 0.9372 - val_loss: 0.1936 - val_accuracy: 0.9253 - val_recall: 0.9547 - val_auc: 0.9683\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 122s 261ms/step - loss: 0.1703 - accuracy: 0.9402 - recall: 0.9653 - auc: 0.9760 - val_loss: 0.1573 - val_accuracy: 0.9445 - val_recall: 0.9678 - val_auc: 0.9773\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 120s 256ms/step - loss: 0.1297 - accuracy: 0.9520 - recall: 0.9711 - auc: 0.9857 - val_loss: 0.1476 - val_accuracy: 0.9434 - val_recall: 0.9664 - val_auc: 0.9794\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.1116 - accuracy: 0.9589 - recall: 0.9766 - auc: 0.9893 - val_loss: 0.1686 - val_accuracy: 0.9445 - val_recall: 0.9576 - val_auc: 0.9776\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0776 - accuracy: 0.9722 - recall: 0.9828 - auc: 0.9949 - val_loss: 0.2030 - val_accuracy: 0.9328 - val_recall: 0.9635 - val_auc: 0.9714\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0721 - accuracy: 0.9725 - recall: 0.9843 - auc: 0.9957 - val_loss: 0.2534 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9690\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 126s 268ms/step - loss: 0.0703 - accuracy: 0.9749 - recall: 0.9872 - auc: 0.9962 - val_loss: 0.2605 - val_accuracy: 0.9392 - val_recall: 0.9532 - val_auc: 0.9672\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 127s 271ms/step - loss: 0.0489 - accuracy: 0.9813 - recall: 0.9883 - auc: 0.9977 - val_loss: 0.2536 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9730\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 0.0427 - accuracy: 0.9835 - recall: 0.9901 - auc: 0.9982 - val_loss: 0.2939 - val_accuracy: 0.9424 - val_recall: 0.9547 - val_auc: 0.9691\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 122s 260ms/step - loss: 0.0277 - accuracy: 0.9907 - recall: 0.9952 - auc: 0.9995 - val_loss: 0.2774 - val_accuracy: 0.9434 - val_recall: 0.9488 - val_auc: 0.9654\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0283 - accuracy: 0.9893 - recall: 0.9934 - auc: 0.9994 - val_loss: 0.2106 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9713\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 124s 265ms/step - loss: 0.0387 - accuracy: 0.9861 - recall: 0.9909 - auc: 0.9987 - val_loss: 0.2963 - val_accuracy: 0.9424 - val_recall: 0.9664 - val_auc: 0.9655\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0288 - accuracy: 0.9893 - recall: 0.9931 - auc: 0.9989 - val_loss: 0.3979 - val_accuracy: 0.9338 - val_recall: 0.9737 - val_auc: 0.9587\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.286351  0.887377  0.943307  0.937185  0.193556      0.925294   \n",
      "1   0.170280  0.940219  0.965252  0.976015  0.157257      0.944504   \n",
      "2   0.129660  0.951962  0.971105  0.985696  0.147639      0.943437   \n",
      "3   0.111613  0.958900  0.976591  0.989286  0.168617      0.944504   \n",
      "4   0.077565  0.972244  0.982809  0.994905  0.203023      0.932764   \n",
      "5   0.072097  0.972511  0.984272  0.995717  0.253424      0.940235   \n",
      "6   0.070272  0.974913  0.987198  0.996219  0.260495      0.939168   \n",
      "7   0.048939  0.981318  0.988296  0.997699  0.253580      0.942369   \n",
      "8   0.042660  0.983453  0.990124  0.998169  0.293930      0.942369   \n",
      "9   0.027658  0.990659  0.995245  0.999483  0.277409      0.943437   \n",
      "10  0.028260  0.989325  0.993416  0.999416  0.210610      0.944504   \n",
      "11  0.038690  0.986122  0.990856  0.998737  0.296320      0.942369   \n",
      "12  0.028825  0.989325  0.993050  0.998885  0.397855      0.933831   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.954678  0.968322  \n",
      "1     0.967836  0.977284  \n",
      "2     0.966374  0.979414  \n",
      "3     0.957602  0.977617  \n",
      "4     0.963450  0.971439  \n",
      "5     0.951754  0.968969  \n",
      "6     0.953216  0.967241  \n",
      "7     0.964912  0.973023  \n",
      "8     0.954678  0.969142  \n",
      "9     0.948830  0.965447  \n",
      "10    0.961988  0.971309  \n",
      "11    0.966374  0.965453  \n",
      "12    0.973684  0.958703  \n",
      "147/147 [==============================] - 29s 198ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 123s 517ms/step - loss: 0.3065 - accuracy: 0.8716 - recall: 0.9309 - auc: 0.9248 - val_loss: 0.1923 - val_accuracy: 0.9296 - val_recall: 0.9240 - val_auc: 0.9812\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 121s 516ms/step - loss: 0.1420 - accuracy: 0.9482 - recall: 0.9685 - auc: 0.9820 - val_loss: 0.1797 - val_accuracy: 0.9360 - val_recall: 0.9605 - val_auc: 0.9707\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 125s 532ms/step - loss: 0.1001 - accuracy: 0.9634 - recall: 0.9788 - auc: 0.9911 - val_loss: 0.1929 - val_accuracy: 0.9285 - val_recall: 0.9225 - val_auc: 0.9812\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 120s 509ms/step - loss: 0.0910 - accuracy: 0.9682 - recall: 0.9799 - auc: 0.9922 - val_loss: 0.1843 - val_accuracy: 0.9402 - val_recall: 0.9708 - val_auc: 0.9741\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 2432s 10s/step - loss: 0.0658 - accuracy: 0.9749 - recall: 0.9850 - auc: 0.9962 - val_loss: 0.2059 - val_accuracy: 0.9338 - val_recall: 0.9708 - val_auc: 0.9718\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 96s 409ms/step - loss: 0.0554 - accuracy: 0.9795 - recall: 0.9861 - auc: 0.9971 - val_loss: 0.3524 - val_accuracy: 0.8890 - val_recall: 0.9927 - val_auc: 0.9634\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 102s 432ms/step - loss: 0.0502 - accuracy: 0.9813 - recall: 0.9894 - auc: 0.9977 - val_loss: 0.2661 - val_accuracy: 0.9402 - val_recall: 0.9444 - val_auc: 0.9695\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 106s 450ms/step - loss: 0.0277 - accuracy: 0.9907 - recall: 0.9938 - auc: 0.9989 - val_loss: 0.2658 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9685\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 107s 454ms/step - loss: 0.0182 - accuracy: 0.9931 - recall: 0.9956 - auc: 0.9998 - val_loss: 0.3562 - val_accuracy: 0.9360 - val_recall: 0.9678 - val_auc: 0.9568\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 107s 454ms/step - loss: 0.0280 - accuracy: 0.9893 - recall: 0.9927 - auc: 0.9989 - val_loss: 0.4348 - val_accuracy: 0.9157 - val_recall: 0.9868 - val_auc: 0.9459\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 109s 463ms/step - loss: 0.0159 - accuracy: 0.9925 - recall: 0.9945 - auc: 0.9998 - val_loss: 0.3601 - val_accuracy: 0.9413 - val_recall: 0.9664 - val_auc: 0.9616\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.306545  0.871631  0.930871  0.924816  0.192308      0.929562   \n",
      "1   0.142018  0.948225  0.968544  0.982038  0.179749      0.935966   \n",
      "2   0.100099  0.963437  0.978786  0.991119  0.192881      0.928495   \n",
      "3   0.091043  0.968241  0.979883  0.992166  0.184327      0.940235   \n",
      "4   0.065755  0.974913  0.985004  0.996199  0.205924      0.933831   \n",
      "5   0.055367  0.979450  0.986101  0.997087  0.352383      0.889007   \n",
      "6   0.050208  0.981318  0.989393  0.997681  0.266091      0.940235   \n",
      "7   0.027695  0.990659  0.993782  0.998927  0.265799      0.940235   \n",
      "8   0.018219  0.993061  0.995611  0.999777  0.356191      0.935966   \n",
      "9   0.027952  0.989325  0.992685  0.998923  0.434763      0.915688   \n",
      "10  0.015894  0.992527  0.994514  0.999837  0.360053      0.941302   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.923977  0.981231  \n",
      "1     0.960526  0.970746  \n",
      "2     0.922515  0.981159  \n",
      "3     0.970760  0.974074  \n",
      "4     0.970760  0.971835  \n",
      "5     0.992690  0.963395  \n",
      "6     0.944444  0.969495  \n",
      "7     0.951754  0.968512  \n",
      "8     0.967836  0.956759  \n",
      "9     0.986842  0.945918  \n",
      "10    0.966374  0.961552  \n",
      "74/74 [==============================] - 23s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 106s 560ms/step - loss: 0.2815 - accuracy: 0.9026 - recall: 0.9535 - auc: 0.9438 - val_loss: 0.1492 - val_accuracy: 0.9445 - val_recall: 0.9649 - val_auc: 0.9796\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 103s 545ms/step - loss: 0.1348 - accuracy: 0.9522 - recall: 0.9707 - auc: 0.9841 - val_loss: 0.1461 - val_accuracy: 0.9477 - val_recall: 0.9547 - val_auc: 0.9830\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 104s 554ms/step - loss: 0.1083 - accuracy: 0.9594 - recall: 0.9755 - auc: 0.9906 - val_loss: 0.1512 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9807\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 103s 546ms/step - loss: 0.0783 - accuracy: 0.9722 - recall: 0.9810 - auc: 0.9939 - val_loss: 0.1671 - val_accuracy: 0.9445 - val_recall: 0.9635 - val_auc: 0.9785\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 104s 553ms/step - loss: 0.0588 - accuracy: 0.9760 - recall: 0.9854 - auc: 0.9969 - val_loss: 0.1785 - val_accuracy: 0.9477 - val_recall: 0.9664 - val_auc: 0.9756\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0500 - accuracy: 0.9832 - recall: 0.9898 - auc: 0.9976 - val_loss: 0.2126 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9733\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 104s 553ms/step - loss: 0.0413 - accuracy: 0.9856 - recall: 0.9923 - auc: 0.9987 - val_loss: 0.2230 - val_accuracy: 0.9445 - val_recall: 0.9708 - val_auc: 0.9715\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0235 - accuracy: 0.9909 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2833 - val_accuracy: 0.9445 - val_recall: 0.9664 - val_auc: 0.9636\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 104s 554ms/step - loss: 0.0236 - accuracy: 0.9907 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2452 - val_accuracy: 0.9434 - val_recall: 0.9488 - val_auc: 0.9651\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 106s 563ms/step - loss: 0.0183 - accuracy: 0.9939 - recall: 0.9971 - auc: 0.9996 - val_loss: 0.2770 - val_accuracy: 0.9424 - val_recall: 0.9708 - val_auc: 0.9592\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 105s 557ms/step - loss: 0.0094 - accuracy: 0.9965 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9624\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0137 - accuracy: 0.9939 - recall: 0.9963 - auc: 0.9999 - val_loss: 0.3096 - val_accuracy: 0.9445 - val_recall: 0.9576 - val_auc: 0.9596\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.281500  0.902589  0.953548  0.943786  0.149173      0.944504   \n",
      "1   0.134789  0.952228  0.970739  0.984134  0.146123      0.947705   \n",
      "2   0.108265  0.959434  0.975494  0.990626  0.151172      0.943437   \n",
      "3   0.078313  0.972244  0.980980  0.993867  0.167134      0.944504   \n",
      "4   0.058803  0.975981  0.985369  0.996888  0.178479      0.947705   \n",
      "5   0.049970  0.983187  0.989759  0.997595  0.212579      0.945571   \n",
      "6   0.041347  0.985588  0.992319  0.998650  0.223001      0.944504   \n",
      "7   0.023544  0.990926  0.995611  0.999585  0.283347      0.944504   \n",
      "8   0.023583  0.990659  0.995611  0.999568  0.245153      0.943437   \n",
      "9   0.018346  0.993862  0.997074  0.999632  0.276999      0.942369   \n",
      "10  0.009430  0.996531  0.998903  0.999956  0.323370      0.945571   \n",
      "11  0.013717  0.993862  0.996342  0.999864  0.309592      0.944504   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.964912  0.979630  \n",
      "1     0.954678  0.983031  \n",
      "2     0.959064  0.980720  \n",
      "3     0.963450  0.978544  \n",
      "4     0.966374  0.975565  \n",
      "5     0.960526  0.973294  \n",
      "6     0.970760  0.971509  \n",
      "7     0.966374  0.963586  \n",
      "8     0.948830  0.965097  \n",
      "9     0.970760  0.959235  \n",
      "10    0.960526  0.962407  \n",
      "11    0.957602  0.959556  \n",
      "59/59 [==============================] - 22s 374ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 95s 802ms/step - loss: 0.4719 - accuracy: 0.8161 - recall: 0.9195 - auc: 0.8565 - val_loss: 0.1762 - val_accuracy: 0.9338 - val_recall: 0.9649 - val_auc: 0.9748\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 93s 786ms/step - loss: 0.1879 - accuracy: 0.9285 - recall: 0.9594 - auc: 0.9714 - val_loss: 0.1643 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9750\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 92s 782ms/step - loss: 0.1352 - accuracy: 0.9512 - recall: 0.9685 - auc: 0.9844 - val_loss: 0.1719 - val_accuracy: 0.9413 - val_recall: 0.9708 - val_auc: 0.9735\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 92s 779ms/step - loss: 0.1086 - accuracy: 0.9624 - recall: 0.9755 - auc: 0.9897 - val_loss: 0.1674 - val_accuracy: 0.9424 - val_recall: 0.9488 - val_auc: 0.9788\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0985 - accuracy: 0.9650 - recall: 0.9795 - auc: 0.9913 - val_loss: 0.1569 - val_accuracy: 0.9434 - val_recall: 0.9635 - val_auc: 0.9770\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0793 - accuracy: 0.9706 - recall: 0.9824 - auc: 0.9943 - val_loss: 0.1735 - val_accuracy: 0.9413 - val_recall: 0.9561 - val_auc: 0.9772\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 93s 785ms/step - loss: 0.0680 - accuracy: 0.9741 - recall: 0.9824 - auc: 0.9965 - val_loss: 0.1761 - val_accuracy: 0.9424 - val_recall: 0.9518 - val_auc: 0.9778\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 93s 787ms/step - loss: 0.0556 - accuracy: 0.9792 - recall: 0.9872 - auc: 0.9970 - val_loss: 0.1746 - val_accuracy: 0.9317 - val_recall: 0.9327 - val_auc: 0.9789\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 91s 775ms/step - loss: 0.0415 - accuracy: 0.9853 - recall: 0.9927 - auc: 0.9988 - val_loss: 0.2083 - val_accuracy: 0.9370 - val_recall: 0.9371 - val_auc: 0.9752\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0397 - accuracy: 0.9880 - recall: 0.9952 - auc: 0.9989 - val_loss: 0.2332 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9699\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0272 - accuracy: 0.9909 - recall: 0.9949 - auc: 0.9995 - val_loss: 0.2306 - val_accuracy: 0.9360 - val_recall: 0.9415 - val_auc: 0.9721\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 92s 783ms/step - loss: 0.0275 - accuracy: 0.9912 - recall: 0.9945 - auc: 0.9990 - val_loss: 0.2548 - val_accuracy: 0.9466 - val_recall: 0.9620 - val_auc: 0.9671\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 91s 775ms/step - loss: 0.0219 - accuracy: 0.9912 - recall: 0.9952 - auc: 0.9997 - val_loss: 0.2989 - val_accuracy: 0.9360 - val_recall: 0.9561 - val_auc: 0.9634\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0166 - accuracy: 0.9947 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.2616 - val_accuracy: 0.9349 - val_recall: 0.9547 - val_auc: 0.9637\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1327s 11s/step - loss: 0.0164 - accuracy: 0.9955 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.3263 - val_accuracy: 0.9370 - val_recall: 0.9503 - val_auc: 0.9604\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 117s 991ms/step - loss: 0.0094 - accuracy: 0.9973 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9402 - val_recall: 0.9605 - val_auc: 0.9607\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 114s 963ms/step - loss: 0.0072 - accuracy: 0.9971 - recall: 0.9993 - auc: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9608\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 114s 967ms/step - loss: 0.0060 - accuracy: 0.9981 - recall: 0.9996 - auc: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9402 - val_recall: 0.9547 - val_auc: 0.9695\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.471899  0.816120  0.919532  0.856486  0.176164      0.933831   \n",
      "1   0.187888  0.928476  0.959400  0.971426  0.164320      0.937033   \n",
      "2   0.135242  0.951161  0.968544  0.984427  0.171905      0.941302   \n",
      "3   0.108624  0.962370  0.975494  0.989695  0.167444      0.942369   \n",
      "4   0.098469  0.965039  0.979517  0.991337  0.156905      0.943437   \n",
      "5   0.079289  0.970643  0.982443  0.994348  0.173466      0.941302   \n",
      "6   0.068028  0.974113  0.982443  0.996504  0.176075      0.942369   \n",
      "7   0.055609  0.979183  0.987198  0.997035  0.174591      0.931697   \n",
      "8   0.041470  0.985322  0.992685  0.998796  0.208304      0.937033   \n",
      "9   0.039727  0.987990  0.995245  0.998940  0.233233      0.943437   \n",
      "10  0.027204  0.990926  0.994879  0.999516  0.230631      0.935966   \n",
      "11  0.027515  0.991193  0.994514  0.999048  0.254787      0.946638   \n",
      "12  0.021948  0.991193  0.995245  0.999701  0.298896      0.935966   \n",
      "13  0.016643  0.994662  0.997805  0.999824  0.261608      0.934899   \n",
      "14  0.016380  0.995463  0.997805  0.999820  0.326311      0.937033   \n",
      "15  0.009386  0.997331  0.998903  0.999955  0.305458      0.940235   \n",
      "16  0.007249  0.997064  0.999268  0.999981  0.360749      0.939168   \n",
      "17  0.006011  0.998132  0.999634  0.999989  0.280047      0.940235   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.964912  0.974771  \n",
      "1     0.967836  0.975039  \n",
      "2     0.970760  0.973543  \n",
      "3     0.948830  0.978810  \n",
      "4     0.963450  0.977030  \n",
      "5     0.956140  0.977203  \n",
      "6     0.951754  0.977801  \n",
      "7     0.932749  0.978882  \n",
      "8     0.937135  0.975172  \n",
      "9     0.959064  0.969856  \n",
      "10    0.941520  0.972107  \n",
      "11    0.961988  0.967137  \n",
      "12    0.956140  0.963407  \n",
      "13    0.954678  0.963745  \n",
      "14    0.950292  0.960362  \n",
      "15    0.960526  0.960723  \n",
      "16    0.954678  0.960824  \n",
      "17    0.954678  0.969538  \n",
      "37/37 [==============================] - 26s 688ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 115s 2s/step - loss: 0.4763 - accuracy: 0.8257 - recall: 0.9104 - auc: 0.8621 - val_loss: 0.1772 - val_accuracy: 0.9360 - val_recall: 0.9737 - val_auc: 0.9734\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.1549 - accuracy: 0.9400 - recall: 0.9631 - auc: 0.9806 - val_loss: 0.2026 - val_accuracy: 0.9285 - val_recall: 0.9883 - val_auc: 0.9724\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.1302 - accuracy: 0.9549 - recall: 0.9726 - auc: 0.9838 - val_loss: 0.1633 - val_accuracy: 0.9445 - val_recall: 0.9810 - val_auc: 0.9777\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.1043 - accuracy: 0.9624 - recall: 0.9744 - auc: 0.9905 - val_loss: 0.1901 - val_accuracy: 0.9296 - val_recall: 0.9839 - val_auc: 0.9735\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 112s 2s/step - loss: 0.0841 - accuracy: 0.9712 - recall: 0.9835 - auc: 0.9939 - val_loss: 0.1623 - val_accuracy: 0.9402 - val_recall: 0.9722 - val_auc: 0.9751\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 112s 2s/step - loss: 0.0691 - accuracy: 0.9762 - recall: 0.9850 - auc: 0.9956 - val_loss: 0.2033 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9722\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 120s 2s/step - loss: 0.0479 - accuracy: 0.9829 - recall: 0.9909 - auc: 0.9978 - val_loss: 0.1709 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9775\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0359 - accuracy: 0.9891 - recall: 0.9941 - auc: 0.9986 - val_loss: 0.2186 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9694\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0282 - accuracy: 0.9912 - recall: 0.9960 - auc: 0.9990 - val_loss: 0.2097 - val_accuracy: 0.9392 - val_recall: 0.9605 - val_auc: 0.9706\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0223 - accuracy: 0.9931 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2129 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9705\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.0208 - accuracy: 0.9928 - recall: 0.9967 - auc: 0.9997 - val_loss: 0.2356 - val_accuracy: 0.9392 - val_recall: 0.9532 - val_auc: 0.9680\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0146 - accuracy: 0.9965 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.2607 - val_accuracy: 0.9424 - val_recall: 0.9635 - val_auc: 0.9648\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 111s 2s/step - loss: 0.0069 - accuracy: 0.9979 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9640\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.476267  0.825727  0.910388  0.862130  0.177177      0.935966   \n",
      "1   0.154883  0.939952  0.963058  0.980603  0.202630      0.928495   \n",
      "2   0.130205  0.954897  0.972568  0.983823  0.163347      0.944504   \n",
      "3   0.104302  0.962370  0.974396  0.990475  0.190098      0.929562   \n",
      "4   0.084089  0.971177  0.983541  0.993905  0.162277      0.940235   \n",
      "5   0.069094  0.976248  0.985004  0.995592  0.203283      0.937033   \n",
      "6   0.047928  0.982920  0.990856  0.997783  0.170939      0.942369   \n",
      "7   0.035906  0.989058  0.994148  0.998637  0.218613      0.942369   \n",
      "8   0.028233  0.991193  0.995977  0.999020  0.209707      0.939168   \n",
      "9   0.022312  0.993061  0.995611  0.999625  0.212922      0.939168   \n",
      "10  0.020845  0.992794  0.996708  0.999728  0.235633      0.939168   \n",
      "11  0.014647  0.996531  0.998537  0.999853  0.260720      0.942369   \n",
      "12  0.006895  0.997865  0.998537  0.999982  0.256643      0.944504   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.973684  0.973407  \n",
      "1     0.988304  0.972381  \n",
      "2     0.980994  0.977738  \n",
      "3     0.983918  0.973545  \n",
      "4     0.972222  0.975071  \n",
      "5     0.979532  0.972162  \n",
      "6     0.964912  0.977539  \n",
      "7     0.972222  0.969431  \n",
      "8     0.960526  0.970564  \n",
      "9     0.957602  0.970526  \n",
      "10    0.953216  0.967981  \n",
      "11    0.963450  0.964759  \n",
      "12    0.961988  0.963965  \n",
      "19/19 [==============================] - 25s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 134s 281ms/step - loss: 0.2988 - accuracy: 0.8775 - recall: 0.9250 - auc: 0.9289 - val_loss: 0.3196 - val_accuracy: 0.8506 - val_recall: 0.8070 - val_auc: 0.9724\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.1744 - accuracy: 0.9389 - recall: 0.9583 - auc: 0.9744 - val_loss: 0.1602 - val_accuracy: 0.9381 - val_recall: 0.9532 - val_auc: 0.9764\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 129s 276ms/step - loss: 0.1085 - accuracy: 0.9573 - recall: 0.9737 - auc: 0.9898 - val_loss: 0.1804 - val_accuracy: 0.9424 - val_recall: 0.9751 - val_auc: 0.9756\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 130s 276ms/step - loss: 0.0995 - accuracy: 0.9656 - recall: 0.9777 - auc: 0.9909 - val_loss: 0.1781 - val_accuracy: 0.9360 - val_recall: 0.9795 - val_auc: 0.9754\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0785 - accuracy: 0.9738 - recall: 0.9843 - auc: 0.9938 - val_loss: 0.2426 - val_accuracy: 0.9349 - val_recall: 0.9503 - val_auc: 0.9688\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0900 - accuracy: 0.9696 - recall: 0.9846 - auc: 0.9913 - val_loss: 0.2056 - val_accuracy: 0.9402 - val_recall: 0.9576 - val_auc: 0.9723\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 131s 280ms/step - loss: 0.0804 - accuracy: 0.9696 - recall: 0.9806 - auc: 0.9931 - val_loss: 0.2035 - val_accuracy: 0.9402 - val_recall: 0.9474 - val_auc: 0.9766\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0415 - accuracy: 0.9837 - recall: 0.9920 - auc: 0.9977 - val_loss: 0.2398 - val_accuracy: 0.9285 - val_recall: 0.9503 - val_auc: 0.9689\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0299 - accuracy: 0.9888 - recall: 0.9945 - auc: 0.9983 - val_loss: 0.3055 - val_accuracy: 0.9264 - val_recall: 0.9430 - val_auc: 0.9631\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0798 - accuracy: 0.9776 - recall: 0.9854 - auc: 0.9933 - val_loss: 0.3148 - val_accuracy: 0.9349 - val_recall: 0.9488 - val_auc: 0.9630\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 128s 274ms/step - loss: 0.0348 - accuracy: 0.9875 - recall: 0.9934 - auc: 0.9984 - val_loss: 0.3338 - val_accuracy: 0.9317 - val_recall: 0.9488 - val_auc: 0.9611\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0237 - accuracy: 0.9923 - recall: 0.9963 - auc: 0.9995 - val_loss: 0.3488 - val_accuracy: 0.9370 - val_recall: 0.9518 - val_auc: 0.9651\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 128s 273ms/step - loss: 0.0218 - accuracy: 0.9936 - recall: 0.9974 - auc: 0.9977 - val_loss: 0.4539 - val_accuracy: 0.9285 - val_recall: 0.9518 - val_auc: 0.9469\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 128s 272ms/step - loss: 0.0265 - accuracy: 0.9901 - recall: 0.9927 - auc: 0.9985 - val_loss: 0.5325 - val_accuracy: 0.9253 - val_recall: 0.9693 - val_auc: 0.9277\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0106 - accuracy: 0.9971 - recall: 0.9993 - auc: 0.9994 - val_loss: 0.6074 - val_accuracy: 0.9274 - val_recall: 0.9415 - val_auc: 0.9465\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.0279 - accuracy: 0.9915 - recall: 0.9963 - auc: 0.9980 - val_loss: 0.4722 - val_accuracy: 0.9253 - val_recall: 0.9371 - val_auc: 0.9526\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 131s 280ms/step - loss: 0.0244 - accuracy: 0.9904 - recall: 0.9934 - auc: 0.9989 - val_loss: 0.4616 - val_accuracy: 0.9360 - val_recall: 0.9532 - val_auc: 0.9548\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.298783  0.877502  0.925018  0.928877  0.319629      0.850587   \n",
      "1   0.174449  0.938884  0.958303  0.974380  0.160156      0.938100   \n",
      "2   0.108473  0.957299  0.973665  0.989788  0.180354      0.942369   \n",
      "3   0.099538  0.965572  0.977688  0.990879  0.178063      0.935966   \n",
      "4   0.078514  0.973846  0.984272  0.993829  0.242555      0.934899   \n",
      "5   0.089971  0.969576  0.984638  0.991292  0.205611      0.940235   \n",
      "6   0.080427  0.969576  0.980614  0.993066  0.203472      0.940235   \n",
      "7   0.041492  0.983720  0.991953  0.997738  0.239834      0.928495   \n",
      "8   0.029919  0.988791  0.994514  0.998335  0.305466      0.926361   \n",
      "9   0.079847  0.977582  0.985369  0.993266  0.314843      0.934899   \n",
      "10  0.034754  0.987457  0.993416  0.998449  0.333776      0.931697   \n",
      "11  0.023729  0.992260  0.996342  0.999536  0.348798      0.937033   \n",
      "12  0.021814  0.993595  0.997440  0.997705  0.453879      0.928495   \n",
      "13  0.026526  0.990125  0.992685  0.998532  0.532543      0.925294   \n",
      "14  0.010583  0.997064  0.999268  0.999417  0.607444      0.927428   \n",
      "15  0.027872  0.991460  0.996342  0.998035  0.472176      0.925294   \n",
      "16  0.024403  0.990392  0.993416  0.998932  0.461597      0.935966   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.807018  0.972442  \n",
      "1     0.953216  0.976438  \n",
      "2     0.975146  0.975635  \n",
      "3     0.979532  0.975366  \n",
      "4     0.950292  0.968810  \n",
      "5     0.957602  0.972251  \n",
      "6     0.947368  0.976643  \n",
      "7     0.950292  0.968902  \n",
      "8     0.942982  0.963098  \n",
      "9     0.948830  0.963028  \n",
      "10    0.948830  0.961104  \n",
      "11    0.951754  0.965060  \n",
      "12    0.951754  0.946926  \n",
      "13    0.969298  0.927712  \n",
      "14    0.941520  0.946499  \n",
      "15    0.937135  0.952552  \n",
      "16    0.953216  0.954771  \n",
      "147/147 [==============================] - 29s 198ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 130s 543ms/step - loss: 0.3669 - accuracy: 0.8489 - recall: 0.9459 - auc: 0.9044 - val_loss: 0.2046 - val_accuracy: 0.9210 - val_recall: 0.9883 - val_auc: 0.9729\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 124s 527ms/step - loss: 0.1771 - accuracy: 0.9349 - recall: 0.9612 - auc: 0.9745 - val_loss: 0.1754 - val_accuracy: 0.9381 - val_recall: 0.9620 - val_auc: 0.9713\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1510 - accuracy: 0.9480 - recall: 0.9682 - auc: 0.9813 - val_loss: 0.1786 - val_accuracy: 0.9402 - val_recall: 0.9401 - val_auc: 0.9792\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1126 - accuracy: 0.9608 - recall: 0.9737 - auc: 0.9882 - val_loss: 0.1653 - val_accuracy: 0.9413 - val_recall: 0.9664 - val_auc: 0.9766\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 123s 525ms/step - loss: 0.1047 - accuracy: 0.9605 - recall: 0.9777 - auc: 0.9903 - val_loss: 0.2037 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9748\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 124s 528ms/step - loss: 0.0860 - accuracy: 0.9674 - recall: 0.9813 - auc: 0.9933 - val_loss: 0.2065 - val_accuracy: 0.9296 - val_recall: 0.9518 - val_auc: 0.9740\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 112s 478ms/step - loss: 0.0734 - accuracy: 0.9704 - recall: 0.9843 - auc: 0.9959 - val_loss: 0.2440 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9670\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 98s 415ms/step - loss: 0.0470 - accuracy: 0.9805 - recall: 0.9894 - auc: 0.9979 - val_loss: 0.2696 - val_accuracy: 0.9360 - val_recall: 0.9444 - val_auc: 0.9697\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 101s 430ms/step - loss: 0.0511 - accuracy: 0.9800 - recall: 0.9887 - auc: 0.9975 - val_loss: 0.2558 - val_accuracy: 0.9360 - val_recall: 0.9503 - val_auc: 0.9702\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 97s 411ms/step - loss: 0.0383 - accuracy: 0.9859 - recall: 0.9909 - auc: 0.9979 - val_loss: 0.3635 - val_accuracy: 0.9178 - val_recall: 0.9737 - val_auc: 0.9454\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 97s 412ms/step - loss: 0.0351 - accuracy: 0.9867 - recall: 0.9912 - auc: 0.9984 - val_loss: 0.2640 - val_accuracy: 0.9445 - val_recall: 0.9649 - val_auc: 0.9648\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 99s 422ms/step - loss: 0.0302 - accuracy: 0.9888 - recall: 0.9938 - auc: 0.9990 - val_loss: 0.3390 - val_accuracy: 0.9317 - val_recall: 0.9591 - val_auc: 0.9611\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 98s 415ms/step - loss: 0.0282 - accuracy: 0.9901 - recall: 0.9949 - auc: 0.9994 - val_loss: 0.3598 - val_accuracy: 0.9392 - val_recall: 0.9635 - val_auc: 0.9513\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.366865  0.848946  0.945867  0.904416  0.204576      0.921025   \n",
      "1   0.177108  0.934881  0.961229  0.974518  0.175430      0.938100   \n",
      "2   0.150977  0.947958  0.968179  0.981252  0.178600      0.940235   \n",
      "3   0.112555  0.960769  0.973665  0.988182  0.165316      0.941302   \n",
      "4   0.104663  0.960502  0.977688  0.990311  0.203744      0.942369   \n",
      "5   0.086044  0.967441  0.981346  0.993295  0.206539      0.929562   \n",
      "6   0.073378  0.970376  0.984272  0.995854  0.243975      0.937033   \n",
      "7   0.047018  0.980518  0.989393  0.997854  0.269633      0.935966   \n",
      "8   0.051138  0.979984  0.988661  0.997484  0.255843      0.935966   \n",
      "9   0.038278  0.985855  0.990856  0.997918  0.363499      0.917823   \n",
      "10  0.035053  0.986656  0.991222  0.998417  0.264000      0.944504   \n",
      "11  0.030194  0.988791  0.993782  0.998986  0.339027      0.931697   \n",
      "12  0.028159  0.990125  0.994879  0.999374  0.359824      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.988304  0.972921  \n",
      "1     0.961988  0.971263  \n",
      "2     0.940058  0.979220  \n",
      "3     0.966374  0.976597  \n",
      "4     0.964912  0.974765  \n",
      "5     0.951754  0.973990  \n",
      "6     0.967836  0.967001  \n",
      "7     0.944444  0.969662  \n",
      "8     0.950292  0.970220  \n",
      "9     0.973684  0.945427  \n",
      "10    0.964912  0.964817  \n",
      "11    0.959064  0.961101  \n",
      "12    0.963450  0.951333  \n",
      "74/74 [==============================] - 20s 269ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 97s 511ms/step - loss: 0.3519 - accuracy: 0.8775 - recall: 0.9440 - auc: 0.9171 - val_loss: 0.1890 - val_accuracy: 0.9210 - val_recall: 0.9635 - val_auc: 0.9701\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 96s 510ms/step - loss: 0.1813 - accuracy: 0.9357 - recall: 0.9627 - auc: 0.9732 - val_loss: 0.1635 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9762\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 96s 512ms/step - loss: 0.1334 - accuracy: 0.9528 - recall: 0.9722 - auc: 0.9845 - val_loss: 0.1519 - val_accuracy: 0.9413 - val_recall: 0.9737 - val_auc: 0.9785\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 98s 520ms/step - loss: 0.1176 - accuracy: 0.9594 - recall: 0.9744 - auc: 0.9877 - val_loss: 0.1589 - val_accuracy: 0.9392 - val_recall: 0.9795 - val_auc: 0.9800\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 95s 507ms/step - loss: 0.1003 - accuracy: 0.9680 - recall: 0.9824 - auc: 0.9901 - val_loss: 0.1877 - val_accuracy: 0.9381 - val_recall: 0.9561 - val_auc: 0.9739\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 96s 508ms/step - loss: 0.0726 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9953 - val_loss: 0.2028 - val_accuracy: 0.9466 - val_recall: 0.9605 - val_auc: 0.9763\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 96s 513ms/step - loss: 0.0471 - accuracy: 0.9827 - recall: 0.9898 - auc: 0.9970 - val_loss: 0.2046 - val_accuracy: 0.9445 - val_recall: 0.9591 - val_auc: 0.9733\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 98s 520ms/step - loss: 0.0400 - accuracy: 0.9859 - recall: 0.9916 - auc: 0.9978 - val_loss: 0.2235 - val_accuracy: 0.9360 - val_recall: 0.9532 - val_auc: 0.9715\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 99s 524ms/step - loss: 0.0510 - accuracy: 0.9821 - recall: 0.9898 - auc: 0.9967 - val_loss: 0.2285 - val_accuracy: 0.9413 - val_recall: 0.9591 - val_auc: 0.9743\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 97s 517ms/step - loss: 0.0437 - accuracy: 0.9821 - recall: 0.9909 - auc: 0.9980 - val_loss: 0.2446 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9683\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 96s 513ms/step - loss: 0.0348 - accuracy: 0.9859 - recall: 0.9916 - auc: 0.9990 - val_loss: 0.3248 - val_accuracy: 0.9466 - val_recall: 0.9635 - val_auc: 0.9608\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 98s 523ms/step - loss: 0.0216 - accuracy: 0.9915 - recall: 0.9960 - auc: 0.9992 - val_loss: 0.3764 - val_accuracy: 0.9402 - val_recall: 0.9576 - val_auc: 0.9541\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 95s 504ms/step - loss: 0.0331 - accuracy: 0.9875 - recall: 0.9931 - auc: 0.9990 - val_loss: 0.2683 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9650\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 95s 507ms/step - loss: 0.0229 - accuracy: 0.9909 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.4319 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9577\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.351859  0.877502  0.944038  0.917100  0.189048      0.921025   \n",
      "1   0.181254  0.935682  0.962692  0.973215  0.163500      0.939168   \n",
      "2   0.133384  0.952762  0.972202  0.984469  0.151901      0.941302   \n",
      "3   0.117581  0.959434  0.974396  0.987682  0.158877      0.939168   \n",
      "4   0.100262  0.967974  0.982443  0.990054  0.187742      0.938100   \n",
      "5   0.072618  0.973579  0.983175  0.995324  0.202801      0.946638   \n",
      "6   0.047075  0.982653  0.989759  0.997026  0.204614      0.944504   \n",
      "7   0.040019  0.985855  0.991587  0.997797  0.223452      0.935966   \n",
      "8   0.051008  0.982119  0.989759  0.996696  0.228483      0.941302   \n",
      "9   0.043661  0.982119  0.990856  0.998030  0.244624      0.944504   \n",
      "10  0.034783  0.985855  0.991587  0.998996  0.324824      0.946638   \n",
      "11  0.021619  0.991460  0.995977  0.999195  0.376420      0.940235   \n",
      "12  0.033108  0.987457  0.993050  0.999032  0.268319      0.938100   \n",
      "13  0.022876  0.990926  0.995245  0.999596  0.431910      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.963450  0.970073  \n",
      "1     0.954678  0.976152  \n",
      "2     0.973684  0.978541  \n",
      "3     0.979532  0.979971  \n",
      "4     0.956140  0.973866  \n",
      "5     0.960526  0.976316  \n",
      "6     0.959064  0.973314  \n",
      "7     0.953216  0.971491  \n",
      "8     0.959064  0.974300  \n",
      "9     0.961988  0.968273  \n",
      "10    0.963450  0.960772  \n",
      "11    0.957602  0.954098  \n",
      "12    0.959064  0.965019  \n",
      "13    0.960526  0.957660  \n",
      "59/59 [==============================] - 19s 324ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 88s 736ms/step - loss: 0.3823 - accuracy: 0.8337 - recall: 0.9323 - auc: 0.8704 - val_loss: 0.2239 - val_accuracy: 0.9189 - val_recall: 0.9079 - val_auc: 0.9759\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 90s 760ms/step - loss: 0.1871 - accuracy: 0.9357 - recall: 0.9514 - auc: 0.9711 - val_loss: 0.1530 - val_accuracy: 0.9402 - val_recall: 0.9547 - val_auc: 0.9774\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 88s 749ms/step - loss: 0.1609 - accuracy: 0.9440 - recall: 0.9627 - auc: 0.9778 - val_loss: 0.1938 - val_accuracy: 0.9296 - val_recall: 0.9488 - val_auc: 0.9690\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 85s 724ms/step - loss: 0.1312 - accuracy: 0.9501 - recall: 0.9674 - auc: 0.9851 - val_loss: 0.1685 - val_accuracy: 0.9338 - val_recall: 0.9708 - val_auc: 0.9781\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 86s 731ms/step - loss: 0.1026 - accuracy: 0.9634 - recall: 0.9770 - auc: 0.9904 - val_loss: 0.1842 - val_accuracy: 0.9402 - val_recall: 0.9766 - val_auc: 0.9732\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 87s 740ms/step - loss: 0.0929 - accuracy: 0.9666 - recall: 0.9766 - auc: 0.9920 - val_loss: 0.1692 - val_accuracy: 0.9392 - val_recall: 0.9664 - val_auc: 0.9738\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 90s 763ms/step - loss: 0.0769 - accuracy: 0.9717 - recall: 0.9813 - auc: 0.9948 - val_loss: 0.1754 - val_accuracy: 0.9466 - val_recall: 0.9591 - val_auc: 0.9773\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 87s 736ms/step - loss: 0.0580 - accuracy: 0.9786 - recall: 0.9868 - auc: 0.9967 - val_loss: 0.2237 - val_accuracy: 0.9392 - val_recall: 0.9518 - val_auc: 0.9720\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 86s 726ms/step - loss: 0.0458 - accuracy: 0.9813 - recall: 0.9883 - auc: 0.9983 - val_loss: 0.2659 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9676\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 87s 735ms/step - loss: 0.0404 - accuracy: 0.9856 - recall: 0.9916 - auc: 0.9985 - val_loss: 0.2735 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9676\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 93s 786ms/step - loss: 0.0334 - accuracy: 0.9891 - recall: 0.9934 - auc: 0.9990 - val_loss: 0.2260 - val_accuracy: 0.9434 - val_recall: 0.9649 - val_auc: 0.9710\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 89s 757ms/step - loss: 0.0309 - accuracy: 0.9893 - recall: 0.9941 - auc: 0.9992 - val_loss: 0.3550 - val_accuracy: 0.9413 - val_recall: 0.9459 - val_auc: 0.9678\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 94s 802ms/step - loss: 0.0362 - accuracy: 0.9864 - recall: 0.9905 - auc: 0.9988 - val_loss: 0.5071 - val_accuracy: 0.8911 - val_recall: 0.9883 - val_auc: 0.9230\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 106s 897ms/step - loss: 0.0576 - accuracy: 0.9811 - recall: 0.9920 - auc: 0.9940 - val_loss: 0.2548 - val_accuracy: 0.9381 - val_recall: 0.9620 - val_auc: 0.9655\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.382302  0.833734  0.932334  0.870395  0.223931      0.918890   \n",
      "1   0.187129  0.935682  0.951353  0.971113  0.152993      0.940235   \n",
      "2   0.160861  0.943955  0.962692  0.977833  0.193753      0.929562   \n",
      "3   0.131244  0.950093  0.967447  0.985081  0.168480      0.933831   \n",
      "4   0.102645  0.963437  0.976957  0.990447  0.184165      0.940235   \n",
      "5   0.092902  0.966640  0.976591  0.992020  0.169231      0.939168   \n",
      "6   0.076856  0.971711  0.981346  0.994807  0.175393      0.946638   \n",
      "7   0.058007  0.978650  0.986832  0.996709  0.223687      0.939168   \n",
      "8   0.045774  0.981318  0.988296  0.998275  0.265931      0.943437   \n",
      "9   0.040441  0.985588  0.991587  0.998481  0.273497      0.938100   \n",
      "10  0.033417  0.989058  0.993416  0.999016  0.226038      0.943437   \n",
      "11  0.030864  0.989325  0.994148  0.999178  0.355004      0.941302   \n",
      "12  0.036157  0.986389  0.990490  0.998770  0.507130      0.891142   \n",
      "13  0.057630  0.981052  0.991953  0.994030  0.254795      0.938100   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.907895  0.975920  \n",
      "1     0.954678  0.977377  \n",
      "2     0.948830  0.968969  \n",
      "3     0.970760  0.978119  \n",
      "4     0.976608  0.973239  \n",
      "5     0.966374  0.973837  \n",
      "6     0.959064  0.977305  \n",
      "7     0.951754  0.971991  \n",
      "8     0.957602  0.967622  \n",
      "9     0.959064  0.967582  \n",
      "10    0.964912  0.970962  \n",
      "11    0.945906  0.967770  \n",
      "12    0.988304  0.922974  \n",
      "13    0.961988  0.965482  \n",
      "37/37 [==============================] - 21s 546ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.6689 - accuracy: 0.7475 - recall: 0.9268 - auc: 0.7243 - val_loss: 0.2355 - val_accuracy: 0.9210 - val_recall: 0.9503 - val_auc: 0.9668\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2308 - accuracy: 0.9119 - recall: 0.9495 - auc: 0.9586 - val_loss: 0.1671 - val_accuracy: 0.9392 - val_recall: 0.9401 - val_auc: 0.9815\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.1774 - accuracy: 0.9376 - recall: 0.9601 - auc: 0.9744 - val_loss: 0.1710 - val_accuracy: 0.9392 - val_recall: 0.9810 - val_auc: 0.9743\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1527 - accuracy: 0.9413 - recall: 0.9642 - auc: 0.9812 - val_loss: 0.1542 - val_accuracy: 0.9434 - val_recall: 0.9459 - val_auc: 0.9825\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.1311 - accuracy: 0.9546 - recall: 0.9722 - auc: 0.9846 - val_loss: 0.1662 - val_accuracy: 0.9392 - val_recall: 0.9766 - val_auc: 0.9763\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.1139 - accuracy: 0.9605 - recall: 0.9762 - auc: 0.9897 - val_loss: 0.1512 - val_accuracy: 0.9445 - val_recall: 0.9693 - val_auc: 0.9799\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.1148 - accuracy: 0.9570 - recall: 0.9737 - auc: 0.9894 - val_loss: 0.1503 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9817\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0896 - accuracy: 0.9674 - recall: 0.9781 - auc: 0.9934 - val_loss: 0.2090 - val_accuracy: 0.9381 - val_recall: 0.9854 - val_auc: 0.9716\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0876 - accuracy: 0.9682 - recall: 0.9770 - auc: 0.9932 - val_loss: 0.2136 - val_accuracy: 0.9349 - val_recall: 0.9737 - val_auc: 0.9686\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.0772 - accuracy: 0.9736 - recall: 0.9821 - auc: 0.9945 - val_loss: 0.2438 - val_accuracy: 0.9413 - val_recall: 0.9693 - val_auc: 0.9706\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.0629 - accuracy: 0.9757 - recall: 0.9854 - auc: 0.9961 - val_loss: 0.1793 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9749\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0608 - accuracy: 0.9760 - recall: 0.9854 - auc: 0.9970 - val_loss: 0.1914 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9735\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0559 - accuracy: 0.9773 - recall: 0.9861 - auc: 0.9977 - val_loss: 0.2340 - val_accuracy: 0.9381 - val_recall: 0.9678 - val_auc: 0.9694\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.0421 - accuracy: 0.9864 - recall: 0.9912 - auc: 0.9979 - val_loss: 0.2452 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9717\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.668862  0.747531  0.926847  0.724269  0.235526      0.921025   \n",
      "1   0.230809  0.911930  0.949525  0.958563  0.167062      0.939168   \n",
      "2   0.177372  0.937550  0.960132  0.974395  0.171022      0.939168   \n",
      "3   0.152698  0.941286  0.964155  0.981190  0.154172      0.943437   \n",
      "4   0.131139  0.954630  0.972202  0.984617  0.166209      0.939168   \n",
      "5   0.113852  0.960502  0.976225  0.989748  0.151196      0.944504   \n",
      "6   0.114772  0.957032  0.973665  0.989362  0.150304      0.941302   \n",
      "7   0.089555  0.967441  0.978054  0.993374  0.209026      0.938100   \n",
      "8   0.087574  0.968241  0.976957  0.993209  0.213602      0.934899   \n",
      "9   0.077231  0.973579  0.982078  0.994498  0.243821      0.941302   \n",
      "10  0.062882  0.975714  0.985369  0.996108  0.179340      0.943437   \n",
      "11  0.060766  0.975981  0.985369  0.997020  0.191445      0.939168   \n",
      "12  0.055866  0.977315  0.986101  0.997691  0.234039      0.938100   \n",
      "13  0.042121  0.986389  0.991222  0.997887  0.245230      0.945571   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.966773  \n",
      "1     0.940058  0.981488  \n",
      "2     0.980994  0.974271  \n",
      "3     0.945906  0.982462  \n",
      "4     0.976608  0.976313  \n",
      "5     0.969298  0.979890  \n",
      "6     0.960526  0.981699  \n",
      "7     0.985380  0.971627  \n",
      "8     0.973684  0.968593  \n",
      "9     0.969298  0.970624  \n",
      "10    0.959064  0.974898  \n",
      "11    0.957602  0.973482  \n",
      "12    0.967836  0.969382  \n",
      "13    0.960526  0.971673  \n",
      "19/19 [==============================] - 17s 859ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(150,150)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG' # directorio general donde se va a crear la carpeta del historico\n",
    "nombre_historico = 'historico_propia_arqu_batchsize' # nombre de la carpeta creada para guardar los historicos de la CNN propia\n",
    "tabla_arqu_batch_propia = arq_batch_propia(ruta,epochs,batch_sizes,modelos, target_size, directorio_historico, nombre_historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87723f42-a3fa-458e-9c5c-773124b41b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.16      0.94       0.95    0.97  0.96         0.85  0.15   \n",
       "        16         0.15      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        20         0.17      0.94       0.97    0.95  0.96         0.91  0.09   \n",
       "        32         0.20      0.92       0.97    0.92  0.94         0.92  0.08   \n",
       "        64         0.17      0.94       0.96    0.95  0.96         0.90  0.10   \n",
       "Simple2 8          0.16      0.94       0.96    0.96  0.96         0.88  0.12   \n",
       "        16         0.22      0.91       0.98    0.89  0.93         0.96  0.04   \n",
       "        20         0.16      0.94       0.97    0.94  0.96         0.92  0.08   \n",
       "        32         0.17      0.93       0.97    0.93  0.95         0.93  0.07   \n",
       "        64         0.16      0.95       0.95    0.98  0.96         0.86  0.14   \n",
       "Simple3 8          0.21      0.94       0.97    0.95  0.96         0.92  0.08   \n",
       "        16         0.18      0.93       0.98    0.93  0.95         0.94  0.06   \n",
       "        20         0.16      0.94       0.95    0.97  0.96         0.85  0.15   \n",
       "        32         0.16      0.94       0.95    0.97  0.96         0.86  0.14   \n",
       "        64         0.17      0.92       0.96    0.93  0.95         0.91  0.09   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.03  0.98  \n",
       "        16         0.04  0.98  \n",
       "        20         0.05  0.98  \n",
       "        32         0.08  0.98  \n",
       "        64         0.05  0.98  \n",
       "Simple2 8          0.04  0.98  \n",
       "        16         0.11  0.98  \n",
       "        20         0.06  0.98  \n",
       "        32         0.07  0.98  \n",
       "        64         0.02  0.98  \n",
       "Simple3 8          0.05  0.98  \n",
       "        16         0.07  0.98  \n",
       "        20         0.03  0.98  \n",
       "        32         0.03  0.98  \n",
       "        64         0.07  0.98  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50072-e379-42a4-8b45-433ce620d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49bc3227-0635-4649-8182-f24d0cc786c2",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN AlexaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111bdae9-85fc-41c3-9576-e1f0532ec835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos,target_size, directorio_historico, nombre_historico):\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas arquitecturas de modelo y distintos batch size introducidos como parámetros a partir de \n",
    "    la CNN basada en AlexNet establecida previamente. . \n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá ser \n",
    "    (340,340) para coincidir con el input_shape del modelo de CNN alexNet.\n",
    "    - directorio_historico: str. Ruta general donde se va a crear la carpeta del historico para guardar los csv correspondientes\n",
    "    - nombre_historico: str. Nombre de la carpeta creada para guardar los csv de los historicos de la CNN propia\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size para la CNN basada en alexNet.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_AlexaNet(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "            #ENTRENAMIENTO\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history= model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) \n",
    "\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            nombre_archivo = f'hist_anet_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "            ruta_historico = os.path.join(directorio_historico, nombre_historico) #se guarda dentro de una nueva carpeta \n",
    "            # Crea la carpeta si no existe\n",
    "            os.makedirs(ruta_historico, exist_ok=True)\n",
    "            ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "            historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "            #se calculan las métricas a partir de la la función creada previamente\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "            \n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "562c7252-e239-45b8-bc01-6df22183405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1280s 3s/step - loss: 0.3318 - accuracy: 0.8820 - recall: 0.9221 - auc: 0.9265 - val_loss: 0.2169 - val_accuracy: 0.9157 - val_recall: 0.9503 - val_auc: 0.9622\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 285s 608ms/step - loss: 0.2276 - accuracy: 0.9202 - recall: 0.9481 - auc: 0.9617 - val_loss: 0.3180 - val_accuracy: 0.8997 - val_recall: 0.8874 - val_auc: 0.9682\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 297s 633ms/step - loss: 0.2296 - accuracy: 0.9213 - recall: 0.9484 - auc: 0.9656 - val_loss: 0.2463 - val_accuracy: 0.9264 - val_recall: 0.9766 - val_auc: 0.9673\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 294s 626ms/step - loss: 0.1692 - accuracy: 0.9384 - recall: 0.9631 - auc: 0.9772 - val_loss: 0.1629 - val_accuracy: 0.9392 - val_recall: 0.9751 - val_auc: 0.9815\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.1545 - accuracy: 0.9448 - recall: 0.9663 - auc: 0.9801 - val_loss: 0.1918 - val_accuracy: 0.9328 - val_recall: 0.9254 - val_auc: 0.9852\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 298s 634ms/step - loss: 0.1832 - accuracy: 0.9397 - recall: 0.9623 - auc: 0.9734 - val_loss: 0.7004 - val_accuracy: 0.7727 - val_recall: 1.0000 - val_auc: 0.9445\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 303s 646ms/step - loss: 0.1622 - accuracy: 0.9450 - recall: 0.9645 - auc: 0.9796 - val_loss: 0.1995 - val_accuracy: 0.9434 - val_recall: 0.9693 - val_auc: 0.9731\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 293s 625ms/step - loss: 0.1401 - accuracy: 0.9509 - recall: 0.9693 - auc: 0.9835 - val_loss: 0.1477 - val_accuracy: 0.9562 - val_recall: 0.9678 - val_auc: 0.9860\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 306s 652ms/step - loss: 0.1285 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9868 - val_loss: 0.2437 - val_accuracy: 0.9274 - val_recall: 0.9868 - val_auc: 0.9681\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 299s 638ms/step - loss: 0.1334 - accuracy: 0.9533 - recall: 0.9715 - auc: 0.9847 - val_loss: 0.9504 - val_accuracy: 0.9413 - val_recall: 0.9474 - val_auc: 0.9796\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 298s 635ms/step - loss: 0.1181 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9881 - val_loss: 0.1523 - val_accuracy: 0.9466 - val_recall: 0.9737 - val_auc: 0.9839\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.1182 - accuracy: 0.9597 - recall: 0.9740 - auc: 0.9879 - val_loss: 0.7969 - val_accuracy: 0.8965 - val_recall: 0.9196 - val_auc: 0.9363\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 305s 649ms/step - loss: 0.1469 - accuracy: 0.9474 - recall: 0.9693 - auc: 0.9801 - val_loss: 0.1638 - val_accuracy: 0.9381 - val_recall: 0.9386 - val_auc: 0.9824\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 300s 639ms/step - loss: 0.1257 - accuracy: 0.9546 - recall: 0.9711 - auc: 0.9863 - val_loss: 0.1447 - val_accuracy: 0.9520 - val_recall: 0.9708 - val_auc: 0.9829\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 306s 653ms/step - loss: 0.1069 - accuracy: 0.9618 - recall: 0.9777 - auc: 0.9905 - val_loss: 0.2188 - val_accuracy: 0.9466 - val_recall: 0.9810 - val_auc: 0.9680\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 295s 629ms/step - loss: 0.1003 - accuracy: 0.9672 - recall: 0.9799 - auc: 0.9898 - val_loss: 0.2556 - val_accuracy: 0.9328 - val_recall: 0.9956 - val_auc: 0.9685\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 299s 638ms/step - loss: 0.0826 - accuracy: 0.9717 - recall: 0.9821 - auc: 0.9930 - val_loss: 0.2225 - val_accuracy: 0.9317 - val_recall: 0.9942 - val_auc: 0.9735\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 297s 633ms/step - loss: 0.0728 - accuracy: 0.9733 - recall: 0.9828 - auc: 0.9955 - val_loss: 0.2861 - val_accuracy: 0.9168 - val_recall: 0.9942 - val_auc: 0.9689\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.331850  0.882039  0.922092  0.926524  0.216873      0.915688   \n",
      "1   0.227569  0.920203  0.948061  0.961723  0.317993      0.899680   \n",
      "2   0.229614  0.921270  0.948427  0.965647  0.246262      0.926361   \n",
      "3   0.169197  0.938351  0.963058  0.977150  0.162931      0.939168   \n",
      "4   0.154452  0.944756  0.966350  0.980125  0.191782      0.932764   \n",
      "5   0.183218  0.939685  0.962326  0.973370  0.700364      0.772679   \n",
      "6   0.162187  0.945023  0.964521  0.979627  0.199464      0.943437   \n",
      "7   0.140117  0.950894  0.969276  0.983508  0.147742      0.956243   \n",
      "8   0.128510  0.954897  0.971836  0.986835  0.243726      0.927428   \n",
      "9   0.133439  0.953296  0.971470  0.984659  0.950406      0.941302   \n",
      "10  0.118127  0.954897  0.971836  0.988091  0.152286      0.946638   \n",
      "11  0.118217  0.959701  0.974031  0.987890  0.796923      0.896478   \n",
      "12  0.146898  0.947425  0.969276  0.980067  0.163800      0.938100   \n",
      "13  0.125654  0.954630  0.971105  0.986304  0.144703      0.951974   \n",
      "14  0.106949  0.961836  0.977688  0.990468  0.218837      0.946638   \n",
      "15  0.100341  0.967174  0.979883  0.989847  0.255593      0.932764   \n",
      "16  0.082556  0.971711  0.982078  0.992993  0.222453      0.931697   \n",
      "17  0.072759  0.973312  0.982809  0.995469  0.286097      0.916756   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.962243  \n",
      "1     0.887427  0.968160  \n",
      "2     0.976608  0.967299  \n",
      "3     0.975146  0.981480  \n",
      "4     0.925439  0.985204  \n",
      "5     1.000000  0.944465  \n",
      "6     0.969298  0.973083  \n",
      "7     0.967836  0.986042  \n",
      "8     0.986842  0.968088  \n",
      "9     0.947368  0.979622  \n",
      "10    0.973684  0.983901  \n",
      "11    0.919591  0.936279  \n",
      "12    0.938596  0.982364  \n",
      "13    0.970760  0.982924  \n",
      "14    0.980994  0.967963  \n",
      "15    0.995614  0.968509  \n",
      "16    0.994152  0.973531  \n",
      "17    0.994152  0.968917  \n",
      "147/147 [==============================] - 39s 261ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.2988 - accuracy: 0.8820 - recall: 0.9228 - auc: 0.9369 - val_loss: 0.6375 - val_accuracy: 0.7737 - val_recall: 0.9971 - val_auc: 0.9313\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.2087 - accuracy: 0.9226 - recall: 0.9521 - auc: 0.9666 - val_loss: 0.2845 - val_accuracy: 0.9029 - val_recall: 0.9883 - val_auc: 0.9591\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1788 - accuracy: 0.9317 - recall: 0.9579 - auc: 0.9753 - val_loss: 0.2694 - val_accuracy: 0.9072 - val_recall: 0.9912 - val_auc: 0.9670\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 285s 1s/step - loss: 0.1569 - accuracy: 0.9432 - recall: 0.9660 - auc: 0.9798 - val_loss: 1.2729 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8252\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1483 - accuracy: 0.9466 - recall: 0.9667 - auc: 0.9811 - val_loss: 0.2414 - val_accuracy: 0.9178 - val_recall: 0.9912 - val_auc: 0.9689\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.1392 - accuracy: 0.9488 - recall: 0.9671 - auc: 0.9833 - val_loss: 0.1666 - val_accuracy: 0.9456 - val_recall: 0.9401 - val_auc: 0.9878\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.1224 - accuracy: 0.9568 - recall: 0.9715 - auc: 0.9859 - val_loss: 0.2143 - val_accuracy: 0.9242 - val_recall: 0.9181 - val_auc: 0.9828\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 286s 1s/step - loss: 0.1149 - accuracy: 0.9557 - recall: 0.9729 - auc: 0.9881 - val_loss: 0.1854 - val_accuracy: 0.9434 - val_recall: 0.9327 - val_auc: 0.9879\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.1337 - accuracy: 0.9512 - recall: 0.9696 - auc: 0.9848 - val_loss: 0.1153 - val_accuracy: 0.9562 - val_recall: 0.9664 - val_auc: 0.9904\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.1115 - accuracy: 0.9602 - recall: 0.9740 - auc: 0.9888 - val_loss: 0.2250 - val_accuracy: 0.9232 - val_recall: 0.9854 - val_auc: 0.9688\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 277s 1s/step - loss: 0.1195 - accuracy: 0.9557 - recall: 0.9711 - auc: 0.9875 - val_loss: 0.2609 - val_accuracy: 0.9242 - val_recall: 0.9927 - val_auc: 0.9651\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.1062 - accuracy: 0.9642 - recall: 0.9795 - auc: 0.9888 - val_loss: 0.1459 - val_accuracy: 0.9498 - val_recall: 0.9795 - val_auc: 0.9819\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 282s 1s/step - loss: 0.0885 - accuracy: 0.9672 - recall: 0.9788 - auc: 0.9925 - val_loss: 0.1734 - val_accuracy: 0.9509 - val_recall: 0.9518 - val_auc: 0.9834\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0941 - accuracy: 0.9682 - recall: 0.9792 - auc: 0.9916 - val_loss: 0.1346 - val_accuracy: 0.9594 - val_recall: 0.9868 - val_auc: 0.9833\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.0831 - accuracy: 0.9717 - recall: 0.9821 - auc: 0.9927 - val_loss: 0.2066 - val_accuracy: 0.9413 - val_recall: 0.9927 - val_auc: 0.9717\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.0913 - accuracy: 0.9680 - recall: 0.9806 - auc: 0.9916 - val_loss: 0.1822 - val_accuracy: 0.9445 - val_recall: 0.9883 - val_auc: 0.9731\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.0665 - accuracy: 0.9736 - recall: 0.9846 - auc: 0.9953 - val_loss: 0.1837 - val_accuracy: 0.9541 - val_recall: 0.9664 - val_auc: 0.9813\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 277s 1s/step - loss: 0.0567 - accuracy: 0.9786 - recall: 0.9865 - auc: 0.9963 - val_loss: 0.1554 - val_accuracy: 0.9573 - val_recall: 0.9635 - val_auc: 0.9849\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.0739 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9943 - val_loss: 0.1990 - val_accuracy: 0.9477 - val_recall: 0.9795 - val_auc: 0.9764\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.298803  0.882039  0.922824  0.936926  0.637487      0.773746   \n",
      "1   0.208729  0.922605  0.952085  0.966618  0.284475      0.902882   \n",
      "2   0.178813  0.931679  0.957937  0.975261  0.269356      0.907151   \n",
      "3   0.156897  0.943155  0.965984  0.979826  1.272929      0.729989   \n",
      "4   0.148340  0.946624  0.966715  0.981114  0.241414      0.917823   \n",
      "5   0.139194  0.948759  0.967081  0.983317  0.166584      0.945571   \n",
      "6   0.122380  0.956765  0.971470  0.985866  0.214320      0.924226   \n",
      "7   0.114898  0.955698  0.972933  0.988077  0.185398      0.943437   \n",
      "8   0.133701  0.951161  0.969642  0.984839  0.115287      0.956243   \n",
      "9   0.111458  0.960235  0.974031  0.988763  0.225029      0.923159   \n",
      "10  0.119493  0.955698  0.971105  0.987549  0.260885      0.924226   \n",
      "11  0.106244  0.964238  0.979517  0.988828  0.145854      0.949840   \n",
      "12  0.088463  0.967174  0.978786  0.992499  0.173436      0.950907   \n",
      "13  0.094127  0.968241  0.979151  0.991623  0.134587      0.959445   \n",
      "14  0.083071  0.971711  0.982078  0.992662  0.206616      0.941302   \n",
      "15  0.091257  0.967974  0.980614  0.991582  0.182230      0.944504   \n",
      "16  0.066549  0.973579  0.984638  0.995286  0.183652      0.954109   \n",
      "17  0.056693  0.978650  0.986467  0.996326  0.155425      0.957311   \n",
      "18  0.073893  0.973579  0.983175  0.994321  0.199038      0.947705   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.931333  \n",
      "1     0.988304  0.959053  \n",
      "2     0.991228  0.967030  \n",
      "3     1.000000  0.825165  \n",
      "4     0.991228  0.968850  \n",
      "5     0.940058  0.987830  \n",
      "6     0.918129  0.982800  \n",
      "7     0.932749  0.987900  \n",
      "8     0.966374  0.990402  \n",
      "9     0.985380  0.968790  \n",
      "10    0.992690  0.965054  \n",
      "11    0.979532  0.981864  \n",
      "12    0.951754  0.983401  \n",
      "13    0.986842  0.983274  \n",
      "14    0.992690  0.971670  \n",
      "15    0.988304  0.973060  \n",
      "16    0.966374  0.981344  \n",
      "17    0.963450  0.984886  \n",
      "18    0.979532  0.976446  \n",
      "74/74 [==============================] - 35s 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.2941 - accuracy: 0.8927 - recall: 0.9312 - auc: 0.9402 - val_loss: 0.2773 - val_accuracy: 0.8762 - val_recall: 0.9912 - val_auc: 0.9692\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1935 - accuracy: 0.9306 - recall: 0.9554 - auc: 0.9701 - val_loss: 0.4568 - val_accuracy: 0.7695 - val_recall: 0.9985 - val_auc: 0.9339\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1685 - accuracy: 0.9343 - recall: 0.9609 - auc: 0.9757 - val_loss: 0.2662 - val_accuracy: 0.9072 - val_recall: 0.9079 - val_auc: 0.9645\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1474 - accuracy: 0.9472 - recall: 0.9674 - auc: 0.9811 - val_loss: 3.9321 - val_accuracy: 0.2711 - val_recall: 0.0015 - val_auc: 0.6877\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.1604 - accuracy: 0.9397 - recall: 0.9598 - auc: 0.9793 - val_loss: 0.1938 - val_accuracy: 0.9317 - val_recall: 0.9898 - val_auc: 0.9763\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.1336 - accuracy: 0.9546 - recall: 0.9711 - auc: 0.9834 - val_loss: 0.1460 - val_accuracy: 0.9552 - val_recall: 0.9854 - val_auc: 0.9828\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 274s 1s/step - loss: 0.1330 - accuracy: 0.9549 - recall: 0.9737 - auc: 0.9842 - val_loss: 0.2683 - val_accuracy: 0.9200 - val_recall: 0.9898 - val_auc: 0.9659\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1213 - accuracy: 0.9557 - recall: 0.9715 - auc: 0.9870 - val_loss: 1.0159 - val_accuracy: 0.8420 - val_recall: 1.0000 - val_auc: 0.8566\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.1247 - accuracy: 0.9541 - recall: 0.9704 - auc: 0.9870 - val_loss: 0.1610 - val_accuracy: 0.9509 - val_recall: 0.9810 - val_auc: 0.9815\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1280 - accuracy: 0.9552 - recall: 0.9729 - auc: 0.9851 - val_loss: 0.1452 - val_accuracy: 0.9562 - val_recall: 0.9722 - val_auc: 0.9839\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.1024 - accuracy: 0.9629 - recall: 0.9766 - auc: 0.9910 - val_loss: 0.1558 - val_accuracy: 0.9530 - val_recall: 0.9576 - val_auc: 0.9879\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.1130 - accuracy: 0.9578 - recall: 0.9729 - auc: 0.9883 - val_loss: 0.2627 - val_accuracy: 0.9328 - val_recall: 0.9898 - val_auc: 0.9606\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 283s 2s/step - loss: 0.0816 - accuracy: 0.9701 - recall: 0.9828 - auc: 0.9926 - val_loss: 0.2122 - val_accuracy: 0.9274 - val_recall: 0.9620 - val_auc: 0.9741\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.0971 - accuracy: 0.9626 - recall: 0.9759 - auc: 0.9905 - val_loss: 0.2087 - val_accuracy: 0.9328 - val_recall: 0.9722 - val_auc: 0.9687\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.0824 - accuracy: 0.9725 - recall: 0.9850 - auc: 0.9917 - val_loss: 0.3717 - val_accuracy: 0.8527 - val_recall: 0.9927 - val_auc: 0.9686\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.0834 - accuracy: 0.9709 - recall: 0.9828 - auc: 0.9929 - val_loss: 0.1519 - val_accuracy: 0.9584 - val_recall: 0.9825 - val_auc: 0.9818\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.0745 - accuracy: 0.9746 - recall: 0.9854 - auc: 0.9942 - val_loss: 0.9869 - val_accuracy: 0.7492 - val_recall: 1.0000 - val_auc: 0.8664\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.0776 - accuracy: 0.9741 - recall: 0.9839 - auc: 0.9933 - val_loss: 0.1375 - val_accuracy: 0.9562 - val_recall: 0.9825 - val_auc: 0.9860\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.0700 - accuracy: 0.9736 - recall: 0.9843 - auc: 0.9962 - val_loss: 0.1418 - val_accuracy: 0.9584 - val_recall: 0.9854 - val_auc: 0.9822\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.0697 - accuracy: 0.9760 - recall: 0.9835 - auc: 0.9952 - val_loss: 1.7704 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.7051\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.294056  0.892714  0.931236  0.940211  0.277303      0.876201   \n",
      "1   0.193535  0.930611  0.955377  0.970102  0.456794      0.769477   \n",
      "2   0.168495  0.934347  0.960863  0.975737  0.266172      0.907151   \n",
      "3   0.147369  0.947158  0.967447  0.981071  3.932112      0.271078   \n",
      "4   0.160414  0.939685  0.959766  0.979315  0.193823      0.931697   \n",
      "5   0.133595  0.954630  0.971105  0.983408  0.145951      0.955176   \n",
      "6   0.132966  0.954897  0.973665  0.984208  0.268329      0.919957   \n",
      "7   0.121272  0.955698  0.971470  0.987036  1.015888      0.842049   \n",
      "8   0.124725  0.954097  0.970373  0.986990  0.160979      0.950907   \n",
      "9   0.127975  0.955164  0.972933  0.985092  0.145189      0.956243   \n",
      "10  0.102355  0.962904  0.976591  0.990958  0.155850      0.953042   \n",
      "11  0.112957  0.957833  0.972933  0.988255  0.262677      0.932764   \n",
      "12  0.081608  0.970109  0.982809  0.992620  0.212217      0.927428   \n",
      "13  0.097052  0.962637  0.975860  0.990510  0.208662      0.932764   \n",
      "14  0.082384  0.972511  0.985004  0.991675  0.371693      0.852721   \n",
      "15  0.083414  0.970910  0.982809  0.992890  0.151851      0.958378   \n",
      "16  0.074496  0.974646  0.985369  0.994210  0.986862      0.749200   \n",
      "17  0.077578  0.974113  0.983906  0.993348  0.137501      0.956243   \n",
      "18  0.069973  0.973579  0.984272  0.996246  0.141804      0.958378   \n",
      "19  0.069661  0.975981  0.983541  0.995227  1.770445      0.738527   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.991228  0.969238  \n",
      "1     0.998538  0.933896  \n",
      "2     0.907895  0.964464  \n",
      "3     0.001462  0.687718  \n",
      "4     0.989766  0.976296  \n",
      "5     0.985380  0.982817  \n",
      "6     0.989766  0.965889  \n",
      "7     1.000000  0.856638  \n",
      "8     0.980994  0.981480  \n",
      "9     0.972222  0.983909  \n",
      "10    0.957602  0.987917  \n",
      "11    0.989766  0.960558  \n",
      "12    0.961988  0.974109  \n",
      "13    0.972222  0.968709  \n",
      "14    0.992690  0.968567  \n",
      "15    0.982456  0.981780  \n",
      "16    1.000000  0.866358  \n",
      "17    0.982456  0.985961  \n",
      "18    0.985380  0.982219  \n",
      "19    1.000000  0.705077  \n",
      "59/59 [==============================] - 34s 574ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 269s 2s/step - loss: 0.3376 - accuracy: 0.8807 - recall: 0.9225 - auc: 0.9262 - val_loss: 0.2976 - val_accuracy: 0.8730 - val_recall: 0.9693 - val_auc: 0.9410\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 266s 2s/step - loss: 0.2128 - accuracy: 0.9221 - recall: 0.9510 - auc: 0.9644 - val_loss: 0.2839 - val_accuracy: 0.8922 - val_recall: 0.9854 - val_auc: 0.9540\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1951 - accuracy: 0.9287 - recall: 0.9546 - auc: 0.9702 - val_loss: 1.5472 - val_accuracy: 0.4568 - val_recall: 0.2558 - val_auc: 0.8837\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1691 - accuracy: 0.9400 - recall: 0.9631 - auc: 0.9758 - val_loss: 0.7876 - val_accuracy: 0.7449 - val_recall: 0.9985 - val_auc: 0.9330\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 271s 2s/step - loss: 0.1615 - accuracy: 0.9386 - recall: 0.9616 - auc: 0.9779 - val_loss: 0.6403 - val_accuracy: 0.7641 - val_recall: 1.0000 - val_auc: 0.9625\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1339 - accuracy: 0.9512 - recall: 0.9700 - auc: 0.9837 - val_loss: 0.3358 - val_accuracy: 0.8559 - val_recall: 0.9942 - val_auc: 0.9644\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.1230 - accuracy: 0.9530 - recall: 0.9729 - auc: 0.9866 - val_loss: 0.2136 - val_accuracy: 0.9221 - val_recall: 0.9927 - val_auc: 0.9736\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1055 - accuracy: 0.9576 - recall: 0.9737 - auc: 0.9902 - val_loss: 0.1203 - val_accuracy: 0.9584 - val_recall: 0.9854 - val_auc: 0.9882\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1191 - accuracy: 0.9597 - recall: 0.9744 - auc: 0.9878 - val_loss: 0.1688 - val_accuracy: 0.9402 - val_recall: 0.9459 - val_auc: 0.9821\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.1149 - accuracy: 0.9589 - recall: 0.9773 - auc: 0.9876 - val_loss: 0.1541 - val_accuracy: 0.9456 - val_recall: 0.9503 - val_auc: 0.9854\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0941 - accuracy: 0.9661 - recall: 0.9788 - auc: 0.9917 - val_loss: 0.4942 - val_accuracy: 0.8517 - val_recall: 0.8056 - val_auc: 0.9747\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0930 - accuracy: 0.9674 - recall: 0.9799 - auc: 0.9917 - val_loss: 0.1195 - val_accuracy: 0.9541 - val_recall: 0.9868 - val_auc: 0.9894\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0931 - accuracy: 0.9661 - recall: 0.9792 - auc: 0.9911 - val_loss: 0.2844 - val_accuracy: 0.9157 - val_recall: 0.8962 - val_auc: 0.9812\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 266s 2s/step - loss: 0.0862 - accuracy: 0.9653 - recall: 0.9788 - auc: 0.9934 - val_loss: 0.2424 - val_accuracy: 0.9168 - val_recall: 0.9196 - val_auc: 0.9680\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.1123 - accuracy: 0.9600 - recall: 0.9773 - auc: 0.9868 - val_loss: 1.0736 - val_accuracy: 0.7417 - val_recall: 1.0000 - val_auc: 0.8708\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0925 - accuracy: 0.9664 - recall: 0.9788 - auc: 0.9915 - val_loss: 0.1591 - val_accuracy: 0.9456 - val_recall: 0.9839 - val_auc: 0.9810\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0806 - accuracy: 0.9696 - recall: 0.9828 - auc: 0.9943 - val_loss: 0.1970 - val_accuracy: 0.9242 - val_recall: 0.9766 - val_auc: 0.9705\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 263s 2s/step - loss: 0.1225 - accuracy: 0.9525 - recall: 0.9726 - auc: 0.9864 - val_loss: 0.8100 - val_accuracy: 0.6809 - val_recall: 0.5687 - val_auc: 0.9654\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0960 - accuracy: 0.9656 - recall: 0.9806 - auc: 0.9909 - val_loss: 0.2108 - val_accuracy: 0.9360 - val_recall: 0.9927 - val_auc: 0.9757\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.0627 - accuracy: 0.9768 - recall: 0.9854 - auc: 0.9958 - val_loss: 0.1306 - val_accuracy: 0.9498 - val_recall: 0.9722 - val_auc: 0.9861\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.337571  0.880705  0.922458  0.926207  0.297612      0.872999   \n",
      "1   0.212829  0.922071  0.950988  0.964387  0.283873      0.892209   \n",
      "2   0.195090  0.928743  0.954645  0.970196  1.547167      0.456777   \n",
      "3   0.169089  0.939952  0.963058  0.975821  0.787565      0.744931   \n",
      "4   0.161499  0.938618  0.961595  0.977922  0.640289      0.764141   \n",
      "5   0.133934  0.951161  0.970007  0.983697  0.335839      0.855923   \n",
      "6   0.123013  0.953029  0.972933  0.986555  0.213613      0.922092   \n",
      "7   0.105538  0.957566  0.973665  0.990217  0.120267      0.958378   \n",
      "8   0.119076  0.959701  0.974396  0.987801  0.168814      0.940235   \n",
      "9   0.114864  0.958900  0.977323  0.987622  0.154137      0.945571   \n",
      "10  0.094071  0.966106  0.978786  0.991675  0.494240      0.851654   \n",
      "11  0.093009  0.967441  0.979883  0.991727  0.119476      0.954109   \n",
      "12  0.093069  0.966106  0.979151  0.991123  0.284413      0.915688   \n",
      "13  0.086225  0.965306  0.978786  0.993377  0.242444      0.916756   \n",
      "14  0.112291  0.959968  0.977323  0.986848  1.073555      0.741729   \n",
      "15  0.092507  0.966373  0.978786  0.991456  0.159124      0.945571   \n",
      "16  0.080618  0.969576  0.982809  0.994267  0.197025      0.924226   \n",
      "17  0.122549  0.952495  0.972568  0.986350  0.809984      0.680896   \n",
      "18  0.095995  0.965572  0.980614  0.990864  0.210844      0.935966   \n",
      "19  0.062727  0.976781  0.985369  0.995802  0.130595      0.949840   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.969298  0.941044  \n",
      "1     0.985380  0.953976  \n",
      "2     0.255848  0.883705  \n",
      "3     0.998538  0.932980  \n",
      "4     1.000000  0.962517  \n",
      "5     0.994152  0.964384  \n",
      "6     0.992690  0.973612  \n",
      "7     0.985380  0.988229  \n",
      "8     0.945906  0.982083  \n",
      "9     0.950292  0.985354  \n",
      "10    0.805556  0.974661  \n",
      "11    0.986842  0.989390  \n",
      "12    0.896199  0.981165  \n",
      "13    0.919591  0.967989  \n",
      "14    1.000000  0.870842  \n",
      "15    0.983918  0.981017  \n",
      "16    0.976608  0.970538  \n",
      "17    0.568713  0.965427  \n",
      "18    0.992690  0.975736  \n",
      "19    0.972222  0.986126  \n",
      "37/37 [==============================] - 33s 875ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.3479 - accuracy: 0.8759 - recall: 0.9247 - auc: 0.9176 - val_loss: 0.5910 - val_accuracy: 0.7001 - val_recall: 0.5994 - val_auc: 0.9302\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1971 - accuracy: 0.9253 - recall: 0.9495 - auc: 0.9682 - val_loss: 0.2658 - val_accuracy: 0.8783 - val_recall: 0.9766 - val_auc: 0.9599\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1562 - accuracy: 0.9402 - recall: 0.9616 - auc: 0.9799 - val_loss: 0.2844 - val_accuracy: 0.8751 - val_recall: 0.9971 - val_auc: 0.9738\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1580 - accuracy: 0.9392 - recall: 0.9609 - auc: 0.9798 - val_loss: 0.3742 - val_accuracy: 0.8463 - val_recall: 0.9985 - val_auc: 0.9684\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1322 - accuracy: 0.9514 - recall: 0.9689 - auc: 0.9847 - val_loss: 0.3259 - val_accuracy: 0.8591 - val_recall: 0.8275 - val_auc: 0.9669\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1154 - accuracy: 0.9565 - recall: 0.9718 - auc: 0.9884 - val_loss: 0.2186 - val_accuracy: 0.9200 - val_recall: 0.9927 - val_auc: 0.9770\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1195 - accuracy: 0.9552 - recall: 0.9740 - auc: 0.9877 - val_loss: 0.1608 - val_accuracy: 0.9434 - val_recall: 0.9839 - val_auc: 0.9815\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0990 - accuracy: 0.9626 - recall: 0.9762 - auc: 0.9911 - val_loss: 0.5499 - val_accuracy: 0.7801 - val_recall: 1.0000 - val_auc: 0.9779\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1085 - accuracy: 0.9589 - recall: 0.9762 - auc: 0.9898 - val_loss: 0.2561 - val_accuracy: 0.8943 - val_recall: 0.9985 - val_auc: 0.9847\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0960 - accuracy: 0.9645 - recall: 0.9795 - auc: 0.9906 - val_loss: 0.4596 - val_accuracy: 0.8399 - val_recall: 0.9985 - val_auc: 0.9614\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0900 - accuracy: 0.9682 - recall: 0.9828 - auc: 0.9920 - val_loss: 0.2363 - val_accuracy: 0.9210 - val_recall: 0.9985 - val_auc: 0.9791\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0885 - accuracy: 0.9661 - recall: 0.9806 - auc: 0.9925 - val_loss: 0.7686 - val_accuracy: 0.6734 - val_recall: 0.5556 - val_auc: 0.9462\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0808 - accuracy: 0.9722 - recall: 0.9832 - auc: 0.9934 - val_loss: 0.2533 - val_accuracy: 0.9146 - val_recall: 0.9985 - val_auc: 0.9732\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0869 - accuracy: 0.9674 - recall: 0.9824 - auc: 0.9916 - val_loss: 0.1390 - val_accuracy: 0.9509 - val_recall: 0.9561 - val_auc: 0.9876\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0692 - accuracy: 0.9733 - recall: 0.9828 - auc: 0.9957 - val_loss: 0.1417 - val_accuracy: 0.9541 - val_recall: 0.9898 - val_auc: 0.9866\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0552 - accuracy: 0.9789 - recall: 0.9854 - auc: 0.9970 - val_loss: 0.2613 - val_accuracy: 0.9296 - val_recall: 0.9971 - val_auc: 0.9588\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0516 - accuracy: 0.9808 - recall: 0.9887 - auc: 0.9970 - val_loss: 0.1575 - val_accuracy: 0.9530 - val_recall: 0.9854 - val_auc: 0.9785\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0592 - accuracy: 0.9778 - recall: 0.9857 - auc: 0.9972 - val_loss: 0.2241 - val_accuracy: 0.9317 - val_recall: 0.9883 - val_auc: 0.9719\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0564 - accuracy: 0.9778 - recall: 0.9857 - auc: 0.9969 - val_loss: 0.1286 - val_accuracy: 0.9562 - val_recall: 0.9722 - val_auc: 0.9821\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0408 - accuracy: 0.9843 - recall: 0.9912 - auc: 0.9986 - val_loss: 0.1783 - val_accuracy: 0.9488 - val_recall: 0.9942 - val_auc: 0.9762\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.347858  0.875901  0.924653  0.917645  0.590988      0.700107   \n",
      "1   0.197117  0.925274  0.949525  0.968168  0.265778      0.878335   \n",
      "2   0.156219  0.940219  0.961595  0.979926  0.284413      0.875133   \n",
      "3   0.158021  0.939151  0.960863  0.979770  0.374210      0.846318   \n",
      "4   0.132245  0.951428  0.968910  0.984728  0.325927      0.859125   \n",
      "5   0.115408  0.956499  0.971836  0.988435  0.218562      0.919957   \n",
      "6   0.119543  0.955164  0.974031  0.987693  0.160849      0.943437   \n",
      "7   0.099003  0.962637  0.976225  0.991064  0.549916      0.780149   \n",
      "8   0.108484  0.958900  0.976225  0.989823  0.256131      0.894344   \n",
      "9   0.096034  0.964505  0.979517  0.990594  0.459649      0.839915   \n",
      "10  0.090014  0.968241  0.982809  0.992015  0.236295      0.921025   \n",
      "11  0.088457  0.966106  0.980614  0.992458  0.768586      0.673426   \n",
      "12  0.080795  0.972244  0.983175  0.993383  0.253279      0.914621   \n",
      "13  0.086863  0.967441  0.982443  0.991589  0.138962      0.950907   \n",
      "14  0.069181  0.973312  0.982809  0.995714  0.141698      0.954109   \n",
      "15  0.055237  0.978916  0.985369  0.997049  0.261319      0.929562   \n",
      "16  0.051635  0.980785  0.988661  0.997011  0.157474      0.953042   \n",
      "17  0.059218  0.977849  0.985735  0.997187  0.224089      0.931697   \n",
      "18  0.056392  0.977849  0.985735  0.996929  0.128558      0.956243   \n",
      "19  0.040826  0.984254  0.991222  0.998613  0.178298      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.599415  0.930200  \n",
      "1     0.976608  0.959894  \n",
      "2     0.997076  0.973820  \n",
      "3     0.998538  0.968408  \n",
      "4     0.827485  0.966938  \n",
      "5     0.992690  0.976978  \n",
      "6     0.983918  0.981546  \n",
      "7     1.000000  0.977934  \n",
      "8     0.998538  0.984661  \n",
      "9     0.998538  0.961393  \n",
      "10    0.998538  0.979067  \n",
      "11    0.555556  0.946247  \n",
      "12    0.998538  0.973153  \n",
      "13    0.956140  0.987619  \n",
      "14    0.989766  0.986573  \n",
      "15    0.997076  0.958816  \n",
      "16    0.985380  0.978550  \n",
      "17    0.988304  0.971867  \n",
      "18    0.972222  0.982095  \n",
      "19    0.994152  0.976152  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 282s 599ms/step - loss: 0.3634 - accuracy: 0.8660 - recall: 0.9089 - auc: 0.9151 - val_loss: 0.2181 - val_accuracy: 0.9136 - val_recall: 0.9181 - val_auc: 0.9681\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 287s 613ms/step - loss: 0.2189 - accuracy: 0.9125 - recall: 0.9404 - auc: 0.9633 - val_loss: 0.9072 - val_accuracy: 0.7193 - val_recall: 0.9678 - val_auc: 0.8304\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 282s 602ms/step - loss: 0.1705 - accuracy: 0.9349 - recall: 0.9572 - auc: 0.9751 - val_loss: 0.2028 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9626\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 287s 611ms/step - loss: 0.1596 - accuracy: 0.9389 - recall: 0.9579 - auc: 0.9788 - val_loss: 0.1637 - val_accuracy: 0.9360 - val_recall: 0.9503 - val_auc: 0.9796\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 293s 623ms/step - loss: 0.1523 - accuracy: 0.9472 - recall: 0.9649 - auc: 0.9794 - val_loss: 0.1777 - val_accuracy: 0.9370 - val_recall: 0.9810 - val_auc: 0.9786\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 281s 598ms/step - loss: 0.1616 - accuracy: 0.9413 - recall: 0.9653 - auc: 0.9774 - val_loss: 0.1450 - val_accuracy: 0.9488 - val_recall: 0.9883 - val_auc: 0.9865\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 281s 598ms/step - loss: 0.1512 - accuracy: 0.9440 - recall: 0.9663 - auc: 0.9808 - val_loss: 0.1393 - val_accuracy: 0.9488 - val_recall: 0.9751 - val_auc: 0.9848\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 288s 615ms/step - loss: 0.1190 - accuracy: 0.9576 - recall: 0.9707 - auc: 0.9873 - val_loss: 0.1577 - val_accuracy: 0.9509 - val_recall: 0.9649 - val_auc: 0.9824\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 282s 601ms/step - loss: 0.1219 - accuracy: 0.9522 - recall: 0.9711 - auc: 0.9871 - val_loss: 0.1740 - val_accuracy: 0.9434 - val_recall: 0.9854 - val_auc: 0.9794\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 286s 608ms/step - loss: 0.1140 - accuracy: 0.9562 - recall: 0.9733 - auc: 0.9890 - val_loss: 0.1312 - val_accuracy: 0.9520 - val_recall: 0.9693 - val_auc: 0.9868\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 284s 605ms/step - loss: 0.1114 - accuracy: 0.9597 - recall: 0.9770 - auc: 0.9886 - val_loss: 0.1409 - val_accuracy: 0.9562 - val_recall: 0.9795 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 284s 604ms/step - loss: 0.1107 - accuracy: 0.9584 - recall: 0.9759 - auc: 0.9889 - val_loss: 0.2374 - val_accuracy: 0.9509 - val_recall: 0.9532 - val_auc: 0.9859\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 283s 603ms/step - loss: 0.0892 - accuracy: 0.9656 - recall: 0.9792 - auc: 0.9927 - val_loss: 0.3049 - val_accuracy: 0.9328 - val_recall: 0.9854 - val_auc: 0.9637\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 279s 595ms/step - loss: 0.0980 - accuracy: 0.9626 - recall: 0.9784 - auc: 0.9917 - val_loss: 0.1683 - val_accuracy: 0.9509 - val_recall: 0.9649 - val_auc: 0.9828\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 282s 600ms/step - loss: 0.0818 - accuracy: 0.9690 - recall: 0.9828 - auc: 0.9938 - val_loss: 0.2179 - val_accuracy: 0.9541 - val_recall: 0.9576 - val_auc: 0.9845\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 279s 595ms/step - loss: 0.0946 - accuracy: 0.9629 - recall: 0.9777 - auc: 0.9919 - val_loss: 0.1807 - val_accuracy: 0.9552 - val_recall: 0.9708 - val_auc: 0.9833\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 291s 620ms/step - loss: 0.0769 - accuracy: 0.9666 - recall: 0.9821 - auc: 0.9950 - val_loss: 0.4144 - val_accuracy: 0.9381 - val_recall: 0.9810 - val_auc: 0.9542\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 291s 619ms/step - loss: 0.0752 - accuracy: 0.9714 - recall: 0.9861 - auc: 0.9940 - val_loss: 0.2098 - val_accuracy: 0.9509 - val_recall: 0.9678 - val_auc: 0.9867\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 284s 606ms/step - loss: 0.0726 - accuracy: 0.9754 - recall: 0.9868 - auc: 0.9952 - val_loss: 0.2040 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9823\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 287s 612ms/step - loss: 0.0648 - accuracy: 0.9725 - recall: 0.9850 - auc: 0.9963 - val_loss: 0.8036 - val_accuracy: 0.9338 - val_recall: 0.9868 - val_auc: 0.9579\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.363376  0.866026  0.908925  0.915148  0.218119      0.913554   \n",
      "1   0.218927  0.912463  0.940380  0.963294  0.907165      0.719317   \n",
      "2   0.170453  0.934881  0.957206  0.975130  0.202849      0.942369   \n",
      "3   0.159558  0.938884  0.957937  0.978772  0.163714      0.935966   \n",
      "4   0.152271  0.947158  0.964887  0.979374  0.177705      0.937033   \n",
      "5   0.161590  0.941286  0.965252  0.977413  0.145046      0.948773   \n",
      "6   0.151157  0.943955  0.966350  0.980841  0.139295      0.948773   \n",
      "7   0.118988  0.957566  0.970739  0.987315  0.157655      0.950907   \n",
      "8   0.121899  0.952228  0.971105  0.987122  0.174018      0.943437   \n",
      "9   0.113960  0.956232  0.973299  0.989001  0.131197      0.951974   \n",
      "10  0.111361  0.959701  0.976957  0.988576  0.140935      0.956243   \n",
      "11  0.110706  0.958367  0.975860  0.988938  0.237445      0.950907   \n",
      "12  0.089177  0.965572  0.979151  0.992704  0.304852      0.932764   \n",
      "13  0.097990  0.962637  0.978420  0.991671  0.168291      0.950907   \n",
      "14  0.081802  0.969042  0.982809  0.993818  0.217942      0.954109   \n",
      "15  0.094647  0.962904  0.977688  0.991926  0.180677      0.955176   \n",
      "16  0.076852  0.966640  0.982078  0.995017  0.414376      0.938100   \n",
      "17  0.075246  0.971444  0.986101  0.994033  0.209756      0.950907   \n",
      "18  0.072602  0.975447  0.986832  0.995232  0.204022      0.955176   \n",
      "19  0.064787  0.972511  0.985004  0.996344  0.803572      0.933831   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.918129  0.968079  \n",
      "1     0.967836  0.830363  \n",
      "2     0.972222  0.962575  \n",
      "3     0.950292  0.979558  \n",
      "4     0.980994  0.978553  \n",
      "5     0.988304  0.986452  \n",
      "6     0.975146  0.984753  \n",
      "7     0.964912  0.982390  \n",
      "8     0.985380  0.979437  \n",
      "9     0.969298  0.986833  \n",
      "10    0.979532  0.986493  \n",
      "11    0.953216  0.985920  \n",
      "12    0.985380  0.963684  \n",
      "13    0.964912  0.982814  \n",
      "14    0.957602  0.984473  \n",
      "15    0.970760  0.983317  \n",
      "16    0.980994  0.954184  \n",
      "17    0.967836  0.986698  \n",
      "18    0.979532  0.982277  \n",
      "19    0.986842  0.957943  \n",
      "147/147 [==============================] - 40s 270ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.3349 - accuracy: 0.8743 - recall: 0.9228 - auc: 0.9224 - val_loss: 0.7576 - val_accuracy: 0.7311 - val_recall: 0.6404 - val_auc: 0.8793\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.2085 - accuracy: 0.9165 - recall: 0.9429 - auc: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9178 - val_recall: 0.9751 - val_auc: 0.9709\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.1677 - accuracy: 0.9373 - recall: 0.9594 - auc: 0.9771 - val_loss: 0.5533 - val_accuracy: 0.8773 - val_recall: 0.9781 - val_auc: 0.9072\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1615 - accuracy: 0.9416 - recall: 0.9642 - auc: 0.9789 - val_loss: 0.1993 - val_accuracy: 0.9328 - val_recall: 0.9254 - val_auc: 0.9805\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.1452 - accuracy: 0.9418 - recall: 0.9645 - auc: 0.9828 - val_loss: 0.6405 - val_accuracy: 0.7791 - val_recall: 0.9985 - val_auc: 0.9171\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 275s 1s/step - loss: 0.1518 - accuracy: 0.9437 - recall: 0.9660 - auc: 0.9800 - val_loss: 0.2472 - val_accuracy: 0.9242 - val_recall: 0.9591 - val_auc: 0.9615\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.1160 - accuracy: 0.9584 - recall: 0.9748 - auc: 0.9876 - val_loss: 0.1335 - val_accuracy: 0.9552 - val_recall: 0.9883 - val_auc: 0.9883\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.1181 - accuracy: 0.9520 - recall: 0.9722 - auc: 0.9873 - val_loss: 0.2112 - val_accuracy: 0.9253 - val_recall: 0.9912 - val_auc: 0.9775\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.1144 - accuracy: 0.9565 - recall: 0.9740 - auc: 0.9882 - val_loss: 0.1260 - val_accuracy: 0.9541 - val_recall: 0.9737 - val_auc: 0.9892\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.0990 - accuracy: 0.9637 - recall: 0.9784 - auc: 0.9913 - val_loss: 0.1435 - val_accuracy: 0.9520 - val_recall: 0.9868 - val_auc: 0.9847\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.0949 - accuracy: 0.9642 - recall: 0.9802 - auc: 0.9926 - val_loss: 0.1326 - val_accuracy: 0.9520 - val_recall: 0.9518 - val_auc: 0.9881\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0958 - accuracy: 0.9664 - recall: 0.9813 - auc: 0.9923 - val_loss: 0.2184 - val_accuracy: 0.9061 - val_recall: 0.9883 - val_auc: 0.9804\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0957 - accuracy: 0.9674 - recall: 0.9817 - auc: 0.9898 - val_loss: 0.3111 - val_accuracy: 0.9402 - val_recall: 0.9459 - val_auc: 0.9768\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.0810 - accuracy: 0.9693 - recall: 0.9821 - auc: 0.9942 - val_loss: 0.1382 - val_accuracy: 0.9488 - val_recall: 0.9825 - val_auc: 0.9867\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.0979 - accuracy: 0.9650 - recall: 0.9832 - auc: 0.9905 - val_loss: 0.5849 - val_accuracy: 0.9114 - val_recall: 0.9459 - val_auc: 0.9289\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0953 - accuracy: 0.9645 - recall: 0.9810 - auc: 0.9915 - val_loss: 0.2122 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9714\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0805 - accuracy: 0.9693 - recall: 0.9806 - auc: 0.9938 - val_loss: 0.1370 - val_accuracy: 0.9520 - val_recall: 0.9678 - val_auc: 0.9854\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 270s 1s/step - loss: 0.0732 - accuracy: 0.9706 - recall: 0.9824 - auc: 0.9957 - val_loss: 0.1449 - val_accuracy: 0.9530 - val_recall: 0.9751 - val_auc: 0.9871\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.0636 - accuracy: 0.9741 - recall: 0.9861 - auc: 0.9960 - val_loss: 0.2939 - val_accuracy: 0.9104 - val_recall: 0.9927 - val_auc: 0.9635\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.334881  0.874299  0.922824  0.922412  0.757599      0.731057   \n",
      "1   0.208549  0.916467  0.942941  0.965633  0.219790      0.917823   \n",
      "2   0.167705  0.937283  0.959400  0.977128  0.553290      0.877268   \n",
      "3   0.161540  0.941553  0.964155  0.978871  0.199305      0.932764   \n",
      "4   0.145171  0.941820  0.964521  0.982839  0.640489      0.779082   \n",
      "5   0.151790  0.943688  0.965984  0.980002  0.247202      0.924226   \n",
      "6   0.115957  0.958367  0.974762  0.987648  0.133549      0.955176   \n",
      "7   0.118102  0.951962  0.972202  0.987318  0.211241      0.925294   \n",
      "8   0.114433  0.956499  0.974031  0.988152  0.125961      0.954109   \n",
      "9   0.099021  0.963704  0.978420  0.991317  0.143526      0.951974   \n",
      "10  0.094880  0.964238  0.980249  0.992560  0.132643      0.951974   \n",
      "11  0.095808  0.966373  0.981346  0.992303  0.218366      0.906083   \n",
      "12  0.095650  0.967441  0.981712  0.989837  0.311062      0.940235   \n",
      "13  0.080992  0.969309  0.982078  0.994224  0.138210      0.948773   \n",
      "14  0.097884  0.965039  0.983175  0.990519  0.584871      0.911419   \n",
      "15  0.095338  0.964505  0.980980  0.991488  0.212244      0.941302   \n",
      "16  0.080455  0.969309  0.980614  0.993799  0.136954      0.951974   \n",
      "17  0.073205  0.970643  0.982443  0.995739  0.144906      0.953042   \n",
      "18  0.063644  0.974113  0.986101  0.996048  0.293943      0.910352   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.640351  0.879302  \n",
      "1     0.975146  0.970902  \n",
      "2     0.978070  0.907172  \n",
      "3     0.925439  0.980454  \n",
      "4     0.998538  0.917068  \n",
      "5     0.959064  0.961486  \n",
      "6     0.988304  0.988272  \n",
      "7     0.991228  0.977510  \n",
      "8     0.973684  0.989162  \n",
      "9     0.986842  0.984721  \n",
      "10    0.951754  0.988116  \n",
      "11    0.988304  0.980361  \n",
      "12    0.945906  0.976834  \n",
      "13    0.982456  0.986692  \n",
      "14    0.945906  0.928883  \n",
      "15    0.960526  0.971384  \n",
      "16    0.967836  0.985415  \n",
      "17    0.975146  0.987068  \n",
      "18    0.992690  0.963497  \n",
      "74/74 [==============================] - 35s 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.3348 - accuracy: 0.8818 - recall: 0.9195 - auc: 0.9301 - val_loss: 1.4786 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.7308\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.2031 - accuracy: 0.9199 - recall: 0.9470 - auc: 0.9677 - val_loss: 0.3073 - val_accuracy: 0.8794 - val_recall: 0.9795 - val_auc: 0.9589\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.1635 - accuracy: 0.9405 - recall: 0.9623 - auc: 0.9773 - val_loss: 0.2157 - val_accuracy: 0.9178 - val_recall: 0.9444 - val_auc: 0.9661\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.1487 - accuracy: 0.9432 - recall: 0.9674 - auc: 0.9812 - val_loss: 0.2263 - val_accuracy: 0.9221 - val_recall: 0.9664 - val_auc: 0.9576\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 268s 1s/step - loss: 0.1597 - accuracy: 0.9437 - recall: 0.9678 - auc: 0.9769 - val_loss: 0.2542 - val_accuracy: 0.9050 - val_recall: 0.8830 - val_auc: 0.9824\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 273s 1s/step - loss: 0.1283 - accuracy: 0.9504 - recall: 0.9682 - auc: 0.9857 - val_loss: 0.7185 - val_accuracy: 0.8655 - val_recall: 0.9883 - val_auc: 0.8943\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 269s 1s/step - loss: 0.1314 - accuracy: 0.9490 - recall: 0.9689 - auc: 0.9845 - val_loss: 0.1974 - val_accuracy: 0.9306 - val_recall: 0.9751 - val_auc: 0.9721\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 273s 1s/step - loss: 0.1205 - accuracy: 0.9549 - recall: 0.9748 - auc: 0.9873 - val_loss: 0.1723 - val_accuracy: 0.9402 - val_recall: 0.9693 - val_auc: 0.9752\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.1049 - accuracy: 0.9613 - recall: 0.9784 - auc: 0.9903 - val_loss: 0.1656 - val_accuracy: 0.9413 - val_recall: 0.9854 - val_auc: 0.9799\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.1021 - accuracy: 0.9613 - recall: 0.9777 - auc: 0.9902 - val_loss: 0.6235 - val_accuracy: 0.9061 - val_recall: 0.9430 - val_auc: 0.9623\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.1006 - accuracy: 0.9618 - recall: 0.9799 - auc: 0.9905 - val_loss: 0.6094 - val_accuracy: 0.8068 - val_recall: 0.9985 - val_auc: 0.9283\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 271s 1s/step - loss: 0.0994 - accuracy: 0.9616 - recall: 0.9777 - auc: 0.9916 - val_loss: 0.1668 - val_accuracy: 0.9392 - val_recall: 0.9927 - val_auc: 0.9860\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0931 - accuracy: 0.9602 - recall: 0.9744 - auc: 0.9920 - val_loss: 0.1823 - val_accuracy: 0.9370 - val_recall: 0.9883 - val_auc: 0.9781\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 268s 1s/step - loss: 0.0884 - accuracy: 0.9680 - recall: 0.9828 - auc: 0.9919 - val_loss: 0.1746 - val_accuracy: 0.9488 - val_recall: 0.9518 - val_auc: 0.9862\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 271s 1s/step - loss: 0.0903 - accuracy: 0.9664 - recall: 0.9806 - auc: 0.9921 - val_loss: 0.5635 - val_accuracy: 0.8538 - val_recall: 0.9956 - val_auc: 0.9310\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0796 - accuracy: 0.9696 - recall: 0.9857 - auc: 0.9941 - val_loss: 0.2010 - val_accuracy: 0.9392 - val_recall: 0.9664 - val_auc: 0.9758\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.0864 - accuracy: 0.9698 - recall: 0.9843 - auc: 0.9933 - val_loss: 0.1445 - val_accuracy: 0.9594 - val_recall: 0.9678 - val_auc: 0.9859\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.0756 - accuracy: 0.9720 - recall: 0.9835 - auc: 0.9951 - val_loss: 0.3231 - val_accuracy: 0.9018 - val_recall: 0.9912 - val_auc: 0.9566\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0625 - accuracy: 0.9749 - recall: 0.9879 - auc: 0.9964 - val_loss: 0.3446 - val_accuracy: 0.8954 - val_recall: 0.9942 - val_auc: 0.9649\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 274s 1s/step - loss: 0.0576 - accuracy: 0.9797 - recall: 0.9905 - auc: 0.9964 - val_loss: 0.1444 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9809\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.334804  0.881772  0.919532  0.930129  1.478558      0.731057   \n",
      "1   0.203082  0.919936  0.946964  0.967739  0.307331      0.879402   \n",
      "2   0.163515  0.940486  0.962326  0.977277  0.215674      0.917823   \n",
      "3   0.148684  0.943155  0.967447  0.981237  0.226301      0.922092   \n",
      "4   0.159657  0.943688  0.967813  0.976861  0.254165      0.905016   \n",
      "5   0.128272  0.950360  0.968179  0.985724  0.718457      0.865528   \n",
      "6   0.131428  0.949026  0.968910  0.984463  0.197382      0.930630   \n",
      "7   0.120494  0.954897  0.974762  0.987274  0.172329      0.940235   \n",
      "8   0.104925  0.961302  0.978420  0.990325  0.165619      0.941302   \n",
      "9   0.102096  0.961302  0.977688  0.990167  0.623542      0.906083   \n",
      "10  0.100552  0.961836  0.979883  0.990547  0.609372      0.806830   \n",
      "11  0.099355  0.961569  0.977688  0.991620  0.166830      0.939168   \n",
      "12  0.093067  0.960235  0.974396  0.991974  0.182290      0.937033   \n",
      "13  0.088415  0.967974  0.982809  0.991931  0.174596      0.948773   \n",
      "14  0.090338  0.966373  0.980614  0.992085  0.563481      0.853789   \n",
      "15  0.079603  0.969576  0.985735  0.994078  0.201044      0.939168   \n",
      "16  0.086450  0.969843  0.984272  0.993301  0.144486      0.959445   \n",
      "17  0.075578  0.971978  0.983541  0.995053  0.323108      0.901814   \n",
      "18  0.062488  0.974913  0.987930  0.996412  0.344565      0.895411   \n",
      "19  0.057650  0.979717  0.990490  0.996365  0.144420      0.955176   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.730772  \n",
      "1     0.979532  0.958879  \n",
      "2     0.944444  0.966114  \n",
      "3     0.966374  0.957640  \n",
      "4     0.883041  0.982421  \n",
      "5     0.988304  0.894306  \n",
      "6     0.975146  0.972133  \n",
      "7     0.969298  0.975178  \n",
      "8     0.985380  0.979882  \n",
      "9     0.942982  0.962309  \n",
      "10    0.998538  0.928305  \n",
      "11    0.992690  0.985972  \n",
      "12    0.988304  0.978076  \n",
      "13    0.951754  0.986163  \n",
      "14    0.995614  0.931027  \n",
      "15    0.966374  0.975799  \n",
      "16    0.967836  0.985932  \n",
      "17    0.991228  0.956608  \n",
      "18    0.994152  0.964875  \n",
      "19    0.979532  0.980858  \n",
      "59/59 [==============================] - 34s 575ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.3548 - accuracy: 0.8684 - recall: 0.9126 - auc: 0.9151 - val_loss: 1.6606 - val_accuracy: 0.7300 - val_recall: 0.9971 - val_auc: 0.6890\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 264s 2s/step - loss: 0.1991 - accuracy: 0.9258 - recall: 0.9521 - auc: 0.9683 - val_loss: 0.3037 - val_accuracy: 0.8719 - val_recall: 0.9927 - val_auc: 0.9742\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 264s 2s/step - loss: 0.1906 - accuracy: 0.9269 - recall: 0.9521 - auc: 0.9710 - val_loss: 1.4301 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7646\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 259s 2s/step - loss: 0.1464 - accuracy: 0.9453 - recall: 0.9631 - auc: 0.9814 - val_loss: 0.6865 - val_accuracy: 0.7748 - val_recall: 0.9942 - val_auc: 0.9149\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 261s 2s/step - loss: 0.1444 - accuracy: 0.9477 - recall: 0.9656 - auc: 0.9817 - val_loss: 0.2851 - val_accuracy: 0.9125 - val_recall: 0.9035 - val_auc: 0.9662\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 260s 2s/step - loss: 0.1498 - accuracy: 0.9445 - recall: 0.9671 - auc: 0.9812 - val_loss: 0.2241 - val_accuracy: 0.9114 - val_recall: 0.9898 - val_auc: 0.9788\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 262s 2s/step - loss: 0.1203 - accuracy: 0.9552 - recall: 0.9711 - auc: 0.9872 - val_loss: 0.5774 - val_accuracy: 0.8132 - val_recall: 0.9985 - val_auc: 0.9520\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.1179 - accuracy: 0.9557 - recall: 0.9722 - auc: 0.9881 - val_loss: 1.2070 - val_accuracy: 0.7460 - val_recall: 1.0000 - val_auc: 0.8167\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 255s 2s/step - loss: 0.1141 - accuracy: 0.9568 - recall: 0.9740 - auc: 0.9887 - val_loss: 0.8162 - val_accuracy: 0.8004 - val_recall: 0.7442 - val_auc: 0.9263\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.1054 - accuracy: 0.9594 - recall: 0.9792 - auc: 0.9893 - val_loss: 0.1986 - val_accuracy: 0.9242 - val_recall: 0.9898 - val_auc: 0.9790\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.1038 - accuracy: 0.9565 - recall: 0.9766 - auc: 0.9913 - val_loss: 1.4855 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.7603\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.0984 - accuracy: 0.9648 - recall: 0.9810 - auc: 0.9897 - val_loss: 0.1648 - val_accuracy: 0.9328 - val_recall: 0.9839 - val_auc: 0.9833\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0909 - accuracy: 0.9640 - recall: 0.9806 - auc: 0.9925 - val_loss: 0.1429 - val_accuracy: 0.9466 - val_recall: 0.9839 - val_auc: 0.9848\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0741 - accuracy: 0.9741 - recall: 0.9868 - auc: 0.9946 - val_loss: 0.1366 - val_accuracy: 0.9520 - val_recall: 0.9795 - val_auc: 0.9848\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0813 - accuracy: 0.9714 - recall: 0.9854 - auc: 0.9939 - val_loss: 0.2621 - val_accuracy: 0.9210 - val_recall: 0.9971 - val_auc: 0.9705\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0736 - accuracy: 0.9730 - recall: 0.9850 - auc: 0.9948 - val_loss: 0.1439 - val_accuracy: 0.9488 - val_recall: 0.9868 - val_auc: 0.9847\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0771 - accuracy: 0.9706 - recall: 0.9832 - auc: 0.9940 - val_loss: 0.6631 - val_accuracy: 0.8666 - val_recall: 0.9956 - val_auc: 0.9096\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0739 - accuracy: 0.9704 - recall: 0.9861 - auc: 0.9947 - val_loss: 0.1674 - val_accuracy: 0.9477 - val_recall: 0.9883 - val_auc: 0.9851\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 254s 2s/step - loss: 0.0656 - accuracy: 0.9733 - recall: 0.9872 - auc: 0.9956 - val_loss: 0.1585 - val_accuracy: 0.9477 - val_recall: 0.9605 - val_auc: 0.9855\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0684 - accuracy: 0.9762 - recall: 0.9876 - auc: 0.9955 - val_loss: 0.1715 - val_accuracy: 0.9509 - val_recall: 0.9474 - val_auc: 0.9894\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.354794  0.868428  0.912582  0.915098  1.660625      0.729989   \n",
      "1   0.199074  0.925807  0.952085  0.968286  0.303657      0.871932   \n",
      "2   0.190610  0.926875  0.952085  0.971040  1.430150      0.729989   \n",
      "3   0.146370  0.945290  0.963058  0.981431  0.686505      0.774813   \n",
      "4   0.144422  0.947692  0.965618  0.981708  0.285132      0.912487   \n",
      "5   0.149844  0.944489  0.967081  0.981216  0.224113      0.911419   \n",
      "6   0.120261  0.955164  0.971105  0.987200  0.577386      0.813234   \n",
      "7   0.117913  0.955698  0.972202  0.988089  1.207011      0.745998   \n",
      "8   0.114071  0.956765  0.974031  0.988739  0.816210      0.800427   \n",
      "9   0.105446  0.959434  0.979151  0.989334  0.198604      0.924226   \n",
      "10  0.103834  0.956499  0.976591  0.991299  1.485475      0.758805   \n",
      "11  0.098415  0.964772  0.980980  0.989664  0.164785      0.932764   \n",
      "12  0.090888  0.963971  0.980614  0.992523  0.142902      0.946638   \n",
      "13  0.074139  0.974113  0.986832  0.994647  0.136604      0.951974   \n",
      "14  0.081315  0.971444  0.985369  0.993904  0.262083      0.921025   \n",
      "15  0.073569  0.973045  0.985004  0.994824  0.143942      0.948773   \n",
      "16  0.077138  0.970643  0.983175  0.993958  0.663133      0.866596   \n",
      "17  0.073929  0.970376  0.986101  0.994657  0.167434      0.947705   \n",
      "18  0.065575  0.973312  0.987198  0.995646  0.158531      0.947705   \n",
      "19  0.068414  0.976248  0.987564  0.995451  0.171516      0.950907   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.688969  \n",
      "1     0.992690  0.974233  \n",
      "2     1.000000  0.764588  \n",
      "3     0.994152  0.914933  \n",
      "4     0.903509  0.966244  \n",
      "5     0.989766  0.978755  \n",
      "6     0.998538  0.951968  \n",
      "7     1.000000  0.816656  \n",
      "8     0.744152  0.926259  \n",
      "9     0.989766  0.979015  \n",
      "10    1.000000  0.760283  \n",
      "11    0.983918  0.983297  \n",
      "12    0.983918  0.984765  \n",
      "13    0.979532  0.984768  \n",
      "14    0.997076  0.970526  \n",
      "15    0.986842  0.984690  \n",
      "16    0.995614  0.909643  \n",
      "17    0.988304  0.985094  \n",
      "18    0.960526  0.985504  \n",
      "19    0.947368  0.989442  \n",
      "37/37 [==============================] - 33s 873ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 245s 4s/step - loss: 0.3942 - accuracy: 0.8671 - recall: 0.9170 - auc: 0.9100 - val_loss: 1.5837 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.6215\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.2036 - accuracy: 0.9223 - recall: 0.9495 - auc: 0.9661 - val_loss: 0.4162 - val_accuracy: 0.7695 - val_recall: 1.0000 - val_auc: 0.9536\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.1713 - accuracy: 0.9357 - recall: 0.9587 - auc: 0.9759 - val_loss: 0.6659 - val_accuracy: 0.7567 - val_recall: 1.0000 - val_auc: 0.9435\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1541 - accuracy: 0.9453 - recall: 0.9623 - auc: 0.9792 - val_loss: 0.8988 - val_accuracy: 0.7332 - val_recall: 1.0000 - val_auc: 0.9333\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1359 - accuracy: 0.9490 - recall: 0.9678 - auc: 0.9846 - val_loss: 0.4448 - val_accuracy: 0.7844 - val_recall: 0.9401 - val_auc: 0.8512\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 249s 4s/step - loss: 0.1300 - accuracy: 0.9485 - recall: 0.9674 - auc: 0.9853 - val_loss: 0.3155 - val_accuracy: 0.8378 - val_recall: 0.9956 - val_auc: 0.9710\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1111 - accuracy: 0.9576 - recall: 0.9722 - auc: 0.9895 - val_loss: 0.6496 - val_accuracy: 0.7481 - val_recall: 1.0000 - val_auc: 0.9518\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.1085 - accuracy: 0.9584 - recall: 0.9711 - auc: 0.9906 - val_loss: 2.0520 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 248s 4s/step - loss: 0.1162 - accuracy: 0.9584 - recall: 0.9777 - auc: 0.9879 - val_loss: 0.2232 - val_accuracy: 0.9104 - val_recall: 0.9751 - val_auc: 0.9650\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1119 - accuracy: 0.9568 - recall: 0.9737 - auc: 0.9895 - val_loss: 1.5725 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6642\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.1028 - accuracy: 0.9605 - recall: 0.9777 - auc: 0.9912 - val_loss: 1.0162 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.9038\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 252s 4s/step - loss: 0.0977 - accuracy: 0.9650 - recall: 0.9817 - auc: 0.9918 - val_loss: 1.0270 - val_accuracy: 0.7663 - val_recall: 1.0000 - val_auc: 0.8514\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 249s 4s/step - loss: 0.1029 - accuracy: 0.9608 - recall: 0.9755 - auc: 0.9909 - val_loss: 0.3178 - val_accuracy: 0.8335 - val_recall: 0.9956 - val_auc: 0.9749\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 250s 4s/step - loss: 0.0929 - accuracy: 0.9685 - recall: 0.9810 - auc: 0.9914 - val_loss: 0.2920 - val_accuracy: 0.8858 - val_recall: 0.9942 - val_auc: 0.9775\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 250s 4s/step - loss: 0.0871 - accuracy: 0.9706 - recall: 0.9839 - auc: 0.9923 - val_loss: 0.6231 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.9344\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0688 - accuracy: 0.9768 - recall: 0.9876 - auc: 0.9959 - val_loss: 0.1379 - val_accuracy: 0.9498 - val_recall: 0.9868 - val_auc: 0.9883\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 248s 4s/step - loss: 0.0823 - accuracy: 0.9701 - recall: 0.9846 - auc: 0.9932 - val_loss: 0.1500 - val_accuracy: 0.9488 - val_recall: 0.9620 - val_auc: 0.9826\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0831 - accuracy: 0.9720 - recall: 0.9843 - auc: 0.9932 - val_loss: 0.2743 - val_accuracy: 0.8581 - val_recall: 0.9927 - val_auc: 0.9788\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0745 - accuracy: 0.9725 - recall: 0.9832 - auc: 0.9950 - val_loss: 0.2534 - val_accuracy: 0.9317 - val_recall: 0.9898 - val_auc: 0.9645\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 252s 4s/step - loss: 0.0671 - accuracy: 0.9741 - recall: 0.9846 - auc: 0.9965 - val_loss: 0.4350 - val_accuracy: 0.8378 - val_recall: 0.9942 - val_auc: 0.9581\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.394162  0.867094  0.916971  0.910021  1.583741      0.727855   \n",
      "1   0.203599  0.922338  0.949525  0.966054  0.416235      0.769477   \n",
      "2   0.171342  0.935682  0.958669  0.975926  0.665934      0.756670   \n",
      "3   0.154059  0.945290  0.962326  0.979242  0.898848      0.733191   \n",
      "4   0.135943  0.949026  0.967813  0.984610  0.444811      0.784418   \n",
      "5   0.129978  0.948492  0.967447  0.985252  0.315526      0.837780   \n",
      "6   0.111053  0.957566  0.972202  0.989481  0.649609      0.748132   \n",
      "7   0.108455  0.958367  0.971105  0.990635  2.052042      0.729989   \n",
      "8   0.116151  0.958367  0.977688  0.987928  0.223166      0.910352   \n",
      "9   0.111851  0.956765  0.973665  0.989535  1.572530      0.729989   \n",
      "10  0.102833  0.960502  0.977688  0.991229  1.016184      0.729989   \n",
      "11  0.097688  0.965039  0.981712  0.991791  1.026962      0.766275   \n",
      "12  0.102899  0.960769  0.975494  0.990919  0.317830      0.833511   \n",
      "13  0.092865  0.968508  0.980980  0.991392  0.291985      0.885806   \n",
      "14  0.087130  0.970643  0.983906  0.992272  0.623110      0.737460   \n",
      "15  0.068822  0.976781  0.987564  0.995914  0.137916      0.949840   \n",
      "16  0.082300  0.970109  0.984638  0.993156  0.149960      0.948773   \n",
      "17  0.083096  0.971978  0.984272  0.993160  0.274314      0.858058   \n",
      "18  0.074505  0.972511  0.983175  0.995013  0.253372      0.931697   \n",
      "19  0.067133  0.974113  0.984638  0.996510  0.435010      0.837780   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.621461  \n",
      "1     1.000000  0.953598  \n",
      "2     1.000000  0.943462  \n",
      "3     1.000000  0.933274  \n",
      "4     0.940058  0.851175  \n",
      "5     0.995614  0.971046  \n",
      "6     1.000000  0.951766  \n",
      "7     1.000000  0.500514  \n",
      "8     0.975146  0.964985  \n",
      "9     1.000000  0.664179  \n",
      "10    1.000000  0.903766  \n",
      "11    1.000000  0.851360  \n",
      "12    0.995614  0.974909  \n",
      "13    0.994152  0.977458  \n",
      "14    1.000000  0.934367  \n",
      "15    0.986842  0.988330  \n",
      "16    0.961988  0.982644  \n",
      "17    0.992690  0.978844  \n",
      "18    0.989766  0.964543  \n",
      "19    0.994152  0.958131  \n",
      "19/19 [==============================] - 31s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 278s 590ms/step - loss: 0.3866 - accuracy: 0.8468 - recall: 0.8954 - auc: 0.8931 - val_loss: 1.0925 - val_accuracy: 0.8239 - val_recall: 0.9854 - val_auc: 0.8062\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 276s 588ms/step - loss: 0.2523 - accuracy: 0.9079 - recall: 0.9407 - auc: 0.9513 - val_loss: 0.2017 - val_accuracy: 0.9189 - val_recall: 0.9518 - val_auc: 0.9671\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 279s 593ms/step - loss: 0.2206 - accuracy: 0.9175 - recall: 0.9495 - auc: 0.9615 - val_loss: 0.2875 - val_accuracy: 0.8815 - val_recall: 0.8480 - val_auc: 0.9809\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 273s 582ms/step - loss: 0.2005 - accuracy: 0.9250 - recall: 0.9514 - auc: 0.9690 - val_loss: 0.2120 - val_accuracy: 0.9082 - val_recall: 0.9693 - val_auc: 0.9699\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 278s 593ms/step - loss: 0.1859 - accuracy: 0.9338 - recall: 0.9561 - auc: 0.9700 - val_loss: 0.1673 - val_accuracy: 0.9466 - val_recall: 0.9561 - val_auc: 0.9802\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 290s 618ms/step - loss: 0.1772 - accuracy: 0.9349 - recall: 0.9576 - auc: 0.9740 - val_loss: 0.2201 - val_accuracy: 0.9210 - val_recall: 0.9883 - val_auc: 0.9721\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 268s 571ms/step - loss: 0.1836 - accuracy: 0.9373 - recall: 0.9587 - auc: 0.9728 - val_loss: 0.2167 - val_accuracy: 0.9018 - val_recall: 0.9766 - val_auc: 0.9709\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 287s 612ms/step - loss: 0.1505 - accuracy: 0.9450 - recall: 0.9726 - auc: 0.9803 - val_loss: 0.1462 - val_accuracy: 0.9541 - val_recall: 0.9737 - val_auc: 0.9816\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 284s 604ms/step - loss: 0.1352 - accuracy: 0.9522 - recall: 0.9751 - auc: 0.9842 - val_loss: 0.1427 - val_accuracy: 0.9477 - val_recall: 0.9722 - val_auc: 0.9848\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 306s 653ms/step - loss: 0.1467 - accuracy: 0.9493 - recall: 0.9718 - auc: 0.9818 - val_loss: 0.2288 - val_accuracy: 0.9125 - val_recall: 0.9927 - val_auc: 0.9764\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 280s 596ms/step - loss: 0.1446 - accuracy: 0.9536 - recall: 0.9751 - auc: 0.9802 - val_loss: 0.1525 - val_accuracy: 0.9413 - val_recall: 0.9401 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 280s 598ms/step - loss: 0.1198 - accuracy: 0.9592 - recall: 0.9777 - auc: 0.9867 - val_loss: 0.1142 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9887\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 285s 607ms/step - loss: 0.1158 - accuracy: 0.9602 - recall: 0.9839 - auc: 0.9867 - val_loss: 0.1305 - val_accuracy: 0.9477 - val_recall: 0.9825 - val_auc: 0.9843\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 295s 628ms/step - loss: 0.1137 - accuracy: 0.9613 - recall: 0.9821 - auc: 0.9873 - val_loss: 0.1483 - val_accuracy: 0.9392 - val_recall: 0.9868 - val_auc: 0.9849\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 306s 652ms/step - loss: 0.1059 - accuracy: 0.9597 - recall: 0.9828 - auc: 0.9897 - val_loss: 0.1266 - val_accuracy: 0.9445 - val_recall: 0.9781 - val_auc: 0.9875\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 302s 643ms/step - loss: 0.1121 - accuracy: 0.9613 - recall: 0.9821 - auc: 0.9875 - val_loss: 0.1175 - val_accuracy: 0.9552 - val_recall: 0.9722 - val_auc: 0.9892\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 317s 677ms/step - loss: 0.0843 - accuracy: 0.9672 - recall: 0.9802 - auc: 0.9934 - val_loss: 0.1445 - val_accuracy: 0.9445 - val_recall: 0.9898 - val_auc: 0.9875\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 327s 697ms/step - loss: 0.1014 - accuracy: 0.9624 - recall: 0.9832 - auc: 0.9900 - val_loss: 0.1900 - val_accuracy: 0.9168 - val_recall: 0.9898 - val_auc: 0.9781\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 306s 651ms/step - loss: 0.0872 - accuracy: 0.9666 - recall: 0.9839 - auc: 0.9921 - val_loss: 0.1325 - val_accuracy: 0.9541 - val_recall: 0.9839 - val_auc: 0.9839\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 306s 651ms/step - loss: 0.0859 - accuracy: 0.9717 - recall: 0.9868 - auc: 0.9925 - val_loss: 0.1652 - val_accuracy: 0.9520 - val_recall: 0.9883 - val_auc: 0.9805\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.386609  0.846811  0.895391  0.893118  1.092505      0.823906   \n",
      "1   0.252285  0.907926  0.940746  0.951273  0.201670      0.918890   \n",
      "2   0.220556  0.917534  0.949525  0.961524  0.287459      0.881537   \n",
      "3   0.200501  0.925007  0.951353  0.968964  0.211960      0.908218   \n",
      "4   0.185861  0.933814  0.956108  0.969972  0.167314      0.946638   \n",
      "5   0.177244  0.934881  0.957571  0.973954  0.220057      0.921025   \n",
      "6   0.183617  0.937283  0.958669  0.972797  0.216740      0.901814   \n",
      "7   0.150529  0.945023  0.972568  0.980254  0.146202      0.954109   \n",
      "8   0.135162  0.952228  0.975128  0.984187  0.142713      0.947705   \n",
      "9   0.146724  0.949293  0.971836  0.981848  0.228768      0.912487   \n",
      "10  0.144562  0.953563  0.975128  0.980245  0.152535      0.941302   \n",
      "11  0.119796  0.959167  0.977688  0.986652  0.114245      0.955176   \n",
      "12  0.115762  0.960235  0.983906  0.986721  0.130477      0.947705   \n",
      "13  0.113708  0.961302  0.982078  0.987251  0.148299      0.939168   \n",
      "14  0.105911  0.959701  0.982809  0.989748  0.126611      0.944504   \n",
      "15  0.112121  0.961302  0.982078  0.987466  0.117508      0.955176   \n",
      "16  0.084334  0.967174  0.980249  0.993425  0.144502      0.944504   \n",
      "17  0.101403  0.962370  0.983175  0.990006  0.189984      0.916756   \n",
      "18  0.087178  0.966640  0.983906  0.992130  0.132539      0.954109   \n",
      "19  0.085940  0.971711  0.986832  0.992497  0.165236      0.951974   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.985380  0.806209  \n",
      "1     0.951754  0.967082  \n",
      "2     0.847953  0.980884  \n",
      "3     0.969298  0.969931  \n",
      "4     0.956140  0.980203  \n",
      "5     0.988304  0.972127  \n",
      "6     0.976608  0.970873  \n",
      "7     0.973684  0.981638  \n",
      "8     0.972222  0.984834  \n",
      "9     0.992690  0.976351  \n",
      "10    0.940058  0.986544  \n",
      "11    0.979532  0.988737  \n",
      "12    0.982456  0.984262  \n",
      "13    0.986842  0.984872  \n",
      "14    0.978070  0.987512  \n",
      "15    0.972222  0.989226  \n",
      "16    0.989766  0.987486  \n",
      "17    0.989766  0.978148  \n",
      "18    0.983918  0.983915  \n",
      "19    0.988304  0.980532  \n",
      "147/147 [==============================] - 42s 283ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.3923 - accuracy: 0.8353 - recall: 0.8983 - auc: 0.8870 - val_loss: 0.2534 - val_accuracy: 0.9018 - val_recall: 0.8947 - val_auc: 0.9648\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.2500 - accuracy: 0.9103 - recall: 0.9448 - auc: 0.9517 - val_loss: 0.3004 - val_accuracy: 0.8485 - val_recall: 0.9927 - val_auc: 0.9724\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.2026 - accuracy: 0.9253 - recall: 0.9510 - auc: 0.9673 - val_loss: 0.1695 - val_accuracy: 0.9402 - val_recall: 0.9708 - val_auc: 0.9791\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 313s 1s/step - loss: 0.1844 - accuracy: 0.9341 - recall: 0.9583 - auc: 0.9714 - val_loss: 0.4647 - val_accuracy: 0.7823 - val_recall: 0.9985 - val_auc: 0.9577\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 318s 1s/step - loss: 0.1608 - accuracy: 0.9408 - recall: 0.9623 - auc: 0.9788 - val_loss: 0.2550 - val_accuracy: 0.8975 - val_recall: 0.9971 - val_auc: 0.9759\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 316s 1s/step - loss: 0.1515 - accuracy: 0.9480 - recall: 0.9693 - auc: 0.9797 - val_loss: 0.1309 - val_accuracy: 0.9530 - val_recall: 0.9795 - val_auc: 0.9866\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 321s 1s/step - loss: 0.1441 - accuracy: 0.9437 - recall: 0.9645 - auc: 0.9824 - val_loss: 0.1881 - val_accuracy: 0.9306 - val_recall: 0.9795 - val_auc: 0.9788\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 320s 1s/step - loss: 0.1433 - accuracy: 0.9512 - recall: 0.9693 - auc: 0.9822 - val_loss: 0.1454 - val_accuracy: 0.9466 - val_recall: 0.9664 - val_auc: 0.9815\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 322s 1s/step - loss: 0.1477 - accuracy: 0.9520 - recall: 0.9700 - auc: 0.9816 - val_loss: 0.1859 - val_accuracy: 0.9381 - val_recall: 0.9868 - val_auc: 0.9761\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 317s 1s/step - loss: 0.1249 - accuracy: 0.9544 - recall: 0.9737 - auc: 0.9864 - val_loss: 0.1300 - val_accuracy: 0.9477 - val_recall: 0.9839 - val_auc: 0.9891\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 316s 1s/step - loss: 0.1369 - accuracy: 0.9493 - recall: 0.9689 - auc: 0.9833 - val_loss: 0.1379 - val_accuracy: 0.9509 - val_recall: 0.9664 - val_auc: 0.9847\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 315s 1s/step - loss: 0.1195 - accuracy: 0.9570 - recall: 0.9755 - auc: 0.9867 - val_loss: 0.1296 - val_accuracy: 0.9530 - val_recall: 0.9766 - val_auc: 0.9877\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 309s 1s/step - loss: 0.1082 - accuracy: 0.9621 - recall: 0.9781 - auc: 0.9887 - val_loss: 0.2695 - val_accuracy: 0.9328 - val_recall: 0.9839 - val_auc: 0.9614\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 314s 1s/step - loss: 0.1078 - accuracy: 0.9626 - recall: 0.9799 - auc: 0.9896 - val_loss: 0.1897 - val_accuracy: 0.9285 - val_recall: 0.9927 - val_auc: 0.9790\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 312s 1s/step - loss: 0.0926 - accuracy: 0.9634 - recall: 0.9795 - auc: 0.9909 - val_loss: 0.3959 - val_accuracy: 0.8762 - val_recall: 0.9781 - val_auc: 0.9422\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 306s 1s/step - loss: 0.0956 - accuracy: 0.9661 - recall: 0.9828 - auc: 0.9908 - val_loss: 0.1904 - val_accuracy: 0.9157 - val_recall: 0.9883 - val_auc: 0.9826\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 306s 1s/step - loss: 0.0956 - accuracy: 0.9656 - recall: 0.9850 - auc: 0.9913 - val_loss: 0.1685 - val_accuracy: 0.9466 - val_recall: 0.9459 - val_auc: 0.9880\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 313s 1s/step - loss: 0.0854 - accuracy: 0.9666 - recall: 0.9817 - auc: 0.9933 - val_loss: 0.1587 - val_accuracy: 0.9530 - val_recall: 0.9839 - val_auc: 0.9817\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 302s 1s/step - loss: 0.0729 - accuracy: 0.9728 - recall: 0.9868 - auc: 0.9943 - val_loss: 0.1651 - val_accuracy: 0.9498 - val_recall: 0.9532 - val_auc: 0.9862\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 303s 1s/step - loss: 0.0771 - accuracy: 0.9709 - recall: 0.9835 - auc: 0.9943 - val_loss: 0.4384 - val_accuracy: 0.8730 - val_recall: 0.9956 - val_auc: 0.9552\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.392270  0.835335  0.898317  0.887002  0.253398      0.901814   \n",
      "1   0.250020  0.910328  0.944770  0.951670  0.300411      0.848453   \n",
      "2   0.202594  0.925274  0.950988  0.967322  0.169460      0.940235   \n",
      "3   0.184405  0.934081  0.958303  0.971395  0.464734      0.782284   \n",
      "4   0.160821  0.940753  0.962326  0.978756  0.254979      0.897545   \n",
      "5   0.151456  0.947958  0.969276  0.979726  0.130875      0.953042   \n",
      "6   0.144052  0.943688  0.964521  0.982418  0.188075      0.930630   \n",
      "7   0.143325  0.951161  0.969276  0.982162  0.145424      0.946638   \n",
      "8   0.147744  0.951962  0.970007  0.981592  0.185894      0.938100   \n",
      "9   0.124939  0.954363  0.973665  0.986411  0.129965      0.947705   \n",
      "10  0.136912  0.949293  0.968910  0.983274  0.137922      0.950907   \n",
      "11  0.119509  0.957032  0.975494  0.986695  0.129646      0.953042   \n",
      "12  0.108157  0.962103  0.978054  0.988696  0.269456      0.932764   \n",
      "13  0.107792  0.962637  0.979883  0.989636  0.189680      0.928495   \n",
      "14  0.092625  0.963437  0.979517  0.990857  0.395899      0.876201   \n",
      "15  0.095634  0.966106  0.982809  0.990835  0.190425      0.915688   \n",
      "16  0.095645  0.965572  0.985004  0.991307  0.168523      0.946638   \n",
      "17  0.085355  0.966640  0.981712  0.993325  0.158685      0.953042   \n",
      "18  0.072912  0.972778  0.986832  0.994327  0.165136      0.949840   \n",
      "19  0.077068  0.970910  0.983541  0.994289  0.438372      0.872999   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.894737  0.964803  \n",
      "1     0.992690  0.972352  \n",
      "2     0.970760  0.979107  \n",
      "3     0.998538  0.957689  \n",
      "4     0.997076  0.975877  \n",
      "5     0.979532  0.986605  \n",
      "6     0.979532  0.978792  \n",
      "7     0.966374  0.981532  \n",
      "8     0.986842  0.976076  \n",
      "9     0.983918  0.989055  \n",
      "10    0.966374  0.984652  \n",
      "11    0.976608  0.987718  \n",
      "12    0.983918  0.961356  \n",
      "13    0.992690  0.978983  \n",
      "14    0.978070  0.942173  \n",
      "15    0.988304  0.982598  \n",
      "16    0.945906  0.987980  \n",
      "17    0.983918  0.981679  \n",
      "18    0.953216  0.986230  \n",
      "19    0.995614  0.955230  \n",
      "74/74 [==============================] - 38s 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 298s 2s/step - loss: 0.3803 - accuracy: 0.8332 - recall: 0.8969 - auc: 0.8944 - val_loss: 0.2875 - val_accuracy: 0.8847 - val_recall: 0.8845 - val_auc: 0.9501\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 302s 2s/step - loss: 0.2597 - accuracy: 0.8943 - recall: 0.9309 - auc: 0.9468 - val_loss: 0.4840 - val_accuracy: 0.7919 - val_recall: 0.9971 - val_auc: 0.9386\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.2079 - accuracy: 0.9181 - recall: 0.9422 - auc: 0.9652 - val_loss: 0.2073 - val_accuracy: 0.9125 - val_recall: 0.9079 - val_auc: 0.9697\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1986 - accuracy: 0.9239 - recall: 0.9488 - auc: 0.9690 - val_loss: 0.2481 - val_accuracy: 0.9189 - val_recall: 0.9211 - val_auc: 0.9660\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1800 - accuracy: 0.9362 - recall: 0.9543 - auc: 0.9729 - val_loss: 1.0167 - val_accuracy: 0.7449 - val_recall: 1.0000 - val_auc: 0.8693\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 300s 2s/step - loss: 0.1779 - accuracy: 0.9365 - recall: 0.9594 - auc: 0.9741 - val_loss: 0.2018 - val_accuracy: 0.9189 - val_recall: 0.9371 - val_auc: 0.9656\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 299s 2s/step - loss: 0.1618 - accuracy: 0.9424 - recall: 0.9605 - auc: 0.9784 - val_loss: 1.0493 - val_accuracy: 0.7972 - val_recall: 0.9985 - val_auc: 0.8135\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 301s 2s/step - loss: 0.1645 - accuracy: 0.9426 - recall: 0.9645 - auc: 0.9759 - val_loss: 0.3139 - val_accuracy: 0.8559 - val_recall: 0.9971 - val_auc: 0.9784\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1580 - accuracy: 0.9426 - recall: 0.9649 - auc: 0.9780 - val_loss: 0.3486 - val_accuracy: 0.8687 - val_recall: 0.8289 - val_auc: 0.9797\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1524 - accuracy: 0.9424 - recall: 0.9653 - auc: 0.9810 - val_loss: 0.1390 - val_accuracy: 0.9488 - val_recall: 0.9825 - val_auc: 0.9852\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1670 - accuracy: 0.9434 - recall: 0.9678 - auc: 0.9760 - val_loss: 0.1528 - val_accuracy: 0.9456 - val_recall: 0.9576 - val_auc: 0.9843\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1464 - accuracy: 0.9509 - recall: 0.9729 - auc: 0.9811 - val_loss: 0.1616 - val_accuracy: 0.9456 - val_recall: 0.9547 - val_auc: 0.9810\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 303s 2s/step - loss: 0.1324 - accuracy: 0.9528 - recall: 0.9751 - auc: 0.9839 - val_loss: 0.1560 - val_accuracy: 0.9392 - val_recall: 0.9722 - val_auc: 0.9792\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1164 - accuracy: 0.9576 - recall: 0.9799 - auc: 0.9880 - val_loss: 0.1896 - val_accuracy: 0.9381 - val_recall: 0.9488 - val_auc: 0.9768\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.1176 - accuracy: 0.9610 - recall: 0.9788 - auc: 0.9879 - val_loss: 0.1318 - val_accuracy: 0.9402 - val_recall: 0.9795 - val_auc: 0.9888\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.1076 - accuracy: 0.9616 - recall: 0.9781 - auc: 0.9891 - val_loss: 0.2367 - val_accuracy: 0.9125 - val_recall: 0.9766 - val_auc: 0.9662\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0980 - accuracy: 0.9624 - recall: 0.9821 - auc: 0.9909 - val_loss: 0.1335 - val_accuracy: 0.9509 - val_recall: 0.9722 - val_auc: 0.9853\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 293s 2s/step - loss: 0.0971 - accuracy: 0.9645 - recall: 0.9799 - auc: 0.9922 - val_loss: 0.1333 - val_accuracy: 0.9594 - val_recall: 0.9576 - val_auc: 0.9909\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0918 - accuracy: 0.9653 - recall: 0.9788 - auc: 0.9927 - val_loss: 0.1099 - val_accuracy: 0.9605 - val_recall: 0.9781 - val_auc: 0.9890\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0960 - accuracy: 0.9632 - recall: 0.9810 - auc: 0.9909 - val_loss: 0.1144 - val_accuracy: 0.9605 - val_recall: 0.9751 - val_auc: 0.9890\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.380252  0.833200  0.896854  0.894387  0.287453      0.884739   \n",
      "1   0.259725  0.894315  0.930871  0.946787  0.483956      0.791889   \n",
      "2   0.207932  0.918068  0.942209  0.965220  0.207346      0.912487   \n",
      "3   0.198569  0.923939  0.948793  0.969020  0.248135      0.918890   \n",
      "4   0.180023  0.936216  0.954279  0.972942  1.016667      0.744931   \n",
      "5   0.177874  0.936483  0.959400  0.974108  0.201840      0.918890   \n",
      "6   0.161784  0.942354  0.960497  0.978440  1.049334      0.797225   \n",
      "7   0.164451  0.942621  0.964521  0.975916  0.313923      0.855923   \n",
      "8   0.157995  0.942621  0.964887  0.978000  0.348574      0.868730   \n",
      "9   0.152432  0.942354  0.965252  0.981040  0.139046      0.948773   \n",
      "10  0.167000  0.943421  0.967813  0.975951  0.152814      0.945571   \n",
      "11  0.146427  0.950894  0.972933  0.981107  0.161598      0.945571   \n",
      "12  0.132363  0.952762  0.975128  0.983882  0.156023      0.939168   \n",
      "13  0.116385  0.957566  0.979883  0.988008  0.189550      0.938100   \n",
      "14  0.117560  0.961035  0.978786  0.987901  0.131832      0.940235   \n",
      "15  0.107592  0.961569  0.978054  0.989086  0.236656      0.912487   \n",
      "16  0.097976  0.962370  0.982078  0.990899  0.133475      0.950907   \n",
      "17  0.097141  0.964505  0.979883  0.992244  0.133346      0.959445   \n",
      "18  0.091761  0.965306  0.978786  0.992704  0.109932      0.960512   \n",
      "19  0.095968  0.963171  0.980980  0.990902  0.114390      0.960512   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.884503  0.950087  \n",
      "1     0.997076  0.938649  \n",
      "2     0.907895  0.969749  \n",
      "3     0.921053  0.966010  \n",
      "4     1.000000  0.869294  \n",
      "5     0.937135  0.965591  \n",
      "6     0.998538  0.813524  \n",
      "7     0.997076  0.978374  \n",
      "8     0.828947  0.979743  \n",
      "9     0.982456  0.985207  \n",
      "10    0.957602  0.984320  \n",
      "11    0.954678  0.981037  \n",
      "12    0.972222  0.979151  \n",
      "13    0.948830  0.976842  \n",
      "14    0.979532  0.988821  \n",
      "15    0.976608  0.966210  \n",
      "16    0.972222  0.985259  \n",
      "17    0.957602  0.990945  \n",
      "18    0.978070  0.989012  \n",
      "19    0.975146  0.988954  \n",
      "59/59 [==============================] - 37s 627ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 295s 2s/step - loss: 0.3638 - accuracy: 0.8519 - recall: 0.8928 - auc: 0.9080 - val_loss: 0.7170 - val_accuracy: 0.7588 - val_recall: 0.9123 - val_auc: 0.8087\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.2894 - accuracy: 0.8858 - recall: 0.9137 - auc: 0.9384 - val_loss: 0.2182 - val_accuracy: 0.9072 - val_recall: 0.9064 - val_auc: 0.9719\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.2220 - accuracy: 0.9141 - recall: 0.9407 - auc: 0.9616 - val_loss: 0.3776 - val_accuracy: 0.8196 - val_recall: 0.9605 - val_auc: 0.9180\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 295s 2s/step - loss: 0.2091 - accuracy: 0.9226 - recall: 0.9444 - auc: 0.9645 - val_loss: 1.5950 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6756\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 305s 3s/step - loss: 0.1739 - accuracy: 0.9325 - recall: 0.9535 - auc: 0.9735 - val_loss: 0.7153 - val_accuracy: 0.7449 - val_recall: 0.9985 - val_auc: 0.9198\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 301s 3s/step - loss: 0.1666 - accuracy: 0.9410 - recall: 0.9631 - auc: 0.9777 - val_loss: 1.2469 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.8054\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 313s 3s/step - loss: 0.1433 - accuracy: 0.9488 - recall: 0.9671 - auc: 0.9830 - val_loss: 0.2165 - val_accuracy: 0.9306 - val_recall: 0.9254 - val_auc: 0.9837\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 305s 3s/step - loss: 0.1240 - accuracy: 0.9586 - recall: 0.9777 - auc: 0.9858 - val_loss: 0.1623 - val_accuracy: 0.9402 - val_recall: 0.9854 - val_auc: 0.9810\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 303s 3s/step - loss: 0.1306 - accuracy: 0.9482 - recall: 0.9689 - auc: 0.9848 - val_loss: 0.7674 - val_accuracy: 0.7737 - val_recall: 0.9927 - val_auc: 0.9060\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 310s 3s/step - loss: 0.1708 - accuracy: 0.9410 - recall: 0.9634 - auc: 0.9747 - val_loss: 0.4736 - val_accuracy: 0.7759 - val_recall: 0.9985 - val_auc: 0.9452\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.1235 - accuracy: 0.9557 - recall: 0.9700 - auc: 0.9862 - val_loss: 0.1315 - val_accuracy: 0.9573 - val_recall: 0.9810 - val_auc: 0.9851\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.1120 - accuracy: 0.9602 - recall: 0.9770 - auc: 0.9879 - val_loss: 0.6829 - val_accuracy: 0.7716 - val_recall: 1.0000 - val_auc: 0.9449\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.1031 - accuracy: 0.9661 - recall: 0.9810 - auc: 0.9890 - val_loss: 0.8163 - val_accuracy: 0.7866 - val_recall: 1.0000 - val_auc: 0.8678\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.1002 - accuracy: 0.9634 - recall: 0.9792 - auc: 0.9910 - val_loss: 0.5147 - val_accuracy: 0.8388 - val_recall: 0.9927 - val_auc: 0.9350\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.1159 - accuracy: 0.9562 - recall: 0.9781 - auc: 0.9883 - val_loss: 0.1440 - val_accuracy: 0.9562 - val_recall: 0.9825 - val_auc: 0.9826\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.0999 - accuracy: 0.9661 - recall: 0.9835 - auc: 0.9902 - val_loss: 0.2331 - val_accuracy: 0.9221 - val_recall: 0.9912 - val_auc: 0.9732\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.0876 - accuracy: 0.9658 - recall: 0.9817 - auc: 0.9934 - val_loss: 0.1474 - val_accuracy: 0.9498 - val_recall: 0.9898 - val_auc: 0.9827\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 294s 2s/step - loss: 0.0880 - accuracy: 0.9701 - recall: 0.9843 - auc: 0.9922 - val_loss: 0.3680 - val_accuracy: 0.8645 - val_recall: 0.9985 - val_auc: 0.9530\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 289s 2s/step - loss: 0.0847 - accuracy: 0.9704 - recall: 0.9850 - auc: 0.9936 - val_loss: 0.2071 - val_accuracy: 0.9349 - val_recall: 0.9898 - val_auc: 0.9750\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.0699 - accuracy: 0.9762 - recall: 0.9857 - auc: 0.9959 - val_loss: 0.2761 - val_accuracy: 0.9242 - val_recall: 0.9912 - val_auc: 0.9621\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.363765  0.851882  0.892831  0.908013  0.716968      0.758805   \n",
      "1   0.289414  0.885775  0.913680  0.938394  0.218245      0.907151   \n",
      "2   0.221990  0.914065  0.940746  0.961584  0.377642      0.819637   \n",
      "3   0.209054  0.922605  0.944404  0.964450  1.594999      0.729989   \n",
      "4   0.173887  0.932479  0.953548  0.973517  0.715263      0.744931   \n",
      "5   0.166581  0.941019  0.963058  0.977714  1.246939      0.738527   \n",
      "6   0.143334  0.948759  0.967081  0.982976  0.216453      0.930630   \n",
      "7   0.123992  0.958634  0.977688  0.985828  0.162308      0.940235   \n",
      "8   0.130584  0.948225  0.968910  0.984791  0.767446      0.773746   \n",
      "9   0.170808  0.941019  0.963424  0.974658  0.473570      0.775880   \n",
      "10  0.123462  0.955698  0.970007  0.986189  0.131548      0.957311   \n",
      "11  0.111973  0.960235  0.976957  0.987892  0.682946      0.771612   \n",
      "12  0.103086  0.966106  0.980980  0.988954  0.816289      0.786553   \n",
      "13  0.100228  0.963437  0.979151  0.990959  0.514670      0.838847   \n",
      "14  0.115870  0.956232  0.978054  0.988330  0.143968      0.956243   \n",
      "15  0.099863  0.966106  0.983541  0.990236  0.233116      0.922092   \n",
      "16  0.087565  0.965839  0.981712  0.993385  0.147410      0.949840   \n",
      "17  0.087954  0.970109  0.984272  0.992164  0.368027      0.864461   \n",
      "18  0.084665  0.970376  0.985004  0.993645  0.207058      0.934899   \n",
      "19  0.069873  0.976248  0.985735  0.995893  0.276110      0.924226   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.912281  0.808719  \n",
      "1     0.906433  0.971890  \n",
      "2     0.960526  0.917964  \n",
      "3     1.000000  0.675583  \n",
      "4     0.998538  0.919799  \n",
      "5     1.000000  0.805362  \n",
      "6     0.925439  0.983739  \n",
      "7     0.985380  0.981037  \n",
      "8     0.992690  0.906005  \n",
      "9     0.998538  0.945213  \n",
      "10    0.980994  0.985120  \n",
      "11    1.000000  0.944907  \n",
      "12    1.000000  0.867840  \n",
      "13    0.992690  0.935043  \n",
      "14    0.982456  0.982647  \n",
      "15    0.991228  0.973173  \n",
      "16    0.989766  0.982739  \n",
      "17    0.998538  0.953049  \n",
      "18    0.989766  0.974990  \n",
      "19    0.991228  0.962101  \n",
      "37/37 [==============================] - 36s 965ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.3698 - accuracy: 0.8297 - recall: 0.8855 - auc: 0.8967 - val_loss: 0.3438 - val_accuracy: 0.8420 - val_recall: 0.9152 - val_auc: 0.9015\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.2621 - accuracy: 0.8956 - recall: 0.9276 - auc: 0.9503 - val_loss: 0.8927 - val_accuracy: 0.7524 - val_recall: 0.9985 - val_auc: 0.8831\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.2068 - accuracy: 0.9221 - recall: 0.9488 - auc: 0.9675 - val_loss: 2.1253 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5388\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1981 - accuracy: 0.9221 - recall: 0.9503 - auc: 0.9691 - val_loss: 1.0496 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.8798\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1860 - accuracy: 0.9314 - recall: 0.9568 - auc: 0.9733 - val_loss: 0.3529 - val_accuracy: 0.8164 - val_recall: 0.9956 - val_auc: 0.9527\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1468 - accuracy: 0.9429 - recall: 0.9682 - auc: 0.9820 - val_loss: 0.5081 - val_accuracy: 0.8292 - val_recall: 0.9985 - val_auc: 0.9354\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1345 - accuracy: 0.9514 - recall: 0.9707 - auc: 0.9836 - val_loss: 0.1687 - val_accuracy: 0.9477 - val_recall: 0.9561 - val_auc: 0.9831\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1297 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9858 - val_loss: 0.3947 - val_accuracy: 0.8623 - val_recall: 0.9971 - val_auc: 0.9614\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1266 - accuracy: 0.9618 - recall: 0.9795 - auc: 0.9863 - val_loss: 0.2896 - val_accuracy: 0.8911 - val_recall: 0.9971 - val_auc: 0.9778\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1266 - accuracy: 0.9525 - recall: 0.9671 - auc: 0.9871 - val_loss: 0.2470 - val_accuracy: 0.8837 - val_recall: 0.9942 - val_auc: 0.9743\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1055 - accuracy: 0.9605 - recall: 0.9788 - auc: 0.9897 - val_loss: 0.2188 - val_accuracy: 0.9072 - val_recall: 0.9693 - val_auc: 0.9704\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 277s 5s/step - loss: 0.0924 - accuracy: 0.9626 - recall: 0.9799 - auc: 0.9926 - val_loss: 0.2377 - val_accuracy: 0.8687 - val_recall: 0.9971 - val_auc: 0.9832\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0958 - accuracy: 0.9640 - recall: 0.9828 - auc: 0.9916 - val_loss: 0.4739 - val_accuracy: 0.8783 - val_recall: 0.9971 - val_auc: 0.9330\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0820 - accuracy: 0.9706 - recall: 0.9835 - auc: 0.9935 - val_loss: 0.2228 - val_accuracy: 0.9242 - val_recall: 0.9898 - val_auc: 0.9802\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.0900 - accuracy: 0.9701 - recall: 0.9835 - auc: 0.9926 - val_loss: 2.5554 - val_accuracy: 0.7364 - val_recall: 1.0000 - val_auc: 0.5921\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0875 - accuracy: 0.9658 - recall: 0.9835 - auc: 0.9930 - val_loss: 0.2372 - val_accuracy: 0.9328 - val_recall: 0.9225 - val_auc: 0.9853\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.0771 - accuracy: 0.9701 - recall: 0.9843 - auc: 0.9939 - val_loss: 0.1648 - val_accuracy: 0.9456 - val_recall: 0.9561 - val_auc: 0.9830\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.0725 - accuracy: 0.9728 - recall: 0.9865 - auc: 0.9953 - val_loss: 0.1844 - val_accuracy: 0.9392 - val_recall: 0.9795 - val_auc: 0.9754\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 297s 5s/step - loss: 0.0745 - accuracy: 0.9730 - recall: 0.9839 - auc: 0.9934 - val_loss: 0.2388 - val_accuracy: 0.9168 - val_recall: 0.9868 - val_auc: 0.9672\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 292s 5s/step - loss: 0.0683 - accuracy: 0.9730 - recall: 0.9821 - auc: 0.9954 - val_loss: 0.1131 - val_accuracy: 0.9605 - val_recall: 0.9781 - val_auc: 0.9873\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.369783  0.829730  0.885516  0.896664  0.343757      0.842049   \n",
      "1   0.262143  0.895650  0.927579  0.950316  0.892689      0.752401   \n",
      "2   0.206841  0.922071  0.948793  0.967498  2.125311      0.729989   \n",
      "3   0.198062  0.922071  0.950256  0.969140  1.049604      0.737460   \n",
      "4   0.185985  0.931412  0.956840  0.973279  0.352910      0.816435   \n",
      "5   0.146848  0.942888  0.968179  0.981984  0.508114      0.829242   \n",
      "6   0.134499  0.951428  0.970739  0.983579  0.168665      0.947705   \n",
      "7   0.129746  0.954897  0.971836  0.985813  0.394652      0.862327   \n",
      "8   0.126581  0.961836  0.979517  0.986311  0.289648      0.891142   \n",
      "9   0.126612  0.952495  0.967081  0.987118  0.246953      0.883671   \n",
      "10  0.105501  0.960502  0.978786  0.989739  0.218757      0.907151   \n",
      "11  0.092418  0.962637  0.979883  0.992550  0.237706      0.868730   \n",
      "12  0.095832  0.963971  0.982809  0.991608  0.473934      0.878335   \n",
      "13  0.081958  0.970643  0.983541  0.993484  0.222848      0.924226   \n",
      "14  0.090038  0.970109  0.983541  0.992553  2.555391      0.736393   \n",
      "15  0.087490  0.965839  0.983541  0.992981  0.237215      0.932764   \n",
      "16  0.077124  0.970109  0.984272  0.993931  0.164788      0.945571   \n",
      "17  0.072505  0.972778  0.986467  0.995258  0.184350      0.939168   \n",
      "18  0.074503  0.973045  0.983906  0.993383  0.238786      0.916756   \n",
      "19  0.068340  0.973045  0.982078  0.995428  0.113143      0.960512   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.915205  0.901480  \n",
      "1     0.998538  0.883133  \n",
      "2     1.000000  0.538815  \n",
      "3     1.000000  0.879776  \n",
      "4     0.995614  0.952696  \n",
      "5     0.998538  0.935441  \n",
      "6     0.956140  0.983083  \n",
      "7     0.997076  0.961442  \n",
      "8     0.997076  0.977822  \n",
      "9     0.994152  0.974323  \n",
      "10    0.969298  0.970356  \n",
      "11    0.997076  0.983233  \n",
      "12    0.997076  0.933003  \n",
      "13    0.989766  0.980223  \n",
      "14    1.000000  0.592062  \n",
      "15    0.922515  0.985345  \n",
      "16    0.956140  0.982976  \n",
      "17    0.979532  0.975380  \n",
      "18    0.986842  0.967183  \n",
      "19    0.978070  0.987255  \n",
      "19/19 [==============================] - 37s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#alexNet\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG' # directorio general donde se va a crear la carpeta del historico\n",
    "nombre_historico = 'historico_alexnet_arqu_batchsize' # nombre de la carpeta creada para guardar los historicos de la CNN alexNet\n",
    "tabla_arqu_batch_alexnet = arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos, target_size, directorio_historico, nombre_historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7400968-2326-40c3-b7fa-b9d81426bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.18      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        16         0.16      0.95       0.96    0.97  0.96         0.90  0.10   \n",
       "        20         1.83      0.74       0.74    1.00  0.85         0.04  0.96   \n",
       "        32         0.16      0.95       0.96    0.97  0.97         0.90  0.10   \n",
       "        64         0.19      0.95       0.94    0.99  0.97         0.84  0.16   \n",
       "Simple2 8          0.15      0.95       0.96    0.96  0.96         0.91  0.09   \n",
       "        16         0.14      0.95       0.96    0.98  0.97         0.88  0.12   \n",
       "        20         0.17      0.95       0.96    0.98  0.97         0.89  0.11   \n",
       "        32         0.21      0.94       0.97    0.95  0.96         0.92  0.08   \n",
       "        64         0.48      0.83       0.81    1.00  0.90         0.38  0.62   \n",
       "Simple3 8          0.18      0.94       0.93    0.99  0.96         0.81  0.19   \n",
       "        16         0.14      0.95       0.95    0.99  0.97         0.85  0.15   \n",
       "        20         0.15      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        32         0.31      0.91       0.90    0.99  0.94         0.72  0.28   \n",
       "        64         0.17      0.95       0.96    0.98  0.97         0.89  0.11   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.03  0.98  \n",
       "        16         0.03  0.98  \n",
       "        20         0.00  0.86  \n",
       "        32         0.03  0.98  \n",
       "        64         0.01  0.99  \n",
       "Simple2 8          0.04  0.98  \n",
       "        16         0.02  0.99  \n",
       "        20         0.02  0.98  \n",
       "        32         0.05  0.98  \n",
       "        64         0.00  0.98  \n",
       "Simple3 8          0.01  0.98  \n",
       "        16         0.01  0.98  \n",
       "        20         0.03  0.99  \n",
       "        32         0.01  0.98  \n",
       "        64         0.02  0.99  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a2a96-1b98-4f6e-849f-97a4ecb623f0",
   "metadata": {},
   "source": [
    "A partir de ahora, con los resultados obtenidos, se puede determinar que se va a trabajar con la CNN basada en alexNet, el modelo Simple3 y un batch size de 64. Todas las explicaciones se encuentran correctamente documentadas tanto en la memoria como en los anexos del TFG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c14476-66a8-40c7-9a36-ee0c3dbc3902",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura \"Simple3\" CNN AlexaNet y un batchsize de 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73731a-d655-471e-9c50-b140eb09768f",
   "metadata": {},
   "source": [
    "A partir de los resultados obtenidos previamente, se comparan distintos valores de número de neuronas en las capas ocultas para determinar con cuál funciona mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b48cb3f-7e05-4106-8555-daf0dde2a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple3 AlexNet batch size=64\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size, directorio_historico, nombre_historico):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas: lista con los distintos valores de neuronas en las capas ocultas para probar en cada entrenamiento\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función \n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test). En este caso seá 64\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá\n",
    "    ser (340,340) ya que se emplea la CNN de alexNet\n",
    "    - directorio_historico: str. Ruta general donde se va a crear la carpeta del historico\n",
    "    - nombre_historico: str. Nombre de la carpeta creada para guardar los historicos de la CNN AlexNet, modelo Simple3 y batch size=64\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    \n",
    "    #bucle en el que se recorren cada uno los valores de neuronas para las capas ocultas\n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple3 y la CNN de alexNet que es con el que se han obtenido mejores resultados\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "        #ENTRENAMIENTO\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) \n",
    "\n",
    "        #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "        nombre_archivo = f'historico_{neurona}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "        ruta_historico = os.path.join(directorio_historico, nombre_historico) #se guarda dentro de una nueva carpeta \n",
    "        # Crea la carpeta correspondiente si no existe\n",
    "        os.makedirs(ruta_historico, exist_ok=True)\n",
    "        ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "        historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        \n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "   \n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ae0dd62-ee02-48af-af94-827756ce2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Modelo con 512 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 236s 4s/step - loss: 0.4708 - accuracy: 0.8369 - recall: 0.9012 - auc: 0.8748 - val_loss: 1.1573 - val_accuracy: 0.3479 - val_recall: 0.1082 - val_auc: 0.9242\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 253s 4s/step - loss: 0.2688 - accuracy: 0.9053 - recall: 0.9334 - auc: 0.9460 - val_loss: 0.2655 - val_accuracy: 0.8922 - val_recall: 0.9708 - val_auc: 0.9575\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 254s 4s/step - loss: 0.1934 - accuracy: 0.9287 - recall: 0.9543 - auc: 0.9692 - val_loss: 0.7621 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.9304\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.1856 - accuracy: 0.9293 - recall: 0.9535 - auc: 0.9731 - val_loss: 0.6683 - val_accuracy: 0.7631 - val_recall: 1.0000 - val_auc: 0.9551\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1489 - accuracy: 0.9453 - recall: 0.9642 - auc: 0.9807 - val_loss: 0.3856 - val_accuracy: 0.8250 - val_recall: 0.9985 - val_auc: 0.9679\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.1421 - accuracy: 0.9458 - recall: 0.9663 - auc: 0.9835 - val_loss: 1.9012 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5381\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.1246 - accuracy: 0.9565 - recall: 0.9737 - auc: 0.9863 - val_loss: 0.2458 - val_accuracy: 0.9007 - val_recall: 0.9795 - val_auc: 0.9670\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1235 - accuracy: 0.9522 - recall: 0.9674 - auc: 0.9865 - val_loss: 0.1513 - val_accuracy: 0.9520 - val_recall: 0.9605 - val_auc: 0.9824\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1119 - accuracy: 0.9589 - recall: 0.9766 - auc: 0.9880 - val_loss: 0.1910 - val_accuracy: 0.9285 - val_recall: 0.9854 - val_auc: 0.9790\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1036 - accuracy: 0.9610 - recall: 0.9792 - auc: 0.9897 - val_loss: 0.1171 - val_accuracy: 0.9605 - val_recall: 0.9839 - val_auc: 0.9901\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0866 - accuracy: 0.9672 - recall: 0.9795 - auc: 0.9926 - val_loss: 0.2581 - val_accuracy: 0.8922 - val_recall: 0.9942 - val_auc: 0.9783\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0764 - accuracy: 0.9744 - recall: 0.9865 - auc: 0.9940 - val_loss: 0.1593 - val_accuracy: 0.9594 - val_recall: 0.9605 - val_auc: 0.9872\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0747 - accuracy: 0.9736 - recall: 0.9861 - auc: 0.9947 - val_loss: 0.1557 - val_accuracy: 0.9552 - val_recall: 0.9649 - val_auc: 0.9862\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0800 - accuracy: 0.9701 - recall: 0.9846 - auc: 0.9939 - val_loss: 0.3722 - val_accuracy: 0.8613 - val_recall: 0.9971 - val_auc: 0.9718\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0805 - accuracy: 0.9693 - recall: 0.9828 - auc: 0.9944 - val_loss: 0.1525 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9816\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0596 - accuracy: 0.9805 - recall: 0.9912 - auc: 0.9963 - val_loss: 0.8410 - val_accuracy: 0.8122 - val_recall: 0.9985 - val_auc: 0.8674\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0563 - accuracy: 0.9800 - recall: 0.9909 - auc: 0.9967 - val_loss: 0.1168 - val_accuracy: 0.9594 - val_recall: 0.9781 - val_auc: 0.9888\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0674 - accuracy: 0.9757 - recall: 0.9868 - auc: 0.9957 - val_loss: 0.2095 - val_accuracy: 0.9317 - val_recall: 0.9751 - val_auc: 0.9741\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0667 - accuracy: 0.9765 - recall: 0.9890 - auc: 0.9945 - val_loss: 0.3822 - val_accuracy: 0.8975 - val_recall: 0.9620 - val_auc: 0.9444\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0556 - accuracy: 0.9811 - recall: 0.9905 - auc: 0.9966 - val_loss: 0.2266 - val_accuracy: 0.9434 - val_recall: 0.9868 - val_auc: 0.9721\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.470828  0.836936  0.901244  0.874808  1.157280      0.347919   \n",
      "1   0.268767  0.905258  0.933431  0.945997  0.265501      0.892209   \n",
      "2   0.193384  0.928743  0.954279  0.969249  0.762084      0.758805   \n",
      "3   0.185574  0.929277  0.953548  0.973085  0.668329      0.763074   \n",
      "4   0.148860  0.945290  0.964155  0.980655  0.385554      0.824973   \n",
      "5   0.142095  0.945823  0.966350  0.983549  1.901228      0.729989   \n",
      "6   0.124650  0.956499  0.973665  0.986325  0.245778      0.900747   \n",
      "7   0.123502  0.952228  0.967447  0.986522  0.151268      0.951974   \n",
      "8   0.111935  0.958900  0.976591  0.987993  0.191036      0.928495   \n",
      "9   0.103572  0.961035  0.979151  0.989683  0.117100      0.960512   \n",
      "10  0.086598  0.967174  0.979517  0.992575  0.258088      0.892209   \n",
      "11  0.076367  0.974379  0.986467  0.993997  0.159292      0.959445   \n",
      "12  0.074654  0.973579  0.986101  0.994724  0.155718      0.955176   \n",
      "13  0.080011  0.970109  0.984638  0.993859  0.372215      0.861259   \n",
      "14  0.080460  0.969309  0.982809  0.994400  0.152473      0.940235   \n",
      "15  0.059585  0.980518  0.991222  0.996311  0.841036      0.812167   \n",
      "16  0.056290  0.979984  0.990856  0.996746  0.116838      0.959445   \n",
      "17  0.067434  0.975714  0.986832  0.995666  0.209484      0.931697   \n",
      "18  0.066709  0.976515  0.989027  0.994548  0.382179      0.897545   \n",
      "19  0.055586  0.981052  0.990490  0.996636  0.226607      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.108187  0.924231  \n",
      "1     0.970760  0.957498  \n",
      "2     1.000000  0.930411  \n",
      "3     1.000000  0.955077  \n",
      "4     0.998538  0.967859  \n",
      "5     1.000000  0.538098  \n",
      "6     0.979532  0.967030  \n",
      "7     0.960526  0.982364  \n",
      "8     0.985380  0.979029  \n",
      "9     0.983918  0.990113  \n",
      "10    0.994152  0.978293  \n",
      "11    0.960526  0.987221  \n",
      "12    0.964912  0.986198  \n",
      "13    0.997076  0.971792  \n",
      "14    0.961988  0.981610  \n",
      "15    0.998538  0.867364  \n",
      "16    0.978070  0.988787  \n",
      "17    0.975146  0.974080  \n",
      "18    0.961988  0.944352  \n",
      "19    0.986842  0.972141  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 1024 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.5301 - accuracy: 0.8281 - recall: 0.8855 - auc: 0.8656 - val_loss: 5.8967 - val_accuracy: 0.2711 - val_recall: 0.0015 - val_auc: 0.5456\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.2641 - accuracy: 0.9031 - recall: 0.9349 - auc: 0.9469 - val_loss: 0.8622 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.9516\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1865 - accuracy: 0.9285 - recall: 0.9568 - auc: 0.9718 - val_loss: 1.1636 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8607\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1749 - accuracy: 0.9338 - recall: 0.9583 - auc: 0.9733 - val_loss: 1.4292 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7482\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1361 - accuracy: 0.9477 - recall: 0.9653 - auc: 0.9843 - val_loss: 0.3373 - val_accuracy: 0.8623 - val_recall: 0.8246 - val_auc: 0.9707\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1439 - accuracy: 0.9453 - recall: 0.9671 - auc: 0.9827 - val_loss: 0.7290 - val_accuracy: 0.7567 - val_recall: 1.0000 - val_auc: 0.9397\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1143 - accuracy: 0.9576 - recall: 0.9773 - auc: 0.9882 - val_loss: 2.4738 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1063 - accuracy: 0.9632 - recall: 0.9792 - auc: 0.9876 - val_loss: 1.7107 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.6046\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1125 - accuracy: 0.9586 - recall: 0.9748 - auc: 0.9880 - val_loss: 1.2680 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8469\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0954 - accuracy: 0.9680 - recall: 0.9813 - auc: 0.9905 - val_loss: 0.9401 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8550\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0880 - accuracy: 0.9690 - recall: 0.9846 - auc: 0.9914 - val_loss: 1.7370 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.5945\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0997 - accuracy: 0.9602 - recall: 0.9762 - auc: 0.9902 - val_loss: 0.3943 - val_accuracy: 0.8292 - val_recall: 0.9956 - val_auc: 0.9600\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0934 - accuracy: 0.9629 - recall: 0.9795 - auc: 0.9921 - val_loss: 0.4291 - val_accuracy: 0.8047 - val_recall: 1.0000 - val_auc: 0.9734\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0772 - accuracy: 0.9709 - recall: 0.9839 - auc: 0.9948 - val_loss: 0.1356 - val_accuracy: 0.9584 - val_recall: 0.9766 - val_auc: 0.9847\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0694 - accuracy: 0.9744 - recall: 0.9868 - auc: 0.9954 - val_loss: 0.3344 - val_accuracy: 0.8388 - val_recall: 0.9912 - val_auc: 0.9498\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0733 - accuracy: 0.9738 - recall: 0.9846 - auc: 0.9942 - val_loss: 1.1044 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.8399\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0697 - accuracy: 0.9736 - recall: 0.9857 - auc: 0.9951 - val_loss: 0.1750 - val_accuracy: 0.9562 - val_recall: 0.9839 - val_auc: 0.9738\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0632 - accuracy: 0.9746 - recall: 0.9865 - auc: 0.9962 - val_loss: 0.1513 - val_accuracy: 0.9530 - val_recall: 0.9868 - val_auc: 0.9826\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0527 - accuracy: 0.9808 - recall: 0.9898 - auc: 0.9972 - val_loss: 0.2002 - val_accuracy: 0.9541 - val_recall: 0.9693 - val_auc: 0.9797\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0587 - accuracy: 0.9803 - recall: 0.9898 - auc: 0.9947 - val_loss: 0.1965 - val_accuracy: 0.9488 - val_recall: 0.9883 - val_auc: 0.9723\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.530102  0.828129  0.885516  0.865639  5.896713      0.271078   \n",
      "1   0.264127  0.903122  0.934894  0.946945  0.862186      0.729989   \n",
      "2   0.186493  0.928476  0.956840  0.971797  1.163648      0.731057   \n",
      "3   0.174923  0.933814  0.958303  0.973281  1.429186      0.729989   \n",
      "4   0.136135  0.947692  0.965252  0.984316  0.337250      0.862327   \n",
      "5   0.143866  0.945290  0.967081  0.982671  0.729039      0.756670   \n",
      "6   0.114251  0.957566  0.977323  0.988234  2.473793      0.729989   \n",
      "7   0.106278  0.963171  0.979151  0.987550  1.710713      0.731057   \n",
      "8   0.112528  0.958634  0.974762  0.987960  1.267959      0.731057   \n",
      "9   0.095442  0.967974  0.981346  0.990518  0.940124      0.731057   \n",
      "10  0.088009  0.969042  0.984638  0.991386  1.736952      0.731057   \n",
      "11  0.099682  0.960235  0.976225  0.990185  0.394298      0.829242   \n",
      "12  0.093394  0.962904  0.979517  0.992123  0.429072      0.804696   \n",
      "13  0.077160  0.970910  0.983906  0.994760  0.135580      0.958378   \n",
      "14  0.069383  0.974379  0.986832  0.995390  0.334371      0.838847   \n",
      "15  0.073321  0.973846  0.984638  0.994208  1.104434      0.758805   \n",
      "16  0.069680  0.973579  0.985735  0.995136  0.175011      0.956243   \n",
      "17  0.063173  0.974646  0.986467  0.996205  0.151286      0.953042   \n",
      "18  0.052656  0.980785  0.989759  0.997165  0.200240      0.954109   \n",
      "19  0.058719  0.980251  0.989759  0.994701  0.196542      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.001462  0.545648  \n",
      "1     1.000000  0.951584  \n",
      "2     1.000000  0.860655  \n",
      "3     1.000000  0.748186  \n",
      "4     0.824561  0.970691  \n",
      "5     1.000000  0.939654  \n",
      "6     1.000000  0.500000  \n",
      "7     1.000000  0.604573  \n",
      "8     1.000000  0.846896  \n",
      "9     1.000000  0.854957  \n",
      "10    1.000000  0.594477  \n",
      "11    0.995614  0.959951  \n",
      "12    1.000000  0.973387  \n",
      "13    0.976608  0.984744  \n",
      "14    0.991228  0.949810  \n",
      "15    1.000000  0.839872  \n",
      "16    0.983918  0.973800  \n",
      "17    0.986842  0.982650  \n",
      "18    0.969298  0.979734  \n",
      "19    0.988304  0.972323  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 2048 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.9212 - accuracy: 0.8289 - recall: 0.8877 - auc: 0.8543 - val_loss: 4.6468 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.4985\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.2409 - accuracy: 0.9018 - recall: 0.9305 - auc: 0.9537 - val_loss: 0.5688 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.9357\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.2029 - accuracy: 0.9239 - recall: 0.9481 - auc: 0.9670 - val_loss: 0.6861 - val_accuracy: 0.7343 - val_recall: 1.0000 - val_auc: 0.9486\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.1818 - accuracy: 0.9290 - recall: 0.9532 - auc: 0.9738 - val_loss: 0.2740 - val_accuracy: 0.8847 - val_recall: 0.9795 - val_auc: 0.9570\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.1698 - accuracy: 0.9346 - recall: 0.9565 - auc: 0.9755 - val_loss: 1.0614 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.8582\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1431 - accuracy: 0.9445 - recall: 0.9638 - auc: 0.9830 - val_loss: 2.0808 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5319\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1604 - accuracy: 0.9400 - recall: 0.9609 - auc: 0.9783 - val_loss: 2.2693 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5190\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.1317 - accuracy: 0.9509 - recall: 0.9715 - auc: 0.9847 - val_loss: 1.2488 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7833\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1252 - accuracy: 0.9565 - recall: 0.9715 - auc: 0.9846 - val_loss: 0.6132 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8771\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.1229 - accuracy: 0.9525 - recall: 0.9704 - auc: 0.9863 - val_loss: 1.8817 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5025\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0980 - accuracy: 0.9656 - recall: 0.9813 - auc: 0.9912 - val_loss: 0.6300 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.9478\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0959 - accuracy: 0.9640 - recall: 0.9777 - auc: 0.9917 - val_loss: 1.1068 - val_accuracy: 0.7449 - val_recall: 1.0000 - val_auc: 0.8532\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.0923 - accuracy: 0.9640 - recall: 0.9802 - auc: 0.9916 - val_loss: 0.3008 - val_accuracy: 0.8495 - val_recall: 0.9912 - val_auc: 0.9710\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0809 - accuracy: 0.9701 - recall: 0.9810 - auc: 0.9923 - val_loss: 0.1871 - val_accuracy: 0.9338 - val_recall: 0.9693 - val_auc: 0.9712\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0700 - accuracy: 0.9744 - recall: 0.9872 - auc: 0.9955 - val_loss: 0.3745 - val_accuracy: 0.8655 - val_recall: 0.9971 - val_auc: 0.9584\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.0721 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9952 - val_loss: 0.1329 - val_accuracy: 0.9498 - val_recall: 0.9576 - val_auc: 0.9862\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0750 - accuracy: 0.9722 - recall: 0.9824 - auc: 0.9943 - val_loss: 0.4313 - val_accuracy: 0.7930 - val_recall: 0.9868 - val_auc: 0.9004\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.0575 - accuracy: 0.9792 - recall: 0.9883 - auc: 0.9961 - val_loss: 0.1524 - val_accuracy: 0.9413 - val_recall: 0.9649 - val_auc: 0.9806\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0591 - accuracy: 0.9762 - recall: 0.9854 - auc: 0.9966 - val_loss: 0.4328 - val_accuracy: 0.9168 - val_recall: 0.9693 - val_auc: 0.9352\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0736 - accuracy: 0.9765 - recall: 0.9876 - auc: 0.9936 - val_loss: 0.1996 - val_accuracy: 0.9072 - val_recall: 0.9488 - val_auc: 0.9689\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.921205  0.828930  0.887710  0.854262  4.646806      0.729989   \n",
      "1   0.240912  0.901788  0.930505  0.953665  0.568845      0.737460   \n",
      "2   0.202896  0.923939  0.948061  0.966983  0.686120      0.734258   \n",
      "3   0.181832  0.929010  0.953182  0.973821  0.274046      0.884739   \n",
      "4   0.169791  0.934614  0.956474  0.975460  1.061414      0.735326   \n",
      "5   0.143069  0.944489  0.963789  0.983046  2.080767      0.729989   \n",
      "6   0.160447  0.939952  0.960863  0.978260  2.269310      0.729989   \n",
      "7   0.131745  0.950894  0.971470  0.984691  1.248754      0.729989   \n",
      "8   0.125241  0.956499  0.971470  0.984617  0.613244      0.729989   \n",
      "9   0.122868  0.952495  0.970373  0.986344  1.881663      0.729989   \n",
      "10  0.098003  0.965572  0.981346  0.991235  0.629963      0.735326   \n",
      "11  0.095867  0.963971  0.977688  0.991651  1.106832      0.744931   \n",
      "12  0.092287  0.963971  0.980249  0.991591  0.300815      0.849520   \n",
      "13  0.080886  0.970109  0.980980  0.992299  0.187149      0.933831   \n",
      "14  0.070016  0.974379  0.987198  0.995455  0.374477      0.865528   \n",
      "15  0.072095  0.973579  0.983175  0.995170  0.132929      0.949840   \n",
      "16  0.075025  0.972244  0.982443  0.994339  0.431314      0.792956   \n",
      "17  0.057452  0.979183  0.988296  0.996089  0.152395      0.941302   \n",
      "18  0.059068  0.976248  0.985369  0.996650  0.432823      0.916756   \n",
      "19  0.073602  0.976515  0.987564  0.993619  0.199598      0.907151   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.498538  \n",
      "1     1.000000  0.935678  \n",
      "2     1.000000  0.948619  \n",
      "3     0.979532  0.956967  \n",
      "4     1.000000  0.858178  \n",
      "5     1.000000  0.531933  \n",
      "6     1.000000  0.519009  \n",
      "7     1.000000  0.783273  \n",
      "8     1.000000  0.877106  \n",
      "9     1.000000  0.502496  \n",
      "10    1.000000  0.947790  \n",
      "11    1.000000  0.853186  \n",
      "12    0.991228  0.970951  \n",
      "13    0.969298  0.971182  \n",
      "14    0.997076  0.958420  \n",
      "15    0.957602  0.986152  \n",
      "16    0.986842  0.900354  \n",
      "17    0.964912  0.980610  \n",
      "18    0.969298  0.935199  \n",
      "19    0.948830  0.968905  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=64\n",
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG' # directorio general donde se va a crear la carpeta del historico\n",
    "nombre_historico = 'historico_3_64' # nombre de la carpeta creada para guardar los historicos de la CNN alexNet, modelo Simple3 y batchsize 64\n",
    "table_neuronas_simple3_64 = neuronas(num_neuronas, epochs, ruta, batch_size, target_size, directorio_historico, nombre_historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc46c5b-93f0-48ca-8bbc-365df29d7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024.0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048.0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Loss  Accuracy  Precision  Recall    F1  Specificity  \\\n",
       "Número de neuronas                                                         \n",
       "512.0               0.15      0.95       0.95    0.98  0.96         0.86   \n",
       "1024.0              0.23      0.94       0.93    0.99  0.96         0.81   \n",
       "2048.0              0.20      0.91       0.93    0.95  0.94         0.79   \n",
       "\n",
       "                     fpr   fnr   AUC  \n",
       "Número de neuronas                    \n",
       "512.0               0.14  0.02  0.98  \n",
       "1024.0              0.19  0.01  0.99  \n",
       "2048.0              0.21  0.05  0.97  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_neuronas_simple3_64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa1344-69d6-4800-8201-9fa62b2be003",
   "metadata": {},
   "source": [
    "Por lo tanto, se puede apreciar que, el mejor modelo se corresponde con el modelo realizado inicialmente con 100 y 16 neuronas en la última capa. Todas las axplicaciones correspondientes se encuentran en la memoria y anexos del TFG.\n",
    "\n",
    "El modelo final elegido es: CNN alexNet, modelo Simple3, batch size = 64 y 100 y 16 neuronas en la última capa reespectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700f86e-79e7-4849-9ae5-ed2561c7baa5",
   "metadata": {},
   "source": [
    "## Visualización por medio de una gráfica de la evolución tanto en accuracy como en loss en el entrenamiento y la validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab157af6-1b68-47d2-a051-1bcfe7ddecd8",
   "metadata": {},
   "source": [
    "En cada una de las funciones realizadas previamente donde se comparaban distintos modelos de CNN, distintas arquitecturas y distintos hiperparámetros, se han guardado en distintos csv los valores obtenidos del entrenamiento y validación (loss, accuracy, recall, auc, val_loss, val_accuracy, val_recall y val_auc). A partir de estos csv, se ha realizado una función para crear una gráfica con la columna loss y val_loss o auc y val_auc para visualizar el rendimiento del modelo a lo largo de tiempo tanto el de entrenamiento como el de validación. Con estas gráficas se puede observar si el modelo está aprendiendo correctamente o, por el contrario existe sobreajuste o subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cda88-63ee-4881-8a97-d15b3ada9661",
   "metadata": {},
   "source": [
    "#### Loss:\n",
    "- loss: mide el error del modelo en el conjunto de entrenameinto\n",
    "- val_loss: mide el error del modelo en el conjunto de validación\n",
    "\n",
    "Si ambas líneas descienden y se estabilizan, indica que el modelo está aprendiendo correctamente.\n",
    "Si la pérdida de validación empieza a aumentar mientras la pérdida de entrenamiento sigue disminuyendo, puede indicar sobreajuste.\n",
    "Si ambas líneas son altas y no descienden, puede indicar subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e6803-9c06-4784-874e-2829b14996b0",
   "metadata": {},
   "source": [
    "#### AUC\n",
    "- auc: mide la capacidad del modelo para distinguir entre clases (un valor mayor indica un mejor modelo)\n",
    "- val_auc: mide la capacidad del modelo para distinguir entre clases en el conjunto de validación (un valor mayor indica un mejor modelo)\n",
    "\n",
    "Si ambas líneas ascienden y se estabilizan en valores altos, indica un buen rendimiento del modelo.\n",
    "Si el AUC de validación disminuye mientras el AUC de entrenamiento sigue aumentando, puede indicar sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c78584-3367-4376-aa81-6901cd088c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grafica(directorio_historico, metrica_entrenamiento, metrica_validacion):\n",
    "\n",
    "    '''\n",
    "    Función empleada para la obtención de una gráfica a partir de uno de los csv creados previamente para observar la evolución de dos métricas \n",
    "    (loss o auc generalmente) durante el entrenamiento y la validación del modelo, lo cual es útil para evaluar el rendimiento \n",
    "    del modelo a lo largo de las épocas.\n",
    "    -----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_historico: directorio donde se encuentra el csv del que se desea obtener las gráficas.\n",
    "    - metrica_entrenamiento: metrica monitoreada durante el entrenamiento que se desea visualizar (loss o auc)\n",
    "    - metrica_validacion: metrica monitoreada durante la validación que se desea visualizar (val_loss o val_auc)\n",
    "    --------------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    # Se cargan los datos desde el archivo CSV\n",
    "    df_mejor = pd.read_csv(directorio_historico) \n",
    "    \n",
    "    \n",
    "    # 'columna1' y 'columna2' son los nombres de las columnas que se van a graficar\n",
    "    columna1 = df_mejor[metrica_entrenamiento]\n",
    "    columna2 = df_mejor[metrica_validacion]\n",
    "    \n",
    "    # Se crea la gráfica para las dos columnas\n",
    "    plt.plot(columna1, label='Entrenamiento')\n",
    "    plt.plot(columna2, label='Validación')\n",
    "    \n",
    "    # Se añaden etiquetas al eje x, el eje y y el título de la gráfica\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss/auc') \n",
    "    plt.title('Gráfico evolución entrenamiento y validación')\n",
    "    \n",
    "    # Se añade la leyenda\n",
    "    plt.legend()\n",
    "    \n",
    "    # Se muestra la gráfica\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2a44a-ce51-47d6-9d9d-0c0b570102af",
   "metadata": {},
   "source": [
    "#### Gráfica con la métrica AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec538d6-0371-4d78-b4d5-f945f55bba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG/historico_alexnet_arqu_batchsize/hist_anet_Simple3_64.csv' #cambiar directorio en caso que se emplee otro csv\n",
    "metrica_entrenamiento = 'auc' \n",
    "metrica_validacion = 'val_auc' \n",
    "\n",
    "graf_mejor_modelo=grafica(directorio_historico, metrica_entrenamiento, metrica_validacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac42feb-ac71-4268-94b0-840dc14244c7",
   "metadata": {},
   "source": [
    "#### Gráfica con la métrica loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a26e038-f31c-4f89-9369-5744bb4d8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG/historico_alexnet_arqu_batchsize/hist_anet_Simple3_64.csv' #cambiar directorio en caso que se emplee otro csv\n",
    "metrica_entrenamiento = 'loss' \n",
    "metrica_validacion = 'val_loss' \n",
    "\n",
    "graf_mejor_modelo=grafica(directorio_historico, metrica_entrenamiento, metrica_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0861be5-63bc-4386-83a9-bd839eb78501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec70ad44-41bf-4c21-897f-5dfa8f83fe0d",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como evoluciona del modelo más simple inicial al modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0aa3-f29f-4b6a-bd79-4aec32a7e8dd",
   "metadata": {},
   "source": [
    "Finalmente, se obtiene la matriz de confusión para el modelo inicial (más simple) y el modelo final obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50260c7-560c-42c8-821f-e71deb9e0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def matriz_conf_inicial(ruta, batch_size, target_size, epochs):\n",
    "\n",
    "    '''\n",
    "    Función que crea una matriz de confusión a partir del modelo inicial es decir, con la CNN propia y modelo Simple1 (sin capas ocultas).\n",
    "    ----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso,como se emplea\n",
    "    el modelo Simple1 con la CNN propia, donde el input_shape=(150,150,3), target_size tendrá que ser igual a (150,150)\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    -----------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "\n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    # se emplea el modelo más simple (Simple1) con CNN propia\n",
    "    model = keras.Sequential( \n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5), \n",
    "            layers.Dense(1, activation=\"sigmoid\"), #una unica neurona, sigmoide\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    epochs = epochs\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "    # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 5 épocas (patience)\n",
    "    model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) \n",
    "\n",
    "    # se calcula y_test e y_pred para obtener la matriz de confusion\n",
    "    y_test=test_generator.labels\n",
    "    y_pred=model.predict(test_generator)\n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "\n",
    "    \n",
    "    #PERCEPTRON SKLEARN\n",
    "    labels=np.unique(y_test)\n",
    "    \n",
    "    matriz_conf = metrics.confusion_matrix(y_test, y_pred_bin,labels=labels)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"NORMAL\" , \"PNEUMONIA\"])\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    cm_display.plot(ax=ax)\n",
    "    plt.title(\"Matriz inicial PNEUMONIA-NORMAL\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1c909d-e86c-489b-9f77-44dcf2f1626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 107s 560ms/step - loss: 0.2997 - accuracy: 0.8714 - recall: 0.9455 - auc: 0.9230 - val_loss: 0.1841 - val_accuracy: 0.9296 - val_recall: 0.9810 - val_auc: 0.9703\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 95s 504ms/step - loss: 0.1566 - accuracy: 0.9432 - recall: 0.9685 - auc: 0.9794 - val_loss: 0.1862 - val_accuracy: 0.9306 - val_recall: 0.9868 - val_auc: 0.9706\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 102s 542ms/step - loss: 0.1336 - accuracy: 0.9546 - recall: 0.9755 - auc: 0.9829 - val_loss: 0.2051 - val_accuracy: 0.9285 - val_recall: 0.9898 - val_auc: 0.9750\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 122s 649ms/step - loss: 0.1129 - accuracy: 0.9602 - recall: 0.9770 - auc: 0.9888 - val_loss: 0.1520 - val_accuracy: 0.9477 - val_recall: 0.9635 - val_auc: 0.9795\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 101s 536ms/step - loss: 0.0947 - accuracy: 0.9680 - recall: 0.9817 - auc: 0.9917 - val_loss: 0.1825 - val_accuracy: 0.9392 - val_recall: 0.9810 - val_auc: 0.9759\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 103s 546ms/step - loss: 0.0848 - accuracy: 0.9701 - recall: 0.9799 - auc: 0.9933 - val_loss: 0.1633 - val_accuracy: 0.9424 - val_recall: 0.9635 - val_auc: 0.9738\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 103s 548ms/step - loss: 0.0717 - accuracy: 0.9757 - recall: 0.9854 - auc: 0.9949 - val_loss: 0.1725 - val_accuracy: 0.9466 - val_recall: 0.9576 - val_auc: 0.9777\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 102s 542ms/step - loss: 0.0557 - accuracy: 0.9800 - recall: 0.9876 - auc: 0.9966 - val_loss: 0.1827 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9732\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 103s 546ms/step - loss: 0.0449 - accuracy: 0.9821 - recall: 0.9898 - auc: 0.9984 - val_loss: 0.2779 - val_accuracy: 0.9274 - val_recall: 0.9868 - val_auc: 0.9595\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 103s 549ms/step - loss: 0.0378 - accuracy: 0.9869 - recall: 0.9920 - auc: 0.9984 - val_loss: 0.1915 - val_accuracy: 0.9456 - val_recall: 0.9620 - val_auc: 0.9761\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 103s 547ms/step - loss: 0.0359 - accuracy: 0.9880 - recall: 0.9923 - auc: 0.9989 - val_loss: 0.2151 - val_accuracy: 0.9413 - val_recall: 0.9503 - val_auc: 0.9726\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 102s 541ms/step - loss: 0.0347 - accuracy: 0.9893 - recall: 0.9931 - auc: 0.9990 - val_loss: 0.2083 - val_accuracy: 0.9488 - val_recall: 0.9591 - val_auc: 0.9733\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 106s 566ms/step - loss: 0.0292 - accuracy: 0.9917 - recall: 0.9941 - auc: 0.9984 - val_loss: 0.2422 - val_accuracy: 0.9381 - val_recall: 0.9722 - val_auc: 0.9620\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 107s 570ms/step - loss: 0.0228 - accuracy: 0.9917 - recall: 0.9945 - auc: 0.9996 - val_loss: 0.2450 - val_accuracy: 0.9445 - val_recall: 0.9678 - val_auc: 0.9672\n",
      "59/59 [==============================] - 23s 393ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGaCAYAAAB0c4sFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABen0lEQVR4nO3deVhU1RsH8O9lGxYBQYEBQ3DBFdxN0VJKcMkls0RETQNNszRS0sxU1AQxA8u1jM0Ft1JTKxXLNLdESnNLTcEVwp8hOwww9/cHcZtxBpzRUUS+n577PM255545AyPzznuWK4iiKIKIiIgIgFF1d4CIiIieHAwMiIiISMLAgIiIiCQMDIiIiEjCwICIiIgkDAyIiIhIwsCAiIiIJCbV3QEiIqInRVFRERQKhcHaMzMzg7m5ucHaexwYGBAREaE8KGjkVgcZmWUGa1MulyM1NbVGBQcMDIiIiAAoFApkZJbhaoo7bKwffqQ9J1cJt45pUCgUDAyIiIhqqjrWAupYCw/djhIP30Z1YGBARESkokxUoswAdxEqE5UP30g14KoEIiIikjBjQEREpEIJEUo8fMrAEG1UB2YMiIiIVCgN+J+uSktL8dFHH6FRo0awsLBA48aNMW/ePCiV/7UhiiLCwsLg4uICCwsL+Pj44OzZs2rtFBcXY9KkSahfvz6srKwwaNAg3LhxQ6/Xz8CAiIiomkVGRmLVqlVYtmwZzp8/j0WLFuGTTz7B0qVLpTqLFi1CVFQUli1bhuTkZMjlcvj5+SE3N1eqExISgm3btmHjxo04dOgQ8vLyMGDAAJSV6b4EUxBFsWbmOoiIiAwoJycHtra2uP5nA4MtV3RtcRPZ2dmwsbGpsu6AAQPg5OSEmJgYqezVV1+FpaUl1q5dC1EU4eLigpCQEEyfPh1AeXbAyckJkZGRGD9+PLKzs+Hg4IC1a9di2LBhAIBbt27B1dUV33//Pfr06aNTv5kxICIiUlExx8AQB1AecKgexcXFGs/53HPP4ccff8TFixcBAKdOncKhQ4fw0ksvAQBSU1ORkZGB3r17S9fIZDL07NkTR44cAQCkpKSgpKRErY6Liws8PT2lOrrg5EMiIqJHyNXVVe3xnDlzEBYWplY2ffp0ZGdno0WLFjA2NkZZWRkWLFiA4cOHAwAyMjIAAE5OTmrXOTk54erVq1IdMzMz2NnZadSpuF4XDAyIiIhUKCGizICrEq5fv642lCCTyTTqbtq0CevWrUNiYiJat26NkydPIiQkBC4uLhg9erRUTxDUN00SRVGj7F661FHFwICIiEiFoZcr2tjY3HeOwfvvv48PPvgAAQEBAAAvLy9cvXoVERERGD16NORyOYDyrICzs7N0XWZmppRFkMvlUCgUyMrKUssaZGZmolu3bjr3m3MMiIiIqllBQQGMjNQ/ko2NjaXlio0aNYJcLkdSUpJ0XqFQ4MCBA9KHfseOHWFqaqpWJz09HWfOnNErMGDGgIiISEWZKKLMAAv29Glj4MCBWLBgARo2bIjWrVvj999/R1RUFIKCggCUDyGEhIQgPDwcHh4e8PDwQHh4OCwtLREYGAgAsLW1RXBwMKZOnYp69erB3t4eoaGh8PLygq+vr859YWBARESkQvnvYYh2dLV06VLMmjULEydORGZmJlxcXDB+/HjMnj1bqjNt2jQUFhZi4sSJyMrKQpcuXbB3715YW1tLdaKjo2FiYgJ/f38UFhaiV69eiI+Ph7Gxsc594T4GRERE+G8fgz/PO8HaAPsY5OYq0aLl3zrtY/AkYcaAiIhIRZmBViUYoo3qwMmHVKn4+HgIggBBEPDzzz9rnBdFEU2bNoUgCPDx8Xmg51ixYgXi4+P1uubnn3+utE/6qniNaWlpel+blpYGQRAea/91vbaiXsVhbGwMJycnDB06FOfPn9d4DYIgYOPGjRrthIWFQRAE/O9//5PKxowZo9b2vce9ffj666+19vGdd97RWELl7u5e5ftpzZo1Vb4nd+/ejf79+8PBwQEymQyurq4YPXo0zp07V+lrc3R0VNtSVrUvAwYMUCsTBAHvvPOO1r6dPn0agiDA1NQU6enpWutUpuI1LVy4UONcxXv0xIkTGuce5PVWHKampmjYsCHGjRundY37w/4uAGDKlCkQBEHj51ih4v23ePFireerS5louKMmYmBA92Vtba22TWeFAwcO4PLly2rjW/p6kMCgQ4cOOHr0KDp06PDAz1uhf//+OHr0qNryH105Ozvj6NGj6N+/v17XGbL/9xMeHo6jR49i//79mD59OpKSktC9e3fcvHlTo+7MmTNRUlKiU7sWFhY4evSo1uNhWVtb4+DBg7h8+bLGudjY2EpTstOmTUO/fv2gVCqxYsUKJCUlYc6cOUhOTkaHDh2wdetWrdfdvn0bixYteuh+f/XVVwDKb4azZs2aB2pj4cKF+Oeff3Sq+6Cvd/fu3Th69Ch++OEHBAQEIDY2Fr169dL6u3/Q3wUAlJSUYN26ddJzanvP0ZOJgQHd17Bhw/DNN98gJydHrTwmJgbe3t5o2LDhY+lHSUkJSktLYWNjg65duxpkzM7BwQFdu3bVuuHI/chkMnTt2hUODg56XWfI/t+Ph4cHunbtih49emDKlCmIiopCVlaWRjDWr18/XLlyBatWrdKpXSMjI3Tt2lXr8bCee+45NGjQALGxsWrlly9fxsGDB6U94FVt2LABn3zyCd566y388MMPGDp0KHr06IGxY8ciOTkZnp6eGDVqFK5cuaJxbd++fREdHa3XznD3Ki4uxvr169G2bVutfdeFr68v8vPzsWDBgvvWfZjX27FjR3Tt2hW+vr5YtGiRlGE4dOiQRt0H+V1U+Pbbb3H79m30798fZWVlSEhI0OGn8GRQGvCoiRgY0H1VbMm5YcMGqSw7OxvffPONtJTmXnPnzkWXLl1gb28PGxsbdOjQATExMVCd6+ru7o6zZ8/iwIEDUkrS3d0dwH9p6LVr12Lq1Klo0KABZDIZ/vrrL410umo6vKrUtjbahhJ8fHzg6emJ5ORkPP/887C0tETjxo2xcOFCtVugVjaU8Oeff2L48OFwcnKCTCZDw4YN8frrr0v7o2sbDjhx4gQCAgLg7u4OCwsLuLu7Y/jw4dJWp4ZS8cF9b7svvvgi+vTpg/nz52tNqz9ORkZGeP3115GQkKD2846NjYWrq6vWZVcLFiyAnZ2d1pS0lZUVli5dioKCAkRHR2uc//jjj1FaWqqxRa0+tm/fjjt37mDs2LEYPXo0Ll68qPWDtirNmzdHcHAwli9fft/f+8O83nt16tQJAPD3339rnHuQ30WFmJgYmJmZIS4uDq6uroiLi0NNmeuuhIAyAxxK6L7b4JOEgQHdl42NDV577TW1bw0bNmyAkZFRpd8Y0tLSMH78eGzevBlbt27FkCFDMGnSJMyfP1+qs23bNjRu3Bjt27eX0tDbtm1Ta2fGjBm4du0aVq1ahZ07d8LR0VHjuSpS+qrHjh07YGNjg5YtWz7Qa87IyMCIESMwcuRI7NixA/369cOMGTOk1GhlTp06hc6dO+PYsWOYN28efvjhB0RERKC4uBgKhaLS69LS0tC8eXMsWbIEe/bsQWRkJNLT09G5c2e18f2H9ddffwGA1ixHZGQk/ve//+GTTz7Rqa3S0lKNQ/XD42EEBQXh1q1b2LNnDwBI3zjHjBmjsQlMeno6zp49i969e8PS0lJre97e3nB0dFTb+KWCm5sbJk6ciJiYGOkGNvqKiYmBTCbDiBEjEBQUBEEQtA6/3U9YWBiMjY0xa9asSus87Ou9V2pqKgCgWbNmWs/r87uocOPGDezduxcvv/wyHBwcMHr0aPz11184ePDgfftD1Y+rEkgnQUFBeOGFF3D27Fm0bt0asbGxGDp0aKXzC+Li4qT/VyqV8PHxgSiK+OyzzzBr1iwIgoD27dvDwsJCSq1r06RJE2zZsqXKvlWk9CsUFBTghRdegJWVFX744YcHeLXAnTt38P333+PZZ58FUJ7m/fnnn5GYmIjXX3+90uumTJkCExMTHD9+XO3Dd8SIEVU+32uvvYbXXntNelxWVibdhjUxMRGTJ09+oNehVCpRWlqKkpISnDhxAlOnToWxsbHWgK5t27YIDAxEVFQUJk6cKG3Bqk1+fj5MTU01ynv16oV9+/Y9UF9VNWnSBD169EBsbCz69euHPXv24NatW3jjjTc0JuFdu3YNQPnOcFVp1KgR/vjjD63nZs6cidjYWHz44YeVTpaszNWrV/Hjjz/C398fdnZ2sLOzQ48ePbBlyxZ8/vnnes3BkcvleO+99xAREYHQ0FC0adNGo87Dvt6ysjKUlpYiLy8PSUlJWLlyJYYPH17pnBd9fhcV4uLioFQqERwcDKD878eCBQsQExODnj17VtnvJ4FSLD8M0U5NxIwB6aRnz55o0qQJYmNjcfr0aSQnJ1c6jAAAP/30E3x9fWFrawtjY2OYmppi9uzZuHPnDjIzM3V+3ldffVWvfpaVlWHYsGE4f/48vv/+e7i5uel1fQW5XC4FBRXatGlTZYq3oKAABw4cgL+/v97zDvLy8jB9+nQ0bdoUJiYmMDExQZ06dZCfn6+2ikBfw4YNg6mpKSwtLdGjRw+UlZXh66+/1vqBA5Sn1UtKSjB37twq27WwsEBycrLGsWLFigfu672CgoKwY8cO3LlzBzExMXjhhRekoaYHUdWNZOrVq4fp06fjm2++wa+//qpXuxUfgqr/HoKCgpCfn49NmzZJZRUfyPfLrkybNg329vaYPn26Xv24V2WvVy6Xw9TUFHZ2dvD390fHjh3vO/6vz+9CFEVp+MDPzw9AeZDi4+Ojda7Sk8gQwwgVR03EwIB0IggC3njjDaxbtw6rVq1Cs2bN8Pzzz2ute/z4cel+4KtXr8bhw4eRnJyMmTNnAgAKCwt1fl59VwtMmDABu3fvxtdff4127drpda2qevXqaZTJZLIq+56VlYWysjI888wzej9fYGAgli1bhrFjx2LPnj04fvw4kpOT4eDgoNfP616RkZFITk7Gb7/9hmvXruHKlSsYPHhwpfXd3d0xceJEfPXVV7h06VKl9YyMjNCpUyeNQzUdbWJSnpAsKyvT2kZpaalUR5vXXnsN5ubmiI6Oxs6dO6Vvn/eqmPxakRKvzNWrVzVuf6uq4k5206ZNq7IdVUqlEvHx8XBxcUHHjh1x9+5d3L17F76+vrCyslIbTmjSpAlMTU2lY968eVrbtLGxwUcffYTdu3dj//79Gucf9vXu27cPycnJ2LNnD1599VUcPHgQkyZNqrItXX8XQPmXgtTUVAwdOhQ5OTnSz8Tf3x8FBQVqc5XoycShBNLZmDFjMHv2bKxatarKmdMbN26Eqakpdu3aBXNzc6l8+/btej+nPrcKDQsLw1dffYW4uDgpMHmc7O3tYWxsjBs3buh1XXZ2Nnbt2oU5c+bggw8+kMqLi4t1XrpWmcaNG0uTy3T10UcfSWn11q1bP/BzV9zxrbJlajdv3tS4t7wqS0tLBAQEICIiAjY2NhgyZIjWes7OzmjdujX27t2LgoICrePuR48exd9//42hQ4dW+nwWFhYICwvDm2++ie+++66qlybZt2+flEXSFkweO3YM586dQ6tWrbBz505pAioAuLi4VNruW2+9hc8++wzTp0/HW2+9pXbuYV9v27ZtUb9+fQCAn58f+vTpgy+//BLBwcHo3Lmz1v7o+rsAIAVDUVFRiIqK0np+/PjxlV7/JDDUt31mDOip16BBA7z//vsYOHCg2v3B7yUIAkxMTNT25i4sLMTatWs16t7vW7iuYmJiMHfuXMybNw9jxox56PYehIWFBXr27IktW7boNWFQEASIoqixZPKrr76q9Nv2o1SRVv/6669x/PjxB27Hw8MDbm5u2LJli8Zs9Nu3b2P//v33vbHLW2+9hYEDB2L27NlqQea9Zs6ciaysLISGhmqcy8/Px+TJk2FpaYn33nuvyucLCgpCy5Yt8cEHH+g0kTImJgZGRkbYvn079u/fr3ZUvN8rJu16eXmpZVeqCgzMzMzw8ccfIzk5WescG0O9XkEQsHz5chgbG+Ojjz6qsq4uv4usrCxs27YN3bt31/h57N+/HyNGjEBycjLOnDlT5XNVN6UoGOyoiZgxIL1o25ntXv3790dUVBQCAwPx5ptv4s6dO1i8eLHWvQK8vLywceNGbNq0CY0bN4a5uTm8vLz06tPRo0cxYcIEdO/eHX5+fjh27JjaeUOsrddVVFQUnnvuOXTp0gUffPABmjZtir///hs7duzAF198oXUimo2NDXr06IFPPvkE9evXh7u7Ow4cOICYmBjUrVv3sfVdVUhICJYvX17p5E2lUqnxc67Qvn176Xe9ePFi+Pv7o1evXhg3bhzkcjkuXbqEhQsXwszMrMrZ9wDQrl07nTJNw4cPx2+//YbFixcjLS0NQUFBcHJywoULFxAdHY3Lly8jMTERjRs3rrIdY2NjhIeH45VXXgGASudiAOUTVL/99lv06dMHL7/8stY60dHRWLNmDSIiIrRO1rzfa1q8eLHW34GhXi9QHsC9+eabWLFiBQ4dOoTnnntOaz1dfhfr169HUVERJk+erHXHxHr16mH9+vWIiYlRW0p5+vRprZM+O3fu/MDzhOjBMTAgg3vxxRcRGxuLyMhIDBw4EA0aNMC4cePg6OioMTY5d+5cpKenY9y4ccjNzYWbm5ve2xNfuHABpaWlOHz4MLy9vTXOP861023btsXx48cxZ84czJgxA7m5uZDL5XjxxRdhZmZW6XWJiYl49913MW3aNJSWlqJ79+5ISkrSe1dFQ7G0tJTS6toUFhZq/VkDwKVLl9C0aVMA5WPTSUlJWLRoESZOnIi8vDw4ODigV69emDNnDpo0aWKwPn/yySd48cUXsWzZMkyYMAE5OTlwdHTEiy++iC1btqBVq1Y6tTN48GB069YNR44cqbLeunXrUFxcXGVa/M0338SECROwc+fOKtPv2giCgMjIyEqHxQz1egFgzpw5WLNmDWbPno2ffvpJr36qiomJgaOjY6XzWLy8vNC1a1esW7cOkZGRUvmaNWu07hYZFxdXLRnA2j6UwLsrEhER4b+7K/50xhV1DHB3xbxcJV70vF7j7q7IOQZEREQk4VACERGRCtFAEwdFTj4kIiKq+Wr7HAMOJRAREZGEGQMiIiIVZaIRysSH/95cVkOn9jMwICIiUqGEAKUBEupK1MzIgIFBLaJUKnHr1i1YW1vrtdUwEdGTShRF5ObmwsXFpdLbQJN+GBjUIrdu3aryJjJERDXV9evXH+gGZtrU9smHDAxqkYrteD39Z8HYrPJ954kMwW7dg99ngUhXpSjBIXyvdbvxB2W4OQYcSqAnXMXwgbGZOQMDeuRMBP3uDUD0QP797OXwqOEwMCAiIlJRPvnw4QMNQ7RRHRgYEBERqVDCCGW1eFUCp3ASERGRhBkDIiIiFZx8SERERBIljGr1BkccSiAiIiIJMwZEREQqykQBZQa4ZbIh2qgODAyIiIhUlBloVUIZhxKIiIiopmPGgIiISIVSNILSAKsSlFyVQEREVPNxKIGIiIjoX8wYEBERqVDCMCsKlA/flWrBwICIiEiF4TY4qplJ+ZrZayIioqeIu7s7BEHQON5++20AgCiKCAsLg4uLCywsLODj44OzZ8+qtVFcXIxJkyahfv36sLKywqBBg3Djxg29+8LAgIiISEXFvRIMcegqOTkZ6enp0pGUlAQAGDp0KABg0aJFiIqKwrJly5CcnAy5XA4/Pz/k5uZKbYSEhGDbtm3YuHEjDh06hLy8PAwYMABlZWV6vX4GBkRERCqUEAx26MrBwQFyuVw6du3ahSZNmqBnz54QRRFLlizBzJkzMWTIEHh6eiIhIQEFBQVITEwEAGRnZyMmJgaffvopfH190b59e6xbtw6nT5/Gvn379Hr9DAyIiIgeoZycHLWjuLi4yvoKhQLr1q1DUFAQBEFAamoqMjIy0Lt3b6mOTCZDz549ceTIEQBASkoKSkpK1Oq4uLjA09NTqqMrBgZEREQqDD2U4OrqCltbW+mIiIio8vm3b9+Ou3fvYsyYMQCAjIwMAICTk5NaPScnJ+lcRkYGzMzMYGdnV2kdXXFVAhERkQrDbXBU3sb169dhY2Mjlctksiqvi4mJQb9+/eDi4qJWLgjqQxOiKGqU3UuXOvdixoCIiOgRsrGxUTuqCgyuXr2Kffv2YezYsVKZXC4HAI1v/pmZmVIWQS6XQ6FQICsrq9I6umJgQEREpEIpCgY79BUXFwdHR0f0799fKmvUqBHkcrm0UgEon4dw4MABdOvWDQDQsWNHmJqaqtVJT0/HmTNnpDq64lACERGRCqWBhhL03eBIqVQiLi4Oo0ePhonJfx/PgiAgJCQE4eHh8PDwgIeHB8LDw2FpaYnAwEAAgK2tLYKDgzF16lTUq1cP9vb2CA0NhZeXF3x9ffXqBwMDIiKiJ8C+fftw7do1BAUFaZybNm0aCgsLMXHiRGRlZaFLly7Yu3cvrK2tpTrR0dEwMTGBv78/CgsL0atXL8THx8PY2FivfgiiWEPvC0l6y8nJga2tLdqOXABjM/Pq7g495ezjjlZ3F6gWKBVL8DO+RXZ2ttoEvwdR8Tcy/PgLMK/z8N+bi/JK8eGz+w3St8eJGQMiIiIVZRBQpsfmRFW1UxNx8iERERFJmDEgIiJSoRSNoNTjPgdVtVMTMTAgIiJSUQbDDAPod+uiJ0fNDGeIiIjokWDGgIiISAWHEoiIiEiiegOkh22nJqqZvSYiIqJHghkDIiIiFSIEKA0w+VCsofsYMDAgIiJSwaEEIiIion8xY0BERKTiQW+ZrK2dmoiBARERkYoyA9122RBtVIea2WsiIiJ6JJgxICIiUsGhBCIiIpIoYQSlARLqhmijOtTMXhMREdEjwYwBERGRijJRQJkBhgEM0UZ1YGBARESkorbPMeBQAhEREUmYMSAiIlIhGui2y2IN3RKZgQEREZGKMggoM8ANkAzRRnWomeEMERERPRLMGBAREalQioaZOKgUDdCZasDAgIiISIXSQHMMDNFGdaiZvSYiIqJHghkDIiIiFUoIUBpg4qAh2qgODAyIiIhU1PadDzmUQERERBJmDIiIiFTU9smHDAyIiIhUKGGgeyXU0DkGNTOcISIiokeCGQMiIiIVooFWJYg1NGPAwICIiEgFb7tMRERE9C9mDIiIiFRwVQIRERFJOJRARERE9C8GBkRERCoq7pVgiEMfN2/exMiRI1GvXj1YWlqiXbt2SElJkc6LooiwsDC4uLjAwsICPj4+OHv2rFobxcXFmDRpEurXrw8rKysMGjQIN27c0KsfDAyIiIhUVAwlGOLQVVZWFrp37w5TU1P88MMPOHfuHD799FPUrVtXqrNo0SJERUVh2bJlSE5Ohlwuh5+fH3Jzc6U6ISEh2LZtGzZu3IhDhw4hLy8PAwYMQFlZmc594RwDIiKiahYZGQlXV1fExcVJZe7u7tL/i6KIJUuWYObMmRgyZAgAICEhAU5OTkhMTMT48eORnZ2NmJgYrF27Fr6+vgCAdevWwdXVFfv27UOfPn106gszBkRERCoMnTHIyclRO4qLizWec8eOHejUqROGDh0KR0dHtG/fHqtXr5bOp6amIiMjA71795bKZDIZevbsiSNHjgAAUlJSUFJSolbHxcUFnp6eUh1dMDAgIiJ6hFxdXWFraysdERERGnWuXLmClStXwsPDA3v27MGECRMwefJkrFmzBgCQkZEBAHByclK7zsnJSTqXkZEBMzMz2NnZVVpHFxxKICIiUmHo5YrXr1+HjY2NVC6TyTTrKpXo1KkTwsPDAQDt27fH2bNnsXLlSrz++utSPUFQ75coihpl99KljioGBlTrjOnxG15onQo3h7soLjHGH9fkWLanK67+r65Ux8KsBO/0OYaeLdNga1mE9CxrbDrqhW+OtwYA2FgU4c1eJ9C16XU42ebjboE5fj7njlX7OiO/WPMfPVGFAa//D/1fvwMnVwUA4OoFc6yPdsKJ/eUfHFOjr6H3sCy1a86nWCJkoMdj72ttZejAwMbGRi0w0MbZ2RmtWrVSK2vZsiW++eYbAIBcLgdQnhVwdnaW6mRmZkpZBLlcDoVCgaysLLWsQWZmJrp166Zzv5/qoYQxY8ZAEAQsXLhQrXz79u1q0VNZWRmio6PRpk0bmJubo27duujXrx8OHz6sdl18fDwEQZAOJycnDBw4UGO5SMXzTpgwQaNPEydOhCAIGDNmjMa5I0eOwNjYGH379tU4l5aWBkEQcPLkST1+AqRNh0bp2HKsNYJWvYJ34gbA2EiJpWN2wdy0RKoz5aXD8Pa4jtlbXoT/kmHYcKQNQgccQo+WqQAAB+sCOFjn47Pd3ghYOhRzv3kB3s2uY9aQA9X1sqiGuJ1uithwZ0zq1wyT+jXDqcN1EBaXBrdmRVKd5J+sEdC2lXTMGtWoGntMj0P37t1x4cIFtbKLFy/Czc0NANCoUSPI5XIkJSVJ5xUKBQ4cOCB96Hfs2BGmpqZqddLT03HmzBkGBqrMzc0RGRmJrKwsredFUURAQADmzZuHyZMn4/z58zhw4ABcXV3h4+OD7du3q9W3sbFBeno6bt26he+++w75+fno378/FAqFWj1XV1ds3LgRhYWFUllRURE2bNiAhg0bau1LbGwsJk2ahEOHDuHatWsP98KpUpMT+mPX7y1wJdMelzLqY943L8DZLg8tG9yW6ng1/Bvf/d4cv6U2QPpdG2xLboVLGfXQ6t86lzPtMX1DH/zypztu/mOLE1caYGXSs3i+RRqMjZTV9dKoBvg1yRbJP9ng5hUZbl6RIT7SGUX5RmjRMV+qU6IQkHXbVDpy7zK5+ziJMMxeBqIez/nee+/h2LFjCA8Px19//YXExER8+eWXePvttwGUDyGEhIQgPDwc27Ztw5kzZzBmzBhYWloiMDAQAGBra4vg4GBMnToVP/74I37//XeMHDkSXl5e0ioFXTz1gYGvry/kcrnWyR4AsHnzZnz99ddYs2YNxo4di0aNGqFt27b48ssvMWjQIIwdOxb5+f/9gxUEAXK5HM7OzujUqRPee+89XL16VSPS69ChAxo2bIitW7dKZVu3boWrqyvat2+v0Y/8/Hxs3rwZb731FgYMGID4+HjD/ADovuqYlwd1OQXmUtnJq87o0SINDjZ5AER0bHQTDetn4+gl1yrbyS82Q5nyqf9nRQZiZCSi58tZkFkqcf6ElVTexjsPm/44i5hfziPkk+uwrVdSRStkaNWxj0Hnzp2xbds2bNiwAZ6enpg/fz6WLFmCESNGSHWmTZuGkJAQTJw4EZ06dcLNmzexd+9eWFtbS3Wio6MxePBg+Pv7o3v37rC0tMTOnTthbGysc1+e+r9gxsbGCA8Px9KlS7Xu/pSYmIhmzZph4MCBGuemTp2KO3fuqKVlVN29exeJiYkAAFNTU43zb7zxhtqa1NjYWAQFBWlta9OmTWjevDmaN2+OkSNHIi4uDqKoT7ypqbi4WGOZDN1LxHsvHcHvaXJczrSXShfv6o4rmXb4fvo6HJ23Gp+P+Q6RO57HqavOWluxtShCsE8Kth5vpfU8kSr3FoXYfuk0dqX9gckLb2BesDuuXSoPTE/st0bkO26YNrQxvpzngmbtCrBoyxWYmjET9bQbMGAATp8+jaKiIpw/fx7jxo1TOy8IAsLCwpCeno6ioiIcOHAAnp6eanXMzc2xdOlS3LlzBwUFBdi5cydcXSv/QqPNUx8YAMArr7yCdu3aYc6cORrnLl68iJYtW2q9rqL84sWLUll2djbq1KkDKysr2NnZYePGjRg0aBBatGihcf2oUaNw6NAhpKWl4erVqzh8+DBGjhyp9bliYmKkc3379kVeXh5+/PFHvV+rqoiICLUlMvq+OWqDaQMPoan8Dj7apJ5mC/A+DS/XvzFlbV+MWv4qlvzQDdMH/YJnm2gGl1YyBaJf/x6pt+2w+qeOj6vrVIPduCzDRL9meHeAB3atqY/Qz66hoUf5HIMDO+xw/EcbXL1ggV+TbPHRiMZo0LgYz/ZiYP+4VEfG4ElSKwIDoHxXqYSEBJw7d07va1UnKlpbW+PkyZNISUnBqlWr0KRJE6xatUrrdfXr10f//v2RkJCAuLg49O/fH/Xr19eod+HCBRw/fhwBAQEAABMTEwwbNgyxsbF691XVjBkzkJ2dLR3Xr19/qPaeNqEDDqFHizS8FTMImTl1pHKZSSkm+h1H9A/d8Muf7vjr73rYcswTSaebYORzp9TasDRT4PPR36FQYYr31/dBmVL3dB3VXqUlRriVJsOlPywRF+GM1HMWGDz2tta6/2SaIvOGKRo0Vmg9T4ZX2wODWjOjpUePHujTpw8+/PBDtRUBzZo1qzRYOH/+PADAw+O/ZUJGRkZo2rQpAKBFixbIyMjAsGHDcPDgQa1tBAUF4Z133gEALF++XGudmJgYlJaWokGDBlKZKIowNTXVWHaiD5lMpnW9LIl4f+Ah+LRKxYSvBuFWlvoyIhNjJUxNlBDv+UetVAoQhP+Gd6xkCnw+5juUlBphyrq+UJTWmn9O9AiYmmkfOrS2K4WDSwn++ZvvL3o8ak3GAChPre/cuVNta8iAgABcunQJO3fu1Kj/6aefol69evDz86u0zffeew+nTp3Ctm3btJ7v27cvFAoFFAqF1n2qS0tLsWbNGnz66ac4efKkdJw6dQpubm5Yv379A7xSqsr0Qb+gX9tLmLXJFwXFZqhXpwD16hRAZlIKAMgvNkPKFWdM7nsUHRrdhItdDga0/xMvtb+In8+VLxuzNFNg6ZhdsDArwfxtPqgjK5HaMRI4FkyVe+ODdHg+mwenZxRwb1GIMdPT0aZbHvZvs4O5ZRnGzb6Flh3z4fSMAm288zAvIRXZ/5jg8A+21d31WoMZg1qkTZs2GDFiBJYuXSqVBQQEYMuWLRg9ejQ++eQT9OrVCzk5OVi+fDl27NiBLVu2wMrKqtI2bWxsMHbsWMyZMweDBw/W2F3K2NhYyjxomxW6a9cuZGVlITg4GLa26v/wX3vtNcTExEgZBwAaqx8AoFWrVjAzM9Pth0B4rUt5huiLcTvUyud+7YNdv5fPFZm5yQ9v9/4V8/1/hI1FMTLuWmNl0rP45t/JhS0a3IZXw0wAwPapG9TaGfRJINLvVr2ZCdVedR1K8f7Sa7B3LEVBrjFSz5vjoxGN8dtBa5iZK+HeohC+r2XByqYM/2Sa4NThOgif4IbCfA5TPS6iKGhkDB+0nZqoVgUGADB//nxs3rxZeiwIAjZv3ozPPvsM0dHRePvttyGTyeDt7Y39+/fjueeeu2+b7777Lj7//HNs2bIF/v7+Guer2vEqJiYGvr6+GkEBALz66qsIDw/Hb7/9Bnv78hnzFfMQVKWmpqrdhYuq1nmm5sZT97qTZ4l5W1+o9PxvqQ10aofoXtFTK58ErCgywszAJo+xN0SaBPFh18RRjZGTkwNbW1u0HbkAxmbm97+A6CHYxx2t7i5QLVAqluBnfIvs7Oz7bjt8PxV/I72/nQQTq4efn1WaX4yjLy81SN8ep1qXMSAiIqqKoe+VUNPUqsmHREREVDVmDIiIiFRw8iERERFJOJRARERE9C9mDIiIiFRwKIGIiIgkooGGEmpqYMChBCIiIpIwY0BERKRCBGCIrf9q6u6BDAyIiIhUKCFAgAFWJRigjerAoQQiIiKSMGNARESkgqsSiIiISKIUBQjc4IiIiIiIGQMiIiI1omigVQk1dFkCAwMiIiIVtX2OAYcSiIiISMKMARERkYranjFgYEBERKSCqxKIiIiI/sWMARERkQquSiAiIiJJeWBgiDkGBuhMNeBQAhEREUmYMSAiIlLBVQlEREQkEf89DNFOTcShBCIiIpIwY0BERKSCQwlERET0n1o+lsChBCIiIpIwY0BERKTKQEMJ4FACERFRzVfbdz7kUAIREVE1CwsLgyAIaodcLpfOi6KIsLAwuLi4wMLCAj4+Pjh79qxaG8XFxZg0aRLq168PKysrDBo0CDdu3NC7LwwMiIiIVFSsSjDEoY/WrVsjPT1dOk6fPi2dW7RoEaKiorBs2TIkJydDLpfDz88Pubm5Up2QkBBs27YNGzduxKFDh5CXl4cBAwagrKxMr35wKIGIiEiVKBhmfoCebZiYmKhlCaRmRBFLlizBzJkzMWTIEABAQkICnJyckJiYiPHjxyM7OxsxMTFYu3YtfH19AQDr1q2Dq6sr9u3bhz59+ujcD2YMiIiIHqGcnBy1o7i4WGu9S5cuwcXFBY0aNUJAQACuXLkCAEhNTUVGRgZ69+4t1ZXJZOjZsyeOHDkCAEhJSUFJSYlaHRcXF3h6ekp1dMXAgIiISEXF5ENDHADg6uoKW1tb6YiIiNB4zi5dumDNmjXYs2cPVq9ejYyMDHTr1g137txBRkYGAMDJyUntGicnJ+lcRkYGzMzMYGdnV2kdXXEogYiISJWBNzi6fv06bGxspGKZTKZRtV+/ftL/e3l5wdvbG02aNEFCQgK6du0KABAE9aEJURQ1yjS6oEOdezFjQERE9AjZ2NioHdoCg3tZWVnBy8sLly5dkuYd3PvNPzMzU8oiyOVyKBQKZGVlVVpHVwwMiIiIVFTXqgRVxcXFOH/+PJydndGoUSPI5XIkJSVJ5xUKBQ4cOIBu3boBADp27AhTU1O1Ounp6Thz5oxUR1c6DSV8/vnnOjc4efJkvTpARET0xHnMmxOFhoZi4MCBaNiwITIzM/Hxxx8jJycHo0ePhiAICAkJQXh4ODw8PODh4YHw8HBYWloiMDAQAGBra4vg4GBMnToV9erVg729PUJDQ+Hl5SWtUtCVToFBdHS0To0JgsDAgIiISE83btzA8OHD8b///Q8ODg7o2rUrjh07Bjc3NwDAtGnTUFhYiIkTJyIrKwtdunTB3r17YW1tLbURHR0NExMT+Pv7o7CwEL169UJ8fDyMjY316osgijV100bSV05ODmxtbdF25AIYm5lXd3foKWcfd7S6u0C1QKlYgp/xLbKzs9Um+D2Iir+Rrl/MgZHFw/+NVBYW4fr4uQbp2+P0wHMMFAoFLly4gNLSUkP2h4iIqHqJBjxqIL0Dg4KCAgQHB8PS0hKtW7fGtWvXAJTPLVi4cKHBO0hERESPj96BwYwZM3Dq1Cn8/PPPMDf/L9Xi6+uLTZs2GbRzREREj59gwKPm0XuDo+3bt2PTpk3o2rWr2qYJrVq1wuXLlw3aOSIiosfOwBsc1TR6Zwxu374NR0dHjfL8/Hy9d1ciIiKiJ4vegUHnzp3x3XffSY8rgoHVq1fD29vbcD0jIiKqDrV88qHeQwkRERHo27cvzp07h9LSUnz22Wc4e/Ysjh49igMHDjyKPhIRET0+1XTb5SeF3hmDbt264fDhwygoKECTJk2wd+9eODk54ejRo+jYseOj6CMRERE9Jg90d0UvLy8kJCQYui9ERETVTvWWyQ/bTk30QIFBWVkZtm3bhvPnz0MQBLRs2RIvv/wyTEx4F2ciIqrhavmqBL0/yc+cOYOXX34ZGRkZaN68OQDg4sWLcHBwwI4dO+Dl5WXwThIREdHjofccg7Fjx6J169a4ceMGfvvtN/z222+4fv062rRpgzfffPNR9JGIiOjxqZh8aIijBtI7Y3Dq1CmcOHECdnZ2UpmdnR0WLFiAzp07G7RzREREj5sglh+GaKcm0jtj0Lx5c/z9998a5ZmZmWjatKlBOkVERETVQ6eMQU5OjvT/4eHhmDx5MsLCwtC1a1cAwLFjxzBv3jxERkY+ml4SERE9Lpx8eH9169ZV2+5YFEX4+/tLZeK/azIGDhyIsrKyR9BNIiKix6SWb3CkU2Cwf//+R90PIiIiegLoFBj07NnzUfeDiIjoycChhAdTUFCAa9euQaFQqJW3adPmoTtFRERUbRgY6Of27dt444038MMPP2g9zzkGRERENZfeyxVDQkKQlZWFY8eOwcLCArt370ZCQgI8PDywY8eOR9FHIiKix4e3XdbPTz/9hG+//RadO3eGkZER3Nzc4OfnBxsbG0RERKB///6Pop9ERESPRy1flaB3xiA/Px+Ojo4AAHt7e9y+fRtA+R0Xf/vtN8P2joiIiB6rB9r58MKFCwCAdu3a4YsvvsDNmzexatUqODs7G7yDREREj1PFlsiGOGoivYcSQkJCkJ6eDgCYM2cO+vTpg/Xr18PMzAzx8fGG7h8REdHjxVUJ+hkxYoT0/+3bt0daWhr+/PNPNGzYEPXr1zdo54iIiOjxeuB9DCpYWlqiQ4cOhugLERERVTOdAoMpU6bo3GBUVNQDd4aIiKi6CTDQbZcfvolqoVNg8Pvvv+vUmOqNlujJZbfuOEwE0+ruBj3l9tw6Wd1doFogJ1cJu2bV3YunC2+iREREpKqW72Pw0HMMiIiIniq1fFWC3vsYEBER0dOLGQMiIiJVtTxjwMCAiIhIhaF2LaypOx9yKIGIiIgkDxQYrF27Ft27d4eLiwuuXr0KAFiyZAm+/fZbg3aOiIjosavlt13WOzBYuXIlpkyZgpdeegl3795FWVkZAKBu3bpYsmSJoftHRET0eDEw0M/SpUuxevVqzJw5E8bGxlJ5p06dcPr0aYN2joiIiB4vvQOD1NRUtG/fXqNcJpMhPz/fIJ0iIiKqLk/CbZcjIiIgCAJCQkKkMlEUERYWBhcXF1hYWMDHxwdnz55Vu664uBiTJk1C/fr1YWVlhUGDBuHGjRt6PbfegUGjRo1w8uRJjfIffvgBrVq10rc5IiKiJ0vFzoeGOB5AcnIyvvzyS7Rp00atfNGiRYiKisKyZcuQnJwMuVwOPz8/5ObmSnVCQkKwbds2bNy4EYcOHUJeXh4GDBggDfvrQu/A4P3338fbb7+NTZs2QRRFHD9+HAsWLMCHH36I999/X9/miIiI6F95eXkYMWIEVq9eDTs7O6lcFEUsWbIEM2fOxJAhQ+Dp6YmEhAQUFBQgMTERAJCdnY2YmBh8+umn8PX1Rfv27bFu3TqcPn0a+/bt07kPegcGb7zxBubMmYNp06ahoKAAgYGBWLVqFT777DMEBATo2xwREdGTxcCTD3NyctSO4uLiSp/67bffRv/+/eHr66tWnpqaioyMDPTu3Vsqk8lk6NmzJ44cOQIASElJQUlJiVodFxcXeHp6SnV08UAbHI0bNw7jxo3D//73PyiVSjg6Oj5IM0RERE8cQ29w5OrqqlY+Z84chIWFadTfuHEjUlJScOLECY1zGRkZAAAnJye1cicnJ2nbgIyMDJiZmallGirqVFyvi4fa+bB+/foPczkREdFT7/r167CxsZEey2QyrXXeffdd7N27F+bm5pW2JQjq8xZEUdQou5cudVTpHRg0atSoyie4cuWKvk0SERE9OQx8rwQbGxu1wECblJQUZGZmomPHjlJZWVkZDh48iGXLluHChQsAyrMCzs7OUp3MzEwpiyCXy6FQKJCVlaWWNcjMzES3bt107rbegYHq0gkAKCkpwe+//47du3dz8iEREdV8BhpK0Ce46NWrl8ZeQG+88QZatGiB6dOno3HjxpDL5UhKSpK2DFAoFDhw4AAiIyMBAB07doSpqSmSkpLg7+8PAEhPT8eZM2ewaNEinfuid2Dw7rvvai1fvny51nERIiIiqpq1tTU8PT3VyqysrFCvXj2pPCQkBOHh4fDw8ICHhwfCw8NhaWmJwMBAAICtrS2Cg4MxdepU1KtXD/b29ggNDYWXl5fGZMaqGOzuiv369cOMGTMQFxdnqCaJiIgevyf0tsvTpk1DYWEhJk6ciKysLHTp0gV79+6FtbW1VCc6OhomJibw9/dHYWEhevXqhfj4eLWdiu/HYIHB119/DXt7e0M1R0REVD2ekMDg559/VnssCALCwsK0rmioYG5ujqVLl2Lp0qUP/Lx6Bwbt27dXm3woiiIyMjJw+/ZtrFix4oE7QkRERNVP78Bg8ODBao+NjIzg4OAAHx8ftGjRwlD9IiIiqhaG3segptErMCgtLYW7uzv69OkDuVz+qPpERERE1USvLZFNTEzw1ltvVbmdIxEREdVcet8roUuXLvj9998fRV+IiIiqn4HvlVDT6D3HYOLEiZg6dSpu3LiBjh07wsrKSu38vbeJJCIiqkk4x0BHQUFBWLJkCYYNGwYAmDx5snROEARpL2Z97vlMRERETxadA4OEhAQsXLgQqampj7I/RERE1a+Gfts3BJ0DA1Es/ym5ubk9ss4QERFVuydkg6PqotfkQ31u20hEREQ1j16TD5s1a3bf4OCff/55qA4RERFVJ04+1MPcuXNha2v7qPpCRERU/Wr5UIJegUFAQAAcHR0fVV+IiIiomukcGHB+ARER1QYcStBRxaoEIiKipxqHEnSjVCofZT+IiIjoCaD3lshERERPNWYMiIiIqEJtn2Og990ViYiI6OnFjAEREZEqDiUQERGRpJYHBhxKICIiIgkzBkRERCpq++RDBgZERESqOJRAREREVI4ZAyIiIhUcSiAiIqL/cCiBiIiIqBwzBkRERKpqecaAgQEREZEK4d/DEO3URBxKICIiIgkzBkRERKo4lEBEREQVavtyRQ4lEBERkYQZAyIiIlUcSiAiIiI1NfRD3RA4lEBEREQSZgyIiIhU1PbJhwwMiIiIVNXyOQYcSiAiIqpmK1euRJs2bWBjYwMbGxt4e3vjhx9+kM6LooiwsDC4uLjAwsICPj4+OHv2rFobxcXFmDRpEurXrw8rKysMGjQIN27c0LsvDAyIiIhUVAwlGOLQ1TPPPIOFCxfixIkTOHHiBF588UW8/PLL0of/okWLEBUVhWXLliE5ORlyuRx+fn7Izc2V2ggJCcG2bduwceNGHDp0CHl5eRgwYADKysr0ev0cSiAiIlJl4KGEnJwctWKZTAaZTKZWNnDgQLXHCxYswMqVK3Hs2DG0atUKS5YswcyZMzFkyBAAQEJCApycnJCYmIjx48cjOzsbMTExWLt2LXx9fQEA69atg6urK/bt24c+ffro3G1mDIiIiB4hV1dX2NraSkdERESV9cvKyrBx40bk5+fD29sbqampyMjIQO/evaU6MpkMPXv2xJEjRwAAKSkpKCkpUavj4uICT09PqY6umDEgIiJSYehVCdevX4eNjY1Ufm+2oMLp06fh7e2NoqIi1KlTB9u2bUOrVq2kD3YnJye1+k5OTrh69SoAICMjA2ZmZrCzs9Ook5GRoVe/GRgQERGpMvBQQsWEwvtp3rw5Tp48ibt37+Kbb77B6NGjceDAAem8IKjfyFkURY0yjS7oUOdeHEogIiJ6ApiZmaFp06bo1KkTIiIi0LZtW3z22WeQy+UAoPHNPzMzU8oiyOVyKBQKZGVlVVpHVwwMiIiIVIkGPB6mG6KI4uJiNGrUCHK5HElJSdI5hUKBAwcOoFu3bgCAjh07wtTUVK1Oeno6zpw5I9XRFYcSiIiIVFTHzocffvgh+vXrB1dXV+Tm5mLjxo34+eefsXv3bgiCgJCQEISHh8PDwwMeHh4IDw+HpaUlAgMDAQC2trYIDg7G1KlTUa9ePdjb2yM0NBReXl7SKgVdMTAgIiKqZn///TdGjRqF9PR02Nraok2bNti9ezf8/PwAANOmTUNhYSEmTpyIrKwsdOnSBXv37oW1tbXURnR0NExMTODv74/CwkL06tUL8fHxMDY21qsvgiiKNXTTRtJXTk4ObG1t4YOXYSKYVnd36Cm359bJ6u4C1QI5uUrYNbuC7OxsnSb4VdnWv38j274eDmMz84fuW5miCKfWfGiQvj1OzBgQERGpEEQRggG+MxuijerAyYdEREQkYcaACMCA1/+H/q/fgZOrAgBw9YI51kc74cT+8vTf1Ohr6D1MfRnQ+RRLhAz0eOx9pZqjrBRY+6kcP221Q9ZtU9g7lsDP/x8EhvwNIyOgtASIj3RG8k82SL9qBisbJdo/n4vgD2+hnrxUakdRLGD1PBf8vN0OxUUC2j+Xh3cibsDBpaQaX91TrJbfXZGBARGA2+mmiA13xq208h3J/Ib+g7C4NLzduxmuXiwfa0z+yRqfvucqXVNaot+mIVT7bFruhO/W1EfoZ9fg1rwIl05Z4NP3GsLKpgyvjP0figuN8NdpSwSG/I3GrQqRl22MVXMaYM6Yxli2+6LUzqo5DfBrkg1mrEyDjV0ZvpzngtmvN8ayPReg57wy0kF1rEp4klTrUMKYMWMgCAIEQYCpqSkaN26M0NBQ5OfnIy0tDYIgwNHRUe3uUQDQrl07hIWFSY99fHykdlSPCRMmAIDU1smTJzX6MHjwYIwZM0ajrYULF2rUfemllyAIgtpzA8DZs2fh7+8PBwcHyGQyeHh4YNasWSgoKFCr5+7uDkEQcOzYMbXykJAQ+Pj4SI/DwsLQrl07jee/ceMGzMzM0KJFC41z9HB+TbJF8k82uHlFhptXZIiPdEZRvhFadMyX6pQoBGTdNpWO3LuMq6lq51Ms4d0nG118cyB3VeD5Adno0DMXl05ZAgCsbJRYuOkyeg66C9emxWjZsQATP76BS39YIvNG+QTh/Bwj7Nlgj3Gzb6FDjzw09SrE9KVXkfanOX7/xbqqpyd6INU+x6Bv375IT0/HlStX8PHHH2PFihUIDQ2Vzufm5mLx4sX3bWfcuHFIT09XOxYtWvRAfXJ1dUVcXJxa2a1bt/DTTz/B2dlZrfzYsWPo0qULFAoFvvvuO1y8eBHh4eFISEiAn58fFAqFWn1zc3NMnz79gfoVHx8Pf39/FBQU4PDhww/UBt2fkZGIni9nQWapxPkTVlJ5G+88bPrjLGJ+OY+QT67Dth7TuFQ1z875OHnIGjcul2eiLp81x9njVuj8Yk6l1+TnGEMQRFjZlt8q99IfligtMULHnv99QaonL4VbiyKcS7aqrBl6GE/IBkfVpdq/8shkMmm7x8DAQOzfvx/bt2+XPjwnTZqEqKgovP3223B0dKy0HUtLS6mdhzVgwABs3rwZhw8fRvfu3QGUfyj37t0b165dk+qJoojg4GC0bNkSW7duhZFReZzl5uaGZs2aoX379oiOjlYLBMaPH4+VK1fi+++/x0svvaRzn0RRRFxcHFasWIFnnnkGMTExUt8qU1xcjOLiYunxvbf+JHXuLQqxZOdfMJMpUZhvhHnB7rh2qXwY4cR+a/yyqy7+vmEKeUMFRk/LwKItV/BOXw+UKKo9vqYnlP87mcjPNcbYHi1gZAwoy4AxH6TjhVfuaq2vKBIQG+6CF17JgpW1EgDwT6YJTM2UsK5bplbXrn4Jsm5X+5/wpxKHEp4wFhYWKCn575vY8OHD0bRpU8ybN++x9cHMzAwjRoxQyxrEx8cjKChIrd7Jkydx7tw5TJkyRQoKKrRt2xa+vr7YsGGDWrm7uzsmTJiAGTNmQKlU6tyn/fv3o6CgAL6+vhg1ahQ2b96sMcRyr4iICLVbfbq6ulZZv7a7cVmGiX7N8O4AD+z6d1y4oUcRAODADjsc/9EGVy9Y4NckW3w0ojEaNC7Gs70YbFHlDnxbFz9+Y4cPll/F8j0XEPrZNXy9yhFJm+006paWAOFvuUNUAu9E3Lhv26IoAJzmQo/AExUYHD9+HImJiejVq5dUVjHe/+WXX+Ly5cuVXrtixQrUqVNH7UhISHjgvgQHB2Pz5s3Iz8/HwYMHkZ2djf79+6vVuXixfHJQy5YttbbRsmVLqY6qjz76CKmpqVi/fr3O/YmJiUFAQACMjY3RunVrNG3aFJs2barymhkzZiA7O1s6rl+/rvPz1UalJUa4lSbDpT8sERfhjNRzFhg89rbWuv9kmiLzhikaNFZoPU8EAKvnu2DYO5nwGXwXjVoWwfe1LAwZdxsbl6rf1Ka0BFgw3h0Z180QsfGylC0AAHvHUpQojJB7V32W4d07JrCrXwp6BGr5UEK1Bwa7du1CnTp1YG5uDm9vb/To0QNLly5Vq9OnTx8899xzmDVrVqXtjBgxAidPnlQ7XnnllQfuV5s2beDh4YGvv/4asbGxGDVqFExN9dstsLLbXTo4OCA0NBSzZ8/WmIOgzd27d7F161aMHDlSKhs5ciRiY2OrvE4mk0m3+9T1tp+kztRM+79sa7tSOLiU4J+/mcqlyhUXGUEwUn8PGRmLUN33piIouJkqw8JNf8HGXn3IwKNNAUxMlfjt4H8TDe/8bYKrf5qjVed8kOFVDCUY4qiJqv2v2gsvvICVK1fC1NQULi4u0odvWlqaWr2FCxfC29sb77//vtZ2bG1t0bRp00rPAUB2drbGubt378LNzU3rdUFBQVi+fDnOnTuH48ePa5xv1qwZAODcuXNaVxH8+eef8PDQvs59ypQpWL58OVasWKH1vKrExEQUFRWhS5cuUpkoilAqlTh37hxatWp13zaoam98kI7kn6xx+5YZLOqUweflu2jTLQ8fjWgMc8syjAr9G4e+s8U/f5vCyVWBN2akI/sfExz+wba6u05PsK5+Odj4uRMcG5TArXkRLp+xwNYvHNE74A6A8n0O5o9rhL9OW2DemitQlgn4J7P8z7J13TKYmomwslGiz/B/8OVcF9jYlcK6bhlWz3eBe4sitH++6uFEogdR7YGBlZVVpR/oqp599lkMGTIEH3zwgd7PYWdnBwcHByQnJ6Nnz55SeWFhobTUUJvAwECEhoaibdu2Wj9827VrhxYtWiA6OhoBAQFq8wxOnTqFffv2ISIiQmvbderUwaxZszB37lwMHDiwyv7HxMRg6tSpassqAWDy5MmIjY3VadUGVa2uQyneX3oN9o6lKMg1Rup5c3w0ojF+O2gNM3Ml3FsUwve1LFjZlOGfTBOcOlwH4RPcUJjPReRUuYkf30DCImcsm/EM7t4xQT2nErw06n8Y8d7fAIDb6WY4trc8uJzop74MedHXf6FttzwAwISwmzA2FrFggjsUhUZo91wu5iZc4R4Gjwo3OKo5FixYgNatW8PERLPbBQUFyMjIUCuTyWSwsyuf5BMaGorw8HA4OTmhW7duyMrKQmRkJExMTNRS9Krs7OyQnp5e6RCCIAj46quv0Lt3b7z66quYMWMG5HI5fv31V0ydOhXe3t4ICQmp9PWMHz8eS5YswYYNG9SyAapOnjyJ3377DevXr9fYv2D48OGYOXMmIiIi9B7mIHXRUyufmKkoMsLMwCaPsTf0tLCso8Rb827irXk3tZ6Xuyp0utmUmbmItxfcxNsLtLdDhldThwEModrnGOijWbNmCAoKQlFRkca51atXw9nZWe0YPny4dD40NBQff/wxFi9ejLZt22Lw4MEQRRG//PJLlWPvdevWhZVV5WuFu3fvjmPHjsHY2BgvvfQSmjZtihkzZmD06NFISkqCTCar9FpTU1PMnz9f6+upEBMTg1atWmnd1Gjw4MH4559/sHPnzkqvJyIi0gdvu1yL8LbL9Djxtsv0ODyK2y53HPoxTEwf/rbLpSVFSNnyEW+7TEREVJNxgyMiIiKifzFjQEREpIqrEoiIiKiCoCw/DNFOTcShBCIiIpIwY0BERKSKQwlERERUgasSiIiIiP7FjAEREZEqUQQMsfdfDd0/kIEBERGRCg4lEBEREf2LGQMiIiJVXJVAREREFTiUQERERPQvZgyIiIhUcVUCERERVeBQAhEREdG/mDEgIiJSxVUJREREVIFDCURERET/YsaAiIhIlVIsPwzRTg3EwICIiEhVLZ9jwKEEIiIikjAwICIiUiHgvwmID3Xo8ZwRERHo3LkzrK2t4ejoiMGDB+PChQtqdURRRFhYGFxcXGBhYQEfHx+cPXtWrU5xcTEmTZqE+vXrw8rKCoMGDcKNGzf0ev0MDIiIiKrZgQMH8Pbbb+PYsWNISkpCaWkpevfujfz8fKnOokWLEBUVhWXLliE5ORlyuRx+fn7Izc2V6oSEhGDbtm3YuHEjDh06hLy8PAwYMABlZWU694VzDIiIiFQZeEvknJwctWKZTAaZTKZWtnv3brXHcXFxcHR0REpKCnr06AFRFLFkyRLMnDkTQ4YMAQAkJCTAyckJiYmJGD9+PLKzsxETE4O1a9fC19cXALBu3Tq4urpi37596NOnj07dZsaAiIhIhUGGEVT2QnB1dYWtra10RERE3LcP2dnZAAB7e3sAQGpqKjIyMtC7d2+pjkwmQ8+ePXHkyBEAQEpKCkpKStTquLi4wNPTU6qjC2YMiIiIHqHr16/DxsZGenxvtuBeoihiypQpeO655+Dp6QkAyMjIAAA4OTmp1XVycsLVq1elOmZmZrCzs9OoU3G9LhgYEBERqTLwckUbGxu1wOB+3nnnHfzxxx84dOiQxjlBUJ/SKIqiRplGN3Soo4pDCURERCoEUTTYoa9JkyZhx44d2L9/P5555hmpXC6XA4DGN//MzEwpiyCXy6FQKJCVlVVpHV0wMCAiIqpmoijinXfewdatW/HTTz+hUaNGaucbNWoEuVyOpKQkqUyhUODAgQPo1q0bAKBjx44wNTVVq5Oeno4zZ85IdXTBoQQiIiJVyn8PQ7Sjo7fffhuJiYn49ttvYW1tLWUGbG1tYWFhAUEQEBISgvDwcHh4eMDDwwPh4eGwtLREYGCgVDc4OBhTp05FvXr1YG9vj9DQUHh5eUmrFHTBwICIiEjFgw4DaGtHVytXrgQA+Pj4qJXHxcVhzJgxAIBp06ahsLAQEydORFZWFrp06YK9e/fC2tpaqh8dHQ0TExP4+/ujsLAQvXr1Qnx8PIyNjfXptyEWa1JNkJOTA1tbW/jgZZgIptXdHXrK7bl1srq7QLVATq4Sds2uIDs7W68Jflrb+vdvZI/nZ8PExPyh+1ZaWoSDv8wzSN8eJ2YMiIiIVNXymygxMCAiIlJl4J0PaxquSiAiIiIJMwZEREQqVLczfth2aiIGBkRERKo4lEBERERUjhkDIiIiFYKy/DBEOzURAwMiIiJVHEogIiIiKseMARERkSpucEREREQVquNeCU8SDiUQERGRhBkDIiIiVbV88iEDAyIiIlUiAEMsNayZcQGHEoiIiOg/zBgQERGpqO2TDxkYEBERqRJhoDkGD99EdeBQAhEREUmYMSAiIlLFVQlEREQkUQIQDNRODcShBCIiIpIwY0BERKSCqxKIiIjoP7V8jgGHEoiIiEjCjAEREZGqWp4xYGBARESkqpYHBhxKICIiIgkzBkRERKpq+T4GDAyIiIhU1PblihxKICIiIgkzBkRERKpq+eRDBgZERESqlCIgGOBDXVkzAwMOJRAREZGEGQMiIiJVHEogIiKi/xgoMAADA3rCif++0UtRUlPfr1SD5OTW0EXcVKPk5JW/z8Qa+u38ScTAoBbJzc0FABzC99XcE6oN7JpVdw+oNsnNzYWtra1hGuNQAtUWLi4uuH79OqytrSEIhtjW6+mXk5MDV1dXXL9+HTY2NtXdHXqK8b32YERRRG5uLlxcXAzXqFKEQdKqNXRVAgODWsTIyAjPPPNMdXejRrKxseEfa3os+F7Tn8EyBdXs4MGD+OSTT5CSkoL09HRs27YNgwcPls6Looi5c+fiyy+/RFZWFrp06YLly5ejdevWUp3i4mKEhoZiw4YNKCwsRK9evbBixQq9/vZzuSIREZEqUWm4Qw/5+flo27Ytli1bpvX8okWLEBUVhWXLliE5ORlyuRx+fn7SMDEAhISEYNu2bdi4cSMOHTqEvLw8DBgwAGVlZTr3gxkDIiIiVQaeY5CTk6NWLJPJIJPJNKr369cP/fr1q6QpEUuWLMHMmTMxZMgQAEBCQgKcnJyQmJiI8ePHIzs7GzExMVi7di18fX0BAOvWrYOrqyv27duHPn366NRtZgyIqiCTyTBnzhyt/4iJDInvtaeXq6srbG1tpSMiIkLvNlJTU5GRkYHevXtLZTKZDD179sSRI0cAACkpKSgpKVGr4+LiAk9PT6mOLpgxIKqCTCZDWFhYdXeDagG+154gBp58eO+E0gcJ/jIyMgAATk5OauVOTk64evWqVMfMzAx2dnYadSqu1wUDAyIiIlUGHkow5ITSe1eUiaJ431VmutRRxaEEIiKiJ5xcLgcAjW/+mZmZUhZBLpdDoVAgKyur0jq6YGBARESkSsR/WYOHOgzXpUaNGkEulyMpKUkqUygUOHDgALp16wYA6NixI0xNTdXqpKen48yZM1IdXXAogYiISFU17XyYl5eHv/76S3qcmpqKkydPwt7eHg0bNkRISAjCw8Ph4eEBDw8PhIeHw9LSEoGBgQDK93MIDg7G1KlTUa9ePdjb2yM0NBReXl7SKgVdMGNANc6YMWMgCAIWLlyoVr59+3a1cbSysjJER0ejTZs2MDc3R926ddGvXz8cPnxY7br4+HgIgiAdTk5OGDhwIM6ePav1eSdMmKDRp4kTJ0IQBIwZM0bj3JEjR2BsbIy+fftqnEtLS4MgCDh58qQePwF6EBW/P0EQYGpqisaNGyM0NBT5+fnS78HR0VFtTTgAtGvXTm1SoI+Pj9r7peKoeF9U9TsdPHiw2nukoq1738sA8NJLL0EQBI0JiWfPnoW/vz8cHBwgk8ng4eGBWbNmoaCgQK2eu7s7BEHAsWPH1MpDQkLg4+MjPQ4LC0O7du00nv/GjRswMzNDixYtNM7Ro3HixAm0b98e7du3BwBMmTIF7du3x+zZswEA06ZNQ0hICCZOnIhOnTrh5s2b2Lt3L6ytraU2oqOjMXjwYPj7+6N79+6wtLTEzp07YWxsrHM/GBhQjWRubo7IyEiNsbQKoigiICAA8+bNw+TJk3H+/HkcOHAArq6u8PHxwfbt29Xq29jYID09Hbdu3cJ3332H/Px89O/fHwqFQq2eq6srNm7ciMLCQqmsqKgIGzZsQMOGDbX2JTY2FpMmTcKhQ4dw7dq1h3vh9FD69u2L9PR0XLlyBR9//DFWrFiB0NBQ6Xxubi4WL15833bGjRuH9PR0tWPRokUP1CdXV1fExcWpld26dQs//fQTnJ2d1cqPHTuGLl26QKFQ4LvvvsPFixcRHh6OhIQE+Pn5abxfzc3NMX369AfqV3x8PPz9/VFQUKARTD/1lErDHXrw8fGBKIoaR3x8PABIgWJ6ejqKiopw4MABeHp6qrVhbm6OpUuX4s6dOygoKMDOnTvh6uqqVz8YGFCN5OvrC7lcXul64M2bN+Prr7/GmjVrMHbsWDRq1Aht27bFl19+iUGDBmHs2LHIz8+X6guCALlcDmdnZ3Tq1Anvvfcerl69igsXLqi126FDBzRs2BBbt26VyrZu3QpXV1cpyleVn5+PzZs346233sKAAQOkf+BUPWQyGeRyOVxdXREYGIgRI0aoBYmTJk1CVFQUMjMzq2zH0tIScrlc7XjQWecDBgzAnTt31D584+Pj0bt3bzg6OkploigiODgYLVu2xNatW/Hss8/Czc0NQ4cOxc6dO3H06FFER0ertT1+/HgcO3YM33+v343TRFFEXFwcRo0ahcDAQMTExDzQa6uxDDK/wFC3bn78GBhQjWRsbIzw8HAsXboUN27c0DifmJiIZs2aYeDAgRrnpk6dijt37qhN0FF19+5dJCYmAgBMTU01zr/xxhtq3/BiY2MRFBSkta1NmzahefPmaN68OUaOHIm4uDjeHvYJYmFhgZKSEunx8OHD0bRpU8ybN++x9cHMzAwjRoxQe0/Fx8drvKdOnjyJc+fOYcqUKTAyUv/T3bZtW/j6+mLDhg1q5e7u7pgwYQJmzJgBpR7fXvfv34+CggL4+vpi1KhR2Lx5s8YQCz29GBhQjfXKK6+gXbt2mDNnjsa5ixcvomXLllqvqyi/ePGiVJadnY06derAysoKdnZ22LhxIwYNGqR1fHXUqFE4dOgQ0tLScPXqVRw+fBgjR47U+lwxMTHSub59+yIvLw8//vij3q+VDO/48eNITExEr169pLKK8f4vv/wSly9frvTaFStWoE6dOmpHQkLCA/clODgYmzdvRn5+Pg4ePIjs7Gz0799frU7F+7Wq97Xqe7rCRx99hNTUVKxfv17n/sTExCAgIADGxsZo3bo1mjZtik2bNunximo4ZgyIaq7IyEgkJCTg3Llzel+rOlHR2toaJ0+eREpKClatWoUmTZpg1apVWq+rX78++vfvj4SEBMTFxaF///6oX7++Rr0LFy7g+PHjCAgIAACYmJhg2LBhiI2N1buvZBi7du1CnTp1YG5uDm9vb/To0QNLly5Vq9OnTx8899xzmDVrVqXtjBgxAidPnlQ7XnnllQfuV5s2beDh4YGvv/4asbGxGDVqlNZsVVUq28TGwcEBoaGhmD17tsYcBG3u3r2LrVu3qgW7I0eOrF3vW6VouKMG4nJFqtF69OiBPn364MMPP1Sb7d2sWbNKg4Xz588DADw8PKQyIyMjNG3aFADQokULZGRkYNiwYTh48KDWNoKCgvDOO+8AAJYvX661TkxMDEpLS9GgQQOpTBRFmJqaIisrS2PbUnr0XnjhBaxcuRKmpqZwcXGRPnzT0tLU6i1cuBDe3t54//33tbZja2srvV+0nQPKs1D3unv3Ltzc3LReFxQUhOXLl+PcuXM4fvy4xvlmzZoBAM6dO6d1FcGff/6p9p5WNWXKFCxfvhwrVqzQel5VYmIiioqK0KVLF6lMFEUolUqcO3cOrVq1um8bVLMxY0A1XkREBHbu3Kl2k5CAgABcunQJO3fu1Kj/6aefol69evDz86u0zffeew+nTp3Ctm3btJ7v27cvFAoFFAqF1juWlZaWYs2aNfj000/VvlWeOnUKbm5ueqV1yXCsrKzQtGlTuLm5VfmN/Nlnn8WQIUPwwQcf6P0cdnZ2cHBwQHJyslp5YWEhzp49i+bNm2u9LjAwEKdPn4anp6fWD9927dqhRYsWiI6O1pgvcOrUKezbtw/Dhw/X2nadOnUwa9YsLFiwQONOf/eKiYnB1KlTNd63L7zwQq3JGoii0mBHTcSMAdV4bdq0wYgRI9RSwgEBAdiyZQtGjx6NTz75BL169UJOTg6WL1+OHTt2YMuWLbCysqq0TRsbG4wdOxZz5szB4MGDNVK0xsbGUuZB2/rgXbt2ISsrC8HBwdI3yAqvvfYaYmJipIwDAI3VDwDQqlUrmJmZ6fZDIINbsGABWrduDRMTzT+TBQUFGlvTymQyKQsUGhqK8PBwODk5oVu3bsjKykJkZCRMTEwqnY9iZ2eH9PT0SgMWQRDw1VdfoXfv3nj11VcxY8YMyOVy/Prrr5g6dSq8vb0REhJS6esZP348lixZgg0bNqhlA1SdPHkSv/32G9avX68xv2b48OGYOXMmIiIi9B7mqHFEAw0DcI4BUfWZP3++2mx/QRCwefNmzJw5E9HR0WjRogWef/55XL16Ffv378fgwYPv2+a7776L8+fPY8uWLVrPV3VjlJiYGPj6+moEBQDw6quvSn+AKwQEBEgbm1Qct27dum8f6dFp1qwZgoKCUFRUpHFu9erVcHZ2VjtUv62Hhobi448/xuLFi9G2bVsMHjwYoijil19+qXJZY926dasMWLt3745jx47B2NgYL730Epo2bYoZM2Zg9OjRSEpKqvKufaamppg/f77W11MhJiYGrVq10jrpdvDgwfjnn3+0ZuHo6SKIXDtFRESEnJwc2NraopftKJgID5+tKxUV+DF7LbKzsw12d8XHgUMJREREqpRKQDDA/IAaOseAQwlEREQkYcaAiIhIlSjCIPdMrqEj9QwMiIiIVIhKJUQDDCXU1OWKHEogIiIiCTMGREREqjiUQERERBKlCAi1NzDgUAIRERFJGBgQ1VJhYWFqN+MZM2aMTjtCGlpaWhoEQcDJkycrrePu7o4lS5bo3GZ8fDzq1q370H0TBAHbt29/6HaohhHF8j0IHvpgxoCIHtKYMWMgCAIEQYCpqSkaN26M0NBQ5OfnP/Ln/uyzzxAfH69TXV0+zIlqKlEpGuyoiTjHgOgJ07dvX8TFxaGkpAS//PILxo4di/z8fKxcuVKjbklJicFuaKPtvg5EVPswY0D0hJHJZJDL5XB1dUVgYCBGjBghpbMr0v+xsbFo3LgxZDIZRFFEdnY23nzzTTg6OsLGxgYvvvgiTp06pdbuwoUL4eTkBGtrawQHB2vcTOfeoQSlUonIyEg0bdoUMpkMDRs2xIIFCwAAjRo1AgC0b98egiDAx8dHui4uLg4tW7aEubk5WrRogRUrVqg9z/Hjx9G+fXuYm5ujU6dO+P333/X+GUVFRcHLywtWVlZwdXXFxIkTkZeXp1Fv+/btaNasGczNzeHn54fr16+rnd+5cyc6duwIc3NzNG7cGHPnzkVpaane/aGnjEGGEZTcEpmIHg0LCwuUlJRIj//66y9s3rwZ33zzjZTK79+/PzIyMvD9998jJSUFHTp0QK9evfDPP/8AADZv3ow5c+ZgwYIFOHHiBJydnTU+sO81Y8YMREZGYtasWTh37hwSExPh5OQEoPzDHQD27duH9PR0bN26FUD5XQdnzpyJBQsW4Pz58wgPD8esWbOQkJAAAMjPz8eAAQPQvHlzpKSkICwsDKGhoXr/TIyMjPD555/jzJkzSEhIwE8//YRp06ap1SkoKMCCBQuQkJCAw4cPIycnBwEBAdL5PXv2YOTIkZg8eTLOnTuHL774AvHx8VLwQ7VXbR9KgEhET4zRo0eLL7/8svT4119/FevVqyf6+/uLoiiKc+bMEU1NTcXMzEypzo8//ija2NiIRUVFam01adJE/OKLL0RRFEVvb29xwoQJaue7dOkitm3bVutz5+TkiDKZTFy9erXWfqampooAxN9//12t3NXVVUxMTFQrmz9/vujt7S2Koih+8cUXor29vZifny+dX7lypda2VLm5uYnR0dGVnt+8ebNYr1496XFcXJwIQDx27JhUdv78eRGA+Ouvv4qiKIrPP/+8GB4ertbO2rVrRWdnZ+kxAHHbtm2VPi89XbKzs0UAoo/wiuhr5P/Qh4/wighAzM7Oru6XphfOMSB6wuzatQt16tRBaWkpSkpK8PLLL2Pp0qXSeTc3Nzg4OEiPU1JSkJeXh3r16qm1U1hYiMuXLwMAzp8/jwkTJqid9/b2xv79+7X24fz58yguLkavXr107vft27dx/fp1BAcHY9y4cVJ5aWmpNH/h/PnzaNu2LSwtLdX6oa/9+/cjPDwc586dQ05ODkpLS1FUVIT8/HxYWVkBAExMTNCpUyfpmhYtWqBu3bo4f/48nn32WaSkpCA5OVktQ1BWVoaioiIUFBSo9ZFql1Kx2CDDAKUouX+lJxADA6InzAsvvICVK1fC1NQULi4uGpMLKz74KiiVSjg7O+Pnn3/WaOtBl+xZWFjofY1SWf6HdPXq1ejSpYvaOWNjYwCAaIDlW1evXsVLL72ECRMmYP78+bC3t8ehQ4cQHBysNuQClC83vFdFmVKpxNy5czFkyBCNOubm5g/dT6p5zMzMIJfLcSjje4O1KZfLYWZmZrD2HgcGBkRPGCsrKzRt2lTn+h06dEBGRgZMTEzg7u6utU7Lli1x7NgxvP7661LZsWPHKm3Tw8MDFhYW+PHHHzF27FiN8xV/6MrKyqQyJycnNGjQAFeuXMGIESO0ttuqVSusXbsWhYWFUvBRVT+0OXHiBEpLS/Hpp5/CyKh8mtTmzZs16pWWluLEiRN49tlnAQAXLlzA3bt30aJFCwDlP7cLFy7o9bOmp5u5uTlSU1OhUCgM1qaZmVmNCzQZGBDVcL6+vvD29sbgwYMRGRmJ5s2b49atW/j+++8xePBgdOrUCe+++y5Gjx6NTp064bnnnsP69etx9uxZNG7cWGub5ubmmD59OqZNmwYzMzN0794dt2/fxtmzZxEcHAxHR0dYWFhg9+7deOaZZ2Bubg5bW1uEhYVh8uTJsLGxQb9+/VBcXIwTJ04gKysLU6ZMQWBgIGbOnIng4GB89NFHSEtLw+LFi/V6vU2aNEFpaSmWLl2KgQMH4vDhw1i1apVGPVNTU0yaNAmff/45TE1N8c4776Br165SoDB79mwMGDAArq6uGDp0KIyMjPDHH3/g9OnT+Pjjj/X/RdBTwdzcvMZ9kBsaVyUQ1XCCIOD7779Hjx49EBQUhGbNmiEgIABpaWnSKoJhw4Zh9uzZmD59Ojp27IirV6/irbfeqrLdWbNmYerUqZg9ezZatmyJYcOGITMzE0D5+P3nn3+OL774Ai4uLnj55ZcBAGPHjsVXX32F+Ph4eHl5oWfPnoiPj5eWN9apUwc7d+7EuXPn0L59e8ycORORkZF6vd527dohKioKkZGR8PT0xPr16xEREaFRz9LSEtOnT0dgYCC8vb1hYWGBjRs3Suf79OmDXbt2ISkpCZ07d0bXrl0RFRUFNzc3vfpD9LQRREMM+hEREdFTgRkDIiIikjAwICIiIgkDAyIiIpIwMCAiIiIJAwMiIiKSMDAgIiIiCQMDIiIikjAwICIiIgkDAyIiIpIwMCAiIiIJAwMiIiKS/B8w2oDAb4lgdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=20 #ejemplo de batch size\n",
    "target_size=(150,150) \n",
    "epochs=20\n",
    "\n",
    "matriz_conf_inicial(ruta, batch_size, target_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf11069-ce02-4b6a-a5ed-80714ddf8193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01238b52-cf0f-4227-839b-c01cd01f81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATRIZ FINAL: modelo Simple3, batchsize 64, num neuronas 16 y 100\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def matriz_conf_final(ruta, batch_size, target_size, epochs):\n",
    "\n",
    "    '''\n",
    "    Función que crea una matriz de confusión a partir del modelo final es decir, con la CNN alexNet, modelo Simple3, batch size = 64 y 100 y 16 \n",
    "    neuronas en las capas ocultas reespectivamente.\n",
    "    ----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo.\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. En este caso, el batch size será igual a 64\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso,como se emplea\n",
    "    el modelo Simple3 con la CNN de alexNet, donde el input_shape=(340,340,3), target_size tendrá que ser igual a (340,340)\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    -----------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "\n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    # se emplea el modelo Simple3 con CNN alexNet y 100 y 16 neuronas en las capas ocultas\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "            layers.BatchNormalization(),\n",
    "                \n",
    "            layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "            layers.BatchNormalization(),\n",
    "                \n",
    "            layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "            layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "            layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "            layers.BatchNormalization(),\n",
    "                \n",
    "            layers.Flatten(), #convierte imágenes en vectores\n",
    "            layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    epochs = epochs\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "    # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "    model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) \n",
    "\n",
    "    # se calcula y_test e y_pred para obtener la matriz de confusion\n",
    "    y_test=test_generator.labels\n",
    "    y_pred=model.predict(test_generator)\n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "\n",
    "    \n",
    "    #PERCEPTRON SKLEARN\n",
    "    labels=np.unique(y_test)\n",
    "    \n",
    "    matriz_conf = metrics.confusion_matrix(y_test, y_pred_bin,labels=labels)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"NORMAL\" , \"PNEUMONIA\"])\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    cm_display.plot(ax=ax)\n",
    "    plt.title(\"Matriz final PNEUMONIA-NORMAL\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c07cad9-a813-4652-a54a-3e89f98966ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.3546 - accuracy: 0.8572 - recall: 0.9056 - auc: 0.9133 - val_loss: 2.2369 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.4899\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 310s 5s/step - loss: 0.2386 - accuracy: 0.9109 - recall: 0.9418 - auc: 0.9546 - val_loss: 1.6361 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7082\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 290s 5s/step - loss: 0.1942 - accuracy: 0.9279 - recall: 0.9535 - auc: 0.9693 - val_loss: 0.7934 - val_accuracy: 0.7417 - val_recall: 0.9985 - val_auc: 0.8034\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1640 - accuracy: 0.9386 - recall: 0.9645 - auc: 0.9780 - val_loss: 1.6377 - val_accuracy: 0.7321 - val_recall: 1.0000 - val_auc: 0.6931\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 289s 5s/step - loss: 0.1589 - accuracy: 0.9429 - recall: 0.9653 - auc: 0.9774 - val_loss: 0.7114 - val_accuracy: 0.7588 - val_recall: 0.9985 - val_auc: 0.9424\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1409 - accuracy: 0.9522 - recall: 0.9733 - auc: 0.9821 - val_loss: 0.3437 - val_accuracy: 0.7844 - val_recall: 0.9942 - val_auc: 0.9639\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1381 - accuracy: 0.9480 - recall: 0.9667 - auc: 0.9831 - val_loss: 0.3525 - val_accuracy: 0.8335 - val_recall: 0.9927 - val_auc: 0.9545\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 289s 5s/step - loss: 0.1292 - accuracy: 0.9488 - recall: 0.9696 - auc: 0.9849 - val_loss: 0.4210 - val_accuracy: 0.8506 - val_recall: 0.9956 - val_auc: 0.9544\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 289s 5s/step - loss: 0.1283 - accuracy: 0.9562 - recall: 0.9762 - auc: 0.9856 - val_loss: 0.1923 - val_accuracy: 0.9317 - val_recall: 0.9576 - val_auc: 0.9723\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.1267 - accuracy: 0.9573 - recall: 0.9773 - auc: 0.9856 - val_loss: 0.3107 - val_accuracy: 0.9007 - val_recall: 0.9137 - val_auc: 0.9586\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 288s 5s/step - loss: 0.1069 - accuracy: 0.9616 - recall: 0.9806 - auc: 0.9897 - val_loss: 1.2370 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8153\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 290s 5s/step - loss: 0.1023 - accuracy: 0.9648 - recall: 0.9813 - auc: 0.9899 - val_loss: 0.5849 - val_accuracy: 0.8527 - val_recall: 0.9942 - val_auc: 0.9258\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1011 - accuracy: 0.9645 - recall: 0.9824 - auc: 0.9896 - val_loss: 0.3591 - val_accuracy: 0.8549 - val_recall: 0.9927 - val_auc: 0.9626\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0834 - accuracy: 0.9712 - recall: 0.9868 - auc: 0.9934 - val_loss: 0.2182 - val_accuracy: 0.9370 - val_recall: 0.9313 - val_auc: 0.9843\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0972 - accuracy: 0.9682 - recall: 0.9843 - auc: 0.9907 - val_loss: 1.0214 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.8806\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0848 - accuracy: 0.9688 - recall: 0.9850 - auc: 0.9932 - val_loss: 0.9676 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.9041\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0834 - accuracy: 0.9693 - recall: 0.9835 - auc: 0.9924 - val_loss: 0.6846 - val_accuracy: 0.7492 - val_recall: 1.0000 - val_auc: 0.9392\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 292s 5s/step - loss: 0.0733 - accuracy: 0.9709 - recall: 0.9883 - auc: 0.9957 - val_loss: 0.1568 - val_accuracy: 0.9520 - val_recall: 0.9912 - val_auc: 0.9785\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.0810 - accuracy: 0.9712 - recall: 0.9821 - auc: 0.9939 - val_loss: 0.7022 - val_accuracy: 0.8463 - val_recall: 0.9942 - val_auc: 0.8920\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0594 - accuracy: 0.9808 - recall: 0.9923 - auc: 0.9958 - val_loss: 0.3327 - val_accuracy: 0.9061 - val_recall: 0.9956 - val_auc: 0.9599\n",
      "19/19 [==============================] - 35s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=64 \n",
    "target_size=(340,340) \n",
    "epochs=20\n",
    "\n",
    "matriz_final = matriz_conf_final(ruta, batch_size, target_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497c2ae-7824-446c-9ced-108ae0fb9ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115865-dddc-4ec1-bb3a-efa3419117a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec057b4-58f3-419a-9293-b22e03bfb42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 98s 517ms/step - loss: 0.2834 - accuracy: 0.8850 - recall: 0.9612 - auc: 0.9341 - val_loss: 0.1633 - val_accuracy: 0.9381 - val_recall: 0.9620 - val_auc: 0.9759\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.1477 - accuracy: 0.9432 - recall: 0.9674 - auc: 0.9819 - val_loss: 0.1558 - val_accuracy: 0.9434 - val_recall: 0.9722 - val_auc: 0.9772\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 103s 546ms/step - loss: 0.1168 - accuracy: 0.9576 - recall: 0.9759 - auc: 0.9876 - val_loss: 0.1613 - val_accuracy: 0.9424 - val_recall: 0.9474 - val_auc: 0.9809\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 104s 551ms/step - loss: 0.1088 - accuracy: 0.9618 - recall: 0.9802 - auc: 0.9889 - val_loss: 0.1564 - val_accuracy: 0.9370 - val_recall: 0.9751 - val_auc: 0.9783\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 104s 556ms/step - loss: 0.0975 - accuracy: 0.9634 - recall: 0.9770 - auc: 0.9914 - val_loss: 0.1708 - val_accuracy: 0.9381 - val_recall: 0.9401 - val_auc: 0.9822\n",
      "59/59 [==============================] - 23s 395ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=20 #ejemplo de batch size\n",
    "target_size=(150,150) \n",
    "epochs=5\n",
    "\n",
    "train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "# se emplea el modelo más simple (Simple1) con CNN propia\n",
    "model = keras.Sequential( \n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5), \n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurona, sigmoide\n",
    "    ]\n",
    ")\n",
    "    \n",
    "epochs = epochs\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 5 épocas (patience)\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) \n",
    "\n",
    "# se calcula y_test e y_pred para obtener la matriz de confusion\n",
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)\n",
    "y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "\n",
    "    \n",
    "#PERCEPTRON SKLEARN\n",
    "labels=np.unique(y_test)\n",
    "    \n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred_bin,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"NORMAL\" , \"PNEUMONIA\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz inicial PNEUMONIA-NORMAL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653233d0-b67b-4a1a-a1b0-2466590e02a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8164ade8-e9d9-4d9b-b268-e6685d6effb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4759a3-c8b5-4746-8b45-7372cf9665a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd5374-2e97-4547-83d8-391bfa78251f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9516420-1579-4155-8185-544ddd0ea54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
