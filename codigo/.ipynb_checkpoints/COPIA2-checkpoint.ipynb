{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7176c0-5ed5-4850-a27a-b820414ff96d",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"40%\" src=\"pics/Universidad Burgos.png\">\n",
    "<img style=\"float:right\" width=\"16%\" src=\"pics/person1_bacteria_2.jpeg\">\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Trabajo Fin de Grado\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">NOMBRE TFG</h2>\n",
    "\n",
    "### Nuria Martínez Queralt\n",
    "\n",
    "### Grado en Ingeniería de la Salud \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33e68c-4e8b-4305-91c2-cff54089bbf4",
   "metadata": {},
   "source": [
    "En este notebook se han llevado a cabo una serie de tareas para la realización del TFG, el cual consiste en la identificación de neumonía a partir de radiografías de tórax empleando una red neuronal. Para esto, se deben probar distintos modelos hasta llegar al modelo más optimo de red neuronal para este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296a9ed-5af7-4b30-91c5-7015aefef326",
   "metadata": {},
   "source": [
    "## Redistribución de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1466b-002c-4d9e-8c11-fe752738fabe",
   "metadata": {},
   "source": [
    "Debido a que la distribución inicial obtenida a partir del dataset descargado de internet: \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\" incluye únicamente 16 imágenes en la carpeta de validación (\"val\") y, esto supone problemas para la obtención de buenos resultados a la hora de construir nuestra red neuronal, antes de empezar a trabajar con las imágenes, se debe crear una función para obtener un nuevo dataset con nuevas carpetas \"train\", \"test\" y \"val\" y una nueva distribución de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607cb8f4-f897-4551-a114-31b2c1dcf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def buscar_imagen(directorio_padre, nombre_imagen):\n",
    "    '''\n",
    "    Función empleada para encontrar una imagen concreta (a partir de su nombre) dentro de cualquiera de las subcarpetas del directorio_padre.\n",
    "    ---------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_padre: ruta donde se encuentra la carpeta cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    - nombre_imagen: nombre de la imágen a la que se desea acceder \n",
    "    ----------------------------------------------------------\n",
    "    Return:\n",
    "    - ruta_imagen: ruta completa de la imágen a la que se desea acceder \n",
    "    '''\n",
    "    # Subcarpetas principales en las que buscar\n",
    "    subcarpetas_principales = ['train', 'test', 'val']\n",
    "    # Subcarpetas adicionales en las que buscar dentro de cada subcarpeta principal\n",
    "    subcarpetas_adicionales = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Se itera sobre las subcarpetas principales\n",
    "    for subcarpeta_principal in subcarpetas_principales:\n",
    "        # Se itera sobre las subcarpetas adicionales dentro de cada subcarpeta principal\n",
    "        for subcarpeta_adicional in subcarpetas_adicionales:\n",
    "            # Se obtiene la ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(directorio_padre, subcarpeta_principal, subcarpeta_adicional, nombre_imagen)\n",
    "            # verificar si la imagen existe en la subcarpeta actual\n",
    "            if os.path.exists(ruta_imagen):\n",
    "                return ruta_imagen  # devolver la ruta de la imagen si se encuentra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806f2df1-fbcf-46be-bc11-a7a80fd7b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def redestribucion_imagenes(directorio_principal):\n",
    "\n",
    "    '''\n",
    "    Función empleada para redestribuir las imágenes ubicadas en distintas subcarpetas dentro de la carpeta data en una carpeta nueva con las\n",
    "    mismas subcarpetas pero con un porcentaje distinto de imágenes en cada subcarpeta. La distribución quedaría de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    De igual forma, la distribución de las carpetas \"PNEUMONIA\" y \"NORMAL\" también queda de forma proporcional.\n",
    "    --------------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_principal: ruta donde se encuentra la carpeta data con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    -------------------------------------------------------------------\n",
    "    Return: \n",
    "    - nada\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    En primer lugar, se crea un csv con dos columnas nombres_ficheros y clases compuesto por todas las imágenes existentes en el directorio_padre.\n",
    "    En la columna nombres_ficheros debe aparecer el nombre de TODAS las imágenes que existen dentro de cada subcarpeta y en la columna clases debe \n",
    "    aparecer 0 o 1 en función si se trata de una imagen de la carpeta NORMAL o PNEUMONIA respectivamente.\n",
    "    '''\n",
    "\n",
    "    directorio_padre = os.path.join(directorio_principal, 'data')\n",
    "    \n",
    "    # Listas para almacenar los nombres de las imágenes y las clases (0 o 1 en función de si es normal o neumonía respectivamente)\n",
    "    nombres_ficheros = []\n",
    "    clases = []\n",
    "    \n",
    "    # Recorremos las carpetas de train, test y val\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(directorio_padre, subcarpeta)\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            for nombre_fichero in os.listdir(ruta_clase):\n",
    "                nombres_ficheros.append(nombre_fichero)\n",
    "                clases.append(0 if clase == 'NORMAL' else 1)\n",
    "    \n",
    "    # Se crea el DataFrame con los datos\n",
    "    df_todas = pd.DataFrame({'nombre_fichero': nombres_ficheros,'clase': clases})\n",
    "    \n",
    "    # Se guarda el DataFrame en un archivo CSV\n",
    "    ruta_csv = os.path.join(directorio_padre, 'dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    df_todas.to_csv(ruta_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A partir del csv anterior y, con ayuda de la función train_test_split de skitlearn de divide el csv anterior en dos \n",
    "    subgrupos de train y test en proporción 80, 20 para poder usar el 80% de las imágenes para train y el 20% para test.\n",
    "    También se emplea el parámetro stratify para que exista una proporción de clases en cada uno de los grupos, es decir, en ''NORMAL\" y \"PNEUMONIA\".\n",
    "    '''\n",
    "    \n",
    "    # se emplea train_test_split para dividir el dataset en train (80%) y test (20%)\n",
    "    # random_state=42 se emplea para que cada vez que se ejecute el código, se obtenga la misma división de datos. El valor 42 es un valor que se usa\n",
    "    # comunmente en este caso pero se puede emplear cualquie otro valor entero\n",
    "    # stratify se emplea para agrupar de manera proporcional las clases neumonia y normal en los distintos dataframes\n",
    "    train_df, test_df = train_test_split(df_todas, test_size=0.2, stratify=df_todas['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_csv = os.path.join(directorio_padre, 'train_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_test_csv = os.path.join(directorio_padre, 'test_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_df.to_csv(ruta_train_csv, index=False)\n",
    "    test_df.to_csv(ruta_test_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A continuación, se coge el conjunto de datos obtenido previamente de train, es decir, el csv \"train_df\" y se repite el mismo\n",
    "    proceso pero, esta vez dividiendo este conjunto de datos para train y val en un 80% y 20% respectivamente.\n",
    "    De tal forma que, finalemnte se obtenga el conjunto de test que represeneta el 20% del total (obtenido previamente), el conjunto de train\n",
    "    que representa el 80% del 80% del total ya que, inicialmente nos hemos quedado con el 80% pero luego, de este 80%, el 20% va destinado al conjunto\n",
    "    de validación. Por lo que finalmete quedarías distribuidos de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    '''\n",
    "\n",
    "    # Se emplea train_test_split para dividir el conjunto de datos de entrenamiento en train (80%) y val (20%)\n",
    "    train_def_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_final_csv = os.path.join(directorio_padre, 'train_final_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_val_csv = os.path.join(directorio_padre, 'val_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_def_df.to_csv(ruta_train_final_csv, index=False)\n",
    "    val_df.to_csv(ruta_val_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    Finalmente, se crea una nueva carpeta denominada data_nuevo dentro del directorio principal. Dentro de esta carpeta se crean 3 subcarpetas \n",
    "    (\"train\", \"test\" y \"val\") que corresponderian con los dataframes obtenidos hasta hora: train_def_df, val_df y test_df y, dentro de estas 3 \n",
    "    subcarpetas, se crean 2 carpetas \"NORMAL\" y \"PNEUMONIA\" que corresponden con con las clases determinadas en cada dataframe, 0 en caso de \n",
    "    \"NORMAL\" y 1 para \"PNEUMONIA\". Dentro de estas dos carpetas para (\"train\", \"test\" y \"val\") se encontraran las imagenes correspondientes \n",
    "    para cada caso según los dataframes obtenidos.\n",
    "    '''\n",
    "\n",
    "    # Se crea la nueva carpeta dentro del directorio principal\n",
    "    ruta_principal_nueva = os.path.join(directorio_principal, 'data_nuevo') \n",
    "\n",
    "    # Se crean las carpetas 'train', 'test' y 'val' dentro de la nueva carpeta principal\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(ruta_principal_nueva, subcarpeta)\n",
    "        os.makedirs(ruta_subcarpeta, exist_ok=True) #verifica si la carpeta ruta_subcarpeta ya existe. Si existe, no se hace nada y el programa continúa su ejecución sin lanzar un error. Si no existe, la función os.makedirs() la crea junto con cualquier carpeta intermedia necesaria en la ruta especificada\n",
    "        \n",
    "        # Se crean las subcarpetas 'normal' y 'neumonia' dentro de cada subcarpeta ('train', 'test' y 'val')\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            os.makedirs(ruta_clase, exist_ok=True)\n",
    "    \n",
    "                \n",
    "    # Se copian los archivos CSV a las subcarpetas correspondientes\n",
    "    for df, nombre_carpeta in [(train_def_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "        for index, row in df.iterrows(): #se itera sobre cada dataframe fila a fila\n",
    "            clase = 'NORMAL' if row['clase'] == 0 else 'PNEUMONIA'\n",
    "            nombre_archivo = row['nombre_fichero']\n",
    "    \n",
    "            # ruta de origen donde se busca la imagen concreta a partir de la función realizada previamente\n",
    "            # esta ruta se refiere a donde esta que se desea guardar en la carpeta destino originalmente para poder copiarla\n",
    "            ruta_origen=buscar_imagen(directorio_padre, nombre_archivo)\n",
    "            \n",
    "            # ruta donde se desa guardar (y redestribuir de la forma correcta) las imágenes\n",
    "            ruta_destino = os.path.join(ruta_principal_nueva, nombre_carpeta, clase, nombre_archivo)\n",
    "            \n",
    "            shutil.copyfile(ruta_origen, ruta_destino) # copia las imágenes de la ruta incial a la ruta final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c371aab4-b02f-4ce2-b902-03be9c426b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_principal = 'C:/Users/nuria/Downloads/TFG' #ruta donde se encuentra la carpeta data en mi caso y donde se va a crear la nueva carpeta data_nuevo\n",
    "redestribucion_imagenes(directorio_principal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b4967-0b21-4bea-a7dd-96dfc0bc0206",
   "metadata": {},
   "source": [
    "A partir de aqui, se va a trabajar con la nueva carpeta de imágenes y su nueva distribución para evitar errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f5be-2c05-498e-88e7-da98e1210f1c",
   "metadata": {},
   "source": [
    "## Preparación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd3214-3749-4449-a6ce-2150370b3359",
   "metadata": {},
   "source": [
    "Se prepara el modelo para poder trabajar con las imágenes de train, test y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f44c95-c38d-4885-a5e7-fe86df3e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/paola311/clasificaci-n-de-im-genes-cnn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def preparar_modelo(ruta, batch_size,target_size):\n",
    "\n",
    "    '''\n",
    "    Función que configura los generadores de datos para entrenar, validar y probar un modelo de aprendizaje automático con imágenes.\n",
    "    -----------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. \n",
    "    ----------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    dir_general = ruta #ubicacion donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Añadir esta carpeta a one drive en TFG\n",
    "\n",
    "    dir_train = os.path.join(dir_general, 'train')\n",
    "    dir_validation = os.path.join(dir_general, 'val')\n",
    "    dir_test = os.path.join(dir_general, 'test')\n",
    "    \n",
    "    # Preprocesamiento de imágenes\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    #Iterador que recorre el directorio de imágenes\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dir_train,\n",
    "        target_size=target_size, #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary',\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=True) # el conjunto de datos se barajará aleatoriamente para evitar sobreajuste \n",
    "    \n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        dir_validation,\n",
    "        target_size=target_size, #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary',\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dir_test,\n",
    "        target_size=target_size, #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary',\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False)\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2a919-5a84-4a53-94f1-ad964d37c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=20 #ejemplo de batch size\n",
    "target_size=(340,340) #ejemplo de target_size\n",
    "\n",
    "train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d31e2-5b84-48e0-add1-06484c34f7d2",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como funciona el modelo más simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edc6db-723d-4830-8618-9e9ac1fe251b",
   "metadata": {},
   "source": [
    "Se obtiene la matriz de confusión para un primer modelo muy simple para, así poder comprobar como estos resultados mejoran al introducir capas ocultas, modificar parámetros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7845af-f029-46c0-969b-8550683dff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFICAR / COMPROBAR QUE FUNCIONA\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def matriz_conf(ruta, batch_size, target_size, input_shape, modelo, epochs):\n",
    "    \n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "\n",
    "    input_shape=input_shape\n",
    "    model = modelo\n",
    "    \n",
    "    epochs = epochs\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "    # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 5 épocas (patience)\n",
    "    model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) \n",
    "    \n",
    "    y_test=test_generator.labels\n",
    "    y_pred=model.predict(test_generator)\n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "\n",
    "    \n",
    "    #PERCEPTRON SKLEARN\n",
    "    labels=np.unique(y_test)\n",
    "    \n",
    "    matriz_conf = metrics.confusion_matrix(y_test, y_pred_bin,labels=labels)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"PNEUMONIA\" , \"NORMAL\"])\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    cm_display.plot(ax=ax)\n",
    "    plt.title(\"Matriz de confusión PNEUMONIA-NORMAL\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80060f0f-a95c-4a43-a903-7dadcaf4f1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c40b9-b349-4fba-bd4d-660efaeb45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=20 #ejemplo de batch size\n",
    "target_size=(340,340) #ejemplo de target_size\n",
    "\n",
    "train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0d8bc-a780-43f7-afa1-1b4ebfbe668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se trabaja con el modelo más simple (posteriormente denominado Simple1)\n",
    "\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "model = keras.Sequential( \n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5), \n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurona, sigmoide\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad93d8-8ea8-4134-b9ee-436c775e8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 5 épocas (patience)\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499cd3b-fe4e-4a3a-87d7-791e7f119711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920a58c-c342-4cdc-905e-6fb20cc1cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81208df-f1dd-43c4-8faf-2e511a32a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión con sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred_bin) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad04e18-b7e3-4eb4-84f9-1c49fc4dd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765b599-fb6c-466a-85f0-69781acfa59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON SKLEARN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"neumonía\" , \"no neumonía\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión neumonía-no neumonía\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b896f-e060-488a-a228-64ba1e0fd5b3",
   "metadata": {},
   "source": [
    "Como se puede observar, los resultados en este primer modelo tan simple, sin ninguna capa oculta, son bastante malos ya que, poniendo esto en un caso clínico real, significaría que 230 pacientes con neumonía hubieran sido diagnosticados como no neumonía y 246 pacientes sin neumonía hubieran sido diagnosticados con neumonía, lo que supondría serios problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5654c9-4f71-4980-9ade-721a48531aec",
   "metadata": {},
   "source": [
    "## Creación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5c91f-3b3e-403c-820b-56c4cd7ecfa7",
   "metadata": {},
   "source": [
    "Se crea una función para calcular las distintas métricas que servirán para la posterior evaluación de cada modelo que se realice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62f0ad-3bf5-43b6-b2a6-ae64737f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np \n",
    "\n",
    "'''import numpy as np\n",
    "import tensorflow as tf'''\n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    '''\n",
    "    Funcicón que calcula distintas métricas para la evaluación del modelo.\n",
    "    -----------------------------------------------------\n",
    "    Parámetros: \n",
    "    - y_test: array de etiquetas verdaderas del conjunto de prueba\n",
    "    - y_pred: array de etiquetas predichas por el modelo\n",
    "    ----------------------------------------\n",
    "    Return: \n",
    "    - accuracy: float que indica la proporción de predicciones correctas\n",
    "    - precision: float que indica la proporción de predicciones positivas correctas\n",
    "    - recall: float que indica la proporción de positivos detectados\n",
    "    - f1: float que indica la media armónica de precisión y exhaustividad para evaluar de una forma más equilibrada el rendimiento del modelo\n",
    "    - specificity: float que indica la proporción de negativos detectados\n",
    "    - fpr: float que indica la tasa de falsos positivos, es decir, la proporción de negativos incorrectamente clasificadas como positivos, \n",
    "    respecto al total de casos negativos reales.\n",
    "    - fnr: float que indica la tasa de falsos negativos, es decir, la proporción de positivos incorrectamente clasificadas como negativos, \n",
    "    respecto al total de casos positivos reales.\n",
    "    - auc: float que se emplea para evaluar la capacidad de distinción entre clases positivas y negativas de un modelo de clasificación \n",
    "    binaria. Un 1 significa que es capaz de distinguir perfectamente entre clases, un 0.5 significa una clasificación aleatoria y un 0 indica \n",
    "    que ninguna clase ha sido correctamente clasificada.\n",
    "    '''\n",
    "    \n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "    \n",
    "    #se obtienen los verdaderos negativos, falsos positivos, falsos negativos y verdaderos positivos a partir de la matriz de confusión \n",
    "    #con .ravel() se convierte la matriz en un array unidimensional\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_bin).ravel() \n",
    "\n",
    "    #se calculan cada una de las métricas empleando su correspondiente fórmula\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn) #tasa de falsos positivos\n",
    "    fnr = fn / (fn + tp) #tasa de falsos negativos\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, specificity, fpr, fnr, auc] #se devuleve como una lista para poder trabajar correctmante con las métricas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e775dc-426e-447b-bc1b-35d52330027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59a0d8-8fe2-4590-b50d-d3e1dd996e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e81a3-d57f-49a8-8307-1f4812bed084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1b32f5-76dc-483e-bb31-8c6e0d468c1f",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fdfaa-3ae7-4085-8522-1d295e2ca373",
   "metadata": {},
   "source": [
    "Para realizar una comparación entre distintas arquitecturas y distintos batch_size, en primer lugar, se generan diferentes modelos de arquitectura de red neuronal variando las capas, el número de capas, etc y, después se entrenan y evalúan los modelos generados con distintos batch sizes. Para esto, se emplean las métricas previamente definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423ac6f-2bf9-44f3-b695-4b48c6da47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN comunmente aplicada como punto de partida para la clasificacion de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81631355-c81a-4aa2-9caf-d374da1919c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN propia\n",
    "\n",
    "def establecer_arquitectura_propia(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) según el tipo que se introduzca como parámetro.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(150,150,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model #model.summary??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525f7f5-659b-4a79-9b51-b2e5c6d1a826",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN AlexaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c0f380-66aa-4989-a4ef-88253c46d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN alexaNet\n",
    "def establecer_arquitectura_AlexaNet(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) según el tipo que se introduzca como parámetro.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(340,340,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), #cambiar a menos de 0,5 \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce17fe-abf7-4859-8cbb-4baa86a918c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53a6c14c-63ba-4378-a4bd-4c61b0df546f",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1b7f36-6297-43d4-a8a8-93964cc84ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_propia(ruta,epochs,batch_sizes,modelos,target_size):\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas arquitecturas de modelo y distintos batch size introducidos como parámetros. \n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"establecer_arquitectura(modelo)\"\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_propia(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "            #ENTRENA\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) #hacer grafica val y train para auc o loss\n",
    "\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            nombre_archivo = f'hist_propia_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "            ruta_historico = os.path.join('C:/Users/nuria/Downloads/TFG', 'historico_propia_arqu_batchsize') #se guarda dentro de una nueva carpeta denominada 'historico_2_64'\n",
    "            # Crea la carpeta 'historico_2_64' si no existe\n",
    "            os.makedirs(ruta_historico, exist_ok=True)\n",
    "            ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "            historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "            #se calculan las métricas\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "            #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "            #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "            #cambiar .append por .concat\n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8be533-a397-4df4-8e10-1f131bb07c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 132s 276ms/step - loss: 0.2550 - accuracy: 0.8943 - recall: 0.9535 - auc: 0.9436 - val_loss: 0.1612 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9757\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 128s 273ms/step - loss: 0.1368 - accuracy: 0.9506 - recall: 0.9711 - auc: 0.9837 - val_loss: 0.1533 - val_accuracy: 0.9392 - val_recall: 0.9766 - val_auc: 0.9806\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 127s 271ms/step - loss: 0.1166 - accuracy: 0.9570 - recall: 0.9740 - auc: 0.9874 - val_loss: 0.1883 - val_accuracy: 0.9306 - val_recall: 0.9810 - val_auc: 0.9769\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0902 - accuracy: 0.9666 - recall: 0.9788 - auc: 0.9924 - val_loss: 0.2097 - val_accuracy: 0.9253 - val_recall: 0.9810 - val_auc: 0.9689\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 122s 259ms/step - loss: 0.0742 - accuracy: 0.9738 - recall: 0.9835 - auc: 0.9945 - val_loss: 0.2396 - val_accuracy: 0.9338 - val_recall: 0.9269 - val_auc: 0.9776\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0592 - accuracy: 0.9773 - recall: 0.9857 - auc: 0.9968 - val_loss: 0.1986 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9723\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 124s 263ms/step - loss: 0.0448 - accuracy: 0.9821 - recall: 0.9872 - auc: 0.9980 - val_loss: 0.2237 - val_accuracy: 0.9392 - val_recall: 0.9678 - val_auc: 0.9681\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 123s 261ms/step - loss: 0.0500 - accuracy: 0.9829 - recall: 0.9905 - auc: 0.9978 - val_loss: 0.2481 - val_accuracy: 0.9370 - val_recall: 0.9518 - val_auc: 0.9660\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0237 - accuracy: 0.9925 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.3000 - val_accuracy: 0.9349 - val_recall: 0.9430 - val_auc: 0.9632\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0178 - accuracy: 0.9928 - recall: 0.9949 - auc: 0.9998 - val_loss: 0.2932 - val_accuracy: 0.9317 - val_recall: 0.9430 - val_auc: 0.9615\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0207 - accuracy: 0.9933 - recall: 0.9952 - auc: 0.9992 - val_loss: 0.3537 - val_accuracy: 0.9317 - val_recall: 0.9430 - val_auc: 0.9562\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0142 - accuracy: 0.9952 - recall: 0.9967 - auc: 0.9999 - val_loss: 0.3317 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9583\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.254966  0.894315  0.953548  0.943649  0.161163      0.941302   \n",
      "1   0.136755  0.950627  0.971105  0.983685  0.153286      0.939168   \n",
      "2   0.116592  0.957032  0.974031  0.987410  0.188335      0.930630   \n",
      "3   0.090210  0.966640  0.978786  0.992437  0.209658      0.925294   \n",
      "4   0.074250  0.973846  0.983541  0.994526  0.239587      0.933831   \n",
      "5   0.059241  0.977315  0.985735  0.996798  0.198563      0.940235   \n",
      "6   0.044846  0.982119  0.987198  0.997966  0.223664      0.939168   \n",
      "7   0.049986  0.982920  0.990490  0.997820  0.248072      0.937033   \n",
      "8   0.023701  0.992527  0.995611  0.999610  0.299994      0.934899   \n",
      "9   0.017778  0.992794  0.994879  0.999814  0.293185      0.931697   \n",
      "10  0.020657  0.993328  0.995245  0.999175  0.353679      0.931697   \n",
      "11  0.014151  0.995196  0.996708  0.999878  0.331656      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.960526  0.975663  \n",
      "1     0.976608  0.980578  \n",
      "2     0.980994  0.976943  \n",
      "3     0.980994  0.968882  \n",
      "4     0.926901  0.977599  \n",
      "5     0.961988  0.972329  \n",
      "6     0.967836  0.968111  \n",
      "7     0.951754  0.965996  \n",
      "8     0.942982  0.963182  \n",
      "9     0.942982  0.961451  \n",
      "10    0.942982  0.956187  \n",
      "11    0.954678  0.958322  \n",
      "147/147 [==============================] - 29s 195ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 129s 542ms/step - loss: 0.2337 - accuracy: 0.9061 - recall: 0.9568 - auc: 0.9557 - val_loss: 0.1534 - val_accuracy: 0.9445 - val_recall: 0.9693 - val_auc: 0.9771\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 125s 530ms/step - loss: 0.1450 - accuracy: 0.9474 - recall: 0.9685 - auc: 0.9810 - val_loss: 0.1578 - val_accuracy: 0.9424 - val_recall: 0.9766 - val_auc: 0.9772\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1075 - accuracy: 0.9610 - recall: 0.9777 - auc: 0.9896 - val_loss: 0.1546 - val_accuracy: 0.9456 - val_recall: 0.9576 - val_auc: 0.9807\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 122s 519ms/step - loss: 0.0988 - accuracy: 0.9672 - recall: 0.9810 - auc: 0.9912 - val_loss: 0.1787 - val_accuracy: 0.9338 - val_recall: 0.9357 - val_auc: 0.9790\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 122s 520ms/step - loss: 0.0794 - accuracy: 0.9720 - recall: 0.9832 - auc: 0.9941 - val_loss: 0.1636 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9803\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 122s 521ms/step - loss: 0.0612 - accuracy: 0.9776 - recall: 0.9865 - auc: 0.9964 - val_loss: 0.1980 - val_accuracy: 0.9434 - val_recall: 0.9474 - val_auc: 0.9785\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 121s 515ms/step - loss: 0.0584 - accuracy: 0.9795 - recall: 0.9868 - auc: 0.9967 - val_loss: 0.1859 - val_accuracy: 0.9434 - val_recall: 0.9722 - val_auc: 0.9722\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 122s 517ms/step - loss: 0.0305 - accuracy: 0.9907 - recall: 0.9949 - auc: 0.9988 - val_loss: 0.2916 - val_accuracy: 0.9317 - val_recall: 0.9284 - val_auc: 0.9707\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 121s 513ms/step - loss: 0.0334 - accuracy: 0.9883 - recall: 0.9945 - auc: 0.9991 - val_loss: 0.2256 - val_accuracy: 0.9456 - val_recall: 0.9561 - val_auc: 0.9737\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 121s 516ms/step - loss: 0.0223 - accuracy: 0.9920 - recall: 0.9945 - auc: 0.9992 - val_loss: 0.2643 - val_accuracy: 0.9402 - val_recall: 0.9664 - val_auc: 0.9627\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 122s 519ms/step - loss: 0.0132 - accuracy: 0.9957 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.3003 - val_accuracy: 0.9338 - val_recall: 0.9591 - val_auc: 0.9612\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 122s 520ms/step - loss: 0.0212 - accuracy: 0.9920 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.3627 - val_accuracy: 0.9210 - val_recall: 0.9825 - val_auc: 0.9461\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 123s 523ms/step - loss: 0.0158 - accuracy: 0.9955 - recall: 0.9978 - auc: 0.9997 - val_loss: 0.2948 - val_accuracy: 0.9424 - val_recall: 0.9678 - val_auc: 0.9604\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.233694  0.906058  0.956840  0.955706  0.153361      0.944504   \n",
      "1   0.145013  0.947425  0.968544  0.981019  0.157844      0.942369   \n",
      "2   0.107493  0.961035  0.977688  0.989576  0.154621      0.945571   \n",
      "3   0.098837  0.967174  0.980980  0.991209  0.178688      0.933831   \n",
      "4   0.079431  0.971978  0.983175  0.994139  0.163614      0.948773   \n",
      "5   0.061157  0.977582  0.986467  0.996412  0.198033      0.943437   \n",
      "6   0.058378  0.979450  0.986832  0.996672  0.185851      0.943437   \n",
      "7   0.030511  0.990659  0.994879  0.998753  0.291643      0.931697   \n",
      "8   0.033393  0.988257  0.994514  0.999099  0.225611      0.945571   \n",
      "9   0.022256  0.991994  0.994514  0.999202  0.264304      0.940235   \n",
      "10  0.013185  0.995730  0.997440  0.999892  0.300316      0.933831   \n",
      "11  0.021153  0.991994  0.995245  0.999635  0.362660      0.921025   \n",
      "12  0.015796  0.995463  0.997805  0.999748  0.294762      0.942369   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.969298  0.977062  \n",
      "1     0.976608  0.977189  \n",
      "2     0.957602  0.980697  \n",
      "3     0.935673  0.979015  \n",
      "4     0.960526  0.980278  \n",
      "5     0.947368  0.978530  \n",
      "6     0.972222  0.972216  \n",
      "7     0.928363  0.970691  \n",
      "8     0.956140  0.973678  \n",
      "9     0.966374  0.962714  \n",
      "10    0.959064  0.961194  \n",
      "11    0.982456  0.946123  \n",
      "12    0.967836  0.960393  \n",
      "74/74 [==============================] - 28s 374ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 128s 667ms/step - loss: 0.2687 - accuracy: 0.8850 - recall: 0.9492 - auc: 0.9399 - val_loss: 0.1539 - val_accuracy: 0.9488 - val_recall: 0.9737 - val_auc: 0.9749\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 122s 651ms/step - loss: 0.1336 - accuracy: 0.9536 - recall: 0.9733 - auc: 0.9844 - val_loss: 0.1520 - val_accuracy: 0.9477 - val_recall: 0.9591 - val_auc: 0.9802\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 121s 643ms/step - loss: 0.1254 - accuracy: 0.9536 - recall: 0.9726 - auc: 0.9864 - val_loss: 0.1658 - val_accuracy: 0.9413 - val_recall: 0.9474 - val_auc: 0.9756\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 120s 638ms/step - loss: 0.1049 - accuracy: 0.9634 - recall: 0.9784 - auc: 0.9897 - val_loss: 0.1620 - val_accuracy: 0.9434 - val_recall: 0.9620 - val_auc: 0.9785\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 121s 641ms/step - loss: 0.0861 - accuracy: 0.9701 - recall: 0.9839 - auc: 0.9934 - val_loss: 0.1711 - val_accuracy: 0.9445 - val_recall: 0.9795 - val_auc: 0.9786\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 120s 637ms/step - loss: 0.0833 - accuracy: 0.9704 - recall: 0.9832 - auc: 0.9921 - val_loss: 0.1666 - val_accuracy: 0.9392 - val_recall: 0.9488 - val_auc: 0.9774\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 120s 640ms/step - loss: 0.0586 - accuracy: 0.9789 - recall: 0.9879 - auc: 0.9955 - val_loss: 0.3160 - val_accuracy: 0.9189 - val_recall: 0.9006 - val_auc: 0.9704\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 119s 635ms/step - loss: 0.0548 - accuracy: 0.9819 - recall: 0.9879 - auc: 0.9958 - val_loss: 0.2013 - val_accuracy: 0.9317 - val_recall: 0.9474 - val_auc: 0.9730\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 121s 642ms/step - loss: 0.0447 - accuracy: 0.9867 - recall: 0.9912 - auc: 0.9974 - val_loss: 0.2339 - val_accuracy: 0.9285 - val_recall: 0.9781 - val_auc: 0.9710\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 122s 647ms/step - loss: 0.0309 - accuracy: 0.9891 - recall: 0.9934 - auc: 0.9988 - val_loss: 0.1916 - val_accuracy: 0.9445 - val_recall: 0.9737 - val_auc: 0.9716\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 121s 647ms/step - loss: 0.0403 - accuracy: 0.9856 - recall: 0.9909 - auc: 0.9983 - val_loss: 0.2672 - val_accuracy: 0.9306 - val_recall: 0.9795 - val_auc: 0.9651\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 120s 640ms/step - loss: 0.0224 - accuracy: 0.9931 - recall: 0.9963 - auc: 0.9996 - val_loss: 0.2395 - val_accuracy: 0.9328 - val_recall: 0.9708 - val_auc: 0.9698\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.268661  0.884975  0.949159  0.939918  0.153877      0.948773   \n",
      "1   0.133632  0.953563  0.973299  0.984413  0.151978      0.947705   \n",
      "2   0.125381  0.953563  0.972568  0.986356  0.165765      0.941302   \n",
      "3   0.104866  0.963437  0.978420  0.989664  0.161997      0.943437   \n",
      "4   0.086065  0.970109  0.983906  0.993434  0.171080      0.944504   \n",
      "5   0.083264  0.970376  0.983175  0.992098  0.166648      0.939168   \n",
      "6   0.058640  0.978916  0.987930  0.995539  0.315996      0.918890   \n",
      "7   0.054812  0.981852  0.987930  0.995777  0.201254      0.931697   \n",
      "8   0.044651  0.986656  0.991222  0.997445  0.233852      0.928495   \n",
      "9   0.030866  0.989058  0.993416  0.998779  0.191622      0.944504   \n",
      "10  0.040308  0.985588  0.990856  0.998283  0.267190      0.930630   \n",
      "11  0.022404  0.993061  0.996342  0.999609  0.239474      0.932764   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.973684  0.974877  \n",
      "1     0.959064  0.980171  \n",
      "2     0.947368  0.975574  \n",
      "3     0.961988  0.978541  \n",
      "4     0.979532  0.978558  \n",
      "5     0.948830  0.977432  \n",
      "6     0.900585  0.970405  \n",
      "7     0.947368  0.972959  \n",
      "8     0.978070  0.971023  \n",
      "9     0.973684  0.971641  \n",
      "10    0.979532  0.965071  \n",
      "11    0.970760  0.969761  \n",
      "59/59 [==============================] - 27s 448ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 1969s 17s/step - loss: 0.3697 - accuracy: 0.8308 - recall: 0.9294 - auc: 0.8825 - val_loss: 0.1901 - val_accuracy: 0.9317 - val_recall: 0.9298 - val_auc: 0.9784\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 85s 718ms/step - loss: 0.1711 - accuracy: 0.9359 - recall: 0.9656 - auc: 0.9754 - val_loss: 0.1747 - val_accuracy: 0.9328 - val_recall: 0.9854 - val_auc: 0.9745\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 91s 767ms/step - loss: 0.1297 - accuracy: 0.9512 - recall: 0.9700 - auc: 0.9846 - val_loss: 0.1791 - val_accuracy: 0.9424 - val_recall: 0.9386 - val_auc: 0.9801\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 96s 814ms/step - loss: 0.1158 - accuracy: 0.9605 - recall: 0.9770 - auc: 0.9881 - val_loss: 0.1476 - val_accuracy: 0.9477 - val_recall: 0.9649 - val_auc: 0.9783\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 94s 800ms/step - loss: 0.0953 - accuracy: 0.9653 - recall: 0.9792 - auc: 0.9914 - val_loss: 0.1709 - val_accuracy: 0.9477 - val_recall: 0.9854 - val_auc: 0.9758\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 97s 822ms/step - loss: 0.0903 - accuracy: 0.9688 - recall: 0.9810 - auc: 0.9930 - val_loss: 0.1625 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9782\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 99s 840ms/step - loss: 0.0866 - accuracy: 0.9690 - recall: 0.9813 - auc: 0.9935 - val_loss: 0.1776 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9719\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 101s 852ms/step - loss: 0.0736 - accuracy: 0.9754 - recall: 0.9846 - auc: 0.9944 - val_loss: 0.1616 - val_accuracy: 0.9445 - val_recall: 0.9635 - val_auc: 0.9790\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 100s 849ms/step - loss: 0.0654 - accuracy: 0.9770 - recall: 0.9857 - auc: 0.9960 - val_loss: 0.1748 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9740\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 100s 852ms/step - loss: 0.0531 - accuracy: 0.9827 - recall: 0.9894 - auc: 0.9973 - val_loss: 0.1942 - val_accuracy: 0.9328 - val_recall: 0.9708 - val_auc: 0.9756\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 98s 834ms/step - loss: 0.0427 - accuracy: 0.9835 - recall: 0.9912 - auc: 0.9988 - val_loss: 0.1799 - val_accuracy: 0.9445 - val_recall: 0.9532 - val_auc: 0.9752\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 101s 855ms/step - loss: 0.0347 - accuracy: 0.9875 - recall: 0.9927 - auc: 0.9992 - val_loss: 0.2079 - val_accuracy: 0.9413 - val_recall: 0.9430 - val_auc: 0.9755\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 103s 872ms/step - loss: 0.0300 - accuracy: 0.9907 - recall: 0.9945 - auc: 0.9992 - val_loss: 0.2101 - val_accuracy: 0.9392 - val_recall: 0.9591 - val_auc: 0.9744\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.369716  0.830798  0.929407  0.882521  0.190066      0.931697   \n",
      "1   0.171092  0.935949  0.965618  0.975379  0.174678      0.932764   \n",
      "2   0.129685  0.951161  0.970007  0.984564  0.179082      0.942369   \n",
      "3   0.115828  0.960502  0.976957  0.988061  0.147566      0.947705   \n",
      "4   0.095321  0.965306  0.979151  0.991383  0.170861      0.947705   \n",
      "5   0.090305  0.968775  0.980980  0.992954  0.162546      0.943437   \n",
      "6   0.086604  0.969042  0.981346  0.993471  0.177581      0.937033   \n",
      "7   0.073614  0.975447  0.984638  0.994386  0.161570      0.944504   \n",
      "8   0.065370  0.977048  0.985735  0.996015  0.174773      0.939168   \n",
      "9   0.053092  0.982653  0.989393  0.997280  0.194157      0.932764   \n",
      "10  0.042716  0.983453  0.991222  0.998761  0.179883      0.944504   \n",
      "11  0.034685  0.987457  0.992685  0.999177  0.207929      0.941302   \n",
      "12  0.029978  0.990659  0.994514  0.999200  0.210063      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.929825  0.978405  \n",
      "1     0.985380  0.974525  \n",
      "2     0.938596  0.980070  \n",
      "3     0.964912  0.978304  \n",
      "4     0.985380  0.975759  \n",
      "5     0.957602  0.978209  \n",
      "6     0.979532  0.971916  \n",
      "7     0.963450  0.979006  \n",
      "8     0.957602  0.973959  \n",
      "9     0.970760  0.975556  \n",
      "10    0.953216  0.975242  \n",
      "11    0.942982  0.975487  \n",
      "12    0.959064  0.974395  \n",
      "37/37 [==============================] - 21s 549ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.4250 - accuracy: 0.8118 - recall: 0.9378 - auc: 0.8460 - val_loss: 0.1938 - val_accuracy: 0.9200 - val_recall: 0.9576 - val_auc: 0.9711\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.1638 - accuracy: 0.9367 - recall: 0.9638 - auc: 0.9793 - val_loss: 0.1996 - val_accuracy: 0.9264 - val_recall: 0.9898 - val_auc: 0.9760\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.1258 - accuracy: 0.9528 - recall: 0.9737 - auc: 0.9868 - val_loss: 0.1652 - val_accuracy: 0.9349 - val_recall: 0.9795 - val_auc: 0.9774\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.1071 - accuracy: 0.9597 - recall: 0.9755 - auc: 0.9900 - val_loss: 0.1649 - val_accuracy: 0.9381 - val_recall: 0.9825 - val_auc: 0.9756\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.1089 - accuracy: 0.9573 - recall: 0.9755 - auc: 0.9898 - val_loss: 0.1502 - val_accuracy: 0.9445 - val_recall: 0.9532 - val_auc: 0.9808\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0955 - accuracy: 0.9656 - recall: 0.9799 - auc: 0.9921 - val_loss: 0.1494 - val_accuracy: 0.9466 - val_recall: 0.9693 - val_auc: 0.9788\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0853 - accuracy: 0.9693 - recall: 0.9817 - auc: 0.9927 - val_loss: 0.1523 - val_accuracy: 0.9477 - val_recall: 0.9620 - val_auc: 0.9799\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.1250 - accuracy: 0.9544 - recall: 0.9770 - auc: 0.9871 - val_loss: 0.1830 - val_accuracy: 0.9264 - val_recall: 0.9868 - val_auc: 0.9744\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.0888 - accuracy: 0.9717 - recall: 0.9846 - auc: 0.9926 - val_loss: 0.1476 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9809\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.0668 - accuracy: 0.9778 - recall: 0.9876 - auc: 0.9956 - val_loss: 0.1637 - val_accuracy: 0.9477 - val_recall: 0.9561 - val_auc: 0.9817\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0613 - accuracy: 0.9773 - recall: 0.9868 - auc: 0.9960 - val_loss: 0.1612 - val_accuracy: 0.9498 - val_recall: 0.9620 - val_auc: 0.9785\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 92s 2s/step - loss: 0.0563 - accuracy: 0.9805 - recall: 0.9887 - auc: 0.9967 - val_loss: 0.1615 - val_accuracy: 0.9509 - val_recall: 0.9635 - val_auc: 0.9769\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0551 - accuracy: 0.9816 - recall: 0.9901 - auc: 0.9971 - val_loss: 0.1874 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9749\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0455 - accuracy: 0.9845 - recall: 0.9912 - auc: 0.9976 - val_loss: 0.1635 - val_accuracy: 0.9488 - val_recall: 0.9635 - val_auc: 0.9776\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0361 - accuracy: 0.9901 - recall: 0.9952 - auc: 0.9986 - val_loss: 0.1906 - val_accuracy: 0.9498 - val_recall: 0.9561 - val_auc: 0.9767\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0294 - accuracy: 0.9917 - recall: 0.9960 - auc: 0.9993 - val_loss: 0.1998 - val_accuracy: 0.9456 - val_recall: 0.9444 - val_auc: 0.9767\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.0372 - accuracy: 0.9869 - recall: 0.9923 - auc: 0.9989 - val_loss: 0.2155 - val_accuracy: 0.9402 - val_recall: 0.9766 - val_auc: 0.9713\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 93s 2s/step - loss: 0.0262 - accuracy: 0.9920 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.2006 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9730\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 93s 2s/step - loss: 0.0211 - accuracy: 0.9939 - recall: 0.9963 - auc: 0.9997 - val_loss: 0.2026 - val_accuracy: 0.9466 - val_recall: 0.9605 - val_auc: 0.9744\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0160 - accuracy: 0.9957 - recall: 0.9978 - auc: 0.9999 - val_loss: 0.2235 - val_accuracy: 0.9424 - val_recall: 0.9503 - val_auc: 0.9726\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.424956  0.811849  0.937820  0.846020  0.193828      0.919957   \n",
      "1   0.163797  0.936749  0.963789  0.979322  0.199570      0.926361   \n",
      "2   0.125762  0.952762  0.973665  0.986798  0.165246      0.934899   \n",
      "3   0.107068  0.959701  0.975494  0.989991  0.164894      0.938100   \n",
      "4   0.108850  0.957299  0.975494  0.989769  0.150206      0.944504   \n",
      "5   0.095539  0.965572  0.979883  0.992103  0.149421      0.946638   \n",
      "6   0.085344  0.969309  0.981712  0.992712  0.152297      0.947705   \n",
      "7   0.125005  0.954363  0.976957  0.987059  0.183015      0.926361   \n",
      "8   0.088773  0.971711  0.984638  0.992550  0.147572      0.945571   \n",
      "9   0.066761  0.977849  0.987564  0.995576  0.163730      0.947705   \n",
      "10  0.061270  0.977315  0.986832  0.996002  0.161231      0.949840   \n",
      "11  0.056285  0.980518  0.988661  0.996731  0.161504      0.950907   \n",
      "12  0.055150  0.981585  0.990124  0.997113  0.187390      0.937033   \n",
      "13  0.045539  0.984521  0.991222  0.997581  0.163450      0.948773   \n",
      "14  0.036120  0.990125  0.995245  0.998556  0.190596      0.949840   \n",
      "15  0.029430  0.991727  0.995977  0.999295  0.199841      0.945571   \n",
      "16  0.037180  0.986923  0.992319  0.998945  0.215487      0.940235   \n",
      "17  0.026201  0.991994  0.995245  0.999601  0.200585      0.943437   \n",
      "18  0.021119  0.993862  0.996342  0.999737  0.202591      0.946638   \n",
      "19  0.015992  0.995730  0.997805  0.999861  0.223494      0.942369   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.957602  0.971093  \n",
      "1     0.989766  0.975955  \n",
      "2     0.979532  0.977443  \n",
      "3     0.982456  0.975559  \n",
      "4     0.953216  0.980778  \n",
      "5     0.969298  0.978830  \n",
      "6     0.961988  0.979942  \n",
      "7     0.986842  0.974447  \n",
      "8     0.960526  0.980933  \n",
      "9     0.956140  0.981688  \n",
      "10    0.961988  0.978524  \n",
      "11    0.963450  0.976929  \n",
      "12    0.979532  0.974909  \n",
      "13    0.963450  0.977573  \n",
      "14    0.956140  0.976689  \n",
      "15    0.944444  0.976657  \n",
      "16    0.976608  0.971344  \n",
      "17    0.957602  0.973049  \n",
      "18    0.960526  0.974366  \n",
      "19    0.950292  0.972641  \n",
      "19/19 [==============================] - 19s 973ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 126s 267ms/step - loss: 0.2864 - accuracy: 0.8874 - recall: 0.9433 - auc: 0.9372 - val_loss: 0.1936 - val_accuracy: 0.9253 - val_recall: 0.9547 - val_auc: 0.9683\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 122s 261ms/step - loss: 0.1703 - accuracy: 0.9402 - recall: 0.9653 - auc: 0.9760 - val_loss: 0.1573 - val_accuracy: 0.9445 - val_recall: 0.9678 - val_auc: 0.9773\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 120s 256ms/step - loss: 0.1297 - accuracy: 0.9520 - recall: 0.9711 - auc: 0.9857 - val_loss: 0.1476 - val_accuracy: 0.9434 - val_recall: 0.9664 - val_auc: 0.9794\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.1116 - accuracy: 0.9589 - recall: 0.9766 - auc: 0.9893 - val_loss: 0.1686 - val_accuracy: 0.9445 - val_recall: 0.9576 - val_auc: 0.9776\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.0776 - accuracy: 0.9722 - recall: 0.9828 - auc: 0.9949 - val_loss: 0.2030 - val_accuracy: 0.9328 - val_recall: 0.9635 - val_auc: 0.9714\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0721 - accuracy: 0.9725 - recall: 0.9843 - auc: 0.9957 - val_loss: 0.2534 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9690\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 126s 268ms/step - loss: 0.0703 - accuracy: 0.9749 - recall: 0.9872 - auc: 0.9962 - val_loss: 0.2605 - val_accuracy: 0.9392 - val_recall: 0.9532 - val_auc: 0.9672\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 127s 271ms/step - loss: 0.0489 - accuracy: 0.9813 - recall: 0.9883 - auc: 0.9977 - val_loss: 0.2536 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9730\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 0.0427 - accuracy: 0.9835 - recall: 0.9901 - auc: 0.9982 - val_loss: 0.2939 - val_accuracy: 0.9424 - val_recall: 0.9547 - val_auc: 0.9691\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 122s 260ms/step - loss: 0.0277 - accuracy: 0.9907 - recall: 0.9952 - auc: 0.9995 - val_loss: 0.2774 - val_accuracy: 0.9434 - val_recall: 0.9488 - val_auc: 0.9654\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0283 - accuracy: 0.9893 - recall: 0.9934 - auc: 0.9994 - val_loss: 0.2106 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9713\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 124s 265ms/step - loss: 0.0387 - accuracy: 0.9861 - recall: 0.9909 - auc: 0.9987 - val_loss: 0.2963 - val_accuracy: 0.9424 - val_recall: 0.9664 - val_auc: 0.9655\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.0288 - accuracy: 0.9893 - recall: 0.9931 - auc: 0.9989 - val_loss: 0.3979 - val_accuracy: 0.9338 - val_recall: 0.9737 - val_auc: 0.9587\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.286351  0.887377  0.943307  0.937185  0.193556      0.925294   \n",
      "1   0.170280  0.940219  0.965252  0.976015  0.157257      0.944504   \n",
      "2   0.129660  0.951962  0.971105  0.985696  0.147639      0.943437   \n",
      "3   0.111613  0.958900  0.976591  0.989286  0.168617      0.944504   \n",
      "4   0.077565  0.972244  0.982809  0.994905  0.203023      0.932764   \n",
      "5   0.072097  0.972511  0.984272  0.995717  0.253424      0.940235   \n",
      "6   0.070272  0.974913  0.987198  0.996219  0.260495      0.939168   \n",
      "7   0.048939  0.981318  0.988296  0.997699  0.253580      0.942369   \n",
      "8   0.042660  0.983453  0.990124  0.998169  0.293930      0.942369   \n",
      "9   0.027658  0.990659  0.995245  0.999483  0.277409      0.943437   \n",
      "10  0.028260  0.989325  0.993416  0.999416  0.210610      0.944504   \n",
      "11  0.038690  0.986122  0.990856  0.998737  0.296320      0.942369   \n",
      "12  0.028825  0.989325  0.993050  0.998885  0.397855      0.933831   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.954678  0.968322  \n",
      "1     0.967836  0.977284  \n",
      "2     0.966374  0.979414  \n",
      "3     0.957602  0.977617  \n",
      "4     0.963450  0.971439  \n",
      "5     0.951754  0.968969  \n",
      "6     0.953216  0.967241  \n",
      "7     0.964912  0.973023  \n",
      "8     0.954678  0.969142  \n",
      "9     0.948830  0.965447  \n",
      "10    0.961988  0.971309  \n",
      "11    0.966374  0.965453  \n",
      "12    0.973684  0.958703  \n",
      "147/147 [==============================] - 29s 198ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 123s 517ms/step - loss: 0.3065 - accuracy: 0.8716 - recall: 0.9309 - auc: 0.9248 - val_loss: 0.1923 - val_accuracy: 0.9296 - val_recall: 0.9240 - val_auc: 0.9812\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 121s 516ms/step - loss: 0.1420 - accuracy: 0.9482 - recall: 0.9685 - auc: 0.9820 - val_loss: 0.1797 - val_accuracy: 0.9360 - val_recall: 0.9605 - val_auc: 0.9707\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 125s 532ms/step - loss: 0.1001 - accuracy: 0.9634 - recall: 0.9788 - auc: 0.9911 - val_loss: 0.1929 - val_accuracy: 0.9285 - val_recall: 0.9225 - val_auc: 0.9812\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 120s 509ms/step - loss: 0.0910 - accuracy: 0.9682 - recall: 0.9799 - auc: 0.9922 - val_loss: 0.1843 - val_accuracy: 0.9402 - val_recall: 0.9708 - val_auc: 0.9741\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 2432s 10s/step - loss: 0.0658 - accuracy: 0.9749 - recall: 0.9850 - auc: 0.9962 - val_loss: 0.2059 - val_accuracy: 0.9338 - val_recall: 0.9708 - val_auc: 0.9718\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 96s 409ms/step - loss: 0.0554 - accuracy: 0.9795 - recall: 0.9861 - auc: 0.9971 - val_loss: 0.3524 - val_accuracy: 0.8890 - val_recall: 0.9927 - val_auc: 0.9634\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 102s 432ms/step - loss: 0.0502 - accuracy: 0.9813 - recall: 0.9894 - auc: 0.9977 - val_loss: 0.2661 - val_accuracy: 0.9402 - val_recall: 0.9444 - val_auc: 0.9695\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 106s 450ms/step - loss: 0.0277 - accuracy: 0.9907 - recall: 0.9938 - auc: 0.9989 - val_loss: 0.2658 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9685\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 107s 454ms/step - loss: 0.0182 - accuracy: 0.9931 - recall: 0.9956 - auc: 0.9998 - val_loss: 0.3562 - val_accuracy: 0.9360 - val_recall: 0.9678 - val_auc: 0.9568\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 107s 454ms/step - loss: 0.0280 - accuracy: 0.9893 - recall: 0.9927 - auc: 0.9989 - val_loss: 0.4348 - val_accuracy: 0.9157 - val_recall: 0.9868 - val_auc: 0.9459\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 109s 463ms/step - loss: 0.0159 - accuracy: 0.9925 - recall: 0.9945 - auc: 0.9998 - val_loss: 0.3601 - val_accuracy: 0.9413 - val_recall: 0.9664 - val_auc: 0.9616\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.306545  0.871631  0.930871  0.924816  0.192308      0.929562   \n",
      "1   0.142018  0.948225  0.968544  0.982038  0.179749      0.935966   \n",
      "2   0.100099  0.963437  0.978786  0.991119  0.192881      0.928495   \n",
      "3   0.091043  0.968241  0.979883  0.992166  0.184327      0.940235   \n",
      "4   0.065755  0.974913  0.985004  0.996199  0.205924      0.933831   \n",
      "5   0.055367  0.979450  0.986101  0.997087  0.352383      0.889007   \n",
      "6   0.050208  0.981318  0.989393  0.997681  0.266091      0.940235   \n",
      "7   0.027695  0.990659  0.993782  0.998927  0.265799      0.940235   \n",
      "8   0.018219  0.993061  0.995611  0.999777  0.356191      0.935966   \n",
      "9   0.027952  0.989325  0.992685  0.998923  0.434763      0.915688   \n",
      "10  0.015894  0.992527  0.994514  0.999837  0.360053      0.941302   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.923977  0.981231  \n",
      "1     0.960526  0.970746  \n",
      "2     0.922515  0.981159  \n",
      "3     0.970760  0.974074  \n",
      "4     0.970760  0.971835  \n",
      "5     0.992690  0.963395  \n",
      "6     0.944444  0.969495  \n",
      "7     0.951754  0.968512  \n",
      "8     0.967836  0.956759  \n",
      "9     0.986842  0.945918  \n",
      "10    0.966374  0.961552  \n",
      "74/74 [==============================] - 23s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 106s 560ms/step - loss: 0.2815 - accuracy: 0.9026 - recall: 0.9535 - auc: 0.9438 - val_loss: 0.1492 - val_accuracy: 0.9445 - val_recall: 0.9649 - val_auc: 0.9796\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 103s 545ms/step - loss: 0.1348 - accuracy: 0.9522 - recall: 0.9707 - auc: 0.9841 - val_loss: 0.1461 - val_accuracy: 0.9477 - val_recall: 0.9547 - val_auc: 0.9830\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 104s 554ms/step - loss: 0.1083 - accuracy: 0.9594 - recall: 0.9755 - auc: 0.9906 - val_loss: 0.1512 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9807\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 103s 546ms/step - loss: 0.0783 - accuracy: 0.9722 - recall: 0.9810 - auc: 0.9939 - val_loss: 0.1671 - val_accuracy: 0.9445 - val_recall: 0.9635 - val_auc: 0.9785\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 104s 553ms/step - loss: 0.0588 - accuracy: 0.9760 - recall: 0.9854 - auc: 0.9969 - val_loss: 0.1785 - val_accuracy: 0.9477 - val_recall: 0.9664 - val_auc: 0.9756\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0500 - accuracy: 0.9832 - recall: 0.9898 - auc: 0.9976 - val_loss: 0.2126 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9733\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 104s 553ms/step - loss: 0.0413 - accuracy: 0.9856 - recall: 0.9923 - auc: 0.9987 - val_loss: 0.2230 - val_accuracy: 0.9445 - val_recall: 0.9708 - val_auc: 0.9715\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0235 - accuracy: 0.9909 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2833 - val_accuracy: 0.9445 - val_recall: 0.9664 - val_auc: 0.9636\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 104s 554ms/step - loss: 0.0236 - accuracy: 0.9907 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2452 - val_accuracy: 0.9434 - val_recall: 0.9488 - val_auc: 0.9651\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 106s 563ms/step - loss: 0.0183 - accuracy: 0.9939 - recall: 0.9971 - auc: 0.9996 - val_loss: 0.2770 - val_accuracy: 0.9424 - val_recall: 0.9708 - val_auc: 0.9592\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 105s 557ms/step - loss: 0.0094 - accuracy: 0.9965 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9624\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 103s 550ms/step - loss: 0.0137 - accuracy: 0.9939 - recall: 0.9963 - auc: 0.9999 - val_loss: 0.3096 - val_accuracy: 0.9445 - val_recall: 0.9576 - val_auc: 0.9596\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.281500  0.902589  0.953548  0.943786  0.149173      0.944504   \n",
      "1   0.134789  0.952228  0.970739  0.984134  0.146123      0.947705   \n",
      "2   0.108265  0.959434  0.975494  0.990626  0.151172      0.943437   \n",
      "3   0.078313  0.972244  0.980980  0.993867  0.167134      0.944504   \n",
      "4   0.058803  0.975981  0.985369  0.996888  0.178479      0.947705   \n",
      "5   0.049970  0.983187  0.989759  0.997595  0.212579      0.945571   \n",
      "6   0.041347  0.985588  0.992319  0.998650  0.223001      0.944504   \n",
      "7   0.023544  0.990926  0.995611  0.999585  0.283347      0.944504   \n",
      "8   0.023583  0.990659  0.995611  0.999568  0.245153      0.943437   \n",
      "9   0.018346  0.993862  0.997074  0.999632  0.276999      0.942369   \n",
      "10  0.009430  0.996531  0.998903  0.999956  0.323370      0.945571   \n",
      "11  0.013717  0.993862  0.996342  0.999864  0.309592      0.944504   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.964912  0.979630  \n",
      "1     0.954678  0.983031  \n",
      "2     0.959064  0.980720  \n",
      "3     0.963450  0.978544  \n",
      "4     0.966374  0.975565  \n",
      "5     0.960526  0.973294  \n",
      "6     0.970760  0.971509  \n",
      "7     0.966374  0.963586  \n",
      "8     0.948830  0.965097  \n",
      "9     0.970760  0.959235  \n",
      "10    0.960526  0.962407  \n",
      "11    0.957602  0.959556  \n",
      "59/59 [==============================] - 22s 374ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 95s 802ms/step - loss: 0.4719 - accuracy: 0.8161 - recall: 0.9195 - auc: 0.8565 - val_loss: 0.1762 - val_accuracy: 0.9338 - val_recall: 0.9649 - val_auc: 0.9748\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 93s 786ms/step - loss: 0.1879 - accuracy: 0.9285 - recall: 0.9594 - auc: 0.9714 - val_loss: 0.1643 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9750\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 92s 782ms/step - loss: 0.1352 - accuracy: 0.9512 - recall: 0.9685 - auc: 0.9844 - val_loss: 0.1719 - val_accuracy: 0.9413 - val_recall: 0.9708 - val_auc: 0.9735\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 92s 779ms/step - loss: 0.1086 - accuracy: 0.9624 - recall: 0.9755 - auc: 0.9897 - val_loss: 0.1674 - val_accuracy: 0.9424 - val_recall: 0.9488 - val_auc: 0.9788\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0985 - accuracy: 0.9650 - recall: 0.9795 - auc: 0.9913 - val_loss: 0.1569 - val_accuracy: 0.9434 - val_recall: 0.9635 - val_auc: 0.9770\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0793 - accuracy: 0.9706 - recall: 0.9824 - auc: 0.9943 - val_loss: 0.1735 - val_accuracy: 0.9413 - val_recall: 0.9561 - val_auc: 0.9772\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 93s 785ms/step - loss: 0.0680 - accuracy: 0.9741 - recall: 0.9824 - auc: 0.9965 - val_loss: 0.1761 - val_accuracy: 0.9424 - val_recall: 0.9518 - val_auc: 0.9778\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 93s 787ms/step - loss: 0.0556 - accuracy: 0.9792 - recall: 0.9872 - auc: 0.9970 - val_loss: 0.1746 - val_accuracy: 0.9317 - val_recall: 0.9327 - val_auc: 0.9789\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 91s 775ms/step - loss: 0.0415 - accuracy: 0.9853 - recall: 0.9927 - auc: 0.9988 - val_loss: 0.2083 - val_accuracy: 0.9370 - val_recall: 0.9371 - val_auc: 0.9752\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0397 - accuracy: 0.9880 - recall: 0.9952 - auc: 0.9989 - val_loss: 0.2332 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9699\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0272 - accuracy: 0.9909 - recall: 0.9949 - auc: 0.9995 - val_loss: 0.2306 - val_accuracy: 0.9360 - val_recall: 0.9415 - val_auc: 0.9721\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 92s 783ms/step - loss: 0.0275 - accuracy: 0.9912 - recall: 0.9945 - auc: 0.9990 - val_loss: 0.2548 - val_accuracy: 0.9466 - val_recall: 0.9620 - val_auc: 0.9671\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 91s 775ms/step - loss: 0.0219 - accuracy: 0.9912 - recall: 0.9952 - auc: 0.9997 - val_loss: 0.2989 - val_accuracy: 0.9360 - val_recall: 0.9561 - val_auc: 0.9634\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 92s 781ms/step - loss: 0.0166 - accuracy: 0.9947 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.2616 - val_accuracy: 0.9349 - val_recall: 0.9547 - val_auc: 0.9637\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1327s 11s/step - loss: 0.0164 - accuracy: 0.9955 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.3263 - val_accuracy: 0.9370 - val_recall: 0.9503 - val_auc: 0.9604\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 117s 991ms/step - loss: 0.0094 - accuracy: 0.9973 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9402 - val_recall: 0.9605 - val_auc: 0.9607\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 114s 963ms/step - loss: 0.0072 - accuracy: 0.9971 - recall: 0.9993 - auc: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9608\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 114s 967ms/step - loss: 0.0060 - accuracy: 0.9981 - recall: 0.9996 - auc: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9402 - val_recall: 0.9547 - val_auc: 0.9695\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.471899  0.816120  0.919532  0.856486  0.176164      0.933831   \n",
      "1   0.187888  0.928476  0.959400  0.971426  0.164320      0.937033   \n",
      "2   0.135242  0.951161  0.968544  0.984427  0.171905      0.941302   \n",
      "3   0.108624  0.962370  0.975494  0.989695  0.167444      0.942369   \n",
      "4   0.098469  0.965039  0.979517  0.991337  0.156905      0.943437   \n",
      "5   0.079289  0.970643  0.982443  0.994348  0.173466      0.941302   \n",
      "6   0.068028  0.974113  0.982443  0.996504  0.176075      0.942369   \n",
      "7   0.055609  0.979183  0.987198  0.997035  0.174591      0.931697   \n",
      "8   0.041470  0.985322  0.992685  0.998796  0.208304      0.937033   \n",
      "9   0.039727  0.987990  0.995245  0.998940  0.233233      0.943437   \n",
      "10  0.027204  0.990926  0.994879  0.999516  0.230631      0.935966   \n",
      "11  0.027515  0.991193  0.994514  0.999048  0.254787      0.946638   \n",
      "12  0.021948  0.991193  0.995245  0.999701  0.298896      0.935966   \n",
      "13  0.016643  0.994662  0.997805  0.999824  0.261608      0.934899   \n",
      "14  0.016380  0.995463  0.997805  0.999820  0.326311      0.937033   \n",
      "15  0.009386  0.997331  0.998903  0.999955  0.305458      0.940235   \n",
      "16  0.007249  0.997064  0.999268  0.999981  0.360749      0.939168   \n",
      "17  0.006011  0.998132  0.999634  0.999989  0.280047      0.940235   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.964912  0.974771  \n",
      "1     0.967836  0.975039  \n",
      "2     0.970760  0.973543  \n",
      "3     0.948830  0.978810  \n",
      "4     0.963450  0.977030  \n",
      "5     0.956140  0.977203  \n",
      "6     0.951754  0.977801  \n",
      "7     0.932749  0.978882  \n",
      "8     0.937135  0.975172  \n",
      "9     0.959064  0.969856  \n",
      "10    0.941520  0.972107  \n",
      "11    0.961988  0.967137  \n",
      "12    0.956140  0.963407  \n",
      "13    0.954678  0.963745  \n",
      "14    0.950292  0.960362  \n",
      "15    0.960526  0.960723  \n",
      "16    0.954678  0.960824  \n",
      "17    0.954678  0.969538  \n",
      "37/37 [==============================] - 26s 688ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 115s 2s/step - loss: 0.4763 - accuracy: 0.8257 - recall: 0.9104 - auc: 0.8621 - val_loss: 0.1772 - val_accuracy: 0.9360 - val_recall: 0.9737 - val_auc: 0.9734\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.1549 - accuracy: 0.9400 - recall: 0.9631 - auc: 0.9806 - val_loss: 0.2026 - val_accuracy: 0.9285 - val_recall: 0.9883 - val_auc: 0.9724\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.1302 - accuracy: 0.9549 - recall: 0.9726 - auc: 0.9838 - val_loss: 0.1633 - val_accuracy: 0.9445 - val_recall: 0.9810 - val_auc: 0.9777\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.1043 - accuracy: 0.9624 - recall: 0.9744 - auc: 0.9905 - val_loss: 0.1901 - val_accuracy: 0.9296 - val_recall: 0.9839 - val_auc: 0.9735\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 112s 2s/step - loss: 0.0841 - accuracy: 0.9712 - recall: 0.9835 - auc: 0.9939 - val_loss: 0.1623 - val_accuracy: 0.9402 - val_recall: 0.9722 - val_auc: 0.9751\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 112s 2s/step - loss: 0.0691 - accuracy: 0.9762 - recall: 0.9850 - auc: 0.9956 - val_loss: 0.2033 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9722\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 120s 2s/step - loss: 0.0479 - accuracy: 0.9829 - recall: 0.9909 - auc: 0.9978 - val_loss: 0.1709 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9775\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0359 - accuracy: 0.9891 - recall: 0.9941 - auc: 0.9986 - val_loss: 0.2186 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9694\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0282 - accuracy: 0.9912 - recall: 0.9960 - auc: 0.9990 - val_loss: 0.2097 - val_accuracy: 0.9392 - val_recall: 0.9605 - val_auc: 0.9706\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0223 - accuracy: 0.9931 - recall: 0.9956 - auc: 0.9996 - val_loss: 0.2129 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9705\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 109s 2s/step - loss: 0.0208 - accuracy: 0.9928 - recall: 0.9967 - auc: 0.9997 - val_loss: 0.2356 - val_accuracy: 0.9392 - val_recall: 0.9532 - val_auc: 0.9680\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 110s 2s/step - loss: 0.0146 - accuracy: 0.9965 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.2607 - val_accuracy: 0.9424 - val_recall: 0.9635 - val_auc: 0.9648\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 111s 2s/step - loss: 0.0069 - accuracy: 0.9979 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9640\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.476267  0.825727  0.910388  0.862130  0.177177      0.935966   \n",
      "1   0.154883  0.939952  0.963058  0.980603  0.202630      0.928495   \n",
      "2   0.130205  0.954897  0.972568  0.983823  0.163347      0.944504   \n",
      "3   0.104302  0.962370  0.974396  0.990475  0.190098      0.929562   \n",
      "4   0.084089  0.971177  0.983541  0.993905  0.162277      0.940235   \n",
      "5   0.069094  0.976248  0.985004  0.995592  0.203283      0.937033   \n",
      "6   0.047928  0.982920  0.990856  0.997783  0.170939      0.942369   \n",
      "7   0.035906  0.989058  0.994148  0.998637  0.218613      0.942369   \n",
      "8   0.028233  0.991193  0.995977  0.999020  0.209707      0.939168   \n",
      "9   0.022312  0.993061  0.995611  0.999625  0.212922      0.939168   \n",
      "10  0.020845  0.992794  0.996708  0.999728  0.235633      0.939168   \n",
      "11  0.014647  0.996531  0.998537  0.999853  0.260720      0.942369   \n",
      "12  0.006895  0.997865  0.998537  0.999982  0.256643      0.944504   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.973684  0.973407  \n",
      "1     0.988304  0.972381  \n",
      "2     0.980994  0.977738  \n",
      "3     0.983918  0.973545  \n",
      "4     0.972222  0.975071  \n",
      "5     0.979532  0.972162  \n",
      "6     0.964912  0.977539  \n",
      "7     0.972222  0.969431  \n",
      "8     0.960526  0.970564  \n",
      "9     0.957602  0.970526  \n",
      "10    0.953216  0.967981  \n",
      "11    0.963450  0.964759  \n",
      "12    0.961988  0.963965  \n",
      "19/19 [==============================] - 25s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 134s 281ms/step - loss: 0.2988 - accuracy: 0.8775 - recall: 0.9250 - auc: 0.9289 - val_loss: 0.3196 - val_accuracy: 0.8506 - val_recall: 0.8070 - val_auc: 0.9724\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.1744 - accuracy: 0.9389 - recall: 0.9583 - auc: 0.9744 - val_loss: 0.1602 - val_accuracy: 0.9381 - val_recall: 0.9532 - val_auc: 0.9764\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 129s 276ms/step - loss: 0.1085 - accuracy: 0.9573 - recall: 0.9737 - auc: 0.9898 - val_loss: 0.1804 - val_accuracy: 0.9424 - val_recall: 0.9751 - val_auc: 0.9756\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 130s 276ms/step - loss: 0.0995 - accuracy: 0.9656 - recall: 0.9777 - auc: 0.9909 - val_loss: 0.1781 - val_accuracy: 0.9360 - val_recall: 0.9795 - val_auc: 0.9754\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0785 - accuracy: 0.9738 - recall: 0.9843 - auc: 0.9938 - val_loss: 0.2426 - val_accuracy: 0.9349 - val_recall: 0.9503 - val_auc: 0.9688\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0900 - accuracy: 0.9696 - recall: 0.9846 - auc: 0.9913 - val_loss: 0.2056 - val_accuracy: 0.9402 - val_recall: 0.9576 - val_auc: 0.9723\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 131s 280ms/step - loss: 0.0804 - accuracy: 0.9696 - recall: 0.9806 - auc: 0.9931 - val_loss: 0.2035 - val_accuracy: 0.9402 - val_recall: 0.9474 - val_auc: 0.9766\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0415 - accuracy: 0.9837 - recall: 0.9920 - auc: 0.9977 - val_loss: 0.2398 - val_accuracy: 0.9285 - val_recall: 0.9503 - val_auc: 0.9689\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0299 - accuracy: 0.9888 - recall: 0.9945 - auc: 0.9983 - val_loss: 0.3055 - val_accuracy: 0.9264 - val_recall: 0.9430 - val_auc: 0.9631\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0798 - accuracy: 0.9776 - recall: 0.9854 - auc: 0.9933 - val_loss: 0.3148 - val_accuracy: 0.9349 - val_recall: 0.9488 - val_auc: 0.9630\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 128s 274ms/step - loss: 0.0348 - accuracy: 0.9875 - recall: 0.9934 - auc: 0.9984 - val_loss: 0.3338 - val_accuracy: 0.9317 - val_recall: 0.9488 - val_auc: 0.9611\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.0237 - accuracy: 0.9923 - recall: 0.9963 - auc: 0.9995 - val_loss: 0.3488 - val_accuracy: 0.9370 - val_recall: 0.9518 - val_auc: 0.9651\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 128s 273ms/step - loss: 0.0218 - accuracy: 0.9936 - recall: 0.9974 - auc: 0.9977 - val_loss: 0.4539 - val_accuracy: 0.9285 - val_recall: 0.9518 - val_auc: 0.9469\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 128s 272ms/step - loss: 0.0265 - accuracy: 0.9901 - recall: 0.9927 - auc: 0.9985 - val_loss: 0.5325 - val_accuracy: 0.9253 - val_recall: 0.9693 - val_auc: 0.9277\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.0106 - accuracy: 0.9971 - recall: 0.9993 - auc: 0.9994 - val_loss: 0.6074 - val_accuracy: 0.9274 - val_recall: 0.9415 - val_auc: 0.9465\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.0279 - accuracy: 0.9915 - recall: 0.9963 - auc: 0.9980 - val_loss: 0.4722 - val_accuracy: 0.9253 - val_recall: 0.9371 - val_auc: 0.9526\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 131s 280ms/step - loss: 0.0244 - accuracy: 0.9904 - recall: 0.9934 - auc: 0.9989 - val_loss: 0.4616 - val_accuracy: 0.9360 - val_recall: 0.9532 - val_auc: 0.9548\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.298783  0.877502  0.925018  0.928877  0.319629      0.850587   \n",
      "1   0.174449  0.938884  0.958303  0.974380  0.160156      0.938100   \n",
      "2   0.108473  0.957299  0.973665  0.989788  0.180354      0.942369   \n",
      "3   0.099538  0.965572  0.977688  0.990879  0.178063      0.935966   \n",
      "4   0.078514  0.973846  0.984272  0.993829  0.242555      0.934899   \n",
      "5   0.089971  0.969576  0.984638  0.991292  0.205611      0.940235   \n",
      "6   0.080427  0.969576  0.980614  0.993066  0.203472      0.940235   \n",
      "7   0.041492  0.983720  0.991953  0.997738  0.239834      0.928495   \n",
      "8   0.029919  0.988791  0.994514  0.998335  0.305466      0.926361   \n",
      "9   0.079847  0.977582  0.985369  0.993266  0.314843      0.934899   \n",
      "10  0.034754  0.987457  0.993416  0.998449  0.333776      0.931697   \n",
      "11  0.023729  0.992260  0.996342  0.999536  0.348798      0.937033   \n",
      "12  0.021814  0.993595  0.997440  0.997705  0.453879      0.928495   \n",
      "13  0.026526  0.990125  0.992685  0.998532  0.532543      0.925294   \n",
      "14  0.010583  0.997064  0.999268  0.999417  0.607444      0.927428   \n",
      "15  0.027872  0.991460  0.996342  0.998035  0.472176      0.925294   \n",
      "16  0.024403  0.990392  0.993416  0.998932  0.461597      0.935966   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.807018  0.972442  \n",
      "1     0.953216  0.976438  \n",
      "2     0.975146  0.975635  \n",
      "3     0.979532  0.975366  \n",
      "4     0.950292  0.968810  \n",
      "5     0.957602  0.972251  \n",
      "6     0.947368  0.976643  \n",
      "7     0.950292  0.968902  \n",
      "8     0.942982  0.963098  \n",
      "9     0.948830  0.963028  \n",
      "10    0.948830  0.961104  \n",
      "11    0.951754  0.965060  \n",
      "12    0.951754  0.946926  \n",
      "13    0.969298  0.927712  \n",
      "14    0.941520  0.946499  \n",
      "15    0.937135  0.952552  \n",
      "16    0.953216  0.954771  \n",
      "147/147 [==============================] - 29s 198ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 130s 543ms/step - loss: 0.3669 - accuracy: 0.8489 - recall: 0.9459 - auc: 0.9044 - val_loss: 0.2046 - val_accuracy: 0.9210 - val_recall: 0.9883 - val_auc: 0.9729\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 124s 527ms/step - loss: 0.1771 - accuracy: 0.9349 - recall: 0.9612 - auc: 0.9745 - val_loss: 0.1754 - val_accuracy: 0.9381 - val_recall: 0.9620 - val_auc: 0.9713\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1510 - accuracy: 0.9480 - recall: 0.9682 - auc: 0.9813 - val_loss: 0.1786 - val_accuracy: 0.9402 - val_recall: 0.9401 - val_auc: 0.9792\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 124s 529ms/step - loss: 0.1126 - accuracy: 0.9608 - recall: 0.9737 - auc: 0.9882 - val_loss: 0.1653 - val_accuracy: 0.9413 - val_recall: 0.9664 - val_auc: 0.9766\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 123s 525ms/step - loss: 0.1047 - accuracy: 0.9605 - recall: 0.9777 - auc: 0.9903 - val_loss: 0.2037 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9748\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 124s 528ms/step - loss: 0.0860 - accuracy: 0.9674 - recall: 0.9813 - auc: 0.9933 - val_loss: 0.2065 - val_accuracy: 0.9296 - val_recall: 0.9518 - val_auc: 0.9740\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 112s 478ms/step - loss: 0.0734 - accuracy: 0.9704 - recall: 0.9843 - auc: 0.9959 - val_loss: 0.2440 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9670\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 98s 415ms/step - loss: 0.0470 - accuracy: 0.9805 - recall: 0.9894 - auc: 0.9979 - val_loss: 0.2696 - val_accuracy: 0.9360 - val_recall: 0.9444 - val_auc: 0.9697\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 101s 430ms/step - loss: 0.0511 - accuracy: 0.9800 - recall: 0.9887 - auc: 0.9975 - val_loss: 0.2558 - val_accuracy: 0.9360 - val_recall: 0.9503 - val_auc: 0.9702\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 97s 411ms/step - loss: 0.0383 - accuracy: 0.9859 - recall: 0.9909 - auc: 0.9979 - val_loss: 0.3635 - val_accuracy: 0.9178 - val_recall: 0.9737 - val_auc: 0.9454\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 97s 412ms/step - loss: 0.0351 - accuracy: 0.9867 - recall: 0.9912 - auc: 0.9984 - val_loss: 0.2640 - val_accuracy: 0.9445 - val_recall: 0.9649 - val_auc: 0.9648\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 99s 422ms/step - loss: 0.0302 - accuracy: 0.9888 - recall: 0.9938 - auc: 0.9990 - val_loss: 0.3390 - val_accuracy: 0.9317 - val_recall: 0.9591 - val_auc: 0.9611\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 98s 415ms/step - loss: 0.0282 - accuracy: 0.9901 - recall: 0.9949 - auc: 0.9994 - val_loss: 0.3598 - val_accuracy: 0.9392 - val_recall: 0.9635 - val_auc: 0.9513\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.366865  0.848946  0.945867  0.904416  0.204576      0.921025   \n",
      "1   0.177108  0.934881  0.961229  0.974518  0.175430      0.938100   \n",
      "2   0.150977  0.947958  0.968179  0.981252  0.178600      0.940235   \n",
      "3   0.112555  0.960769  0.973665  0.988182  0.165316      0.941302   \n",
      "4   0.104663  0.960502  0.977688  0.990311  0.203744      0.942369   \n",
      "5   0.086044  0.967441  0.981346  0.993295  0.206539      0.929562   \n",
      "6   0.073378  0.970376  0.984272  0.995854  0.243975      0.937033   \n",
      "7   0.047018  0.980518  0.989393  0.997854  0.269633      0.935966   \n",
      "8   0.051138  0.979984  0.988661  0.997484  0.255843      0.935966   \n",
      "9   0.038278  0.985855  0.990856  0.997918  0.363499      0.917823   \n",
      "10  0.035053  0.986656  0.991222  0.998417  0.264000      0.944504   \n",
      "11  0.030194  0.988791  0.993782  0.998986  0.339027      0.931697   \n",
      "12  0.028159  0.990125  0.994879  0.999374  0.359824      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.988304  0.972921  \n",
      "1     0.961988  0.971263  \n",
      "2     0.940058  0.979220  \n",
      "3     0.966374  0.976597  \n",
      "4     0.964912  0.974765  \n",
      "5     0.951754  0.973990  \n",
      "6     0.967836  0.967001  \n",
      "7     0.944444  0.969662  \n",
      "8     0.950292  0.970220  \n",
      "9     0.973684  0.945427  \n",
      "10    0.964912  0.964817  \n",
      "11    0.959064  0.961101  \n",
      "12    0.963450  0.951333  \n",
      "74/74 [==============================] - 20s 269ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 97s 511ms/step - loss: 0.3519 - accuracy: 0.8775 - recall: 0.9440 - auc: 0.9171 - val_loss: 0.1890 - val_accuracy: 0.9210 - val_recall: 0.9635 - val_auc: 0.9701\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 96s 510ms/step - loss: 0.1813 - accuracy: 0.9357 - recall: 0.9627 - auc: 0.9732 - val_loss: 0.1635 - val_accuracy: 0.9392 - val_recall: 0.9547 - val_auc: 0.9762\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 96s 512ms/step - loss: 0.1334 - accuracy: 0.9528 - recall: 0.9722 - auc: 0.9845 - val_loss: 0.1519 - val_accuracy: 0.9413 - val_recall: 0.9737 - val_auc: 0.9785\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 98s 520ms/step - loss: 0.1176 - accuracy: 0.9594 - recall: 0.9744 - auc: 0.9877 - val_loss: 0.1589 - val_accuracy: 0.9392 - val_recall: 0.9795 - val_auc: 0.9800\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 95s 507ms/step - loss: 0.1003 - accuracy: 0.9680 - recall: 0.9824 - auc: 0.9901 - val_loss: 0.1877 - val_accuracy: 0.9381 - val_recall: 0.9561 - val_auc: 0.9739\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 96s 508ms/step - loss: 0.0726 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9953 - val_loss: 0.2028 - val_accuracy: 0.9466 - val_recall: 0.9605 - val_auc: 0.9763\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 96s 513ms/step - loss: 0.0471 - accuracy: 0.9827 - recall: 0.9898 - auc: 0.9970 - val_loss: 0.2046 - val_accuracy: 0.9445 - val_recall: 0.9591 - val_auc: 0.9733\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 98s 520ms/step - loss: 0.0400 - accuracy: 0.9859 - recall: 0.9916 - auc: 0.9978 - val_loss: 0.2235 - val_accuracy: 0.9360 - val_recall: 0.9532 - val_auc: 0.9715\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 99s 524ms/step - loss: 0.0510 - accuracy: 0.9821 - recall: 0.9898 - auc: 0.9967 - val_loss: 0.2285 - val_accuracy: 0.9413 - val_recall: 0.9591 - val_auc: 0.9743\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 97s 517ms/step - loss: 0.0437 - accuracy: 0.9821 - recall: 0.9909 - auc: 0.9980 - val_loss: 0.2446 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9683\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 96s 513ms/step - loss: 0.0348 - accuracy: 0.9859 - recall: 0.9916 - auc: 0.9990 - val_loss: 0.3248 - val_accuracy: 0.9466 - val_recall: 0.9635 - val_auc: 0.9608\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 98s 523ms/step - loss: 0.0216 - accuracy: 0.9915 - recall: 0.9960 - auc: 0.9992 - val_loss: 0.3764 - val_accuracy: 0.9402 - val_recall: 0.9576 - val_auc: 0.9541\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 95s 504ms/step - loss: 0.0331 - accuracy: 0.9875 - recall: 0.9931 - auc: 0.9990 - val_loss: 0.2683 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9650\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 95s 507ms/step - loss: 0.0229 - accuracy: 0.9909 - recall: 0.9952 - auc: 0.9996 - val_loss: 0.4319 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9577\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.351859  0.877502  0.944038  0.917100  0.189048      0.921025   \n",
      "1   0.181254  0.935682  0.962692  0.973215  0.163500      0.939168   \n",
      "2   0.133384  0.952762  0.972202  0.984469  0.151901      0.941302   \n",
      "3   0.117581  0.959434  0.974396  0.987682  0.158877      0.939168   \n",
      "4   0.100262  0.967974  0.982443  0.990054  0.187742      0.938100   \n",
      "5   0.072618  0.973579  0.983175  0.995324  0.202801      0.946638   \n",
      "6   0.047075  0.982653  0.989759  0.997026  0.204614      0.944504   \n",
      "7   0.040019  0.985855  0.991587  0.997797  0.223452      0.935966   \n",
      "8   0.051008  0.982119  0.989759  0.996696  0.228483      0.941302   \n",
      "9   0.043661  0.982119  0.990856  0.998030  0.244624      0.944504   \n",
      "10  0.034783  0.985855  0.991587  0.998996  0.324824      0.946638   \n",
      "11  0.021619  0.991460  0.995977  0.999195  0.376420      0.940235   \n",
      "12  0.033108  0.987457  0.993050  0.999032  0.268319      0.938100   \n",
      "13  0.022876  0.990926  0.995245  0.999596  0.431910      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.963450  0.970073  \n",
      "1     0.954678  0.976152  \n",
      "2     0.973684  0.978541  \n",
      "3     0.979532  0.979971  \n",
      "4     0.956140  0.973866  \n",
      "5     0.960526  0.976316  \n",
      "6     0.959064  0.973314  \n",
      "7     0.953216  0.971491  \n",
      "8     0.959064  0.974300  \n",
      "9     0.961988  0.968273  \n",
      "10    0.963450  0.960772  \n",
      "11    0.957602  0.954098  \n",
      "12    0.959064  0.965019  \n",
      "13    0.960526  0.957660  \n",
      "59/59 [==============================] - 19s 324ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 88s 736ms/step - loss: 0.3823 - accuracy: 0.8337 - recall: 0.9323 - auc: 0.8704 - val_loss: 0.2239 - val_accuracy: 0.9189 - val_recall: 0.9079 - val_auc: 0.9759\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 90s 760ms/step - loss: 0.1871 - accuracy: 0.9357 - recall: 0.9514 - auc: 0.9711 - val_loss: 0.1530 - val_accuracy: 0.9402 - val_recall: 0.9547 - val_auc: 0.9774\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 88s 749ms/step - loss: 0.1609 - accuracy: 0.9440 - recall: 0.9627 - auc: 0.9778 - val_loss: 0.1938 - val_accuracy: 0.9296 - val_recall: 0.9488 - val_auc: 0.9690\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 85s 724ms/step - loss: 0.1312 - accuracy: 0.9501 - recall: 0.9674 - auc: 0.9851 - val_loss: 0.1685 - val_accuracy: 0.9338 - val_recall: 0.9708 - val_auc: 0.9781\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 86s 731ms/step - loss: 0.1026 - accuracy: 0.9634 - recall: 0.9770 - auc: 0.9904 - val_loss: 0.1842 - val_accuracy: 0.9402 - val_recall: 0.9766 - val_auc: 0.9732\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 87s 740ms/step - loss: 0.0929 - accuracy: 0.9666 - recall: 0.9766 - auc: 0.9920 - val_loss: 0.1692 - val_accuracy: 0.9392 - val_recall: 0.9664 - val_auc: 0.9738\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 90s 763ms/step - loss: 0.0769 - accuracy: 0.9717 - recall: 0.9813 - auc: 0.9948 - val_loss: 0.1754 - val_accuracy: 0.9466 - val_recall: 0.9591 - val_auc: 0.9773\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 87s 736ms/step - loss: 0.0580 - accuracy: 0.9786 - recall: 0.9868 - auc: 0.9967 - val_loss: 0.2237 - val_accuracy: 0.9392 - val_recall: 0.9518 - val_auc: 0.9720\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 86s 726ms/step - loss: 0.0458 - accuracy: 0.9813 - recall: 0.9883 - auc: 0.9983 - val_loss: 0.2659 - val_accuracy: 0.9434 - val_recall: 0.9576 - val_auc: 0.9676\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 87s 735ms/step - loss: 0.0404 - accuracy: 0.9856 - recall: 0.9916 - auc: 0.9985 - val_loss: 0.2735 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9676\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 93s 786ms/step - loss: 0.0334 - accuracy: 0.9891 - recall: 0.9934 - auc: 0.9990 - val_loss: 0.2260 - val_accuracy: 0.9434 - val_recall: 0.9649 - val_auc: 0.9710\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 89s 757ms/step - loss: 0.0309 - accuracy: 0.9893 - recall: 0.9941 - auc: 0.9992 - val_loss: 0.3550 - val_accuracy: 0.9413 - val_recall: 0.9459 - val_auc: 0.9678\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 94s 802ms/step - loss: 0.0362 - accuracy: 0.9864 - recall: 0.9905 - auc: 0.9988 - val_loss: 0.5071 - val_accuracy: 0.8911 - val_recall: 0.9883 - val_auc: 0.9230\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 106s 897ms/step - loss: 0.0576 - accuracy: 0.9811 - recall: 0.9920 - auc: 0.9940 - val_loss: 0.2548 - val_accuracy: 0.9381 - val_recall: 0.9620 - val_auc: 0.9655\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.382302  0.833734  0.932334  0.870395  0.223931      0.918890   \n",
      "1   0.187129  0.935682  0.951353  0.971113  0.152993      0.940235   \n",
      "2   0.160861  0.943955  0.962692  0.977833  0.193753      0.929562   \n",
      "3   0.131244  0.950093  0.967447  0.985081  0.168480      0.933831   \n",
      "4   0.102645  0.963437  0.976957  0.990447  0.184165      0.940235   \n",
      "5   0.092902  0.966640  0.976591  0.992020  0.169231      0.939168   \n",
      "6   0.076856  0.971711  0.981346  0.994807  0.175393      0.946638   \n",
      "7   0.058007  0.978650  0.986832  0.996709  0.223687      0.939168   \n",
      "8   0.045774  0.981318  0.988296  0.998275  0.265931      0.943437   \n",
      "9   0.040441  0.985588  0.991587  0.998481  0.273497      0.938100   \n",
      "10  0.033417  0.989058  0.993416  0.999016  0.226038      0.943437   \n",
      "11  0.030864  0.989325  0.994148  0.999178  0.355004      0.941302   \n",
      "12  0.036157  0.986389  0.990490  0.998770  0.507130      0.891142   \n",
      "13  0.057630  0.981052  0.991953  0.994030  0.254795      0.938100   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.907895  0.975920  \n",
      "1     0.954678  0.977377  \n",
      "2     0.948830  0.968969  \n",
      "3     0.970760  0.978119  \n",
      "4     0.976608  0.973239  \n",
      "5     0.966374  0.973837  \n",
      "6     0.959064  0.977305  \n",
      "7     0.951754  0.971991  \n",
      "8     0.957602  0.967622  \n",
      "9     0.959064  0.967582  \n",
      "10    0.964912  0.970962  \n",
      "11    0.945906  0.967770  \n",
      "12    0.988304  0.922974  \n",
      "13    0.961988  0.965482  \n",
      "37/37 [==============================] - 21s 546ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.6689 - accuracy: 0.7475 - recall: 0.9268 - auc: 0.7243 - val_loss: 0.2355 - val_accuracy: 0.9210 - val_recall: 0.9503 - val_auc: 0.9668\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2308 - accuracy: 0.9119 - recall: 0.9495 - auc: 0.9586 - val_loss: 0.1671 - val_accuracy: 0.9392 - val_recall: 0.9401 - val_auc: 0.9815\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.1774 - accuracy: 0.9376 - recall: 0.9601 - auc: 0.9744 - val_loss: 0.1710 - val_accuracy: 0.9392 - val_recall: 0.9810 - val_auc: 0.9743\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1527 - accuracy: 0.9413 - recall: 0.9642 - auc: 0.9812 - val_loss: 0.1542 - val_accuracy: 0.9434 - val_recall: 0.9459 - val_auc: 0.9825\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.1311 - accuracy: 0.9546 - recall: 0.9722 - auc: 0.9846 - val_loss: 0.1662 - val_accuracy: 0.9392 - val_recall: 0.9766 - val_auc: 0.9763\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.1139 - accuracy: 0.9605 - recall: 0.9762 - auc: 0.9897 - val_loss: 0.1512 - val_accuracy: 0.9445 - val_recall: 0.9693 - val_auc: 0.9799\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.1148 - accuracy: 0.9570 - recall: 0.9737 - auc: 0.9894 - val_loss: 0.1503 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9817\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0896 - accuracy: 0.9674 - recall: 0.9781 - auc: 0.9934 - val_loss: 0.2090 - val_accuracy: 0.9381 - val_recall: 0.9854 - val_auc: 0.9716\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0876 - accuracy: 0.9682 - recall: 0.9770 - auc: 0.9932 - val_loss: 0.2136 - val_accuracy: 0.9349 - val_recall: 0.9737 - val_auc: 0.9686\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.0772 - accuracy: 0.9736 - recall: 0.9821 - auc: 0.9945 - val_loss: 0.2438 - val_accuracy: 0.9413 - val_recall: 0.9693 - val_auc: 0.9706\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.0629 - accuracy: 0.9757 - recall: 0.9854 - auc: 0.9961 - val_loss: 0.1793 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9749\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0608 - accuracy: 0.9760 - recall: 0.9854 - auc: 0.9970 - val_loss: 0.1914 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9735\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0559 - accuracy: 0.9773 - recall: 0.9861 - auc: 0.9977 - val_loss: 0.2340 - val_accuracy: 0.9381 - val_recall: 0.9678 - val_auc: 0.9694\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.0421 - accuracy: 0.9864 - recall: 0.9912 - auc: 0.9979 - val_loss: 0.2452 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9717\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.668862  0.747531  0.926847  0.724269  0.235526      0.921025   \n",
      "1   0.230809  0.911930  0.949525  0.958563  0.167062      0.939168   \n",
      "2   0.177372  0.937550  0.960132  0.974395  0.171022      0.939168   \n",
      "3   0.152698  0.941286  0.964155  0.981190  0.154172      0.943437   \n",
      "4   0.131139  0.954630  0.972202  0.984617  0.166209      0.939168   \n",
      "5   0.113852  0.960502  0.976225  0.989748  0.151196      0.944504   \n",
      "6   0.114772  0.957032  0.973665  0.989362  0.150304      0.941302   \n",
      "7   0.089555  0.967441  0.978054  0.993374  0.209026      0.938100   \n",
      "8   0.087574  0.968241  0.976957  0.993209  0.213602      0.934899   \n",
      "9   0.077231  0.973579  0.982078  0.994498  0.243821      0.941302   \n",
      "10  0.062882  0.975714  0.985369  0.996108  0.179340      0.943437   \n",
      "11  0.060766  0.975981  0.985369  0.997020  0.191445      0.939168   \n",
      "12  0.055866  0.977315  0.986101  0.997691  0.234039      0.938100   \n",
      "13  0.042121  0.986389  0.991222  0.997887  0.245230      0.945571   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.966773  \n",
      "1     0.940058  0.981488  \n",
      "2     0.980994  0.974271  \n",
      "3     0.945906  0.982462  \n",
      "4     0.976608  0.976313  \n",
      "5     0.969298  0.979890  \n",
      "6     0.960526  0.981699  \n",
      "7     0.985380  0.971627  \n",
      "8     0.973684  0.968593  \n",
      "9     0.969298  0.970624  \n",
      "10    0.959064  0.974898  \n",
      "11    0.957602  0.973482  \n",
      "12    0.967836  0.969382  \n",
      "13    0.960526  0.971673  \n",
      "19/19 [==============================] - 17s 859ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631115321.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(150,150)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "tabla_arqu_batch_propia = arq_batch_propia(ruta,epochs,batch_sizes,modelos, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87723f42-a3fa-458e-9c5c-773124b41b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.16      0.94       0.95    0.97  0.96         0.85  0.15   \n",
       "        16         0.15      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        20         0.17      0.94       0.97    0.95  0.96         0.91  0.09   \n",
       "        32         0.20      0.92       0.97    0.92  0.94         0.92  0.08   \n",
       "        64         0.17      0.94       0.96    0.95  0.96         0.90  0.10   \n",
       "Simple2 8          0.16      0.94       0.96    0.96  0.96         0.88  0.12   \n",
       "        16         0.22      0.91       0.98    0.89  0.93         0.96  0.04   \n",
       "        20         0.16      0.94       0.97    0.94  0.96         0.92  0.08   \n",
       "        32         0.17      0.93       0.97    0.93  0.95         0.93  0.07   \n",
       "        64         0.16      0.95       0.95    0.98  0.96         0.86  0.14   \n",
       "Simple3 8          0.21      0.94       0.97    0.95  0.96         0.92  0.08   \n",
       "        16         0.18      0.93       0.98    0.93  0.95         0.94  0.06   \n",
       "        20         0.16      0.94       0.95    0.97  0.96         0.85  0.15   \n",
       "        32         0.16      0.94       0.95    0.97  0.96         0.86  0.14   \n",
       "        64         0.17      0.92       0.96    0.93  0.95         0.91  0.09   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.03  0.98  \n",
       "        16         0.04  0.98  \n",
       "        20         0.05  0.98  \n",
       "        32         0.08  0.98  \n",
       "        64         0.05  0.98  \n",
       "Simple2 8          0.04  0.98  \n",
       "        16         0.11  0.98  \n",
       "        20         0.06  0.98  \n",
       "        32         0.07  0.98  \n",
       "        64         0.02  0.98  \n",
       "Simple3 8          0.05  0.98  \n",
       "        16         0.07  0.98  \n",
       "        20         0.03  0.98  \n",
       "        32         0.03  0.98  \n",
       "        64         0.07  0.98  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50072-e379-42a4-8b45-433ce620d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90df82-9a99-422b-8cc2-7237d372c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, se puede apreciar que la primera arquitectura es la peor de todas (algo que era de esperar) y la mejor opcion es \n",
    "# el Simple 2 ya que, en general (exceptuando para una batch size de 8) obtiene mejores resultados.\n",
    "#Dentro del Simple 2, el mejor valor de batch size es el de 32 ya que es el que presenta mejores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc3227-0635-4649-8182-f24d0cc786c2",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN AlexaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111bdae9-85fc-41c3-9576-e1f0532ec835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos,target_size):\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas arquitecturas de modelo y distintos batch size introducidos como parámetros. \n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"establecer_arquitectura(modelo)\"\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_AlexaNet(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "            #ENTRENA\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history= model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) #hacer grafica val y train para auc o loss\n",
    "\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            nombre_archivo = f'hist_anet_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "            ruta_historico = os.path.join('C:/Users/nuria/Downloads/TFG', 'historico_alexnet_arqu_batchsize') #se guarda dentro de una nueva carpeta denominada 'historico_2_64'\n",
    "            # Crea la carpeta 'historico_2_64' si no existe\n",
    "            os.makedirs(ruta_historico, exist_ok=True)\n",
    "            ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "            historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "            #se calculan las métricas\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "            #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "            #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "            #cambiar .append por .concat\n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "562c7252-e239-45b8-bc01-6df22183405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1280s 3s/step - loss: 0.3318 - accuracy: 0.8820 - recall: 0.9221 - auc: 0.9265 - val_loss: 0.2169 - val_accuracy: 0.9157 - val_recall: 0.9503 - val_auc: 0.9622\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 285s 608ms/step - loss: 0.2276 - accuracy: 0.9202 - recall: 0.9481 - auc: 0.9617 - val_loss: 0.3180 - val_accuracy: 0.8997 - val_recall: 0.8874 - val_auc: 0.9682\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 297s 633ms/step - loss: 0.2296 - accuracy: 0.9213 - recall: 0.9484 - auc: 0.9656 - val_loss: 0.2463 - val_accuracy: 0.9264 - val_recall: 0.9766 - val_auc: 0.9673\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 294s 626ms/step - loss: 0.1692 - accuracy: 0.9384 - recall: 0.9631 - auc: 0.9772 - val_loss: 0.1629 - val_accuracy: 0.9392 - val_recall: 0.9751 - val_auc: 0.9815\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.1545 - accuracy: 0.9448 - recall: 0.9663 - auc: 0.9801 - val_loss: 0.1918 - val_accuracy: 0.9328 - val_recall: 0.9254 - val_auc: 0.9852\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 298s 634ms/step - loss: 0.1832 - accuracy: 0.9397 - recall: 0.9623 - auc: 0.9734 - val_loss: 0.7004 - val_accuracy: 0.7727 - val_recall: 1.0000 - val_auc: 0.9445\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 303s 646ms/step - loss: 0.1622 - accuracy: 0.9450 - recall: 0.9645 - auc: 0.9796 - val_loss: 0.1995 - val_accuracy: 0.9434 - val_recall: 0.9693 - val_auc: 0.9731\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 293s 625ms/step - loss: 0.1401 - accuracy: 0.9509 - recall: 0.9693 - auc: 0.9835 - val_loss: 0.1477 - val_accuracy: 0.9562 - val_recall: 0.9678 - val_auc: 0.9860\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 306s 652ms/step - loss: 0.1285 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9868 - val_loss: 0.2437 - val_accuracy: 0.9274 - val_recall: 0.9868 - val_auc: 0.9681\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 299s 638ms/step - loss: 0.1334 - accuracy: 0.9533 - recall: 0.9715 - auc: 0.9847 - val_loss: 0.9504 - val_accuracy: 0.9413 - val_recall: 0.9474 - val_auc: 0.9796\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 298s 635ms/step - loss: 0.1181 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9881 - val_loss: 0.1523 - val_accuracy: 0.9466 - val_recall: 0.9737 - val_auc: 0.9839\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.1182 - accuracy: 0.9597 - recall: 0.9740 - auc: 0.9879 - val_loss: 0.7969 - val_accuracy: 0.8965 - val_recall: 0.9196 - val_auc: 0.9363\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 305s 649ms/step - loss: 0.1469 - accuracy: 0.9474 - recall: 0.9693 - auc: 0.9801 - val_loss: 0.1638 - val_accuracy: 0.9381 - val_recall: 0.9386 - val_auc: 0.9824\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 300s 639ms/step - loss: 0.1257 - accuracy: 0.9546 - recall: 0.9711 - auc: 0.9863 - val_loss: 0.1447 - val_accuracy: 0.9520 - val_recall: 0.9708 - val_auc: 0.9829\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 306s 653ms/step - loss: 0.1069 - accuracy: 0.9618 - recall: 0.9777 - auc: 0.9905 - val_loss: 0.2188 - val_accuracy: 0.9466 - val_recall: 0.9810 - val_auc: 0.9680\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 295s 629ms/step - loss: 0.1003 - accuracy: 0.9672 - recall: 0.9799 - auc: 0.9898 - val_loss: 0.2556 - val_accuracy: 0.9328 - val_recall: 0.9956 - val_auc: 0.9685\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 299s 638ms/step - loss: 0.0826 - accuracy: 0.9717 - recall: 0.9821 - auc: 0.9930 - val_loss: 0.2225 - val_accuracy: 0.9317 - val_recall: 0.9942 - val_auc: 0.9735\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 297s 633ms/step - loss: 0.0728 - accuracy: 0.9733 - recall: 0.9828 - auc: 0.9955 - val_loss: 0.2861 - val_accuracy: 0.9168 - val_recall: 0.9942 - val_auc: 0.9689\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.331850  0.882039  0.922092  0.926524  0.216873      0.915688   \n",
      "1   0.227569  0.920203  0.948061  0.961723  0.317993      0.899680   \n",
      "2   0.229614  0.921270  0.948427  0.965647  0.246262      0.926361   \n",
      "3   0.169197  0.938351  0.963058  0.977150  0.162931      0.939168   \n",
      "4   0.154452  0.944756  0.966350  0.980125  0.191782      0.932764   \n",
      "5   0.183218  0.939685  0.962326  0.973370  0.700364      0.772679   \n",
      "6   0.162187  0.945023  0.964521  0.979627  0.199464      0.943437   \n",
      "7   0.140117  0.950894  0.969276  0.983508  0.147742      0.956243   \n",
      "8   0.128510  0.954897  0.971836  0.986835  0.243726      0.927428   \n",
      "9   0.133439  0.953296  0.971470  0.984659  0.950406      0.941302   \n",
      "10  0.118127  0.954897  0.971836  0.988091  0.152286      0.946638   \n",
      "11  0.118217  0.959701  0.974031  0.987890  0.796923      0.896478   \n",
      "12  0.146898  0.947425  0.969276  0.980067  0.163800      0.938100   \n",
      "13  0.125654  0.954630  0.971105  0.986304  0.144703      0.951974   \n",
      "14  0.106949  0.961836  0.977688  0.990468  0.218837      0.946638   \n",
      "15  0.100341  0.967174  0.979883  0.989847  0.255593      0.932764   \n",
      "16  0.082556  0.971711  0.982078  0.992993  0.222453      0.931697   \n",
      "17  0.072759  0.973312  0.982809  0.995469  0.286097      0.916756   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.962243  \n",
      "1     0.887427  0.968160  \n",
      "2     0.976608  0.967299  \n",
      "3     0.975146  0.981480  \n",
      "4     0.925439  0.985204  \n",
      "5     1.000000  0.944465  \n",
      "6     0.969298  0.973083  \n",
      "7     0.967836  0.986042  \n",
      "8     0.986842  0.968088  \n",
      "9     0.947368  0.979622  \n",
      "10    0.973684  0.983901  \n",
      "11    0.919591  0.936279  \n",
      "12    0.938596  0.982364  \n",
      "13    0.970760  0.982924  \n",
      "14    0.980994  0.967963  \n",
      "15    0.995614  0.968509  \n",
      "16    0.994152  0.973531  \n",
      "17    0.994152  0.968917  \n",
      "147/147 [==============================] - 39s 261ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.2988 - accuracy: 0.8820 - recall: 0.9228 - auc: 0.9369 - val_loss: 0.6375 - val_accuracy: 0.7737 - val_recall: 0.9971 - val_auc: 0.9313\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.2087 - accuracy: 0.9226 - recall: 0.9521 - auc: 0.9666 - val_loss: 0.2845 - val_accuracy: 0.9029 - val_recall: 0.9883 - val_auc: 0.9591\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1788 - accuracy: 0.9317 - recall: 0.9579 - auc: 0.9753 - val_loss: 0.2694 - val_accuracy: 0.9072 - val_recall: 0.9912 - val_auc: 0.9670\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 285s 1s/step - loss: 0.1569 - accuracy: 0.9432 - recall: 0.9660 - auc: 0.9798 - val_loss: 1.2729 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8252\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1483 - accuracy: 0.9466 - recall: 0.9667 - auc: 0.9811 - val_loss: 0.2414 - val_accuracy: 0.9178 - val_recall: 0.9912 - val_auc: 0.9689\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.1392 - accuracy: 0.9488 - recall: 0.9671 - auc: 0.9833 - val_loss: 0.1666 - val_accuracy: 0.9456 - val_recall: 0.9401 - val_auc: 0.9878\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.1224 - accuracy: 0.9568 - recall: 0.9715 - auc: 0.9859 - val_loss: 0.2143 - val_accuracy: 0.9242 - val_recall: 0.9181 - val_auc: 0.9828\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 286s 1s/step - loss: 0.1149 - accuracy: 0.9557 - recall: 0.9729 - auc: 0.9881 - val_loss: 0.1854 - val_accuracy: 0.9434 - val_recall: 0.9327 - val_auc: 0.9879\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.1337 - accuracy: 0.9512 - recall: 0.9696 - auc: 0.9848 - val_loss: 0.1153 - val_accuracy: 0.9562 - val_recall: 0.9664 - val_auc: 0.9904\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.1115 - accuracy: 0.9602 - recall: 0.9740 - auc: 0.9888 - val_loss: 0.2250 - val_accuracy: 0.9232 - val_recall: 0.9854 - val_auc: 0.9688\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 277s 1s/step - loss: 0.1195 - accuracy: 0.9557 - recall: 0.9711 - auc: 0.9875 - val_loss: 0.2609 - val_accuracy: 0.9242 - val_recall: 0.9927 - val_auc: 0.9651\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.1062 - accuracy: 0.9642 - recall: 0.9795 - auc: 0.9888 - val_loss: 0.1459 - val_accuracy: 0.9498 - val_recall: 0.9795 - val_auc: 0.9819\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 282s 1s/step - loss: 0.0885 - accuracy: 0.9672 - recall: 0.9788 - auc: 0.9925 - val_loss: 0.1734 - val_accuracy: 0.9509 - val_recall: 0.9518 - val_auc: 0.9834\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0941 - accuracy: 0.9682 - recall: 0.9792 - auc: 0.9916 - val_loss: 0.1346 - val_accuracy: 0.9594 - val_recall: 0.9868 - val_auc: 0.9833\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.0831 - accuracy: 0.9717 - recall: 0.9821 - auc: 0.9927 - val_loss: 0.2066 - val_accuracy: 0.9413 - val_recall: 0.9927 - val_auc: 0.9717\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.0913 - accuracy: 0.9680 - recall: 0.9806 - auc: 0.9916 - val_loss: 0.1822 - val_accuracy: 0.9445 - val_recall: 0.9883 - val_auc: 0.9731\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.0665 - accuracy: 0.9736 - recall: 0.9846 - auc: 0.9953 - val_loss: 0.1837 - val_accuracy: 0.9541 - val_recall: 0.9664 - val_auc: 0.9813\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 277s 1s/step - loss: 0.0567 - accuracy: 0.9786 - recall: 0.9865 - auc: 0.9963 - val_loss: 0.1554 - val_accuracy: 0.9573 - val_recall: 0.9635 - val_auc: 0.9849\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.0739 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9943 - val_loss: 0.1990 - val_accuracy: 0.9477 - val_recall: 0.9795 - val_auc: 0.9764\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.298803  0.882039  0.922824  0.936926  0.637487      0.773746   \n",
      "1   0.208729  0.922605  0.952085  0.966618  0.284475      0.902882   \n",
      "2   0.178813  0.931679  0.957937  0.975261  0.269356      0.907151   \n",
      "3   0.156897  0.943155  0.965984  0.979826  1.272929      0.729989   \n",
      "4   0.148340  0.946624  0.966715  0.981114  0.241414      0.917823   \n",
      "5   0.139194  0.948759  0.967081  0.983317  0.166584      0.945571   \n",
      "6   0.122380  0.956765  0.971470  0.985866  0.214320      0.924226   \n",
      "7   0.114898  0.955698  0.972933  0.988077  0.185398      0.943437   \n",
      "8   0.133701  0.951161  0.969642  0.984839  0.115287      0.956243   \n",
      "9   0.111458  0.960235  0.974031  0.988763  0.225029      0.923159   \n",
      "10  0.119493  0.955698  0.971105  0.987549  0.260885      0.924226   \n",
      "11  0.106244  0.964238  0.979517  0.988828  0.145854      0.949840   \n",
      "12  0.088463  0.967174  0.978786  0.992499  0.173436      0.950907   \n",
      "13  0.094127  0.968241  0.979151  0.991623  0.134587      0.959445   \n",
      "14  0.083071  0.971711  0.982078  0.992662  0.206616      0.941302   \n",
      "15  0.091257  0.967974  0.980614  0.991582  0.182230      0.944504   \n",
      "16  0.066549  0.973579  0.984638  0.995286  0.183652      0.954109   \n",
      "17  0.056693  0.978650  0.986467  0.996326  0.155425      0.957311   \n",
      "18  0.073893  0.973579  0.983175  0.994321  0.199038      0.947705   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.931333  \n",
      "1     0.988304  0.959053  \n",
      "2     0.991228  0.967030  \n",
      "3     1.000000  0.825165  \n",
      "4     0.991228  0.968850  \n",
      "5     0.940058  0.987830  \n",
      "6     0.918129  0.982800  \n",
      "7     0.932749  0.987900  \n",
      "8     0.966374  0.990402  \n",
      "9     0.985380  0.968790  \n",
      "10    0.992690  0.965054  \n",
      "11    0.979532  0.981864  \n",
      "12    0.951754  0.983401  \n",
      "13    0.986842  0.983274  \n",
      "14    0.992690  0.971670  \n",
      "15    0.988304  0.973060  \n",
      "16    0.966374  0.981344  \n",
      "17    0.963450  0.984886  \n",
      "18    0.979532  0.976446  \n",
      "74/74 [==============================] - 35s 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.2941 - accuracy: 0.8927 - recall: 0.9312 - auc: 0.9402 - val_loss: 0.2773 - val_accuracy: 0.8762 - val_recall: 0.9912 - val_auc: 0.9692\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1935 - accuracy: 0.9306 - recall: 0.9554 - auc: 0.9701 - val_loss: 0.4568 - val_accuracy: 0.7695 - val_recall: 0.9985 - val_auc: 0.9339\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1685 - accuracy: 0.9343 - recall: 0.9609 - auc: 0.9757 - val_loss: 0.2662 - val_accuracy: 0.9072 - val_recall: 0.9079 - val_auc: 0.9645\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1474 - accuracy: 0.9472 - recall: 0.9674 - auc: 0.9811 - val_loss: 3.9321 - val_accuracy: 0.2711 - val_recall: 0.0015 - val_auc: 0.6877\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.1604 - accuracy: 0.9397 - recall: 0.9598 - auc: 0.9793 - val_loss: 0.1938 - val_accuracy: 0.9317 - val_recall: 0.9898 - val_auc: 0.9763\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.1336 - accuracy: 0.9546 - recall: 0.9711 - auc: 0.9834 - val_loss: 0.1460 - val_accuracy: 0.9552 - val_recall: 0.9854 - val_auc: 0.9828\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 274s 1s/step - loss: 0.1330 - accuracy: 0.9549 - recall: 0.9737 - auc: 0.9842 - val_loss: 0.2683 - val_accuracy: 0.9200 - val_recall: 0.9898 - val_auc: 0.9659\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1213 - accuracy: 0.9557 - recall: 0.9715 - auc: 0.9870 - val_loss: 1.0159 - val_accuracy: 0.8420 - val_recall: 1.0000 - val_auc: 0.8566\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.1247 - accuracy: 0.9541 - recall: 0.9704 - auc: 0.9870 - val_loss: 0.1610 - val_accuracy: 0.9509 - val_recall: 0.9810 - val_auc: 0.9815\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.1280 - accuracy: 0.9552 - recall: 0.9729 - auc: 0.9851 - val_loss: 0.1452 - val_accuracy: 0.9562 - val_recall: 0.9722 - val_auc: 0.9839\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.1024 - accuracy: 0.9629 - recall: 0.9766 - auc: 0.9910 - val_loss: 0.1558 - val_accuracy: 0.9530 - val_recall: 0.9576 - val_auc: 0.9879\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.1130 - accuracy: 0.9578 - recall: 0.9729 - auc: 0.9883 - val_loss: 0.2627 - val_accuracy: 0.9328 - val_recall: 0.9898 - val_auc: 0.9606\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 283s 2s/step - loss: 0.0816 - accuracy: 0.9701 - recall: 0.9828 - auc: 0.9926 - val_loss: 0.2122 - val_accuracy: 0.9274 - val_recall: 0.9620 - val_auc: 0.9741\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.0971 - accuracy: 0.9626 - recall: 0.9759 - auc: 0.9905 - val_loss: 0.2087 - val_accuracy: 0.9328 - val_recall: 0.9722 - val_auc: 0.9687\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 277s 1s/step - loss: 0.0824 - accuracy: 0.9725 - recall: 0.9850 - auc: 0.9917 - val_loss: 0.3717 - val_accuracy: 0.8527 - val_recall: 0.9927 - val_auc: 0.9686\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.0834 - accuracy: 0.9709 - recall: 0.9828 - auc: 0.9929 - val_loss: 0.1519 - val_accuracy: 0.9584 - val_recall: 0.9825 - val_auc: 0.9818\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.0745 - accuracy: 0.9746 - recall: 0.9854 - auc: 0.9942 - val_loss: 0.9869 - val_accuracy: 0.7492 - val_recall: 1.0000 - val_auc: 0.8664\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.0776 - accuracy: 0.9741 - recall: 0.9839 - auc: 0.9933 - val_loss: 0.1375 - val_accuracy: 0.9562 - val_recall: 0.9825 - val_auc: 0.9860\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.0700 - accuracy: 0.9736 - recall: 0.9843 - auc: 0.9962 - val_loss: 0.1418 - val_accuracy: 0.9584 - val_recall: 0.9854 - val_auc: 0.9822\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.0697 - accuracy: 0.9760 - recall: 0.9835 - auc: 0.9952 - val_loss: 1.7704 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.7051\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.294056  0.892714  0.931236  0.940211  0.277303      0.876201   \n",
      "1   0.193535  0.930611  0.955377  0.970102  0.456794      0.769477   \n",
      "2   0.168495  0.934347  0.960863  0.975737  0.266172      0.907151   \n",
      "3   0.147369  0.947158  0.967447  0.981071  3.932112      0.271078   \n",
      "4   0.160414  0.939685  0.959766  0.979315  0.193823      0.931697   \n",
      "5   0.133595  0.954630  0.971105  0.983408  0.145951      0.955176   \n",
      "6   0.132966  0.954897  0.973665  0.984208  0.268329      0.919957   \n",
      "7   0.121272  0.955698  0.971470  0.987036  1.015888      0.842049   \n",
      "8   0.124725  0.954097  0.970373  0.986990  0.160979      0.950907   \n",
      "9   0.127975  0.955164  0.972933  0.985092  0.145189      0.956243   \n",
      "10  0.102355  0.962904  0.976591  0.990958  0.155850      0.953042   \n",
      "11  0.112957  0.957833  0.972933  0.988255  0.262677      0.932764   \n",
      "12  0.081608  0.970109  0.982809  0.992620  0.212217      0.927428   \n",
      "13  0.097052  0.962637  0.975860  0.990510  0.208662      0.932764   \n",
      "14  0.082384  0.972511  0.985004  0.991675  0.371693      0.852721   \n",
      "15  0.083414  0.970910  0.982809  0.992890  0.151851      0.958378   \n",
      "16  0.074496  0.974646  0.985369  0.994210  0.986862      0.749200   \n",
      "17  0.077578  0.974113  0.983906  0.993348  0.137501      0.956243   \n",
      "18  0.069973  0.973579  0.984272  0.996246  0.141804      0.958378   \n",
      "19  0.069661  0.975981  0.983541  0.995227  1.770445      0.738527   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.991228  0.969238  \n",
      "1     0.998538  0.933896  \n",
      "2     0.907895  0.964464  \n",
      "3     0.001462  0.687718  \n",
      "4     0.989766  0.976296  \n",
      "5     0.985380  0.982817  \n",
      "6     0.989766  0.965889  \n",
      "7     1.000000  0.856638  \n",
      "8     0.980994  0.981480  \n",
      "9     0.972222  0.983909  \n",
      "10    0.957602  0.987917  \n",
      "11    0.989766  0.960558  \n",
      "12    0.961988  0.974109  \n",
      "13    0.972222  0.968709  \n",
      "14    0.992690  0.968567  \n",
      "15    0.982456  0.981780  \n",
      "16    1.000000  0.866358  \n",
      "17    0.982456  0.985961  \n",
      "18    0.985380  0.982219  \n",
      "19    1.000000  0.705077  \n",
      "59/59 [==============================] - 34s 574ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 269s 2s/step - loss: 0.3376 - accuracy: 0.8807 - recall: 0.9225 - auc: 0.9262 - val_loss: 0.2976 - val_accuracy: 0.8730 - val_recall: 0.9693 - val_auc: 0.9410\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 266s 2s/step - loss: 0.2128 - accuracy: 0.9221 - recall: 0.9510 - auc: 0.9644 - val_loss: 0.2839 - val_accuracy: 0.8922 - val_recall: 0.9854 - val_auc: 0.9540\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1951 - accuracy: 0.9287 - recall: 0.9546 - auc: 0.9702 - val_loss: 1.5472 - val_accuracy: 0.4568 - val_recall: 0.2558 - val_auc: 0.8837\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1691 - accuracy: 0.9400 - recall: 0.9631 - auc: 0.9758 - val_loss: 0.7876 - val_accuracy: 0.7449 - val_recall: 0.9985 - val_auc: 0.9330\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 271s 2s/step - loss: 0.1615 - accuracy: 0.9386 - recall: 0.9616 - auc: 0.9779 - val_loss: 0.6403 - val_accuracy: 0.7641 - val_recall: 1.0000 - val_auc: 0.9625\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1339 - accuracy: 0.9512 - recall: 0.9700 - auc: 0.9837 - val_loss: 0.3358 - val_accuracy: 0.8559 - val_recall: 0.9942 - val_auc: 0.9644\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.1230 - accuracy: 0.9530 - recall: 0.9729 - auc: 0.9866 - val_loss: 0.2136 - val_accuracy: 0.9221 - val_recall: 0.9927 - val_auc: 0.9736\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1055 - accuracy: 0.9576 - recall: 0.9737 - auc: 0.9902 - val_loss: 0.1203 - val_accuracy: 0.9584 - val_recall: 0.9854 - val_auc: 0.9882\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.1191 - accuracy: 0.9597 - recall: 0.9744 - auc: 0.9878 - val_loss: 0.1688 - val_accuracy: 0.9402 - val_recall: 0.9459 - val_auc: 0.9821\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.1149 - accuracy: 0.9589 - recall: 0.9773 - auc: 0.9876 - val_loss: 0.1541 - val_accuracy: 0.9456 - val_recall: 0.9503 - val_auc: 0.9854\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0941 - accuracy: 0.9661 - recall: 0.9788 - auc: 0.9917 - val_loss: 0.4942 - val_accuracy: 0.8517 - val_recall: 0.8056 - val_auc: 0.9747\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0930 - accuracy: 0.9674 - recall: 0.9799 - auc: 0.9917 - val_loss: 0.1195 - val_accuracy: 0.9541 - val_recall: 0.9868 - val_auc: 0.9894\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0931 - accuracy: 0.9661 - recall: 0.9792 - auc: 0.9911 - val_loss: 0.2844 - val_accuracy: 0.9157 - val_recall: 0.8962 - val_auc: 0.9812\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 266s 2s/step - loss: 0.0862 - accuracy: 0.9653 - recall: 0.9788 - auc: 0.9934 - val_loss: 0.2424 - val_accuracy: 0.9168 - val_recall: 0.9196 - val_auc: 0.9680\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.1123 - accuracy: 0.9600 - recall: 0.9773 - auc: 0.9868 - val_loss: 1.0736 - val_accuracy: 0.7417 - val_recall: 1.0000 - val_auc: 0.8708\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.0925 - accuracy: 0.9664 - recall: 0.9788 - auc: 0.9915 - val_loss: 0.1591 - val_accuracy: 0.9456 - val_recall: 0.9839 - val_auc: 0.9810\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0806 - accuracy: 0.9696 - recall: 0.9828 - auc: 0.9943 - val_loss: 0.1970 - val_accuracy: 0.9242 - val_recall: 0.9766 - val_auc: 0.9705\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 263s 2s/step - loss: 0.1225 - accuracy: 0.9525 - recall: 0.9726 - auc: 0.9864 - val_loss: 0.8100 - val_accuracy: 0.6809 - val_recall: 0.5687 - val_auc: 0.9654\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 265s 2s/step - loss: 0.0960 - accuracy: 0.9656 - recall: 0.9806 - auc: 0.9909 - val_loss: 0.2108 - val_accuracy: 0.9360 - val_recall: 0.9927 - val_auc: 0.9757\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 268s 2s/step - loss: 0.0627 - accuracy: 0.9768 - recall: 0.9854 - auc: 0.9958 - val_loss: 0.1306 - val_accuracy: 0.9498 - val_recall: 0.9722 - val_auc: 0.9861\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.337571  0.880705  0.922458  0.926207  0.297612      0.872999   \n",
      "1   0.212829  0.922071  0.950988  0.964387  0.283873      0.892209   \n",
      "2   0.195090  0.928743  0.954645  0.970196  1.547167      0.456777   \n",
      "3   0.169089  0.939952  0.963058  0.975821  0.787565      0.744931   \n",
      "4   0.161499  0.938618  0.961595  0.977922  0.640289      0.764141   \n",
      "5   0.133934  0.951161  0.970007  0.983697  0.335839      0.855923   \n",
      "6   0.123013  0.953029  0.972933  0.986555  0.213613      0.922092   \n",
      "7   0.105538  0.957566  0.973665  0.990217  0.120267      0.958378   \n",
      "8   0.119076  0.959701  0.974396  0.987801  0.168814      0.940235   \n",
      "9   0.114864  0.958900  0.977323  0.987622  0.154137      0.945571   \n",
      "10  0.094071  0.966106  0.978786  0.991675  0.494240      0.851654   \n",
      "11  0.093009  0.967441  0.979883  0.991727  0.119476      0.954109   \n",
      "12  0.093069  0.966106  0.979151  0.991123  0.284413      0.915688   \n",
      "13  0.086225  0.965306  0.978786  0.993377  0.242444      0.916756   \n",
      "14  0.112291  0.959968  0.977323  0.986848  1.073555      0.741729   \n",
      "15  0.092507  0.966373  0.978786  0.991456  0.159124      0.945571   \n",
      "16  0.080618  0.969576  0.982809  0.994267  0.197025      0.924226   \n",
      "17  0.122549  0.952495  0.972568  0.986350  0.809984      0.680896   \n",
      "18  0.095995  0.965572  0.980614  0.990864  0.210844      0.935966   \n",
      "19  0.062727  0.976781  0.985369  0.995802  0.130595      0.949840   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.969298  0.941044  \n",
      "1     0.985380  0.953976  \n",
      "2     0.255848  0.883705  \n",
      "3     0.998538  0.932980  \n",
      "4     1.000000  0.962517  \n",
      "5     0.994152  0.964384  \n",
      "6     0.992690  0.973612  \n",
      "7     0.985380  0.988229  \n",
      "8     0.945906  0.982083  \n",
      "9     0.950292  0.985354  \n",
      "10    0.805556  0.974661  \n",
      "11    0.986842  0.989390  \n",
      "12    0.896199  0.981165  \n",
      "13    0.919591  0.967989  \n",
      "14    1.000000  0.870842  \n",
      "15    0.983918  0.981017  \n",
      "16    0.976608  0.970538  \n",
      "17    0.568713  0.965427  \n",
      "18    0.992690  0.975736  \n",
      "19    0.972222  0.986126  \n",
      "37/37 [==============================] - 33s 875ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.3479 - accuracy: 0.8759 - recall: 0.9247 - auc: 0.9176 - val_loss: 0.5910 - val_accuracy: 0.7001 - val_recall: 0.5994 - val_auc: 0.9302\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1971 - accuracy: 0.9253 - recall: 0.9495 - auc: 0.9682 - val_loss: 0.2658 - val_accuracy: 0.8783 - val_recall: 0.9766 - val_auc: 0.9599\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1562 - accuracy: 0.9402 - recall: 0.9616 - auc: 0.9799 - val_loss: 0.2844 - val_accuracy: 0.8751 - val_recall: 0.9971 - val_auc: 0.9738\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1580 - accuracy: 0.9392 - recall: 0.9609 - auc: 0.9798 - val_loss: 0.3742 - val_accuracy: 0.8463 - val_recall: 0.9985 - val_auc: 0.9684\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1322 - accuracy: 0.9514 - recall: 0.9689 - auc: 0.9847 - val_loss: 0.3259 - val_accuracy: 0.8591 - val_recall: 0.8275 - val_auc: 0.9669\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1154 - accuracy: 0.9565 - recall: 0.9718 - auc: 0.9884 - val_loss: 0.2186 - val_accuracy: 0.9200 - val_recall: 0.9927 - val_auc: 0.9770\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1195 - accuracy: 0.9552 - recall: 0.9740 - auc: 0.9877 - val_loss: 0.1608 - val_accuracy: 0.9434 - val_recall: 0.9839 - val_auc: 0.9815\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0990 - accuracy: 0.9626 - recall: 0.9762 - auc: 0.9911 - val_loss: 0.5499 - val_accuracy: 0.7801 - val_recall: 1.0000 - val_auc: 0.9779\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1085 - accuracy: 0.9589 - recall: 0.9762 - auc: 0.9898 - val_loss: 0.2561 - val_accuracy: 0.8943 - val_recall: 0.9985 - val_auc: 0.9847\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0960 - accuracy: 0.9645 - recall: 0.9795 - auc: 0.9906 - val_loss: 0.4596 - val_accuracy: 0.8399 - val_recall: 0.9985 - val_auc: 0.9614\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0900 - accuracy: 0.9682 - recall: 0.9828 - auc: 0.9920 - val_loss: 0.2363 - val_accuracy: 0.9210 - val_recall: 0.9985 - val_auc: 0.9791\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0885 - accuracy: 0.9661 - recall: 0.9806 - auc: 0.9925 - val_loss: 0.7686 - val_accuracy: 0.6734 - val_recall: 0.5556 - val_auc: 0.9462\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0808 - accuracy: 0.9722 - recall: 0.9832 - auc: 0.9934 - val_loss: 0.2533 - val_accuracy: 0.9146 - val_recall: 0.9985 - val_auc: 0.9732\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0869 - accuracy: 0.9674 - recall: 0.9824 - auc: 0.9916 - val_loss: 0.1390 - val_accuracy: 0.9509 - val_recall: 0.9561 - val_auc: 0.9876\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0692 - accuracy: 0.9733 - recall: 0.9828 - auc: 0.9957 - val_loss: 0.1417 - val_accuracy: 0.9541 - val_recall: 0.9898 - val_auc: 0.9866\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0552 - accuracy: 0.9789 - recall: 0.9854 - auc: 0.9970 - val_loss: 0.2613 - val_accuracy: 0.9296 - val_recall: 0.9971 - val_auc: 0.9588\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0516 - accuracy: 0.9808 - recall: 0.9887 - auc: 0.9970 - val_loss: 0.1575 - val_accuracy: 0.9530 - val_recall: 0.9854 - val_auc: 0.9785\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0592 - accuracy: 0.9778 - recall: 0.9857 - auc: 0.9972 - val_loss: 0.2241 - val_accuracy: 0.9317 - val_recall: 0.9883 - val_auc: 0.9719\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0564 - accuracy: 0.9778 - recall: 0.9857 - auc: 0.9969 - val_loss: 0.1286 - val_accuracy: 0.9562 - val_recall: 0.9722 - val_auc: 0.9821\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0408 - accuracy: 0.9843 - recall: 0.9912 - auc: 0.9986 - val_loss: 0.1783 - val_accuracy: 0.9488 - val_recall: 0.9942 - val_auc: 0.9762\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.347858  0.875901  0.924653  0.917645  0.590988      0.700107   \n",
      "1   0.197117  0.925274  0.949525  0.968168  0.265778      0.878335   \n",
      "2   0.156219  0.940219  0.961595  0.979926  0.284413      0.875133   \n",
      "3   0.158021  0.939151  0.960863  0.979770  0.374210      0.846318   \n",
      "4   0.132245  0.951428  0.968910  0.984728  0.325927      0.859125   \n",
      "5   0.115408  0.956499  0.971836  0.988435  0.218562      0.919957   \n",
      "6   0.119543  0.955164  0.974031  0.987693  0.160849      0.943437   \n",
      "7   0.099003  0.962637  0.976225  0.991064  0.549916      0.780149   \n",
      "8   0.108484  0.958900  0.976225  0.989823  0.256131      0.894344   \n",
      "9   0.096034  0.964505  0.979517  0.990594  0.459649      0.839915   \n",
      "10  0.090014  0.968241  0.982809  0.992015  0.236295      0.921025   \n",
      "11  0.088457  0.966106  0.980614  0.992458  0.768586      0.673426   \n",
      "12  0.080795  0.972244  0.983175  0.993383  0.253279      0.914621   \n",
      "13  0.086863  0.967441  0.982443  0.991589  0.138962      0.950907   \n",
      "14  0.069181  0.973312  0.982809  0.995714  0.141698      0.954109   \n",
      "15  0.055237  0.978916  0.985369  0.997049  0.261319      0.929562   \n",
      "16  0.051635  0.980785  0.988661  0.997011  0.157474      0.953042   \n",
      "17  0.059218  0.977849  0.985735  0.997187  0.224089      0.931697   \n",
      "18  0.056392  0.977849  0.985735  0.996929  0.128558      0.956243   \n",
      "19  0.040826  0.984254  0.991222  0.998613  0.178298      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.599415  0.930200  \n",
      "1     0.976608  0.959894  \n",
      "2     0.997076  0.973820  \n",
      "3     0.998538  0.968408  \n",
      "4     0.827485  0.966938  \n",
      "5     0.992690  0.976978  \n",
      "6     0.983918  0.981546  \n",
      "7     1.000000  0.977934  \n",
      "8     0.998538  0.984661  \n",
      "9     0.998538  0.961393  \n",
      "10    0.998538  0.979067  \n",
      "11    0.555556  0.946247  \n",
      "12    0.998538  0.973153  \n",
      "13    0.956140  0.987619  \n",
      "14    0.989766  0.986573  \n",
      "15    0.997076  0.958816  \n",
      "16    0.985380  0.978550  \n",
      "17    0.988304  0.971867  \n",
      "18    0.972222  0.982095  \n",
      "19    0.994152  0.976152  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 282s 599ms/step - loss: 0.3634 - accuracy: 0.8660 - recall: 0.9089 - auc: 0.9151 - val_loss: 0.2181 - val_accuracy: 0.9136 - val_recall: 0.9181 - val_auc: 0.9681\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 287s 613ms/step - loss: 0.2189 - accuracy: 0.9125 - recall: 0.9404 - auc: 0.9633 - val_loss: 0.9072 - val_accuracy: 0.7193 - val_recall: 0.9678 - val_auc: 0.8304\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 282s 602ms/step - loss: 0.1705 - accuracy: 0.9349 - recall: 0.9572 - auc: 0.9751 - val_loss: 0.2028 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9626\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 287s 611ms/step - loss: 0.1596 - accuracy: 0.9389 - recall: 0.9579 - auc: 0.9788 - val_loss: 0.1637 - val_accuracy: 0.9360 - val_recall: 0.9503 - val_auc: 0.9796\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 293s 623ms/step - loss: 0.1523 - accuracy: 0.9472 - recall: 0.9649 - auc: 0.9794 - val_loss: 0.1777 - val_accuracy: 0.9370 - val_recall: 0.9810 - val_auc: 0.9786\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 281s 598ms/step - loss: 0.1616 - accuracy: 0.9413 - recall: 0.9653 - auc: 0.9774 - val_loss: 0.1450 - val_accuracy: 0.9488 - val_recall: 0.9883 - val_auc: 0.9865\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 281s 598ms/step - loss: 0.1512 - accuracy: 0.9440 - recall: 0.9663 - auc: 0.9808 - val_loss: 0.1393 - val_accuracy: 0.9488 - val_recall: 0.9751 - val_auc: 0.9848\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 288s 615ms/step - loss: 0.1190 - accuracy: 0.9576 - recall: 0.9707 - auc: 0.9873 - val_loss: 0.1577 - val_accuracy: 0.9509 - val_recall: 0.9649 - val_auc: 0.9824\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 282s 601ms/step - loss: 0.1219 - accuracy: 0.9522 - recall: 0.9711 - auc: 0.9871 - val_loss: 0.1740 - val_accuracy: 0.9434 - val_recall: 0.9854 - val_auc: 0.9794\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 286s 608ms/step - loss: 0.1140 - accuracy: 0.9562 - recall: 0.9733 - auc: 0.9890 - val_loss: 0.1312 - val_accuracy: 0.9520 - val_recall: 0.9693 - val_auc: 0.9868\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 284s 605ms/step - loss: 0.1114 - accuracy: 0.9597 - recall: 0.9770 - auc: 0.9886 - val_loss: 0.1409 - val_accuracy: 0.9562 - val_recall: 0.9795 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 284s 604ms/step - loss: 0.1107 - accuracy: 0.9584 - recall: 0.9759 - auc: 0.9889 - val_loss: 0.2374 - val_accuracy: 0.9509 - val_recall: 0.9532 - val_auc: 0.9859\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 283s 603ms/step - loss: 0.0892 - accuracy: 0.9656 - recall: 0.9792 - auc: 0.9927 - val_loss: 0.3049 - val_accuracy: 0.9328 - val_recall: 0.9854 - val_auc: 0.9637\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 279s 595ms/step - loss: 0.0980 - accuracy: 0.9626 - recall: 0.9784 - auc: 0.9917 - val_loss: 0.1683 - val_accuracy: 0.9509 - val_recall: 0.9649 - val_auc: 0.9828\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 282s 600ms/step - loss: 0.0818 - accuracy: 0.9690 - recall: 0.9828 - auc: 0.9938 - val_loss: 0.2179 - val_accuracy: 0.9541 - val_recall: 0.9576 - val_auc: 0.9845\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 279s 595ms/step - loss: 0.0946 - accuracy: 0.9629 - recall: 0.9777 - auc: 0.9919 - val_loss: 0.1807 - val_accuracy: 0.9552 - val_recall: 0.9708 - val_auc: 0.9833\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 291s 620ms/step - loss: 0.0769 - accuracy: 0.9666 - recall: 0.9821 - auc: 0.9950 - val_loss: 0.4144 - val_accuracy: 0.9381 - val_recall: 0.9810 - val_auc: 0.9542\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 291s 619ms/step - loss: 0.0752 - accuracy: 0.9714 - recall: 0.9861 - auc: 0.9940 - val_loss: 0.2098 - val_accuracy: 0.9509 - val_recall: 0.9678 - val_auc: 0.9867\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 284s 606ms/step - loss: 0.0726 - accuracy: 0.9754 - recall: 0.9868 - auc: 0.9952 - val_loss: 0.2040 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9823\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 287s 612ms/step - loss: 0.0648 - accuracy: 0.9725 - recall: 0.9850 - auc: 0.9963 - val_loss: 0.8036 - val_accuracy: 0.9338 - val_recall: 0.9868 - val_auc: 0.9579\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.363376  0.866026  0.908925  0.915148  0.218119      0.913554   \n",
      "1   0.218927  0.912463  0.940380  0.963294  0.907165      0.719317   \n",
      "2   0.170453  0.934881  0.957206  0.975130  0.202849      0.942369   \n",
      "3   0.159558  0.938884  0.957937  0.978772  0.163714      0.935966   \n",
      "4   0.152271  0.947158  0.964887  0.979374  0.177705      0.937033   \n",
      "5   0.161590  0.941286  0.965252  0.977413  0.145046      0.948773   \n",
      "6   0.151157  0.943955  0.966350  0.980841  0.139295      0.948773   \n",
      "7   0.118988  0.957566  0.970739  0.987315  0.157655      0.950907   \n",
      "8   0.121899  0.952228  0.971105  0.987122  0.174018      0.943437   \n",
      "9   0.113960  0.956232  0.973299  0.989001  0.131197      0.951974   \n",
      "10  0.111361  0.959701  0.976957  0.988576  0.140935      0.956243   \n",
      "11  0.110706  0.958367  0.975860  0.988938  0.237445      0.950907   \n",
      "12  0.089177  0.965572  0.979151  0.992704  0.304852      0.932764   \n",
      "13  0.097990  0.962637  0.978420  0.991671  0.168291      0.950907   \n",
      "14  0.081802  0.969042  0.982809  0.993818  0.217942      0.954109   \n",
      "15  0.094647  0.962904  0.977688  0.991926  0.180677      0.955176   \n",
      "16  0.076852  0.966640  0.982078  0.995017  0.414376      0.938100   \n",
      "17  0.075246  0.971444  0.986101  0.994033  0.209756      0.950907   \n",
      "18  0.072602  0.975447  0.986832  0.995232  0.204022      0.955176   \n",
      "19  0.064787  0.972511  0.985004  0.996344  0.803572      0.933831   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.918129  0.968079  \n",
      "1     0.967836  0.830363  \n",
      "2     0.972222  0.962575  \n",
      "3     0.950292  0.979558  \n",
      "4     0.980994  0.978553  \n",
      "5     0.988304  0.986452  \n",
      "6     0.975146  0.984753  \n",
      "7     0.964912  0.982390  \n",
      "8     0.985380  0.979437  \n",
      "9     0.969298  0.986833  \n",
      "10    0.979532  0.986493  \n",
      "11    0.953216  0.985920  \n",
      "12    0.985380  0.963684  \n",
      "13    0.964912  0.982814  \n",
      "14    0.957602  0.984473  \n",
      "15    0.970760  0.983317  \n",
      "16    0.980994  0.954184  \n",
      "17    0.967836  0.986698  \n",
      "18    0.979532  0.982277  \n",
      "19    0.986842  0.957943  \n",
      "147/147 [==============================] - 40s 270ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.3349 - accuracy: 0.8743 - recall: 0.9228 - auc: 0.9224 - val_loss: 0.7576 - val_accuracy: 0.7311 - val_recall: 0.6404 - val_auc: 0.8793\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.2085 - accuracy: 0.9165 - recall: 0.9429 - auc: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9178 - val_recall: 0.9751 - val_auc: 0.9709\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.1677 - accuracy: 0.9373 - recall: 0.9594 - auc: 0.9771 - val_loss: 0.5533 - val_accuracy: 0.8773 - val_recall: 0.9781 - val_auc: 0.9072\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.1615 - accuracy: 0.9416 - recall: 0.9642 - auc: 0.9789 - val_loss: 0.1993 - val_accuracy: 0.9328 - val_recall: 0.9254 - val_auc: 0.9805\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.1452 - accuracy: 0.9418 - recall: 0.9645 - auc: 0.9828 - val_loss: 0.6405 - val_accuracy: 0.7791 - val_recall: 0.9985 - val_auc: 0.9171\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 275s 1s/step - loss: 0.1518 - accuracy: 0.9437 - recall: 0.9660 - auc: 0.9800 - val_loss: 0.2472 - val_accuracy: 0.9242 - val_recall: 0.9591 - val_auc: 0.9615\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.1160 - accuracy: 0.9584 - recall: 0.9748 - auc: 0.9876 - val_loss: 0.1335 - val_accuracy: 0.9552 - val_recall: 0.9883 - val_auc: 0.9883\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.1181 - accuracy: 0.9520 - recall: 0.9722 - auc: 0.9873 - val_loss: 0.2112 - val_accuracy: 0.9253 - val_recall: 0.9912 - val_auc: 0.9775\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.1144 - accuracy: 0.9565 - recall: 0.9740 - auc: 0.9882 - val_loss: 0.1260 - val_accuracy: 0.9541 - val_recall: 0.9737 - val_auc: 0.9892\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.0990 - accuracy: 0.9637 - recall: 0.9784 - auc: 0.9913 - val_loss: 0.1435 - val_accuracy: 0.9520 - val_recall: 0.9868 - val_auc: 0.9847\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.0949 - accuracy: 0.9642 - recall: 0.9802 - auc: 0.9926 - val_loss: 0.1326 - val_accuracy: 0.9520 - val_recall: 0.9518 - val_auc: 0.9881\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0958 - accuracy: 0.9664 - recall: 0.9813 - auc: 0.9923 - val_loss: 0.2184 - val_accuracy: 0.9061 - val_recall: 0.9883 - val_auc: 0.9804\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0957 - accuracy: 0.9674 - recall: 0.9817 - auc: 0.9898 - val_loss: 0.3111 - val_accuracy: 0.9402 - val_recall: 0.9459 - val_auc: 0.9768\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.0810 - accuracy: 0.9693 - recall: 0.9821 - auc: 0.9942 - val_loss: 0.1382 - val_accuracy: 0.9488 - val_recall: 0.9825 - val_auc: 0.9867\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.0979 - accuracy: 0.9650 - recall: 0.9832 - auc: 0.9905 - val_loss: 0.5849 - val_accuracy: 0.9114 - val_recall: 0.9459 - val_auc: 0.9289\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0953 - accuracy: 0.9645 - recall: 0.9810 - auc: 0.9915 - val_loss: 0.2122 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9714\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0805 - accuracy: 0.9693 - recall: 0.9806 - auc: 0.9938 - val_loss: 0.1370 - val_accuracy: 0.9520 - val_recall: 0.9678 - val_auc: 0.9854\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 270s 1s/step - loss: 0.0732 - accuracy: 0.9706 - recall: 0.9824 - auc: 0.9957 - val_loss: 0.1449 - val_accuracy: 0.9530 - val_recall: 0.9751 - val_auc: 0.9871\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.0636 - accuracy: 0.9741 - recall: 0.9861 - auc: 0.9960 - val_loss: 0.2939 - val_accuracy: 0.9104 - val_recall: 0.9927 - val_auc: 0.9635\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.334881  0.874299  0.922824  0.922412  0.757599      0.731057   \n",
      "1   0.208549  0.916467  0.942941  0.965633  0.219790      0.917823   \n",
      "2   0.167705  0.937283  0.959400  0.977128  0.553290      0.877268   \n",
      "3   0.161540  0.941553  0.964155  0.978871  0.199305      0.932764   \n",
      "4   0.145171  0.941820  0.964521  0.982839  0.640489      0.779082   \n",
      "5   0.151790  0.943688  0.965984  0.980002  0.247202      0.924226   \n",
      "6   0.115957  0.958367  0.974762  0.987648  0.133549      0.955176   \n",
      "7   0.118102  0.951962  0.972202  0.987318  0.211241      0.925294   \n",
      "8   0.114433  0.956499  0.974031  0.988152  0.125961      0.954109   \n",
      "9   0.099021  0.963704  0.978420  0.991317  0.143526      0.951974   \n",
      "10  0.094880  0.964238  0.980249  0.992560  0.132643      0.951974   \n",
      "11  0.095808  0.966373  0.981346  0.992303  0.218366      0.906083   \n",
      "12  0.095650  0.967441  0.981712  0.989837  0.311062      0.940235   \n",
      "13  0.080992  0.969309  0.982078  0.994224  0.138210      0.948773   \n",
      "14  0.097884  0.965039  0.983175  0.990519  0.584871      0.911419   \n",
      "15  0.095338  0.964505  0.980980  0.991488  0.212244      0.941302   \n",
      "16  0.080455  0.969309  0.980614  0.993799  0.136954      0.951974   \n",
      "17  0.073205  0.970643  0.982443  0.995739  0.144906      0.953042   \n",
      "18  0.063644  0.974113  0.986101  0.996048  0.293943      0.910352   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.640351  0.879302  \n",
      "1     0.975146  0.970902  \n",
      "2     0.978070  0.907172  \n",
      "3     0.925439  0.980454  \n",
      "4     0.998538  0.917068  \n",
      "5     0.959064  0.961486  \n",
      "6     0.988304  0.988272  \n",
      "7     0.991228  0.977510  \n",
      "8     0.973684  0.989162  \n",
      "9     0.986842  0.984721  \n",
      "10    0.951754  0.988116  \n",
      "11    0.988304  0.980361  \n",
      "12    0.945906  0.976834  \n",
      "13    0.982456  0.986692  \n",
      "14    0.945906  0.928883  \n",
      "15    0.960526  0.971384  \n",
      "16    0.967836  0.985415  \n",
      "17    0.975146  0.987068  \n",
      "18    0.992690  0.963497  \n",
      "74/74 [==============================] - 35s 462ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.3348 - accuracy: 0.8818 - recall: 0.9195 - auc: 0.9301 - val_loss: 1.4786 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.7308\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.2031 - accuracy: 0.9199 - recall: 0.9470 - auc: 0.9677 - val_loss: 0.3073 - val_accuracy: 0.8794 - val_recall: 0.9795 - val_auc: 0.9589\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.1635 - accuracy: 0.9405 - recall: 0.9623 - auc: 0.9773 - val_loss: 0.2157 - val_accuracy: 0.9178 - val_recall: 0.9444 - val_auc: 0.9661\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.1487 - accuracy: 0.9432 - recall: 0.9674 - auc: 0.9812 - val_loss: 0.2263 - val_accuracy: 0.9221 - val_recall: 0.9664 - val_auc: 0.9576\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 268s 1s/step - loss: 0.1597 - accuracy: 0.9437 - recall: 0.9678 - auc: 0.9769 - val_loss: 0.2542 - val_accuracy: 0.9050 - val_recall: 0.8830 - val_auc: 0.9824\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 273s 1s/step - loss: 0.1283 - accuracy: 0.9504 - recall: 0.9682 - auc: 0.9857 - val_loss: 0.7185 - val_accuracy: 0.8655 - val_recall: 0.9883 - val_auc: 0.8943\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 269s 1s/step - loss: 0.1314 - accuracy: 0.9490 - recall: 0.9689 - auc: 0.9845 - val_loss: 0.1974 - val_accuracy: 0.9306 - val_recall: 0.9751 - val_auc: 0.9721\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 273s 1s/step - loss: 0.1205 - accuracy: 0.9549 - recall: 0.9748 - auc: 0.9873 - val_loss: 0.1723 - val_accuracy: 0.9402 - val_recall: 0.9693 - val_auc: 0.9752\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.1049 - accuracy: 0.9613 - recall: 0.9784 - auc: 0.9903 - val_loss: 0.1656 - val_accuracy: 0.9413 - val_recall: 0.9854 - val_auc: 0.9799\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.1021 - accuracy: 0.9613 - recall: 0.9777 - auc: 0.9902 - val_loss: 0.6235 - val_accuracy: 0.9061 - val_recall: 0.9430 - val_auc: 0.9623\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.1006 - accuracy: 0.9618 - recall: 0.9799 - auc: 0.9905 - val_loss: 0.6094 - val_accuracy: 0.8068 - val_recall: 0.9985 - val_auc: 0.9283\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 271s 1s/step - loss: 0.0994 - accuracy: 0.9616 - recall: 0.9777 - auc: 0.9916 - val_loss: 0.1668 - val_accuracy: 0.9392 - val_recall: 0.9927 - val_auc: 0.9860\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0931 - accuracy: 0.9602 - recall: 0.9744 - auc: 0.9920 - val_loss: 0.1823 - val_accuracy: 0.9370 - val_recall: 0.9883 - val_auc: 0.9781\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 268s 1s/step - loss: 0.0884 - accuracy: 0.9680 - recall: 0.9828 - auc: 0.9919 - val_loss: 0.1746 - val_accuracy: 0.9488 - val_recall: 0.9518 - val_auc: 0.9862\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 271s 1s/step - loss: 0.0903 - accuracy: 0.9664 - recall: 0.9806 - auc: 0.9921 - val_loss: 0.5635 - val_accuracy: 0.8538 - val_recall: 0.9956 - val_auc: 0.9310\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0796 - accuracy: 0.9696 - recall: 0.9857 - auc: 0.9941 - val_loss: 0.2010 - val_accuracy: 0.9392 - val_recall: 0.9664 - val_auc: 0.9758\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.0864 - accuracy: 0.9698 - recall: 0.9843 - auc: 0.9933 - val_loss: 0.1445 - val_accuracy: 0.9594 - val_recall: 0.9678 - val_auc: 0.9859\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.0756 - accuracy: 0.9720 - recall: 0.9835 - auc: 0.9951 - val_loss: 0.3231 - val_accuracy: 0.9018 - val_recall: 0.9912 - val_auc: 0.9566\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 270s 1s/step - loss: 0.0625 - accuracy: 0.9749 - recall: 0.9879 - auc: 0.9964 - val_loss: 0.3446 - val_accuracy: 0.8954 - val_recall: 0.9942 - val_auc: 0.9649\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 274s 1s/step - loss: 0.0576 - accuracy: 0.9797 - recall: 0.9905 - auc: 0.9964 - val_loss: 0.1444 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9809\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.334804  0.881772  0.919532  0.930129  1.478558      0.731057   \n",
      "1   0.203082  0.919936  0.946964  0.967739  0.307331      0.879402   \n",
      "2   0.163515  0.940486  0.962326  0.977277  0.215674      0.917823   \n",
      "3   0.148684  0.943155  0.967447  0.981237  0.226301      0.922092   \n",
      "4   0.159657  0.943688  0.967813  0.976861  0.254165      0.905016   \n",
      "5   0.128272  0.950360  0.968179  0.985724  0.718457      0.865528   \n",
      "6   0.131428  0.949026  0.968910  0.984463  0.197382      0.930630   \n",
      "7   0.120494  0.954897  0.974762  0.987274  0.172329      0.940235   \n",
      "8   0.104925  0.961302  0.978420  0.990325  0.165619      0.941302   \n",
      "9   0.102096  0.961302  0.977688  0.990167  0.623542      0.906083   \n",
      "10  0.100552  0.961836  0.979883  0.990547  0.609372      0.806830   \n",
      "11  0.099355  0.961569  0.977688  0.991620  0.166830      0.939168   \n",
      "12  0.093067  0.960235  0.974396  0.991974  0.182290      0.937033   \n",
      "13  0.088415  0.967974  0.982809  0.991931  0.174596      0.948773   \n",
      "14  0.090338  0.966373  0.980614  0.992085  0.563481      0.853789   \n",
      "15  0.079603  0.969576  0.985735  0.994078  0.201044      0.939168   \n",
      "16  0.086450  0.969843  0.984272  0.993301  0.144486      0.959445   \n",
      "17  0.075578  0.971978  0.983541  0.995053  0.323108      0.901814   \n",
      "18  0.062488  0.974913  0.987930  0.996412  0.344565      0.895411   \n",
      "19  0.057650  0.979717  0.990490  0.996365  0.144420      0.955176   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.730772  \n",
      "1     0.979532  0.958879  \n",
      "2     0.944444  0.966114  \n",
      "3     0.966374  0.957640  \n",
      "4     0.883041  0.982421  \n",
      "5     0.988304  0.894306  \n",
      "6     0.975146  0.972133  \n",
      "7     0.969298  0.975178  \n",
      "8     0.985380  0.979882  \n",
      "9     0.942982  0.962309  \n",
      "10    0.998538  0.928305  \n",
      "11    0.992690  0.985972  \n",
      "12    0.988304  0.978076  \n",
      "13    0.951754  0.986163  \n",
      "14    0.995614  0.931027  \n",
      "15    0.966374  0.975799  \n",
      "16    0.967836  0.985932  \n",
      "17    0.991228  0.956608  \n",
      "18    0.994152  0.964875  \n",
      "19    0.979532  0.980858  \n",
      "59/59 [==============================] - 34s 575ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 267s 2s/step - loss: 0.3548 - accuracy: 0.8684 - recall: 0.9126 - auc: 0.9151 - val_loss: 1.6606 - val_accuracy: 0.7300 - val_recall: 0.9971 - val_auc: 0.6890\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 264s 2s/step - loss: 0.1991 - accuracy: 0.9258 - recall: 0.9521 - auc: 0.9683 - val_loss: 0.3037 - val_accuracy: 0.8719 - val_recall: 0.9927 - val_auc: 0.9742\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 264s 2s/step - loss: 0.1906 - accuracy: 0.9269 - recall: 0.9521 - auc: 0.9710 - val_loss: 1.4301 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7646\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 259s 2s/step - loss: 0.1464 - accuracy: 0.9453 - recall: 0.9631 - auc: 0.9814 - val_loss: 0.6865 - val_accuracy: 0.7748 - val_recall: 0.9942 - val_auc: 0.9149\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 261s 2s/step - loss: 0.1444 - accuracy: 0.9477 - recall: 0.9656 - auc: 0.9817 - val_loss: 0.2851 - val_accuracy: 0.9125 - val_recall: 0.9035 - val_auc: 0.9662\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 260s 2s/step - loss: 0.1498 - accuracy: 0.9445 - recall: 0.9671 - auc: 0.9812 - val_loss: 0.2241 - val_accuracy: 0.9114 - val_recall: 0.9898 - val_auc: 0.9788\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 262s 2s/step - loss: 0.1203 - accuracy: 0.9552 - recall: 0.9711 - auc: 0.9872 - val_loss: 0.5774 - val_accuracy: 0.8132 - val_recall: 0.9985 - val_auc: 0.9520\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.1179 - accuracy: 0.9557 - recall: 0.9722 - auc: 0.9881 - val_loss: 1.2070 - val_accuracy: 0.7460 - val_recall: 1.0000 - val_auc: 0.8167\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 255s 2s/step - loss: 0.1141 - accuracy: 0.9568 - recall: 0.9740 - auc: 0.9887 - val_loss: 0.8162 - val_accuracy: 0.8004 - val_recall: 0.7442 - val_auc: 0.9263\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.1054 - accuracy: 0.9594 - recall: 0.9792 - auc: 0.9893 - val_loss: 0.1986 - val_accuracy: 0.9242 - val_recall: 0.9898 - val_auc: 0.9790\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.1038 - accuracy: 0.9565 - recall: 0.9766 - auc: 0.9913 - val_loss: 1.4855 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.7603\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 256s 2s/step - loss: 0.0984 - accuracy: 0.9648 - recall: 0.9810 - auc: 0.9897 - val_loss: 0.1648 - val_accuracy: 0.9328 - val_recall: 0.9839 - val_auc: 0.9833\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0909 - accuracy: 0.9640 - recall: 0.9806 - auc: 0.9925 - val_loss: 0.1429 - val_accuracy: 0.9466 - val_recall: 0.9839 - val_auc: 0.9848\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0741 - accuracy: 0.9741 - recall: 0.9868 - auc: 0.9946 - val_loss: 0.1366 - val_accuracy: 0.9520 - val_recall: 0.9795 - val_auc: 0.9848\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0813 - accuracy: 0.9714 - recall: 0.9854 - auc: 0.9939 - val_loss: 0.2621 - val_accuracy: 0.9210 - val_recall: 0.9971 - val_auc: 0.9705\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0736 - accuracy: 0.9730 - recall: 0.9850 - auc: 0.9948 - val_loss: 0.1439 - val_accuracy: 0.9488 - val_recall: 0.9868 - val_auc: 0.9847\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0771 - accuracy: 0.9706 - recall: 0.9832 - auc: 0.9940 - val_loss: 0.6631 - val_accuracy: 0.8666 - val_recall: 0.9956 - val_auc: 0.9096\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 257s 2s/step - loss: 0.0739 - accuracy: 0.9704 - recall: 0.9861 - auc: 0.9947 - val_loss: 0.1674 - val_accuracy: 0.9477 - val_recall: 0.9883 - val_auc: 0.9851\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 254s 2s/step - loss: 0.0656 - accuracy: 0.9733 - recall: 0.9872 - auc: 0.9956 - val_loss: 0.1585 - val_accuracy: 0.9477 - val_recall: 0.9605 - val_auc: 0.9855\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0684 - accuracy: 0.9762 - recall: 0.9876 - auc: 0.9955 - val_loss: 0.1715 - val_accuracy: 0.9509 - val_recall: 0.9474 - val_auc: 0.9894\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.354794  0.868428  0.912582  0.915098  1.660625      0.729989   \n",
      "1   0.199074  0.925807  0.952085  0.968286  0.303657      0.871932   \n",
      "2   0.190610  0.926875  0.952085  0.971040  1.430150      0.729989   \n",
      "3   0.146370  0.945290  0.963058  0.981431  0.686505      0.774813   \n",
      "4   0.144422  0.947692  0.965618  0.981708  0.285132      0.912487   \n",
      "5   0.149844  0.944489  0.967081  0.981216  0.224113      0.911419   \n",
      "6   0.120261  0.955164  0.971105  0.987200  0.577386      0.813234   \n",
      "7   0.117913  0.955698  0.972202  0.988089  1.207011      0.745998   \n",
      "8   0.114071  0.956765  0.974031  0.988739  0.816210      0.800427   \n",
      "9   0.105446  0.959434  0.979151  0.989334  0.198604      0.924226   \n",
      "10  0.103834  0.956499  0.976591  0.991299  1.485475      0.758805   \n",
      "11  0.098415  0.964772  0.980980  0.989664  0.164785      0.932764   \n",
      "12  0.090888  0.963971  0.980614  0.992523  0.142902      0.946638   \n",
      "13  0.074139  0.974113  0.986832  0.994647  0.136604      0.951974   \n",
      "14  0.081315  0.971444  0.985369  0.993904  0.262083      0.921025   \n",
      "15  0.073569  0.973045  0.985004  0.994824  0.143942      0.948773   \n",
      "16  0.077138  0.970643  0.983175  0.993958  0.663133      0.866596   \n",
      "17  0.073929  0.970376  0.986101  0.994657  0.167434      0.947705   \n",
      "18  0.065575  0.973312  0.987198  0.995646  0.158531      0.947705   \n",
      "19  0.068414  0.976248  0.987564  0.995451  0.171516      0.950907   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.688969  \n",
      "1     0.992690  0.974233  \n",
      "2     1.000000  0.764588  \n",
      "3     0.994152  0.914933  \n",
      "4     0.903509  0.966244  \n",
      "5     0.989766  0.978755  \n",
      "6     0.998538  0.951968  \n",
      "7     1.000000  0.816656  \n",
      "8     0.744152  0.926259  \n",
      "9     0.989766  0.979015  \n",
      "10    1.000000  0.760283  \n",
      "11    0.983918  0.983297  \n",
      "12    0.983918  0.984765  \n",
      "13    0.979532  0.984768  \n",
      "14    0.997076  0.970526  \n",
      "15    0.986842  0.984690  \n",
      "16    0.995614  0.909643  \n",
      "17    0.988304  0.985094  \n",
      "18    0.960526  0.985504  \n",
      "19    0.947368  0.989442  \n",
      "37/37 [==============================] - 33s 873ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 245s 4s/step - loss: 0.3942 - accuracy: 0.8671 - recall: 0.9170 - auc: 0.9100 - val_loss: 1.5837 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.6215\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.2036 - accuracy: 0.9223 - recall: 0.9495 - auc: 0.9661 - val_loss: 0.4162 - val_accuracy: 0.7695 - val_recall: 1.0000 - val_auc: 0.9536\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.1713 - accuracy: 0.9357 - recall: 0.9587 - auc: 0.9759 - val_loss: 0.6659 - val_accuracy: 0.7567 - val_recall: 1.0000 - val_auc: 0.9435\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1541 - accuracy: 0.9453 - recall: 0.9623 - auc: 0.9792 - val_loss: 0.8988 - val_accuracy: 0.7332 - val_recall: 1.0000 - val_auc: 0.9333\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1359 - accuracy: 0.9490 - recall: 0.9678 - auc: 0.9846 - val_loss: 0.4448 - val_accuracy: 0.7844 - val_recall: 0.9401 - val_auc: 0.8512\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 249s 4s/step - loss: 0.1300 - accuracy: 0.9485 - recall: 0.9674 - auc: 0.9853 - val_loss: 0.3155 - val_accuracy: 0.8378 - val_recall: 0.9956 - val_auc: 0.9710\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1111 - accuracy: 0.9576 - recall: 0.9722 - auc: 0.9895 - val_loss: 0.6496 - val_accuracy: 0.7481 - val_recall: 1.0000 - val_auc: 0.9518\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.1085 - accuracy: 0.9584 - recall: 0.9711 - auc: 0.9906 - val_loss: 2.0520 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 248s 4s/step - loss: 0.1162 - accuracy: 0.9584 - recall: 0.9777 - auc: 0.9879 - val_loss: 0.2232 - val_accuracy: 0.9104 - val_recall: 0.9751 - val_auc: 0.9650\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 247s 4s/step - loss: 0.1119 - accuracy: 0.9568 - recall: 0.9737 - auc: 0.9895 - val_loss: 1.5725 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6642\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 246s 4s/step - loss: 0.1028 - accuracy: 0.9605 - recall: 0.9777 - auc: 0.9912 - val_loss: 1.0162 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.9038\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 252s 4s/step - loss: 0.0977 - accuracy: 0.9650 - recall: 0.9817 - auc: 0.9918 - val_loss: 1.0270 - val_accuracy: 0.7663 - val_recall: 1.0000 - val_auc: 0.8514\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 249s 4s/step - loss: 0.1029 - accuracy: 0.9608 - recall: 0.9755 - auc: 0.9909 - val_loss: 0.3178 - val_accuracy: 0.8335 - val_recall: 0.9956 - val_auc: 0.9749\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 250s 4s/step - loss: 0.0929 - accuracy: 0.9685 - recall: 0.9810 - auc: 0.9914 - val_loss: 0.2920 - val_accuracy: 0.8858 - val_recall: 0.9942 - val_auc: 0.9775\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 250s 4s/step - loss: 0.0871 - accuracy: 0.9706 - recall: 0.9839 - auc: 0.9923 - val_loss: 0.6231 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.9344\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0688 - accuracy: 0.9768 - recall: 0.9876 - auc: 0.9959 - val_loss: 0.1379 - val_accuracy: 0.9498 - val_recall: 0.9868 - val_auc: 0.9883\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 248s 4s/step - loss: 0.0823 - accuracy: 0.9701 - recall: 0.9846 - auc: 0.9932 - val_loss: 0.1500 - val_accuracy: 0.9488 - val_recall: 0.9620 - val_auc: 0.9826\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0831 - accuracy: 0.9720 - recall: 0.9843 - auc: 0.9932 - val_loss: 0.2743 - val_accuracy: 0.8581 - val_recall: 0.9927 - val_auc: 0.9788\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 251s 4s/step - loss: 0.0745 - accuracy: 0.9725 - recall: 0.9832 - auc: 0.9950 - val_loss: 0.2534 - val_accuracy: 0.9317 - val_recall: 0.9898 - val_auc: 0.9645\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 252s 4s/step - loss: 0.0671 - accuracy: 0.9741 - recall: 0.9846 - auc: 0.9965 - val_loss: 0.4350 - val_accuracy: 0.8378 - val_recall: 0.9942 - val_auc: 0.9581\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.394162  0.867094  0.916971  0.910021  1.583741      0.727855   \n",
      "1   0.203599  0.922338  0.949525  0.966054  0.416235      0.769477   \n",
      "2   0.171342  0.935682  0.958669  0.975926  0.665934      0.756670   \n",
      "3   0.154059  0.945290  0.962326  0.979242  0.898848      0.733191   \n",
      "4   0.135943  0.949026  0.967813  0.984610  0.444811      0.784418   \n",
      "5   0.129978  0.948492  0.967447  0.985252  0.315526      0.837780   \n",
      "6   0.111053  0.957566  0.972202  0.989481  0.649609      0.748132   \n",
      "7   0.108455  0.958367  0.971105  0.990635  2.052042      0.729989   \n",
      "8   0.116151  0.958367  0.977688  0.987928  0.223166      0.910352   \n",
      "9   0.111851  0.956765  0.973665  0.989535  1.572530      0.729989   \n",
      "10  0.102833  0.960502  0.977688  0.991229  1.016184      0.729989   \n",
      "11  0.097688  0.965039  0.981712  0.991791  1.026962      0.766275   \n",
      "12  0.102899  0.960769  0.975494  0.990919  0.317830      0.833511   \n",
      "13  0.092865  0.968508  0.980980  0.991392  0.291985      0.885806   \n",
      "14  0.087130  0.970643  0.983906  0.992272  0.623110      0.737460   \n",
      "15  0.068822  0.976781  0.987564  0.995914  0.137916      0.949840   \n",
      "16  0.082300  0.970109  0.984638  0.993156  0.149960      0.948773   \n",
      "17  0.083096  0.971978  0.984272  0.993160  0.274314      0.858058   \n",
      "18  0.074505  0.972511  0.983175  0.995013  0.253372      0.931697   \n",
      "19  0.067133  0.974113  0.984638  0.996510  0.435010      0.837780   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.621461  \n",
      "1     1.000000  0.953598  \n",
      "2     1.000000  0.943462  \n",
      "3     1.000000  0.933274  \n",
      "4     0.940058  0.851175  \n",
      "5     0.995614  0.971046  \n",
      "6     1.000000  0.951766  \n",
      "7     1.000000  0.500514  \n",
      "8     0.975146  0.964985  \n",
      "9     1.000000  0.664179  \n",
      "10    1.000000  0.903766  \n",
      "11    1.000000  0.851360  \n",
      "12    0.995614  0.974909  \n",
      "13    0.994152  0.977458  \n",
      "14    1.000000  0.934367  \n",
      "15    0.986842  0.988330  \n",
      "16    0.961988  0.982644  \n",
      "17    0.992690  0.978844  \n",
      "18    0.989766  0.964543  \n",
      "19    0.994152  0.958131  \n",
      "19/19 [==============================] - 31s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 278s 590ms/step - loss: 0.3866 - accuracy: 0.8468 - recall: 0.8954 - auc: 0.8931 - val_loss: 1.0925 - val_accuracy: 0.8239 - val_recall: 0.9854 - val_auc: 0.8062\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 276s 588ms/step - loss: 0.2523 - accuracy: 0.9079 - recall: 0.9407 - auc: 0.9513 - val_loss: 0.2017 - val_accuracy: 0.9189 - val_recall: 0.9518 - val_auc: 0.9671\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 279s 593ms/step - loss: 0.2206 - accuracy: 0.9175 - recall: 0.9495 - auc: 0.9615 - val_loss: 0.2875 - val_accuracy: 0.8815 - val_recall: 0.8480 - val_auc: 0.9809\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 273s 582ms/step - loss: 0.2005 - accuracy: 0.9250 - recall: 0.9514 - auc: 0.9690 - val_loss: 0.2120 - val_accuracy: 0.9082 - val_recall: 0.9693 - val_auc: 0.9699\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 278s 593ms/step - loss: 0.1859 - accuracy: 0.9338 - recall: 0.9561 - auc: 0.9700 - val_loss: 0.1673 - val_accuracy: 0.9466 - val_recall: 0.9561 - val_auc: 0.9802\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 290s 618ms/step - loss: 0.1772 - accuracy: 0.9349 - recall: 0.9576 - auc: 0.9740 - val_loss: 0.2201 - val_accuracy: 0.9210 - val_recall: 0.9883 - val_auc: 0.9721\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 268s 571ms/step - loss: 0.1836 - accuracy: 0.9373 - recall: 0.9587 - auc: 0.9728 - val_loss: 0.2167 - val_accuracy: 0.9018 - val_recall: 0.9766 - val_auc: 0.9709\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 287s 612ms/step - loss: 0.1505 - accuracy: 0.9450 - recall: 0.9726 - auc: 0.9803 - val_loss: 0.1462 - val_accuracy: 0.9541 - val_recall: 0.9737 - val_auc: 0.9816\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 284s 604ms/step - loss: 0.1352 - accuracy: 0.9522 - recall: 0.9751 - auc: 0.9842 - val_loss: 0.1427 - val_accuracy: 0.9477 - val_recall: 0.9722 - val_auc: 0.9848\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 306s 653ms/step - loss: 0.1467 - accuracy: 0.9493 - recall: 0.9718 - auc: 0.9818 - val_loss: 0.2288 - val_accuracy: 0.9125 - val_recall: 0.9927 - val_auc: 0.9764\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 280s 596ms/step - loss: 0.1446 - accuracy: 0.9536 - recall: 0.9751 - auc: 0.9802 - val_loss: 0.1525 - val_accuracy: 0.9413 - val_recall: 0.9401 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 280s 598ms/step - loss: 0.1198 - accuracy: 0.9592 - recall: 0.9777 - auc: 0.9867 - val_loss: 0.1142 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9887\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 285s 607ms/step - loss: 0.1158 - accuracy: 0.9602 - recall: 0.9839 - auc: 0.9867 - val_loss: 0.1305 - val_accuracy: 0.9477 - val_recall: 0.9825 - val_auc: 0.9843\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 295s 628ms/step - loss: 0.1137 - accuracy: 0.9613 - recall: 0.9821 - auc: 0.9873 - val_loss: 0.1483 - val_accuracy: 0.9392 - val_recall: 0.9868 - val_auc: 0.9849\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 306s 652ms/step - loss: 0.1059 - accuracy: 0.9597 - recall: 0.9828 - auc: 0.9897 - val_loss: 0.1266 - val_accuracy: 0.9445 - val_recall: 0.9781 - val_auc: 0.9875\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 302s 643ms/step - loss: 0.1121 - accuracy: 0.9613 - recall: 0.9821 - auc: 0.9875 - val_loss: 0.1175 - val_accuracy: 0.9552 - val_recall: 0.9722 - val_auc: 0.9892\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 317s 677ms/step - loss: 0.0843 - accuracy: 0.9672 - recall: 0.9802 - auc: 0.9934 - val_loss: 0.1445 - val_accuracy: 0.9445 - val_recall: 0.9898 - val_auc: 0.9875\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 327s 697ms/step - loss: 0.1014 - accuracy: 0.9624 - recall: 0.9832 - auc: 0.9900 - val_loss: 0.1900 - val_accuracy: 0.9168 - val_recall: 0.9898 - val_auc: 0.9781\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 306s 651ms/step - loss: 0.0872 - accuracy: 0.9666 - recall: 0.9839 - auc: 0.9921 - val_loss: 0.1325 - val_accuracy: 0.9541 - val_recall: 0.9839 - val_auc: 0.9839\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 306s 651ms/step - loss: 0.0859 - accuracy: 0.9717 - recall: 0.9868 - auc: 0.9925 - val_loss: 0.1652 - val_accuracy: 0.9520 - val_recall: 0.9883 - val_auc: 0.9805\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.386609  0.846811  0.895391  0.893118  1.092505      0.823906   \n",
      "1   0.252285  0.907926  0.940746  0.951273  0.201670      0.918890   \n",
      "2   0.220556  0.917534  0.949525  0.961524  0.287459      0.881537   \n",
      "3   0.200501  0.925007  0.951353  0.968964  0.211960      0.908218   \n",
      "4   0.185861  0.933814  0.956108  0.969972  0.167314      0.946638   \n",
      "5   0.177244  0.934881  0.957571  0.973954  0.220057      0.921025   \n",
      "6   0.183617  0.937283  0.958669  0.972797  0.216740      0.901814   \n",
      "7   0.150529  0.945023  0.972568  0.980254  0.146202      0.954109   \n",
      "8   0.135162  0.952228  0.975128  0.984187  0.142713      0.947705   \n",
      "9   0.146724  0.949293  0.971836  0.981848  0.228768      0.912487   \n",
      "10  0.144562  0.953563  0.975128  0.980245  0.152535      0.941302   \n",
      "11  0.119796  0.959167  0.977688  0.986652  0.114245      0.955176   \n",
      "12  0.115762  0.960235  0.983906  0.986721  0.130477      0.947705   \n",
      "13  0.113708  0.961302  0.982078  0.987251  0.148299      0.939168   \n",
      "14  0.105911  0.959701  0.982809  0.989748  0.126611      0.944504   \n",
      "15  0.112121  0.961302  0.982078  0.987466  0.117508      0.955176   \n",
      "16  0.084334  0.967174  0.980249  0.993425  0.144502      0.944504   \n",
      "17  0.101403  0.962370  0.983175  0.990006  0.189984      0.916756   \n",
      "18  0.087178  0.966640  0.983906  0.992130  0.132539      0.954109   \n",
      "19  0.085940  0.971711  0.986832  0.992497  0.165236      0.951974   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.985380  0.806209  \n",
      "1     0.951754  0.967082  \n",
      "2     0.847953  0.980884  \n",
      "3     0.969298  0.969931  \n",
      "4     0.956140  0.980203  \n",
      "5     0.988304  0.972127  \n",
      "6     0.976608  0.970873  \n",
      "7     0.973684  0.981638  \n",
      "8     0.972222  0.984834  \n",
      "9     0.992690  0.976351  \n",
      "10    0.940058  0.986544  \n",
      "11    0.979532  0.988737  \n",
      "12    0.982456  0.984262  \n",
      "13    0.986842  0.984872  \n",
      "14    0.978070  0.987512  \n",
      "15    0.972222  0.989226  \n",
      "16    0.989766  0.987486  \n",
      "17    0.989766  0.978148  \n",
      "18    0.983918  0.983915  \n",
      "19    0.988304  0.980532  \n",
      "147/147 [==============================] - 42s 283ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.3923 - accuracy: 0.8353 - recall: 0.8983 - auc: 0.8870 - val_loss: 0.2534 - val_accuracy: 0.9018 - val_recall: 0.8947 - val_auc: 0.9648\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.2500 - accuracy: 0.9103 - recall: 0.9448 - auc: 0.9517 - val_loss: 0.3004 - val_accuracy: 0.8485 - val_recall: 0.9927 - val_auc: 0.9724\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.2026 - accuracy: 0.9253 - recall: 0.9510 - auc: 0.9673 - val_loss: 0.1695 - val_accuracy: 0.9402 - val_recall: 0.9708 - val_auc: 0.9791\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 313s 1s/step - loss: 0.1844 - accuracy: 0.9341 - recall: 0.9583 - auc: 0.9714 - val_loss: 0.4647 - val_accuracy: 0.7823 - val_recall: 0.9985 - val_auc: 0.9577\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 318s 1s/step - loss: 0.1608 - accuracy: 0.9408 - recall: 0.9623 - auc: 0.9788 - val_loss: 0.2550 - val_accuracy: 0.8975 - val_recall: 0.9971 - val_auc: 0.9759\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 316s 1s/step - loss: 0.1515 - accuracy: 0.9480 - recall: 0.9693 - auc: 0.9797 - val_loss: 0.1309 - val_accuracy: 0.9530 - val_recall: 0.9795 - val_auc: 0.9866\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 321s 1s/step - loss: 0.1441 - accuracy: 0.9437 - recall: 0.9645 - auc: 0.9824 - val_loss: 0.1881 - val_accuracy: 0.9306 - val_recall: 0.9795 - val_auc: 0.9788\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 320s 1s/step - loss: 0.1433 - accuracy: 0.9512 - recall: 0.9693 - auc: 0.9822 - val_loss: 0.1454 - val_accuracy: 0.9466 - val_recall: 0.9664 - val_auc: 0.9815\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 322s 1s/step - loss: 0.1477 - accuracy: 0.9520 - recall: 0.9700 - auc: 0.9816 - val_loss: 0.1859 - val_accuracy: 0.9381 - val_recall: 0.9868 - val_auc: 0.9761\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 317s 1s/step - loss: 0.1249 - accuracy: 0.9544 - recall: 0.9737 - auc: 0.9864 - val_loss: 0.1300 - val_accuracy: 0.9477 - val_recall: 0.9839 - val_auc: 0.9891\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 316s 1s/step - loss: 0.1369 - accuracy: 0.9493 - recall: 0.9689 - auc: 0.9833 - val_loss: 0.1379 - val_accuracy: 0.9509 - val_recall: 0.9664 - val_auc: 0.9847\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 315s 1s/step - loss: 0.1195 - accuracy: 0.9570 - recall: 0.9755 - auc: 0.9867 - val_loss: 0.1296 - val_accuracy: 0.9530 - val_recall: 0.9766 - val_auc: 0.9877\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 309s 1s/step - loss: 0.1082 - accuracy: 0.9621 - recall: 0.9781 - auc: 0.9887 - val_loss: 0.2695 - val_accuracy: 0.9328 - val_recall: 0.9839 - val_auc: 0.9614\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 314s 1s/step - loss: 0.1078 - accuracy: 0.9626 - recall: 0.9799 - auc: 0.9896 - val_loss: 0.1897 - val_accuracy: 0.9285 - val_recall: 0.9927 - val_auc: 0.9790\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 312s 1s/step - loss: 0.0926 - accuracy: 0.9634 - recall: 0.9795 - auc: 0.9909 - val_loss: 0.3959 - val_accuracy: 0.8762 - val_recall: 0.9781 - val_auc: 0.9422\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 306s 1s/step - loss: 0.0956 - accuracy: 0.9661 - recall: 0.9828 - auc: 0.9908 - val_loss: 0.1904 - val_accuracy: 0.9157 - val_recall: 0.9883 - val_auc: 0.9826\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 306s 1s/step - loss: 0.0956 - accuracy: 0.9656 - recall: 0.9850 - auc: 0.9913 - val_loss: 0.1685 - val_accuracy: 0.9466 - val_recall: 0.9459 - val_auc: 0.9880\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 313s 1s/step - loss: 0.0854 - accuracy: 0.9666 - recall: 0.9817 - auc: 0.9933 - val_loss: 0.1587 - val_accuracy: 0.9530 - val_recall: 0.9839 - val_auc: 0.9817\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 302s 1s/step - loss: 0.0729 - accuracy: 0.9728 - recall: 0.9868 - auc: 0.9943 - val_loss: 0.1651 - val_accuracy: 0.9498 - val_recall: 0.9532 - val_auc: 0.9862\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 303s 1s/step - loss: 0.0771 - accuracy: 0.9709 - recall: 0.9835 - auc: 0.9943 - val_loss: 0.4384 - val_accuracy: 0.8730 - val_recall: 0.9956 - val_auc: 0.9552\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.392270  0.835335  0.898317  0.887002  0.253398      0.901814   \n",
      "1   0.250020  0.910328  0.944770  0.951670  0.300411      0.848453   \n",
      "2   0.202594  0.925274  0.950988  0.967322  0.169460      0.940235   \n",
      "3   0.184405  0.934081  0.958303  0.971395  0.464734      0.782284   \n",
      "4   0.160821  0.940753  0.962326  0.978756  0.254979      0.897545   \n",
      "5   0.151456  0.947958  0.969276  0.979726  0.130875      0.953042   \n",
      "6   0.144052  0.943688  0.964521  0.982418  0.188075      0.930630   \n",
      "7   0.143325  0.951161  0.969276  0.982162  0.145424      0.946638   \n",
      "8   0.147744  0.951962  0.970007  0.981592  0.185894      0.938100   \n",
      "9   0.124939  0.954363  0.973665  0.986411  0.129965      0.947705   \n",
      "10  0.136912  0.949293  0.968910  0.983274  0.137922      0.950907   \n",
      "11  0.119509  0.957032  0.975494  0.986695  0.129646      0.953042   \n",
      "12  0.108157  0.962103  0.978054  0.988696  0.269456      0.932764   \n",
      "13  0.107792  0.962637  0.979883  0.989636  0.189680      0.928495   \n",
      "14  0.092625  0.963437  0.979517  0.990857  0.395899      0.876201   \n",
      "15  0.095634  0.966106  0.982809  0.990835  0.190425      0.915688   \n",
      "16  0.095645  0.965572  0.985004  0.991307  0.168523      0.946638   \n",
      "17  0.085355  0.966640  0.981712  0.993325  0.158685      0.953042   \n",
      "18  0.072912  0.972778  0.986832  0.994327  0.165136      0.949840   \n",
      "19  0.077068  0.970910  0.983541  0.994289  0.438372      0.872999   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.894737  0.964803  \n",
      "1     0.992690  0.972352  \n",
      "2     0.970760  0.979107  \n",
      "3     0.998538  0.957689  \n",
      "4     0.997076  0.975877  \n",
      "5     0.979532  0.986605  \n",
      "6     0.979532  0.978792  \n",
      "7     0.966374  0.981532  \n",
      "8     0.986842  0.976076  \n",
      "9     0.983918  0.989055  \n",
      "10    0.966374  0.984652  \n",
      "11    0.976608  0.987718  \n",
      "12    0.983918  0.961356  \n",
      "13    0.992690  0.978983  \n",
      "14    0.978070  0.942173  \n",
      "15    0.988304  0.982598  \n",
      "16    0.945906  0.987980  \n",
      "17    0.983918  0.981679  \n",
      "18    0.953216  0.986230  \n",
      "19    0.995614  0.955230  \n",
      "74/74 [==============================] - 38s 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 298s 2s/step - loss: 0.3803 - accuracy: 0.8332 - recall: 0.8969 - auc: 0.8944 - val_loss: 0.2875 - val_accuracy: 0.8847 - val_recall: 0.8845 - val_auc: 0.9501\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 302s 2s/step - loss: 0.2597 - accuracy: 0.8943 - recall: 0.9309 - auc: 0.9468 - val_loss: 0.4840 - val_accuracy: 0.7919 - val_recall: 0.9971 - val_auc: 0.9386\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.2079 - accuracy: 0.9181 - recall: 0.9422 - auc: 0.9652 - val_loss: 0.2073 - val_accuracy: 0.9125 - val_recall: 0.9079 - val_auc: 0.9697\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1986 - accuracy: 0.9239 - recall: 0.9488 - auc: 0.9690 - val_loss: 0.2481 - val_accuracy: 0.9189 - val_recall: 0.9211 - val_auc: 0.9660\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1800 - accuracy: 0.9362 - recall: 0.9543 - auc: 0.9729 - val_loss: 1.0167 - val_accuracy: 0.7449 - val_recall: 1.0000 - val_auc: 0.8693\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 300s 2s/step - loss: 0.1779 - accuracy: 0.9365 - recall: 0.9594 - auc: 0.9741 - val_loss: 0.2018 - val_accuracy: 0.9189 - val_recall: 0.9371 - val_auc: 0.9656\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 299s 2s/step - loss: 0.1618 - accuracy: 0.9424 - recall: 0.9605 - auc: 0.9784 - val_loss: 1.0493 - val_accuracy: 0.7972 - val_recall: 0.9985 - val_auc: 0.8135\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 301s 2s/step - loss: 0.1645 - accuracy: 0.9426 - recall: 0.9645 - auc: 0.9759 - val_loss: 0.3139 - val_accuracy: 0.8559 - val_recall: 0.9971 - val_auc: 0.9784\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1580 - accuracy: 0.9426 - recall: 0.9649 - auc: 0.9780 - val_loss: 0.3486 - val_accuracy: 0.8687 - val_recall: 0.8289 - val_auc: 0.9797\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1524 - accuracy: 0.9424 - recall: 0.9653 - auc: 0.9810 - val_loss: 0.1390 - val_accuracy: 0.9488 - val_recall: 0.9825 - val_auc: 0.9852\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1670 - accuracy: 0.9434 - recall: 0.9678 - auc: 0.9760 - val_loss: 0.1528 - val_accuracy: 0.9456 - val_recall: 0.9576 - val_auc: 0.9843\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1464 - accuracy: 0.9509 - recall: 0.9729 - auc: 0.9811 - val_loss: 0.1616 - val_accuracy: 0.9456 - val_recall: 0.9547 - val_auc: 0.9810\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 303s 2s/step - loss: 0.1324 - accuracy: 0.9528 - recall: 0.9751 - auc: 0.9839 - val_loss: 0.1560 - val_accuracy: 0.9392 - val_recall: 0.9722 - val_auc: 0.9792\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1164 - accuracy: 0.9576 - recall: 0.9799 - auc: 0.9880 - val_loss: 0.1896 - val_accuracy: 0.9381 - val_recall: 0.9488 - val_auc: 0.9768\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.1176 - accuracy: 0.9610 - recall: 0.9788 - auc: 0.9879 - val_loss: 0.1318 - val_accuracy: 0.9402 - val_recall: 0.9795 - val_auc: 0.9888\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.1076 - accuracy: 0.9616 - recall: 0.9781 - auc: 0.9891 - val_loss: 0.2367 - val_accuracy: 0.9125 - val_recall: 0.9766 - val_auc: 0.9662\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0980 - accuracy: 0.9624 - recall: 0.9821 - auc: 0.9909 - val_loss: 0.1335 - val_accuracy: 0.9509 - val_recall: 0.9722 - val_auc: 0.9853\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 293s 2s/step - loss: 0.0971 - accuracy: 0.9645 - recall: 0.9799 - auc: 0.9922 - val_loss: 0.1333 - val_accuracy: 0.9594 - val_recall: 0.9576 - val_auc: 0.9909\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0918 - accuracy: 0.9653 - recall: 0.9788 - auc: 0.9927 - val_loss: 0.1099 - val_accuracy: 0.9605 - val_recall: 0.9781 - val_auc: 0.9890\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.0960 - accuracy: 0.9632 - recall: 0.9810 - auc: 0.9909 - val_loss: 0.1144 - val_accuracy: 0.9605 - val_recall: 0.9751 - val_auc: 0.9890\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.380252  0.833200  0.896854  0.894387  0.287453      0.884739   \n",
      "1   0.259725  0.894315  0.930871  0.946787  0.483956      0.791889   \n",
      "2   0.207932  0.918068  0.942209  0.965220  0.207346      0.912487   \n",
      "3   0.198569  0.923939  0.948793  0.969020  0.248135      0.918890   \n",
      "4   0.180023  0.936216  0.954279  0.972942  1.016667      0.744931   \n",
      "5   0.177874  0.936483  0.959400  0.974108  0.201840      0.918890   \n",
      "6   0.161784  0.942354  0.960497  0.978440  1.049334      0.797225   \n",
      "7   0.164451  0.942621  0.964521  0.975916  0.313923      0.855923   \n",
      "8   0.157995  0.942621  0.964887  0.978000  0.348574      0.868730   \n",
      "9   0.152432  0.942354  0.965252  0.981040  0.139046      0.948773   \n",
      "10  0.167000  0.943421  0.967813  0.975951  0.152814      0.945571   \n",
      "11  0.146427  0.950894  0.972933  0.981107  0.161598      0.945571   \n",
      "12  0.132363  0.952762  0.975128  0.983882  0.156023      0.939168   \n",
      "13  0.116385  0.957566  0.979883  0.988008  0.189550      0.938100   \n",
      "14  0.117560  0.961035  0.978786  0.987901  0.131832      0.940235   \n",
      "15  0.107592  0.961569  0.978054  0.989086  0.236656      0.912487   \n",
      "16  0.097976  0.962370  0.982078  0.990899  0.133475      0.950907   \n",
      "17  0.097141  0.964505  0.979883  0.992244  0.133346      0.959445   \n",
      "18  0.091761  0.965306  0.978786  0.992704  0.109932      0.960512   \n",
      "19  0.095968  0.963171  0.980980  0.990902  0.114390      0.960512   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.884503  0.950087  \n",
      "1     0.997076  0.938649  \n",
      "2     0.907895  0.969749  \n",
      "3     0.921053  0.966010  \n",
      "4     1.000000  0.869294  \n",
      "5     0.937135  0.965591  \n",
      "6     0.998538  0.813524  \n",
      "7     0.997076  0.978374  \n",
      "8     0.828947  0.979743  \n",
      "9     0.982456  0.985207  \n",
      "10    0.957602  0.984320  \n",
      "11    0.954678  0.981037  \n",
      "12    0.972222  0.979151  \n",
      "13    0.948830  0.976842  \n",
      "14    0.979532  0.988821  \n",
      "15    0.976608  0.966210  \n",
      "16    0.972222  0.985259  \n",
      "17    0.957602  0.990945  \n",
      "18    0.978070  0.989012  \n",
      "19    0.975146  0.988954  \n",
      "59/59 [==============================] - 37s 627ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 295s 2s/step - loss: 0.3638 - accuracy: 0.8519 - recall: 0.8928 - auc: 0.9080 - val_loss: 0.7170 - val_accuracy: 0.7588 - val_recall: 0.9123 - val_auc: 0.8087\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.2894 - accuracy: 0.8858 - recall: 0.9137 - auc: 0.9384 - val_loss: 0.2182 - val_accuracy: 0.9072 - val_recall: 0.9064 - val_auc: 0.9719\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.2220 - accuracy: 0.9141 - recall: 0.9407 - auc: 0.9616 - val_loss: 0.3776 - val_accuracy: 0.8196 - val_recall: 0.9605 - val_auc: 0.9180\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 295s 2s/step - loss: 0.2091 - accuracy: 0.9226 - recall: 0.9444 - auc: 0.9645 - val_loss: 1.5950 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6756\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 305s 3s/step - loss: 0.1739 - accuracy: 0.9325 - recall: 0.9535 - auc: 0.9735 - val_loss: 0.7153 - val_accuracy: 0.7449 - val_recall: 0.9985 - val_auc: 0.9198\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 301s 3s/step - loss: 0.1666 - accuracy: 0.9410 - recall: 0.9631 - auc: 0.9777 - val_loss: 1.2469 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.8054\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 313s 3s/step - loss: 0.1433 - accuracy: 0.9488 - recall: 0.9671 - auc: 0.9830 - val_loss: 0.2165 - val_accuracy: 0.9306 - val_recall: 0.9254 - val_auc: 0.9837\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 305s 3s/step - loss: 0.1240 - accuracy: 0.9586 - recall: 0.9777 - auc: 0.9858 - val_loss: 0.1623 - val_accuracy: 0.9402 - val_recall: 0.9854 - val_auc: 0.9810\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 303s 3s/step - loss: 0.1306 - accuracy: 0.9482 - recall: 0.9689 - auc: 0.9848 - val_loss: 0.7674 - val_accuracy: 0.7737 - val_recall: 0.9927 - val_auc: 0.9060\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 310s 3s/step - loss: 0.1708 - accuracy: 0.9410 - recall: 0.9634 - auc: 0.9747 - val_loss: 0.4736 - val_accuracy: 0.7759 - val_recall: 0.9985 - val_auc: 0.9452\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.1235 - accuracy: 0.9557 - recall: 0.9700 - auc: 0.9862 - val_loss: 0.1315 - val_accuracy: 0.9573 - val_recall: 0.9810 - val_auc: 0.9851\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.1120 - accuracy: 0.9602 - recall: 0.9770 - auc: 0.9879 - val_loss: 0.6829 - val_accuracy: 0.7716 - val_recall: 1.0000 - val_auc: 0.9449\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.1031 - accuracy: 0.9661 - recall: 0.9810 - auc: 0.9890 - val_loss: 0.8163 - val_accuracy: 0.7866 - val_recall: 1.0000 - val_auc: 0.8678\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.1002 - accuracy: 0.9634 - recall: 0.9792 - auc: 0.9910 - val_loss: 0.5147 - val_accuracy: 0.8388 - val_recall: 0.9927 - val_auc: 0.9350\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.1159 - accuracy: 0.9562 - recall: 0.9781 - auc: 0.9883 - val_loss: 0.1440 - val_accuracy: 0.9562 - val_recall: 0.9825 - val_auc: 0.9826\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 292s 2s/step - loss: 0.0999 - accuracy: 0.9661 - recall: 0.9835 - auc: 0.9902 - val_loss: 0.2331 - val_accuracy: 0.9221 - val_recall: 0.9912 - val_auc: 0.9732\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 296s 3s/step - loss: 0.0876 - accuracy: 0.9658 - recall: 0.9817 - auc: 0.9934 - val_loss: 0.1474 - val_accuracy: 0.9498 - val_recall: 0.9898 - val_auc: 0.9827\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 294s 2s/step - loss: 0.0880 - accuracy: 0.9701 - recall: 0.9843 - auc: 0.9922 - val_loss: 0.3680 - val_accuracy: 0.8645 - val_recall: 0.9985 - val_auc: 0.9530\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 289s 2s/step - loss: 0.0847 - accuracy: 0.9704 - recall: 0.9850 - auc: 0.9936 - val_loss: 0.2071 - val_accuracy: 0.9349 - val_recall: 0.9898 - val_auc: 0.9750\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.0699 - accuracy: 0.9762 - recall: 0.9857 - auc: 0.9959 - val_loss: 0.2761 - val_accuracy: 0.9242 - val_recall: 0.9912 - val_auc: 0.9621\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.363765  0.851882  0.892831  0.908013  0.716968      0.758805   \n",
      "1   0.289414  0.885775  0.913680  0.938394  0.218245      0.907151   \n",
      "2   0.221990  0.914065  0.940746  0.961584  0.377642      0.819637   \n",
      "3   0.209054  0.922605  0.944404  0.964450  1.594999      0.729989   \n",
      "4   0.173887  0.932479  0.953548  0.973517  0.715263      0.744931   \n",
      "5   0.166581  0.941019  0.963058  0.977714  1.246939      0.738527   \n",
      "6   0.143334  0.948759  0.967081  0.982976  0.216453      0.930630   \n",
      "7   0.123992  0.958634  0.977688  0.985828  0.162308      0.940235   \n",
      "8   0.130584  0.948225  0.968910  0.984791  0.767446      0.773746   \n",
      "9   0.170808  0.941019  0.963424  0.974658  0.473570      0.775880   \n",
      "10  0.123462  0.955698  0.970007  0.986189  0.131548      0.957311   \n",
      "11  0.111973  0.960235  0.976957  0.987892  0.682946      0.771612   \n",
      "12  0.103086  0.966106  0.980980  0.988954  0.816289      0.786553   \n",
      "13  0.100228  0.963437  0.979151  0.990959  0.514670      0.838847   \n",
      "14  0.115870  0.956232  0.978054  0.988330  0.143968      0.956243   \n",
      "15  0.099863  0.966106  0.983541  0.990236  0.233116      0.922092   \n",
      "16  0.087565  0.965839  0.981712  0.993385  0.147410      0.949840   \n",
      "17  0.087954  0.970109  0.984272  0.992164  0.368027      0.864461   \n",
      "18  0.084665  0.970376  0.985004  0.993645  0.207058      0.934899   \n",
      "19  0.069873  0.976248  0.985735  0.995893  0.276110      0.924226   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.912281  0.808719  \n",
      "1     0.906433  0.971890  \n",
      "2     0.960526  0.917964  \n",
      "3     1.000000  0.675583  \n",
      "4     0.998538  0.919799  \n",
      "5     1.000000  0.805362  \n",
      "6     0.925439  0.983739  \n",
      "7     0.985380  0.981037  \n",
      "8     0.992690  0.906005  \n",
      "9     0.998538  0.945213  \n",
      "10    0.980994  0.985120  \n",
      "11    1.000000  0.944907  \n",
      "12    1.000000  0.867840  \n",
      "13    0.992690  0.935043  \n",
      "14    0.982456  0.982647  \n",
      "15    0.991228  0.973173  \n",
      "16    0.989766  0.982739  \n",
      "17    0.998538  0.953049  \n",
      "18    0.989766  0.974990  \n",
      "19    0.991228  0.962101  \n",
      "37/37 [==============================] - 36s 965ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.3698 - accuracy: 0.8297 - recall: 0.8855 - auc: 0.8967 - val_loss: 0.3438 - val_accuracy: 0.8420 - val_recall: 0.9152 - val_auc: 0.9015\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.2621 - accuracy: 0.8956 - recall: 0.9276 - auc: 0.9503 - val_loss: 0.8927 - val_accuracy: 0.7524 - val_recall: 0.9985 - val_auc: 0.8831\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.2068 - accuracy: 0.9221 - recall: 0.9488 - auc: 0.9675 - val_loss: 2.1253 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5388\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1981 - accuracy: 0.9221 - recall: 0.9503 - auc: 0.9691 - val_loss: 1.0496 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.8798\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1860 - accuracy: 0.9314 - recall: 0.9568 - auc: 0.9733 - val_loss: 0.3529 - val_accuracy: 0.8164 - val_recall: 0.9956 - val_auc: 0.9527\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1468 - accuracy: 0.9429 - recall: 0.9682 - auc: 0.9820 - val_loss: 0.5081 - val_accuracy: 0.8292 - val_recall: 0.9985 - val_auc: 0.9354\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1345 - accuracy: 0.9514 - recall: 0.9707 - auc: 0.9836 - val_loss: 0.1687 - val_accuracy: 0.9477 - val_recall: 0.9561 - val_auc: 0.9831\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1297 - accuracy: 0.9549 - recall: 0.9718 - auc: 0.9858 - val_loss: 0.3947 - val_accuracy: 0.8623 - val_recall: 0.9971 - val_auc: 0.9614\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1266 - accuracy: 0.9618 - recall: 0.9795 - auc: 0.9863 - val_loss: 0.2896 - val_accuracy: 0.8911 - val_recall: 0.9971 - val_auc: 0.9778\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1266 - accuracy: 0.9525 - recall: 0.9671 - auc: 0.9871 - val_loss: 0.2470 - val_accuracy: 0.8837 - val_recall: 0.9942 - val_auc: 0.9743\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1055 - accuracy: 0.9605 - recall: 0.9788 - auc: 0.9897 - val_loss: 0.2188 - val_accuracy: 0.9072 - val_recall: 0.9693 - val_auc: 0.9704\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 277s 5s/step - loss: 0.0924 - accuracy: 0.9626 - recall: 0.9799 - auc: 0.9926 - val_loss: 0.2377 - val_accuracy: 0.8687 - val_recall: 0.9971 - val_auc: 0.9832\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0958 - accuracy: 0.9640 - recall: 0.9828 - auc: 0.9916 - val_loss: 0.4739 - val_accuracy: 0.8783 - val_recall: 0.9971 - val_auc: 0.9330\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0820 - accuracy: 0.9706 - recall: 0.9835 - auc: 0.9935 - val_loss: 0.2228 - val_accuracy: 0.9242 - val_recall: 0.9898 - val_auc: 0.9802\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.0900 - accuracy: 0.9701 - recall: 0.9835 - auc: 0.9926 - val_loss: 2.5554 - val_accuracy: 0.7364 - val_recall: 1.0000 - val_auc: 0.5921\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0875 - accuracy: 0.9658 - recall: 0.9835 - auc: 0.9930 - val_loss: 0.2372 - val_accuracy: 0.9328 - val_recall: 0.9225 - val_auc: 0.9853\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.0771 - accuracy: 0.9701 - recall: 0.9843 - auc: 0.9939 - val_loss: 0.1648 - val_accuracy: 0.9456 - val_recall: 0.9561 - val_auc: 0.9830\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.0725 - accuracy: 0.9728 - recall: 0.9865 - auc: 0.9953 - val_loss: 0.1844 - val_accuracy: 0.9392 - val_recall: 0.9795 - val_auc: 0.9754\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 297s 5s/step - loss: 0.0745 - accuracy: 0.9730 - recall: 0.9839 - auc: 0.9934 - val_loss: 0.2388 - val_accuracy: 0.9168 - val_recall: 0.9868 - val_auc: 0.9672\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 292s 5s/step - loss: 0.0683 - accuracy: 0.9730 - recall: 0.9821 - auc: 0.9954 - val_loss: 0.1131 - val_accuracy: 0.9605 - val_recall: 0.9781 - val_auc: 0.9873\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.369783  0.829730  0.885516  0.896664  0.343757      0.842049   \n",
      "1   0.262143  0.895650  0.927579  0.950316  0.892689      0.752401   \n",
      "2   0.206841  0.922071  0.948793  0.967498  2.125311      0.729989   \n",
      "3   0.198062  0.922071  0.950256  0.969140  1.049604      0.737460   \n",
      "4   0.185985  0.931412  0.956840  0.973279  0.352910      0.816435   \n",
      "5   0.146848  0.942888  0.968179  0.981984  0.508114      0.829242   \n",
      "6   0.134499  0.951428  0.970739  0.983579  0.168665      0.947705   \n",
      "7   0.129746  0.954897  0.971836  0.985813  0.394652      0.862327   \n",
      "8   0.126581  0.961836  0.979517  0.986311  0.289648      0.891142   \n",
      "9   0.126612  0.952495  0.967081  0.987118  0.246953      0.883671   \n",
      "10  0.105501  0.960502  0.978786  0.989739  0.218757      0.907151   \n",
      "11  0.092418  0.962637  0.979883  0.992550  0.237706      0.868730   \n",
      "12  0.095832  0.963971  0.982809  0.991608  0.473934      0.878335   \n",
      "13  0.081958  0.970643  0.983541  0.993484  0.222848      0.924226   \n",
      "14  0.090038  0.970109  0.983541  0.992553  2.555391      0.736393   \n",
      "15  0.087490  0.965839  0.983541  0.992981  0.237215      0.932764   \n",
      "16  0.077124  0.970109  0.984272  0.993931  0.164788      0.945571   \n",
      "17  0.072505  0.972778  0.986467  0.995258  0.184350      0.939168   \n",
      "18  0.074503  0.973045  0.983906  0.993383  0.238786      0.916756   \n",
      "19  0.068340  0.973045  0.982078  0.995428  0.113143      0.960512   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.915205  0.901480  \n",
      "1     0.998538  0.883133  \n",
      "2     1.000000  0.538815  \n",
      "3     1.000000  0.879776  \n",
      "4     0.995614  0.952696  \n",
      "5     0.998538  0.935441  \n",
      "6     0.956140  0.983083  \n",
      "7     0.997076  0.961442  \n",
      "8     0.997076  0.977822  \n",
      "9     0.994152  0.974323  \n",
      "10    0.969298  0.970356  \n",
      "11    0.997076  0.983233  \n",
      "12    0.997076  0.933003  \n",
      "13    0.989766  0.980223  \n",
      "14    1.000000  0.592062  \n",
      "15    0.922515  0.985345  \n",
      "16    0.956140  0.982976  \n",
      "17    0.979532  0.975380  \n",
      "18    0.986842  0.967183  \n",
      "19    0.978070  0.987255  \n",
      "19/19 [==============================] - 37s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\3631025187.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#para AlexaNet, es necesario cambiar el tamaño de input_shape\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "tabla_arqu_batch_alexnet = arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7400968-2326-40c3-b7fa-b9d81426bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.18      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        16         0.16      0.95       0.96    0.97  0.96         0.90  0.10   \n",
       "        20         1.83      0.74       0.74    1.00  0.85         0.04  0.96   \n",
       "        32         0.16      0.95       0.96    0.97  0.97         0.90  0.10   \n",
       "        64         0.19      0.95       0.94    0.99  0.97         0.84  0.16   \n",
       "Simple2 8          0.15      0.95       0.96    0.96  0.96         0.91  0.09   \n",
       "        16         0.14      0.95       0.96    0.98  0.97         0.88  0.12   \n",
       "        20         0.17      0.95       0.96    0.98  0.97         0.89  0.11   \n",
       "        32         0.21      0.94       0.97    0.95  0.96         0.92  0.08   \n",
       "        64         0.48      0.83       0.81    1.00  0.90         0.38  0.62   \n",
       "Simple3 8          0.18      0.94       0.93    0.99  0.96         0.81  0.19   \n",
       "        16         0.14      0.95       0.95    0.99  0.97         0.85  0.15   \n",
       "        20         0.15      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        32         0.31      0.91       0.90    0.99  0.94         0.72  0.28   \n",
       "        64         0.17      0.95       0.96    0.98  0.97         0.89  0.11   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.03  0.98  \n",
       "        16         0.03  0.98  \n",
       "        20         0.00  0.86  \n",
       "        32         0.03  0.98  \n",
       "        64         0.01  0.99  \n",
       "Simple2 8          0.04  0.98  \n",
       "        16         0.02  0.99  \n",
       "        20         0.02  0.98  \n",
       "        32         0.05  0.98  \n",
       "        64         0.00  0.98  \n",
       "Simple3 8          0.01  0.98  \n",
       "        16         0.01  0.98  \n",
       "        20         0.03  0.99  \n",
       "        32         0.01  0.98  \n",
       "        64         0.02  0.99  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b8a3-f70f-41ff-822a-b956996a6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple 2 batchsize 64 arquitectura alexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385cf7b2-62fb-4986-83ff-319609499434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A PARTIR DE AQUI IGUAL BASTARIA CON EMPLEAR LA ARQUITECTURA (PROPIA O ALEXA NET) QUE HAYA FUNCIONADO MEJOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15853-36f9-4980-b52a-7b824f0a700b",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura \"Simple2\" CNN propia y un batchsize de 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c884c-043f-451a-b8a2-34f801293780",
   "metadata": {},
   "source": [
    "A partir de los resultados obtenidos previamente, se comparan distintos valores de número de neuronas para determinar con cuál funciona mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563679f-a18b-4449-a256-59ec9f249590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antes hay que ejecutar la funcion preparar modelo y la funcion de metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7770eb-8c52-4a03-94a7-0ec6175bc1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple2\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "\n",
    "    \n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "                [\n",
    "                    keras.Input(shape=input_shape),\n",
    "                    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                    layers.Flatten(), #convierte imágenes en vectores\n",
    "                    layers.Dense(neurona, activation=\"relu\"), #se va cambiando el valor de \"neurona\" para cada uno de los valores que estan en la lista num_neuronas\n",
    "                    layers.Dropout(0.2),\n",
    "                    layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) #hacer grafica val y train para auc o loss\n",
    "        \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "    \n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e149e1-418f-4f88-940c-b5d8a4764223",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "target_size=(150,150)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=32\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e6f12-2aa4-4601-b206-8d060719a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERO DE NEURONAS CON EL MODELO SIMPLE3\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    \n",
    "    \n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) #hacer grafica val y train para auc o loss\n",
    "        \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e774b4c-5c09-401e-8d27-5773b482a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "target_size=(150,150)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=32\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c14476-66a8-40c7-9a36-ee0c3dbc3902",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura \"Simple2\" CNN AlexaNet y un batchsize de 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86ce7a87-bc74-4333-a5ca-902cd12eb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple2 AlexNet\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "\n",
    "    \n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) #hacer grafica val y train para auc o loss\n",
    "        \n",
    "        #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "        nombre_archivo = f'historico_{neurona}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "        ruta_historico = os.path.join('C:/Users/nuria/Downloads/TFG', 'historico_2_64') #se guarda dentro de una nueva carpeta denominada 'historico_2_64'\n",
    "        # Crea la carpeta 'historico_2_64' si no existe\n",
    "        os.makedirs(ruta_historico, exist_ok=True)\n",
    "        ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "        historico.to_csv(ruta_archivo, index=False)\n",
    "    \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "    \n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3a24f46-4382-4420-9ff7-d15217bbd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Modelo con 512 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.7619 - accuracy: 0.8495 - recall: 0.9016 - auc: 0.8856 - val_loss: 2.8680 - val_accuracy: 0.7289 - val_recall: 0.9985 - val_auc: 0.4937\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.2635 - accuracy: 0.8940 - recall: 0.9294 - auc: 0.9460 - val_loss: 0.5446 - val_accuracy: 0.7428 - val_recall: 0.6813 - val_auc: 0.8592\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 288s 5s/step - loss: 0.2177 - accuracy: 0.9114 - recall: 0.9426 - auc: 0.9625 - val_loss: 0.4027 - val_accuracy: 0.8036 - val_recall: 0.9971 - val_auc: 0.9643\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1841 - accuracy: 0.9285 - recall: 0.9510 - auc: 0.9722 - val_loss: 0.1997 - val_accuracy: 0.9200 - val_recall: 0.9722 - val_auc: 0.9736\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1686 - accuracy: 0.9351 - recall: 0.9565 - auc: 0.9764 - val_loss: 0.1575 - val_accuracy: 0.9466 - val_recall: 0.9708 - val_auc: 0.9794\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1426 - accuracy: 0.9437 - recall: 0.9653 - auc: 0.9833 - val_loss: 0.5968 - val_accuracy: 0.7780 - val_recall: 1.0000 - val_auc: 0.9575\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1308 - accuracy: 0.9514 - recall: 0.9707 - auc: 0.9860 - val_loss: 0.1381 - val_accuracy: 0.9541 - val_recall: 0.9722 - val_auc: 0.9852\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1228 - accuracy: 0.9544 - recall: 0.9700 - auc: 0.9872 - val_loss: 0.2329 - val_accuracy: 0.9210 - val_recall: 0.9415 - val_auc: 0.9616\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.1279 - accuracy: 0.9501 - recall: 0.9685 - auc: 0.9860 - val_loss: 0.1653 - val_accuracy: 0.9402 - val_recall: 0.9430 - val_auc: 0.9794\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.1071 - accuracy: 0.9597 - recall: 0.9748 - auc: 0.9898 - val_loss: 0.1144 - val_accuracy: 0.9562 - val_recall: 0.9708 - val_auc: 0.9900\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1032 - accuracy: 0.9589 - recall: 0.9751 - auc: 0.9905 - val_loss: 0.3117 - val_accuracy: 0.9018 - val_recall: 0.9942 - val_auc: 0.9635\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 288s 5s/step - loss: 0.1065 - accuracy: 0.9573 - recall: 0.9744 - auc: 0.9897 - val_loss: 0.1185 - val_accuracy: 0.9573 - val_recall: 0.9854 - val_auc: 0.9912\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.0940 - accuracy: 0.9640 - recall: 0.9770 - auc: 0.9926 - val_loss: 0.1984 - val_accuracy: 0.9285 - val_recall: 0.9883 - val_auc: 0.9805\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.0877 - accuracy: 0.9669 - recall: 0.9781 - auc: 0.9935 - val_loss: 0.1947 - val_accuracy: 0.9541 - val_recall: 0.9737 - val_auc: 0.9780\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.0835 - accuracy: 0.9682 - recall: 0.9817 - auc: 0.9934 - val_loss: 0.1276 - val_accuracy: 0.9584 - val_recall: 0.9649 - val_auc: 0.9882\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0973 - accuracy: 0.9626 - recall: 0.9751 - auc: 0.9920 - val_loss: 0.1555 - val_accuracy: 0.9413 - val_recall: 0.9357 - val_auc: 0.9901\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0772 - accuracy: 0.9738 - recall: 0.9854 - auc: 0.9936 - val_loss: 0.1778 - val_accuracy: 0.9466 - val_recall: 0.9678 - val_auc: 0.9736\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.0712 - accuracy: 0.9736 - recall: 0.9835 - auc: 0.9950 - val_loss: 0.1466 - val_accuracy: 0.9530 - val_recall: 0.9561 - val_auc: 0.9829\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0765 - accuracy: 0.9728 - recall: 0.9824 - auc: 0.9940 - val_loss: 0.5764 - val_accuracy: 0.8218 - val_recall: 0.9985 - val_auc: 0.9341\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0649 - accuracy: 0.9757 - recall: 0.9850 - auc: 0.9963 - val_loss: 0.2524 - val_accuracy: 0.9200 - val_recall: 0.9401 - val_auc: 0.9618\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.761902  0.849480  0.901609  0.885558  2.867983      0.728922   \n",
      "1   0.263462  0.894049  0.929407  0.946036  0.544606      0.742796   \n",
      "2   0.217697  0.911396  0.942575  0.962506  0.402671      0.803629   \n",
      "3   0.184111  0.928476  0.950988  0.972229  0.199659      0.919957   \n",
      "4   0.168606  0.935148  0.956474  0.976413  0.157468      0.946638   \n",
      "5   0.142551  0.943688  0.965252  0.983252  0.596791      0.778015   \n",
      "6   0.130821  0.951428  0.970739  0.985978  0.138144      0.954109   \n",
      "7   0.122780  0.954363  0.970007  0.987247  0.232932      0.921025   \n",
      "8   0.127913  0.950093  0.968544  0.986026  0.165255      0.940235   \n",
      "9   0.107108  0.959701  0.974762  0.989825  0.114443      0.956243   \n",
      "10  0.103192  0.958900  0.975128  0.990493  0.311682      0.901814   \n",
      "11  0.106493  0.957299  0.974396  0.989741  0.118452      0.957311   \n",
      "12  0.094036  0.963971  0.976957  0.992578  0.198410      0.928495   \n",
      "13  0.087735  0.966907  0.978054  0.993500  0.194715      0.954109   \n",
      "14  0.083453  0.968241  0.981712  0.993444  0.127605      0.958378   \n",
      "15  0.097335  0.962637  0.975128  0.991990  0.155495      0.941302   \n",
      "16  0.077180  0.973846  0.985369  0.993629  0.177827      0.946638   \n",
      "17  0.071209  0.973579  0.983541  0.995045  0.146589      0.953042   \n",
      "18  0.076482  0.972778  0.982443  0.993970  0.576384      0.821772   \n",
      "19  0.064878  0.975714  0.985004  0.996310  0.252399      0.919957   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.998538  0.493667  \n",
      "1     0.681287  0.859161  \n",
      "2     0.997076  0.964317  \n",
      "3     0.972222  0.973612  \n",
      "4     0.970760  0.979437  \n",
      "5     1.000000  0.957501  \n",
      "6     0.972222  0.985213  \n",
      "7     0.941520  0.961624  \n",
      "8     0.942982  0.979425  \n",
      "9     0.970760  0.989977  \n",
      "10    0.994152  0.963465  \n",
      "11    0.985380  0.991222  \n",
      "12    0.988304  0.980543  \n",
      "13    0.973684  0.978038  \n",
      "14    0.964912  0.988200  \n",
      "15    0.935673  0.990087  \n",
      "16    0.967836  0.973574  \n",
      "17    0.956140  0.982858  \n",
      "18    0.998538  0.934078  \n",
      "19    0.940058  0.961835  \n",
      "19/19 [==============================] - 34s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7884\\3893710647.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 1024 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 288s 5s/step - loss: 0.7839 - accuracy: 0.8263 - recall: 0.8811 - auc: 0.8591 - val_loss: 6.0416 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.4985\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.2387 - accuracy: 0.9050 - recall: 0.9386 - auc: 0.9556 - val_loss: 1.9421 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.6543\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.2104 - accuracy: 0.9167 - recall: 0.9418 - auc: 0.9653 - val_loss: 0.4949 - val_accuracy: 0.8154 - val_recall: 0.9912 - val_auc: 0.9302\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.1719 - accuracy: 0.9327 - recall: 0.9550 - auc: 0.9754 - val_loss: 1.0459 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.8677\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1513 - accuracy: 0.9429 - recall: 0.9623 - auc: 0.9814 - val_loss: 0.5385 - val_accuracy: 0.7407 - val_recall: 0.6520 - val_auc: 0.9685\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.1368 - accuracy: 0.9482 - recall: 0.9653 - auc: 0.9835 - val_loss: 0.1984 - val_accuracy: 0.9242 - val_recall: 0.9883 - val_auc: 0.9761\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1161 - accuracy: 0.9544 - recall: 0.9722 - auc: 0.9883 - val_loss: 0.3016 - val_accuracy: 0.8911 - val_recall: 0.9868 - val_auc: 0.9551\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1110 - accuracy: 0.9568 - recall: 0.9748 - auc: 0.9888 - val_loss: 0.4270 - val_accuracy: 0.8463 - val_recall: 0.9825 - val_auc: 0.9475\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1129 - accuracy: 0.9584 - recall: 0.9729 - auc: 0.9897 - val_loss: 0.2417 - val_accuracy: 0.9104 - val_recall: 0.8991 - val_auc: 0.9755\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0998 - accuracy: 0.9618 - recall: 0.9748 - auc: 0.9903 - val_loss: 0.5527 - val_accuracy: 0.8324 - val_recall: 0.9956 - val_auc: 0.9405\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0917 - accuracy: 0.9648 - recall: 0.9802 - auc: 0.9915 - val_loss: 0.1747 - val_accuracy: 0.9434 - val_recall: 0.9751 - val_auc: 0.9766\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.0949 - accuracy: 0.9602 - recall: 0.9740 - auc: 0.9922 - val_loss: 0.2897 - val_accuracy: 0.8773 - val_recall: 0.9825 - val_auc: 0.9691\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0911 - accuracy: 0.9640 - recall: 0.9773 - auc: 0.9934 - val_loss: 0.2300 - val_accuracy: 0.9114 - val_recall: 0.9781 - val_auc: 0.9688\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0712 - accuracy: 0.9706 - recall: 0.9839 - auc: 0.9951 - val_loss: 0.1903 - val_accuracy: 0.9392 - val_recall: 0.9810 - val_auc: 0.9766\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0720 - accuracy: 0.9696 - recall: 0.9806 - auc: 0.9953 - val_loss: 0.1192 - val_accuracy: 0.9616 - val_recall: 0.9839 - val_auc: 0.9864\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0700 - accuracy: 0.9749 - recall: 0.9839 - auc: 0.9953 - val_loss: 0.1607 - val_accuracy: 0.9466 - val_recall: 0.9415 - val_auc: 0.9880\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0609 - accuracy: 0.9784 - recall: 0.9887 - auc: 0.9961 - val_loss: 0.1320 - val_accuracy: 0.9562 - val_recall: 0.9635 - val_auc: 0.9884\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.0643 - accuracy: 0.9765 - recall: 0.9846 - auc: 0.9960 - val_loss: 0.9580 - val_accuracy: 0.7503 - val_recall: 0.6623 - val_auc: 0.9565\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0627 - accuracy: 0.9800 - recall: 0.9883 - auc: 0.9962 - val_loss: 0.5121 - val_accuracy: 0.8645 - val_recall: 0.8202 - val_auc: 0.9768\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0595 - accuracy: 0.9754 - recall: 0.9854 - auc: 0.9968 - val_loss: 0.2879 - val_accuracy: 0.8965 - val_recall: 0.8772 - val_auc: 0.9748\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.783916  0.826261  0.881127  0.859098  6.041584      0.729989   \n",
      "1   0.238684  0.904991  0.938552  0.955566  1.942142      0.727855   \n",
      "2   0.210448  0.916733  0.941843  0.965287  0.494926      0.815368   \n",
      "3   0.171932  0.932746  0.955011  0.975406  1.045940      0.738527   \n",
      "4   0.151265  0.942888  0.962326  0.981395  0.538511      0.740662   \n",
      "5   0.136804  0.948225  0.965252  0.983529  0.198378      0.924226   \n",
      "6   0.116098  0.954363  0.972202  0.988311  0.301623      0.891142   \n",
      "7   0.110967  0.956765  0.974762  0.988758  0.426978      0.846318   \n",
      "8   0.112924  0.958367  0.972933  0.989678  0.241706      0.910352   \n",
      "9   0.099766  0.961836  0.974762  0.990335  0.552684      0.832444   \n",
      "10  0.091689  0.964772  0.980249  0.991497  0.174676      0.943437   \n",
      "11  0.094883  0.960235  0.974031  0.992171  0.289715      0.877268   \n",
      "12  0.091098  0.963971  0.977323  0.993354  0.229951      0.911419   \n",
      "13  0.071152  0.970643  0.983906  0.995099  0.190326      0.939168   \n",
      "14  0.071983  0.969576  0.980614  0.995262  0.119241      0.961580   \n",
      "15  0.069994  0.974913  0.983906  0.995338  0.160738      0.946638   \n",
      "16  0.060854  0.978383  0.988661  0.996142  0.132032      0.956243   \n",
      "17  0.064268  0.976515  0.984638  0.995997  0.957970      0.750267   \n",
      "18  0.062743  0.979984  0.988296  0.996173  0.512052      0.864461   \n",
      "19  0.059530  0.975447  0.985369  0.996812  0.287923      0.896478   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.498538  \n",
      "1     0.997076  0.654329  \n",
      "2     0.991228  0.930235  \n",
      "3     1.000000  0.867693  \n",
      "4     0.652047  0.968475  \n",
      "5     0.988304  0.976074  \n",
      "6     0.986842  0.955083  \n",
      "7     0.982456  0.947499  \n",
      "8     0.899123  0.975502  \n",
      "9     0.995614  0.940483  \n",
      "10    0.975146  0.976628  \n",
      "11    0.982456  0.969125  \n",
      "12    0.978070  0.968830  \n",
      "13    0.980994  0.976574  \n",
      "14    0.983918  0.986380  \n",
      "15    0.941520  0.987981  \n",
      "16    0.963450  0.988365  \n",
      "17    0.662281  0.956530  \n",
      "18    0.820175  0.976816  \n",
      "19    0.877193  0.974808  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7884\\3893710647.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 2048 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 283s 5s/step - loss: 1.2195 - accuracy: 0.8441 - recall: 0.8914 - auc: 0.8606 - val_loss: 3.0110 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.5116\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.2625 - accuracy: 0.9010 - recall: 0.9356 - auc: 0.9497 - val_loss: 0.3040 - val_accuracy: 0.8527 - val_recall: 0.9766 - val_auc: 0.9529\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.2218 - accuracy: 0.9178 - recall: 0.9477 - auc: 0.9609 - val_loss: 0.3278 - val_accuracy: 0.8463 - val_recall: 0.9664 - val_auc: 0.9307\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.1781 - accuracy: 0.9338 - recall: 0.9576 - auc: 0.9738 - val_loss: 3.3152 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5040\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 286s 5s/step - loss: 0.1520 - accuracy: 0.9397 - recall: 0.9620 - auc: 0.9803 - val_loss: 5.1257 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1564 - accuracy: 0.9381 - recall: 0.9572 - auc: 0.9798 - val_loss: 2.5453 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5494\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.1429 - accuracy: 0.9464 - recall: 0.9656 - auc: 0.9818 - val_loss: 1.4458 - val_accuracy: 0.7321 - val_recall: 1.0000 - val_auc: 0.7693\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1119 - accuracy: 0.9573 - recall: 0.9733 - auc: 0.9885 - val_loss: 2.9330 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.1256 - accuracy: 0.9538 - recall: 0.9689 - auc: 0.9856 - val_loss: 0.2612 - val_accuracy: 0.9370 - val_recall: 0.9766 - val_auc: 0.9659\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.1307 - accuracy: 0.9528 - recall: 0.9700 - auc: 0.9854 - val_loss: 13.4125 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.4978\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0964 - accuracy: 0.9629 - recall: 0.9773 - auc: 0.9916 - val_loss: 1.0012 - val_accuracy: 0.7887 - val_recall: 0.9971 - val_auc: 0.8696\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0973 - accuracy: 0.9624 - recall: 0.9795 - auc: 0.9922 - val_loss: 0.9859 - val_accuracy: 0.7545 - val_recall: 1.0000 - val_auc: 0.8971\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0972 - accuracy: 0.9629 - recall: 0.9773 - auc: 0.9911 - val_loss: 0.7686 - val_accuracy: 0.7599 - val_recall: 1.0000 - val_auc: 0.9351\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0811 - accuracy: 0.9669 - recall: 0.9817 - auc: 0.9935 - val_loss: 0.4606 - val_accuracy: 0.8613 - val_recall: 0.9971 - val_auc: 0.9534\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0776 - accuracy: 0.9720 - recall: 0.9854 - auc: 0.9946 - val_loss: 0.1973 - val_accuracy: 0.9413 - val_recall: 0.9547 - val_auc: 0.9744\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0747 - accuracy: 0.9709 - recall: 0.9839 - auc: 0.9955 - val_loss: 0.2845 - val_accuracy: 0.9018 - val_recall: 0.9868 - val_auc: 0.9656\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.0623 - accuracy: 0.9805 - recall: 0.9901 - auc: 0.9955 - val_loss: 0.7852 - val_accuracy: 0.7972 - val_recall: 0.9971 - val_auc: 0.8870\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 287s 5s/step - loss: 0.0657 - accuracy: 0.9728 - recall: 0.9835 - auc: 0.9966 - val_loss: 0.1859 - val_accuracy: 0.9424 - val_recall: 0.9810 - val_auc: 0.9781\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.0533 - accuracy: 0.9786 - recall: 0.9883 - auc: 0.9973 - val_loss: 0.1721 - val_accuracy: 0.9477 - val_recall: 0.9444 - val_auc: 0.9874\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0742 - accuracy: 0.9701 - recall: 0.9817 - auc: 0.9954 - val_loss: 0.3639 - val_accuracy: 0.8997 - val_recall: 0.9503 - val_auc: 0.9427\n",
      "        loss  accuracy    recall       auc   val_loss  val_accuracy  \\\n",
      "0   1.219466  0.844142  0.891368  0.860555   3.010973      0.727855   \n",
      "1   0.262456  0.900987  0.935625  0.949667   0.303990      0.852721   \n",
      "2   0.221841  0.917801  0.947696  0.960851   0.327843      0.846318   \n",
      "3   0.178066  0.933814  0.957571  0.973774   3.315175      0.729989   \n",
      "4   0.151997  0.939685  0.961960  0.980330   5.125693      0.729989   \n",
      "5   0.156436  0.938084  0.957206  0.979804   2.545287      0.729989   \n",
      "6   0.142944  0.946357  0.965618  0.981792   1.445759      0.732124   \n",
      "7   0.111854  0.957299  0.973299  0.988461   2.933001      0.729989   \n",
      "8   0.125614  0.953830  0.968910  0.985554   0.261151      0.937033   \n",
      "9   0.130655  0.952762  0.970007  0.985370  13.412493      0.727855   \n",
      "10  0.096364  0.962904  0.977323  0.991619   1.001171      0.788687   \n",
      "11  0.097321  0.962370  0.979517  0.992220   0.985885      0.754536   \n",
      "12  0.097188  0.962904  0.977323  0.991147   0.768603      0.759872   \n",
      "13  0.081065  0.966907  0.981712  0.993450   0.460594      0.861259   \n",
      "14  0.077576  0.971978  0.985369  0.994556   0.197306      0.941302   \n",
      "15  0.074703  0.970910  0.983906  0.995523   0.284507      0.901814   \n",
      "16  0.062346  0.980518  0.990124  0.995483   0.785167      0.797225   \n",
      "17  0.065721  0.972778  0.983541  0.996609   0.185927      0.942369   \n",
      "18  0.053316  0.978650  0.988296  0.997284   0.172110      0.947705   \n",
      "19  0.074152  0.970109  0.981712  0.995433   0.363917      0.899680   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.511621  \n",
      "1     0.976608  0.952948  \n",
      "2     0.966374  0.930686  \n",
      "3     1.000000  0.503953  \n",
      "4     1.000000  0.500000  \n",
      "5     1.000000  0.549407  \n",
      "6     1.000000  0.769350  \n",
      "7     1.000000  0.500000  \n",
      "8     0.976608  0.965900  \n",
      "9     0.997076  0.497807  \n",
      "10    0.997076  0.869565  \n",
      "11    1.000000  0.897141  \n",
      "12    1.000000  0.935098  \n",
      "13    0.997076  0.953358  \n",
      "14    0.954678  0.974430  \n",
      "15    0.986842  0.965551  \n",
      "16    0.997076  0.886988  \n",
      "17    0.980994  0.978056  \n",
      "18    0.944444  0.987354  \n",
      "19    0.950292  0.942685  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7884\\3893710647.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024.0</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048.0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Loss  Accuracy  Precision  Recall    F1  Specificity  \\\n",
       "Número de neuronas                                                         \n",
       "512.0               0.28      0.92       0.95    0.95  0.95         0.85   \n",
       "1024.0              0.35      0.90       0.96    0.89  0.93         0.90   \n",
       "2048.0              0.38      0.90       0.92    0.95  0.93         0.77   \n",
       "\n",
       "                     fpr   fnr   AUC  \n",
       "Número de neuronas                    \n",
       "512.0               0.15  0.05  0.96  \n",
       "1024.0              0.10  0.11  0.96  \n",
       "2048.0              0.23  0.05  0.95  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neuronas=[512, 1024,2048] #lista con distintos valores de neuronas para probar AÑADIR 2048\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=64\n",
    "\n",
    "tabla_num_neuronas=neuronas(num_neuronas, epochs, ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e98ac-0296-45a0-b67f-8d80e41069d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_num_neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c20075f9-46b1-4e9d-8286-ecb5f48e1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac596e0-9565-4de5-8def-5e3aedc17b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa0689-f87a-47b4-85cb-03fa1d59eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b48cb3f-7e05-4106-8555-daf0dde2a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple3 AlexNet\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes.\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    \n",
    "    \n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) #hacer grafica val y train para auc o loss\n",
    "\n",
    "        #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "        nombre_archivo = f'historico_{neurona}.csv' #se define el nombre que van a tener cada uno de los dataframes donde esta el historico\n",
    "        ruta_historico = os.path.join('C:/Users/nuria/Downloads/TFG', 'historico_3_64') #se guarda dentro de una nueva carpeta denominada 'historico_2_64'\n",
    "        # Crea la carpeta 'historico_3_64' si no existe\n",
    "        os.makedirs(ruta_historico, exist_ok=True)\n",
    "        ruta_archivo = os.path.join(ruta_historico, nombre_archivo)\n",
    "        historico.to_csv(ruta_archivo, index=False)\n",
    "        \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    #compara_neuronas_def['Número de neuronas'] = compara_neuronas_def['Número de neuronas'].astype(int) #para convertr la columna Numero neuronas a entero y no aparezca como decimales\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles o poner lo que esta comentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ae0dd62-ee02-48af-af94-827756ce2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Modelo con 512 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 236s 4s/step - loss: 0.4708 - accuracy: 0.8369 - recall: 0.9012 - auc: 0.8748 - val_loss: 1.1573 - val_accuracy: 0.3479 - val_recall: 0.1082 - val_auc: 0.9242\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 253s 4s/step - loss: 0.2688 - accuracy: 0.9053 - recall: 0.9334 - auc: 0.9460 - val_loss: 0.2655 - val_accuracy: 0.8922 - val_recall: 0.9708 - val_auc: 0.9575\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 254s 4s/step - loss: 0.1934 - accuracy: 0.9287 - recall: 0.9543 - auc: 0.9692 - val_loss: 0.7621 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.9304\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.1856 - accuracy: 0.9293 - recall: 0.9535 - auc: 0.9731 - val_loss: 0.6683 - val_accuracy: 0.7631 - val_recall: 1.0000 - val_auc: 0.9551\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1489 - accuracy: 0.9453 - recall: 0.9642 - auc: 0.9807 - val_loss: 0.3856 - val_accuracy: 0.8250 - val_recall: 0.9985 - val_auc: 0.9679\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.1421 - accuracy: 0.9458 - recall: 0.9663 - auc: 0.9835 - val_loss: 1.9012 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5381\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.1246 - accuracy: 0.9565 - recall: 0.9737 - auc: 0.9863 - val_loss: 0.2458 - val_accuracy: 0.9007 - val_recall: 0.9795 - val_auc: 0.9670\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1235 - accuracy: 0.9522 - recall: 0.9674 - auc: 0.9865 - val_loss: 0.1513 - val_accuracy: 0.9520 - val_recall: 0.9605 - val_auc: 0.9824\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1119 - accuracy: 0.9589 - recall: 0.9766 - auc: 0.9880 - val_loss: 0.1910 - val_accuracy: 0.9285 - val_recall: 0.9854 - val_auc: 0.9790\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1036 - accuracy: 0.9610 - recall: 0.9792 - auc: 0.9897 - val_loss: 0.1171 - val_accuracy: 0.9605 - val_recall: 0.9839 - val_auc: 0.9901\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0866 - accuracy: 0.9672 - recall: 0.9795 - auc: 0.9926 - val_loss: 0.2581 - val_accuracy: 0.8922 - val_recall: 0.9942 - val_auc: 0.9783\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0764 - accuracy: 0.9744 - recall: 0.9865 - auc: 0.9940 - val_loss: 0.1593 - val_accuracy: 0.9594 - val_recall: 0.9605 - val_auc: 0.9872\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0747 - accuracy: 0.9736 - recall: 0.9861 - auc: 0.9947 - val_loss: 0.1557 - val_accuracy: 0.9552 - val_recall: 0.9649 - val_auc: 0.9862\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0800 - accuracy: 0.9701 - recall: 0.9846 - auc: 0.9939 - val_loss: 0.3722 - val_accuracy: 0.8613 - val_recall: 0.9971 - val_auc: 0.9718\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0805 - accuracy: 0.9693 - recall: 0.9828 - auc: 0.9944 - val_loss: 0.1525 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9816\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0596 - accuracy: 0.9805 - recall: 0.9912 - auc: 0.9963 - val_loss: 0.8410 - val_accuracy: 0.8122 - val_recall: 0.9985 - val_auc: 0.8674\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0563 - accuracy: 0.9800 - recall: 0.9909 - auc: 0.9967 - val_loss: 0.1168 - val_accuracy: 0.9594 - val_recall: 0.9781 - val_auc: 0.9888\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0674 - accuracy: 0.9757 - recall: 0.9868 - auc: 0.9957 - val_loss: 0.2095 - val_accuracy: 0.9317 - val_recall: 0.9751 - val_auc: 0.9741\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0667 - accuracy: 0.9765 - recall: 0.9890 - auc: 0.9945 - val_loss: 0.3822 - val_accuracy: 0.8975 - val_recall: 0.9620 - val_auc: 0.9444\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0556 - accuracy: 0.9811 - recall: 0.9905 - auc: 0.9966 - val_loss: 0.2266 - val_accuracy: 0.9434 - val_recall: 0.9868 - val_auc: 0.9721\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.470828  0.836936  0.901244  0.874808  1.157280      0.347919   \n",
      "1   0.268767  0.905258  0.933431  0.945997  0.265501      0.892209   \n",
      "2   0.193384  0.928743  0.954279  0.969249  0.762084      0.758805   \n",
      "3   0.185574  0.929277  0.953548  0.973085  0.668329      0.763074   \n",
      "4   0.148860  0.945290  0.964155  0.980655  0.385554      0.824973   \n",
      "5   0.142095  0.945823  0.966350  0.983549  1.901228      0.729989   \n",
      "6   0.124650  0.956499  0.973665  0.986325  0.245778      0.900747   \n",
      "7   0.123502  0.952228  0.967447  0.986522  0.151268      0.951974   \n",
      "8   0.111935  0.958900  0.976591  0.987993  0.191036      0.928495   \n",
      "9   0.103572  0.961035  0.979151  0.989683  0.117100      0.960512   \n",
      "10  0.086598  0.967174  0.979517  0.992575  0.258088      0.892209   \n",
      "11  0.076367  0.974379  0.986467  0.993997  0.159292      0.959445   \n",
      "12  0.074654  0.973579  0.986101  0.994724  0.155718      0.955176   \n",
      "13  0.080011  0.970109  0.984638  0.993859  0.372215      0.861259   \n",
      "14  0.080460  0.969309  0.982809  0.994400  0.152473      0.940235   \n",
      "15  0.059585  0.980518  0.991222  0.996311  0.841036      0.812167   \n",
      "16  0.056290  0.979984  0.990856  0.996746  0.116838      0.959445   \n",
      "17  0.067434  0.975714  0.986832  0.995666  0.209484      0.931697   \n",
      "18  0.066709  0.976515  0.989027  0.994548  0.382179      0.897545   \n",
      "19  0.055586  0.981052  0.990490  0.996636  0.226607      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.108187  0.924231  \n",
      "1     0.970760  0.957498  \n",
      "2     1.000000  0.930411  \n",
      "3     1.000000  0.955077  \n",
      "4     0.998538  0.967859  \n",
      "5     1.000000  0.538098  \n",
      "6     0.979532  0.967030  \n",
      "7     0.960526  0.982364  \n",
      "8     0.985380  0.979029  \n",
      "9     0.983918  0.990113  \n",
      "10    0.994152  0.978293  \n",
      "11    0.960526  0.987221  \n",
      "12    0.964912  0.986198  \n",
      "13    0.997076  0.971792  \n",
      "14    0.961988  0.981610  \n",
      "15    0.998538  0.867364  \n",
      "16    0.978070  0.988787  \n",
      "17    0.975146  0.974080  \n",
      "18    0.961988  0.944352  \n",
      "19    0.986842  0.972141  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 1024 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.5301 - accuracy: 0.8281 - recall: 0.8855 - auc: 0.8656 - val_loss: 5.8967 - val_accuracy: 0.2711 - val_recall: 0.0015 - val_auc: 0.5456\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.2641 - accuracy: 0.9031 - recall: 0.9349 - auc: 0.9469 - val_loss: 0.8622 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.9516\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1865 - accuracy: 0.9285 - recall: 0.9568 - auc: 0.9718 - val_loss: 1.1636 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8607\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1749 - accuracy: 0.9338 - recall: 0.9583 - auc: 0.9733 - val_loss: 1.4292 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7482\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.1361 - accuracy: 0.9477 - recall: 0.9653 - auc: 0.9843 - val_loss: 0.3373 - val_accuracy: 0.8623 - val_recall: 0.8246 - val_auc: 0.9707\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1439 - accuracy: 0.9453 - recall: 0.9671 - auc: 0.9827 - val_loss: 0.7290 - val_accuracy: 0.7567 - val_recall: 1.0000 - val_auc: 0.9397\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.1143 - accuracy: 0.9576 - recall: 0.9773 - auc: 0.9882 - val_loss: 2.4738 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1063 - accuracy: 0.9632 - recall: 0.9792 - auc: 0.9876 - val_loss: 1.7107 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.6046\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1125 - accuracy: 0.9586 - recall: 0.9748 - auc: 0.9880 - val_loss: 1.2680 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8469\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0954 - accuracy: 0.9680 - recall: 0.9813 - auc: 0.9905 - val_loss: 0.9401 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8550\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0880 - accuracy: 0.9690 - recall: 0.9846 - auc: 0.9914 - val_loss: 1.7370 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.5945\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0997 - accuracy: 0.9602 - recall: 0.9762 - auc: 0.9902 - val_loss: 0.3943 - val_accuracy: 0.8292 - val_recall: 0.9956 - val_auc: 0.9600\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0934 - accuracy: 0.9629 - recall: 0.9795 - auc: 0.9921 - val_loss: 0.4291 - val_accuracy: 0.8047 - val_recall: 1.0000 - val_auc: 0.9734\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0772 - accuracy: 0.9709 - recall: 0.9839 - auc: 0.9948 - val_loss: 0.1356 - val_accuracy: 0.9584 - val_recall: 0.9766 - val_auc: 0.9847\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0694 - accuracy: 0.9744 - recall: 0.9868 - auc: 0.9954 - val_loss: 0.3344 - val_accuracy: 0.8388 - val_recall: 0.9912 - val_auc: 0.9498\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0733 - accuracy: 0.9738 - recall: 0.9846 - auc: 0.9942 - val_loss: 1.1044 - val_accuracy: 0.7588 - val_recall: 1.0000 - val_auc: 0.8399\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0697 - accuracy: 0.9736 - recall: 0.9857 - auc: 0.9951 - val_loss: 0.1750 - val_accuracy: 0.9562 - val_recall: 0.9839 - val_auc: 0.9738\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0632 - accuracy: 0.9746 - recall: 0.9865 - auc: 0.9962 - val_loss: 0.1513 - val_accuracy: 0.9530 - val_recall: 0.9868 - val_auc: 0.9826\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0527 - accuracy: 0.9808 - recall: 0.9898 - auc: 0.9972 - val_loss: 0.2002 - val_accuracy: 0.9541 - val_recall: 0.9693 - val_auc: 0.9797\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0587 - accuracy: 0.9803 - recall: 0.9898 - auc: 0.9947 - val_loss: 0.1965 - val_accuracy: 0.9488 - val_recall: 0.9883 - val_auc: 0.9723\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.530102  0.828129  0.885516  0.865639  5.896713      0.271078   \n",
      "1   0.264127  0.903122  0.934894  0.946945  0.862186      0.729989   \n",
      "2   0.186493  0.928476  0.956840  0.971797  1.163648      0.731057   \n",
      "3   0.174923  0.933814  0.958303  0.973281  1.429186      0.729989   \n",
      "4   0.136135  0.947692  0.965252  0.984316  0.337250      0.862327   \n",
      "5   0.143866  0.945290  0.967081  0.982671  0.729039      0.756670   \n",
      "6   0.114251  0.957566  0.977323  0.988234  2.473793      0.729989   \n",
      "7   0.106278  0.963171  0.979151  0.987550  1.710713      0.731057   \n",
      "8   0.112528  0.958634  0.974762  0.987960  1.267959      0.731057   \n",
      "9   0.095442  0.967974  0.981346  0.990518  0.940124      0.731057   \n",
      "10  0.088009  0.969042  0.984638  0.991386  1.736952      0.731057   \n",
      "11  0.099682  0.960235  0.976225  0.990185  0.394298      0.829242   \n",
      "12  0.093394  0.962904  0.979517  0.992123  0.429072      0.804696   \n",
      "13  0.077160  0.970910  0.983906  0.994760  0.135580      0.958378   \n",
      "14  0.069383  0.974379  0.986832  0.995390  0.334371      0.838847   \n",
      "15  0.073321  0.973846  0.984638  0.994208  1.104434      0.758805   \n",
      "16  0.069680  0.973579  0.985735  0.995136  0.175011      0.956243   \n",
      "17  0.063173  0.974646  0.986467  0.996205  0.151286      0.953042   \n",
      "18  0.052656  0.980785  0.989759  0.997165  0.200240      0.954109   \n",
      "19  0.058719  0.980251  0.989759  0.994701  0.196542      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.001462  0.545648  \n",
      "1     1.000000  0.951584  \n",
      "2     1.000000  0.860655  \n",
      "3     1.000000  0.748186  \n",
      "4     0.824561  0.970691  \n",
      "5     1.000000  0.939654  \n",
      "6     1.000000  0.500000  \n",
      "7     1.000000  0.604573  \n",
      "8     1.000000  0.846896  \n",
      "9     1.000000  0.854957  \n",
      "10    1.000000  0.594477  \n",
      "11    0.995614  0.959951  \n",
      "12    1.000000  0.973387  \n",
      "13    0.976608  0.984744  \n",
      "14    0.991228  0.949810  \n",
      "15    1.000000  0.839872  \n",
      "16    0.983918  0.973800  \n",
      "17    0.986842  0.982650  \n",
      "18    0.969298  0.979734  \n",
      "19    0.988304  0.972323  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 2048 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.9212 - accuracy: 0.8289 - recall: 0.8877 - auc: 0.8543 - val_loss: 4.6468 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.4985\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.2409 - accuracy: 0.9018 - recall: 0.9305 - auc: 0.9537 - val_loss: 0.5688 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.9357\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.2029 - accuracy: 0.9239 - recall: 0.9481 - auc: 0.9670 - val_loss: 0.6861 - val_accuracy: 0.7343 - val_recall: 1.0000 - val_auc: 0.9486\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.1818 - accuracy: 0.9290 - recall: 0.9532 - auc: 0.9738 - val_loss: 0.2740 - val_accuracy: 0.8847 - val_recall: 0.9795 - val_auc: 0.9570\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.1698 - accuracy: 0.9346 - recall: 0.9565 - auc: 0.9755 - val_loss: 1.0614 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.8582\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1431 - accuracy: 0.9445 - recall: 0.9638 - auc: 0.9830 - val_loss: 2.0808 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5319\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1604 - accuracy: 0.9400 - recall: 0.9609 - auc: 0.9783 - val_loss: 2.2693 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5190\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.1317 - accuracy: 0.9509 - recall: 0.9715 - auc: 0.9847 - val_loss: 1.2488 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7833\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1252 - accuracy: 0.9565 - recall: 0.9715 - auc: 0.9846 - val_loss: 0.6132 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8771\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.1229 - accuracy: 0.9525 - recall: 0.9704 - auc: 0.9863 - val_loss: 1.8817 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5025\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0980 - accuracy: 0.9656 - recall: 0.9813 - auc: 0.9912 - val_loss: 0.6300 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.9478\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0959 - accuracy: 0.9640 - recall: 0.9777 - auc: 0.9917 - val_loss: 1.1068 - val_accuracy: 0.7449 - val_recall: 1.0000 - val_auc: 0.8532\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.0923 - accuracy: 0.9640 - recall: 0.9802 - auc: 0.9916 - val_loss: 0.3008 - val_accuracy: 0.8495 - val_recall: 0.9912 - val_auc: 0.9710\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0809 - accuracy: 0.9701 - recall: 0.9810 - auc: 0.9923 - val_loss: 0.1871 - val_accuracy: 0.9338 - val_recall: 0.9693 - val_auc: 0.9712\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0700 - accuracy: 0.9744 - recall: 0.9872 - auc: 0.9955 - val_loss: 0.3745 - val_accuracy: 0.8655 - val_recall: 0.9971 - val_auc: 0.9584\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.0721 - accuracy: 0.9736 - recall: 0.9832 - auc: 0.9952 - val_loss: 0.1329 - val_accuracy: 0.9498 - val_recall: 0.9576 - val_auc: 0.9862\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0750 - accuracy: 0.9722 - recall: 0.9824 - auc: 0.9943 - val_loss: 0.4313 - val_accuracy: 0.7930 - val_recall: 0.9868 - val_auc: 0.9004\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.0575 - accuracy: 0.9792 - recall: 0.9883 - auc: 0.9961 - val_loss: 0.1524 - val_accuracy: 0.9413 - val_recall: 0.9649 - val_auc: 0.9806\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.0591 - accuracy: 0.9762 - recall: 0.9854 - auc: 0.9966 - val_loss: 0.4328 - val_accuracy: 0.9168 - val_recall: 0.9693 - val_auc: 0.9352\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0736 - accuracy: 0.9765 - recall: 0.9876 - auc: 0.9936 - val_loss: 0.1996 - val_accuracy: 0.9072 - val_recall: 0.9488 - val_auc: 0.9689\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.921205  0.828930  0.887710  0.854262  4.646806      0.729989   \n",
      "1   0.240912  0.901788  0.930505  0.953665  0.568845      0.737460   \n",
      "2   0.202896  0.923939  0.948061  0.966983  0.686120      0.734258   \n",
      "3   0.181832  0.929010  0.953182  0.973821  0.274046      0.884739   \n",
      "4   0.169791  0.934614  0.956474  0.975460  1.061414      0.735326   \n",
      "5   0.143069  0.944489  0.963789  0.983046  2.080767      0.729989   \n",
      "6   0.160447  0.939952  0.960863  0.978260  2.269310      0.729989   \n",
      "7   0.131745  0.950894  0.971470  0.984691  1.248754      0.729989   \n",
      "8   0.125241  0.956499  0.971470  0.984617  0.613244      0.729989   \n",
      "9   0.122868  0.952495  0.970373  0.986344  1.881663      0.729989   \n",
      "10  0.098003  0.965572  0.981346  0.991235  0.629963      0.735326   \n",
      "11  0.095867  0.963971  0.977688  0.991651  1.106832      0.744931   \n",
      "12  0.092287  0.963971  0.980249  0.991591  0.300815      0.849520   \n",
      "13  0.080886  0.970109  0.980980  0.992299  0.187149      0.933831   \n",
      "14  0.070016  0.974379  0.987198  0.995455  0.374477      0.865528   \n",
      "15  0.072095  0.973579  0.983175  0.995170  0.132929      0.949840   \n",
      "16  0.075025  0.972244  0.982443  0.994339  0.431314      0.792956   \n",
      "17  0.057452  0.979183  0.988296  0.996089  0.152395      0.941302   \n",
      "18  0.059068  0.976248  0.985369  0.996650  0.432823      0.916756   \n",
      "19  0.073602  0.976515  0.987564  0.993619  0.199598      0.907151   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.498538  \n",
      "1     1.000000  0.935678  \n",
      "2     1.000000  0.948619  \n",
      "3     0.979532  0.956967  \n",
      "4     1.000000  0.858178  \n",
      "5     1.000000  0.531933  \n",
      "6     1.000000  0.519009  \n",
      "7     1.000000  0.783273  \n",
      "8     1.000000  0.877106  \n",
      "9     1.000000  0.502496  \n",
      "10    1.000000  0.947790  \n",
      "11    1.000000  0.853186  \n",
      "12    0.991228  0.970951  \n",
      "13    0.969298  0.971182  \n",
      "14    0.997076  0.958420  \n",
      "15    0.957602  0.986152  \n",
      "16    0.986842  0.900354  \n",
      "17    0.964912  0.980610  \n",
      "18    0.969298  0.935199  \n",
      "19    0.948830  0.968905  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_17232\\1052732601.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=64\n",
    "\n",
    "table_neuronas_simple3_64 = neuronas(num_neuronas, epochs, ruta, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc46c5b-93f0-48ca-8bbc-365df29d7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024.0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048.0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Loss  Accuracy  Precision  Recall    F1  Specificity  \\\n",
       "Número de neuronas                                                         \n",
       "512.0               0.15      0.95       0.95    0.98  0.96         0.86   \n",
       "1024.0              0.23      0.94       0.93    0.99  0.96         0.81   \n",
       "2048.0              0.20      0.91       0.93    0.95  0.94         0.79   \n",
       "\n",
       "                     fpr   fnr   AUC  \n",
       "Número de neuronas                    \n",
       "512.0               0.14  0.02  0.98  \n",
       "1024.0              0.19  0.01  0.99  \n",
       "2048.0              0.21  0.05  0.97  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_neuronas_simple3_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805272e-818a-4e2e-bc63-adf2509d6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciona mejor con simle 3 batch size 64 y 100 neuronas en la primera capa y 16 en la segunda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa1344-69d6-4800-8201-9fa62b2be003",
   "metadata": {},
   "source": [
    "Por lo tanto, se puede apreciar que, el mejor modelo se corresponde con 64 neuronas en la capa oculta ya que, \n",
    "tiene un valor mayor en la gran parte de métricas (aunque en loss deberia ser menor) CAMBIAR EN CASO NECESARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700f86e-79e7-4849-9ae5-ed2561c7baa5",
   "metadata": {},
   "source": [
    "## Visualización por medio de una gráfica de la evolución tanto en accuracy como en loss en el entrenamiento y la validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab157af6-1b68-47d2-a051-1bcfe7ddecd8",
   "metadata": {},
   "source": [
    "En cada una de las funciones realizadas previamente donde se comparaban distintos modelos de CNN, distintas arquitecturas y distintos hiperparámetros, se han guardado en distintos csv los valores obtenidos del entrenamiento y validación (loss, accuracy, recall, auc, val_loss, val_accuracy, val_recall y val_auc). A partir de estos csv, se ha realizado una función para crear una cráfica con la columna loss y val_loss o auc y val_auc para visualizar el rendimiento del modelo a lo largo de tiempo tanto el de entrenamiento como el de validación. Con estas gráficas se puede observar si el modelo está aprendiendo correctamente o, por el contrario existe sobreajuste o subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cda88-63ee-4881-8a97-d15b3ada9661",
   "metadata": {},
   "source": [
    "#PARA LA MEMORIA\n",
    "#### Loss:\n",
    "- loss: mide el error del modelo en el conjunto de entrenameinto\n",
    "- val_loss: mide el error del modelo en el conjunto de validación\n",
    "\n",
    "Si ambas líneas descienden y se estabilizan, indica que el modelo está aprendiendo correctamente.\n",
    "Si la pérdida de validación empieza a aumentar mientras la pérdida de entrenamiento sigue disminuyendo, puede indicar sobreajuste.\n",
    "Si ambas líneas son altas y no descienden, puede indicar subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e6803-9c06-4784-874e-2829b14996b0",
   "metadata": {},
   "source": [
    "#### AUC\n",
    "- auc: mide la capacidad del modelo para distinguir entre clases (un valor mayor indica un mejor modelo)\n",
    "- val_auc: mide la capacidad del modelo para distinguir entre clases en el conjunto de validación (un valor mayor indica un mejor modelo)\n",
    "\n",
    "Si ambas líneas ascienden y se estabilizan en valores altos, indica un buen rendimiento del modelo.\n",
    "Si el AUC de validación disminuye mientras el AUC de entrenamiento sigue aumentando, puede indicar sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16c78584-3367-4376-aa81-6901cd088c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFICAR / COMPROBAR QUE FUNCIONA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grafica(directorio_historico, metrica_entrenamiento, metrica_validacion):\n",
    "\n",
    "    '''\n",
    "    Función empleada para crear una gráfica a partir de uno de los csv creados previamente para observar la evolución de dos métricas \n",
    "    (loss o auc generalment) durante el entrenamiento y la validación del modelo, lo cual es útil para evaluar el rendimiento \n",
    "    del modelo a lo largo de las épocas.\n",
    "    -----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_historico: directorio donde se encuentra el csv del que se desea obtener las gráficas.\n",
    "    - metrica_entrenamiento: metrica monitoreada durante el entrenamiento que se desea visualizar (loss o auc)\n",
    "    - metrica_validacion: metrica monitoreada durante la validación que se desea visualizar (loss o auc)\n",
    "    --------------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    # Se cargan los datos desde el archivo CSV\n",
    "    df_mejor = pd.read_csv(directorio_historico) \n",
    "    \n",
    "    \n",
    "    # 'columna1' y 'columna2' son los nombres de las columnas que se van a graficar\n",
    "    columna1 = df_mejor[metrica_entrenamiento]\n",
    "    columna2 = df_mejor[metrica_validacion]\n",
    "    \n",
    "    # Se crea la gráfica para las dos columnas\n",
    "    plt.plot(columna1, label='Entrenamiento')\n",
    "    plt.plot(columna2, label='Validación')\n",
    "    \n",
    "    # Se añaden etiquetas del eje x, el eje y y el título de la gráfica\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss/auc') \n",
    "    plt.title('Gráfico evolución entrenamiento y validación')\n",
    "    \n",
    "    # Se añade la leyenda\n",
    "    plt.legend()\n",
    "    \n",
    "    # Se muestra la gráfica\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec538d6-0371-4d78-b4d5-f945f55bba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directorio_historico = 'C:/Users/nuria/Downloads/TFG/historico_alexnet_arqu_batchsize/hist_anet_Simple3_64.csv' #cambiar directorio en caso que se emplee otro csv\n",
    "metrica_entrenamiento = 'auc' #o loss según cual se emplee\n",
    "metrica_validacion = 'val_auc' #o loss según cual se emplee\n",
    "\n",
    "graf_mejor_modelo=grafica(directorio_historico, metrica_entrenamiento, metrica_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26e038-f31c-4f89-9369-5744bb4d8e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0861be5-63bc-4386-83a9-bd839eb78501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec70ad44-41bf-4c21-897f-5dfa8f83fe0d",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como funciona el modelo elegido finalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0aa3-f29f-4b6a-bd79-4aec32a7e8dd",
   "metadata": {},
   "source": [
    "Finalmente, se obtiene la matriz de confusión para el modelo final obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215b28e-359b-45d2-9bd3-07a0919a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMBIAR TODO LO QUE HAY A CONTINUACION POR EL MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4a642-c3d4-4064-a4b0-0e2b18044a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batchsize=20\n",
    "preparar_modelo(ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab559147-c68c-4bdf-8678-466cbdc88038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se trabaja con el modelo simple1\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "model = keras.Sequential( #funcion establecer arquitectura(simple...)\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        #se necesitan mas capas\n",
    "        layers.Dropout(0.5), #probar otros valores (este es muy alto)\n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurina, sigmoide\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746296f1-e216-486d-aabd-80d626ac8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009464a-c8a2-4e3a-a033-0b0aa6465ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ad034-109d-42ea-84b4-950095a5bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAL, CAMBIAR\n",
    "y_pred=y_pred>0.5 #para convertirlo en un problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00f04a-bdf6-458f-b926-3a6ff26d7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión con sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd24bd6-2635-472a-b10e-facbf5705f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d5d03-8012-46fe-bac0-d9e7cff004d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON SKLEARN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"neumonía\" , \"no neumonía\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión neumonía-no neumonía\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82d04a-c14b-4970-bc4c-f5c2924c6baf",
   "metadata": {},
   "source": [
    "Se puede comprobar como han mejorado los resultados respecto al modelo más simple ya que..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115865-dddc-4ec1-bb3a-efa3419117a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b2ecb-81e3-40a9-9fcb-eec582cd18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARTICULO METIDO EN EL RESUMEN DE LA MEMORIA\n",
    "#https://www.sciencedirect.com/science/article/pii/S001048252030247X?via%3Dihub#bib1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
