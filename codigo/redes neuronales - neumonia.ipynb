{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7176c0-5ed5-4850-a27a-b820414ff96d",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"40%\" src=\"pics/Universidad Burgos.png\">\n",
    "<img style=\"float:right\" width=\"16%\" src=\"pics/person1_bacteria_2.jpeg\">\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Trabajo Fin de Grado\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">NOMBRE TFG</h2>\n",
    "\n",
    "### Nuria Martínez Queralt\n",
    "\n",
    "### Grado en Ingeniería de la Salud \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33e68c-4e8b-4305-91c2-cff54089bbf4",
   "metadata": {},
   "source": [
    "En este notebook se han llevado a cabo una serie de tareas para la realización del TFG, el cual consiste en la identificación de neumonía a partir de radiografías de tórax empleando una red neuronal. Para esto, se deben probar distintos modelos hasta llegar al modelo más optimo de red neuronal para este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296a9ed-5af7-4b30-91c5-7015aefef326",
   "metadata": {},
   "source": [
    "## Redistribución de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1466b-002c-4d9e-8c11-fe752738fabe",
   "metadata": {},
   "source": [
    "Debido a que la distribución inicial obtenida a partir del dataset descargado de internet: \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\" incluye únicamente 16 imágenes en la carpeta de validación (\"val\") y, esto supone problemas para la obtención de buenos resultados a la hora de construir nuestra red neuronal, antes de empezar a trabajar con las imágenes, se debe crear una función para obtener un nuevo dataset con nuevas carpetas \"train\", \"test\" y \"val\" y una nueva distribución de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607cb8f4-f897-4551-a114-31b2c1dcf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def buscar_imagen(directorio_padre, nombre_imagen):\n",
    "    '''\n",
    "    Función empleada para encontrar una imagen concreta (a partir de su nombre) dentro de cualquiera de las subcarpetas del directorio_padre.\n",
    "    ---------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_padre: ruta donde se encuentra la carpeta cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    - nombre_imagen: nombre de la imágen a la que se desea acceder \n",
    "    ----------------------------------------------------------\n",
    "    Return:\n",
    "    - ruta_imagen: ruta completa de la imágen a la que se desea acceder \n",
    "    '''\n",
    "    # Subcarpetas principales en las que buscar\n",
    "    subcarpetas_principales = ['train', 'test', 'val']\n",
    "    # Subcarpetas adicionales en las que buscar dentro de cada subcarpeta principal\n",
    "    subcarpetas_adicionales = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Se itera sobre las subcarpetas principales\n",
    "    for subcarpeta_principal in subcarpetas_principales:\n",
    "        # Se itera sobre las subcarpetas adicionales dentro de cada subcarpeta principal\n",
    "        for subcarpeta_adicional in subcarpetas_adicionales:\n",
    "            # Se obtiene la ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(directorio_padre, subcarpeta_principal, subcarpeta_adicional, nombre_imagen)\n",
    "            # verificar si la imagen existe en la subcarpeta actual\n",
    "            if os.path.exists(ruta_imagen):\n",
    "                return ruta_imagen  # devolver la ruta de la imagen si se encuentra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f2df1-fbcf-46be-bc11-a7a80fd7b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def redestribucion_imagenes(directorio_principal):\n",
    "\n",
    "    '''\n",
    "    Función empleada para redestribuir las imágenes ubicadas en distintas subcarpetas dentro de la carpeta data en una carpeta nueva con las\n",
    "    mismas subcarpetas pero con un porcentaje distinto de imágenes en cada subcarpeta. La distribución quedaría de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    De igual forma, la distribución de las carpetas \"PNEUMONIA\" y \"NORMAL\" también queda de forma proporcional.\n",
    "    --------------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_principal: ruta donde se encuentra la carpeta data con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    -------------------------------------------------------------------\n",
    "    Return: \n",
    "    - nada\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    En primer lugar, se crea un csv con dos columnas nombres_ficheros y clases compuesto por todas las imágenes existentes en el directorio_padre.\n",
    "    En la columna nombres_ficheros debe aparecer el nombre de TODAS las imágenes que existen dentro de cada subcarpeta y en la columna clases debe \n",
    "    aparecer 0 o 1 en función si se trata de una imagen de la carpeta NORMAL o PNEUMONIA respectivamente.\n",
    "    '''\n",
    "\n",
    "    directorio_padre = os.path.join(directorio_principal, 'data')\n",
    "    \n",
    "    # Listas para almacenar los nombres de las imágenes y las clases (0 o 1 en función de si es normal o neumonía respectivamente)\n",
    "    nombres_ficheros = []\n",
    "    clases = []\n",
    "    \n",
    "    # Recorremos las carpetas de train, test y val\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(directorio_padre, subcarpeta)\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            for nombre_fichero in os.listdir(ruta_clase):\n",
    "                #CREO QUE LA SIGUIENTE LINEA NO HACE FALTA\n",
    "                #if nombre_fichero.endswith(('.png', '.jpg', '.jpeg')):  \n",
    "                nombres_ficheros.append(nombre_fichero)\n",
    "                clases.append(0 if clase == 'NORMAL' else 1)\n",
    "    \n",
    "    # Se crea el DataFrame con los datos\n",
    "    df_todas = pd.DataFrame({'nombre_fichero': nombres_ficheros,'clase': clases})\n",
    "    \n",
    "    # Se guarda el DataFrame en un archivo CSV\n",
    "    ruta_csv = os.path.join(directorio_padre, 'dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    df_todas.to_csv(ruta_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A partir del csv anterior y, con ayuda de la función train_test_split de skitlearn de divide el csv anterior en dos \n",
    "    subgrupos de train y test en proporción 80, 20 para poder usar el 80% de las imágenes para train y el 20% para test.\n",
    "    También se emplea el parámetro stratify para que exista una proporción de clases en cada uno de los grupos, es decir, en ''NORMAL\" y \"PNEUMONIA\".\n",
    "    '''\n",
    "    \n",
    "    # se emplea train_test_split para dividir el dataset en train (80%) y test (20%)\n",
    "    # random_state=42 se emplea para que cada vez que se ejecute el código, se obtenga la misma división de datos. El valor 42 es un valor que se usa\n",
    "    # comunmente en este caso pero se puede emplear cualquie otro valor entero\n",
    "    # stratify se emplea para agrupar de manera proporcional las clases neumonia y normal en los distintos dataframes\n",
    "    train_df, test_df = train_test_split(df_todas, test_size=0.2, stratify=df_todas['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_csv = os.path.join(directorio_padre, 'train_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_test_csv = os.path.join(directorio_padre, 'test_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_df.to_csv(ruta_train_csv, index=False)\n",
    "    test_df.to_csv(ruta_test_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    A continuación, se coge el conjunto de datos obtenido previamente de train, es decir, el csv \"train_df\" y se repite el mismo\n",
    "    proceso pero, esta vez dividiendo este conjunto de datos para train y val en un 80% y 20% respectivamente.\n",
    "    De tal forma que, finalemnte se obtenga el conjunto de test que represeneta el 20% del total (obtenido previamente), el conjunto de train\n",
    "    que representa el 80% del 80% del total ya que, inicialmente nos hemos quedado con el 80% pero luego, de este 80%, el 20% va destinado al conjunto\n",
    "    de validación. Por lo que finalmete quedarías distribuidos de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    '''\n",
    "\n",
    "    # Se emplea train_test_split para dividir el conjunto de datos de entrenamiento en train (80%) y val (20%)\n",
    "    train_def_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "    ruta_train_final_csv = os.path.join(directorio_padre, 'train_final_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    ruta_val_csv = os.path.join(directorio_padre, 'val_dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    train_def_df.to_csv(ruta_train_final_csv, index=False)\n",
    "    val_df.to_csv(ruta_val_csv, index=False)\n",
    "\n",
    "    '''\n",
    "    Finalmente, se crea una nueva carpeta denominada data_nuevo dentro del directorio principal. Dentro de esta carpeta se crean 3 subcarpetas \n",
    "    (\"train\", \"test\" y \"val\") que corresponderian con los dataframes obtenidos hasta hora: train_def_df, val_df y test_df y, dentro de estas 3 \n",
    "    subcarpetas, se crean 2 carpetas \"NORMAL\" y \"PNEUMONIA\" que corresponden con con las clases determinadas en cada dataframe, 0 en caso de \n",
    "    \"NORMAL\" y 1 para \"PNEUMONIA\". Dentro de estas dos carpetas para (\"train\", \"test\" y \"val\") se encontraran las imagenes correspondientes \n",
    "    para cada caso según los dataframes obtenidos.\n",
    "    '''\n",
    "\n",
    "    # Se crea la nueva carpeta dentro del directorio principal\n",
    "    ruta_principal_nueva = os.path.join(directorio_principal, 'data_nuevo') \n",
    "\n",
    "    # Se crean las carpetas 'train', 'test' y 'val' dentro de la nueva carpeta principal\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(ruta_principal_nueva, subcarpeta)\n",
    "        os.makedirs(ruta_subcarpeta, exist_ok=True) #verifica si la carpeta ruta_subcarpeta ya existe. Si existe, no se hace nada y el programa continúa su ejecución sin lanzar un error. Si no existe, la función os.makedirs() la crea junto con cualquier carpeta intermedia necesaria en la ruta especificada\n",
    "        \n",
    "        # Se crean las subcarpetas 'normal' y 'neumonia' dentro de cada subcarpeta ('train', 'test' y 'val')\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            os.makedirs(ruta_clase, exist_ok=True)\n",
    "    \n",
    "                \n",
    "    # Se copian los archivos CSV a las subcarpetas correspondientes\n",
    "    for df, nombre_carpeta in [(train_def_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "        for index, row in df.iterrows(): #se itera sobre cada dataframe fila a fila\n",
    "            clase = 'NORMAL' if row['clase'] == 0 else 'PNEUMONIA'\n",
    "            nombre_archivo = row['nombre_fichero']\n",
    "    \n",
    "            # ruta de origen donde se busca la imagen concreta a partir de la función realizada previamente\n",
    "            # esta ruta se refiere a donde esta que se desea guardar en la carpeta destino originalmente para poder copiarla\n",
    "            ruta_origen=buscar_imagen(directorio_padre, nombre_archivo)\n",
    "            \n",
    "            # ruta donde se desa guardar (y redestribuir de la forma correcta) las imágenes\n",
    "            ruta_destino = os.path.join(ruta_principal_nueva, nombre_carpeta, clase, nombre_archivo)\n",
    "            \n",
    "            shutil.copyfile(ruta_origen, ruta_destino) # copia las imágenes de la ruta incial a la ruta final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371aab4-b02f-4ce2-b902-03be9c426b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_principal = 'C:/Users/nuria/Downloads/TFG' #ruta donde se encuentra la carpeta data en mi caso y donde se va a crear la nueva carpeta data_nuevo\n",
    "redestribucion_imagenes(directorio_principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0b525-b5e3-49f0-91c3-8e13ec14d922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21c6e8-2241-47fc-bce8-cab25bad0891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b24f5-d35e-46e0-b66c-33d4569631bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BORRA TODO LO QUE ESTA A CONTINUACIÓN UNA VEZ SE COMPRUEBE QUE LA FUNCIÓN FUNCIONA CORRECTAMNTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba6e4b-f179-42a1-bcf7-6a4b8a20f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se crea un csv con dos columnas nombres_ficheros y clases. En la columna nombres_ficheros debe aparecer el nombre de TODAS \n",
    "las imágenes que existen dentro de cada subcarpeta y en la columna clases debe aparecer 0 o 1 en función si se trata de una imágenes \n",
    "de una de las carpetas de NORMAL o PNEUMONIA respectivamente\n",
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ruta donde se encuentra el dataset con la distribución inicial descargada de internet\n",
    "directorio_padre='C:/Users/nuria/Downloads/TFG/data'\n",
    "\n",
    "# Listas para almacenar los nombres de las imágenes y las clases (0 o 1 en función de si es normal o neumonía respectivamente)\n",
    "nombres_ficheros = []\n",
    "clases = []\n",
    "\n",
    "# Recorremos las carpetas de train, test y val\n",
    "for subcarpeta in ['train', 'test', 'val']:\n",
    "    ruta_subcarpeta = os.path.join(directorio_padre, subcarpeta)\n",
    "    for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "        ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "        for nombre_fichero in os.listdir(ruta_clase):\n",
    "            #CREO QUE LA SIGUIENTE LINEA NO HACE FALTA\n",
    "            #if nombre_fichero.endswith(('.png', '.jpg', '.jpeg')):  # Puedes ajustar esto a tus extensiones de imagen\n",
    "            nombres_ficheros.append(nombre_fichero)\n",
    "            clases.append(0 if clase == 'NORMAL' else 1)\n",
    "\n",
    "# Se crea el DataFrame con los datos\n",
    "df_todas = pd.DataFrame({'nombre_fichero': nombres_ficheros,'clase': clases})\n",
    "\n",
    "# Se guarda el DataFrame en un archivo CSV\n",
    "ruta_csv = os.path.join(directorio_padre, 'dataset_info.csv')\n",
    "df_todas.to_csv(ruta_csv, index=False)\n",
    "\n",
    "print(f'Archivo CSV guardado en: {ruta_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931e6c9-e9b0-4313-b55f-815240ff2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_todas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ab911-10e1-493d-bf1f-967e5f801fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DENTRO DE LAS CARPETAS PNEUMONIA, SE PUEDE TENER EN CUENTA VIRAL Y BACTERIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdac866-53de-4c70-9bfc-2042441bf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A partir del csv anterior y, con ayuda de la función train_test_split de skitlearn de debe dividir el csv anterior en dos \n",
    "subgrupos de train y test en proporción 80, 20 para poder usar el 80% de las imágenes para train y el 20% para test.\n",
    "También se emplea el parámetro stratify para que también exista una proporción de clases en cada uno de los grupos.\n",
    "Posteriormente se deberá dividir el conjunto de train en 2 para obtener así el subconjunto de validación.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# se emplea train_test_split para dividir el dataset en train (80%) y test (20%)\n",
    "# random_state=42 se emplea para que cada vez que se ejecute el código, se obtenga la misma división de datos. El valor 42 es un valor que se usa\n",
    "# comunmente en este caso pero se puede emplear cualquie otro valor entero\n",
    "# stratify se emplea para agrupar de manera proporcional las clases neumonia y normal en los distintos dataframes\n",
    "train_df, test_df = train_test_split(df_todas, test_size=0.2, stratify=df_todas['clase'], random_state=42)\n",
    "\n",
    "# Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "ruta_train_csv = 'C:/Users/nuria/Downloads/TFG/data/train_dataset_info.csv' #cambiar ruta en caso necesario (lo ultimo es el nombre del nuevo)\n",
    "ruta_test_csv = 'C:/Users/nuria/Downloads/TFG/data/test_dataset_info.csv' #cambiar ruta en caso necesario (lo ultimo es el nombre del nuevo)\n",
    "train_df.to_csv(ruta_train_csv, index=False)\n",
    "test_df.to_csv(ruta_test_csv, index=False)\n",
    "\n",
    "print(f'Archivo CSV de entrenamiento guardado en: {ruta_train_csv}')\n",
    "print(f'Archivo CSV de prueba guardado en: {ruta_test_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4311ac3-8915-405f-bcfb-5b6f3000e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171451c6-6c4e-4d6b-9477-3cb6ae30c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fdd81-31fa-4600-8370-be9579e95ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A continuación, se coge el conjunto de datos obtenido previamente de train, es decir, el csv \"train_df\" y se repite el mismo\n",
    "proceso pero, esta vez dividiendo este conjunto de datos para train y val en un 80% y 20% respectivamente.\n",
    "De tal forma que, finalemnte se obtenga el conjunto de test que represeneta el 20% del total (obtenido previamente), el conjunto de train\n",
    "que representa el 80% del 80% del total ya que, inicialmente nos hemos quedado con el 80% pero luego, de este 80%, el 20% va destinado al conjunto\n",
    "de validación. Por lo que finalmete quedarías distribuidos de la siguiente manera:\n",
    "- test: 20% del total\n",
    "- train: 64% del total\n",
    "- val: 16% del total\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Se emplea train_test_split para dividir el conjunto de datos de entrenamiento en train (80%) y val (20%)\n",
    "train_def_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['clase'], random_state=42)\n",
    "\n",
    "# Se guardan los nuevos conjuntos de datos en archivos CSV\n",
    "ruta_train_final_csv = 'C:/Users/nuria/Downloads/TFG/data/train_final_dataset_info.csv' #cambiar ruta en caso necesario (lo ultimo es el nombre del nuevo)\n",
    "ruta_val_csv = 'C:/Users/nuria/Downloads/TFG/data/val_dataset_info.csv' #cambiar ruta en caso necesario (lo ultimo es el nombre del nuevo)\n",
    "train_def_df.to_csv(ruta_train_final_csv, index=False)\n",
    "val_df.to_csv(ruta_val_csv, index=False)\n",
    "\n",
    "print(f'Archivo CSV de entrenamiento final guardado en: {ruta_train_final_csv}')\n",
    "print(f'Archivo CSV de validación guardado en: {ruta_val_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516a642-8ce8-4240-8762-918355fb33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74986d04-2924-4054-8d07-8cf4937258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a0d44-b744-4609-811e-214b7007ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función para encontrar una imagen concreta (a partir de su nombre) dentro de cualquiera de las subcarpetas\n",
    "Esta función es de gran interés para el apartado que se hace a continuación ya que, para encontrar la ruta_origen de la imagen\n",
    "no se sabe en que carpeta está concretamente y por tanto es necesario acceder a su ruta a partir de esta función\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "def buscar_imagen(directorio_padre, nombre_imagen):\n",
    "    # Subcarpetas principales en las que buscar\n",
    "    subcarpetas_principales = ['train', 'test', 'val']\n",
    "    # Subcarpetas adicionales en las que buscar dentro de cada subcarpeta principal\n",
    "    subcarpetas_adicionales = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Se itera sobre las subcarpetas principales\n",
    "    for subcarpeta_principal in subcarpetas_principales:\n",
    "        # Se itera sobre las subcarpetas adicionales dentro de cada subcarpeta principal\n",
    "        for subcarpeta_adicional in subcarpetas_adicionales:\n",
    "            # Se obtiene la ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(directorio_padre, subcarpeta_principal, subcarpeta_adicional, nombre_imagen)\n",
    "            # verificar si la imagen existe en la subcarpeta actual\n",
    "            if os.path.exists(ruta_imagen):\n",
    "                return ruta_imagen  # devolver la ruta de la imagen si se encuentra\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249f54c-e604-4239-8be9-c44bde2eb53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finalmente, se crea una nueva carpeta denominada data_nuevo, dentro de esta carpeta se crean 3 subcarpetas (\"train\", \"test\" y \"val\")\n",
    "que corresponderian con los dataframes obtenidos hasta hora: train_def_df, val_df y test_df y, dentro de estas 3 subcarpetas, se crean\n",
    "2 carpetas \"NORMAL\" y \"PNEUMONIA\" que corresponden con con las clases determinadas en cada dataframe, 0 en caso de \"NORMAL\" y 1 para \"PNEUMONIA\".\n",
    "Dentro de estas dos carpetas para (\"train\", \"test\" y \"val\") se encontraran las imagenes correspondientes para cada caso según los dataframes obtenidos.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta principal donde se crearán las nuevas carpetas\n",
    "ruta_principal_nueva = 'C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "\n",
    "\n",
    "# Se crean las carpetas 'train', 'test' y 'val' dentro de la carpeta principal\n",
    "for subcarpeta in ['train', 'test', 'val']:\n",
    "    ruta_subcarpeta = os.path.join(ruta_principal_nueva, subcarpeta)\n",
    "    os.makedirs(ruta_subcarpeta, exist_ok=True) #verifica si la carpeta ruta_subcarpeta ya existe. Si existe, no se hace nada y el programa continúa su ejecución sin lanzar un error. Si no existe, la función os.makedirs() la crea junto con cualquier carpeta intermedia necesaria en la ruta especificada\n",
    "    \n",
    "    # Se crean las subcarpetas 'normal' y 'neumonia' dentro de cada subcarpeta ('train', 'test' y 'val')\n",
    "    for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "        ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "        os.makedirs(ruta_clase, exist_ok=True)\n",
    "\n",
    "            \n",
    "# Se copian los archivos CSV a las subcarpetas correspondientes\n",
    "for df, nombre_carpeta in [(train_def_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "    for index, row in df.iterrows(): #se itera sobre cada dataframe fila a fila\n",
    "        clase = 'NORMAL' if row['clase'] == 0 else 'PNEUMONIA'\n",
    "        nombre_archivo = row['nombre_fichero']\n",
    "\n",
    "        # ruta de origen donde se busca la imagen concreta a partir de la función realizada previamente\n",
    "        # esta ruta se refiere a donde esta que se desea guardar en la carpeta destino originalmente para poder copiarla\n",
    "        ruta_origen=buscar_imagen('C:/Users/nuria/Downloads/TFG/data', nombre_archivo)\n",
    "        \n",
    "        # ruta donde se desa guardar (y redestribuir de la forma correcta) las imágenes\n",
    "        ruta_destino = os.path.join(ruta_principal_nueva, nombre_carpeta, clase, nombre_archivo)\n",
    "        \n",
    "        shutil.copyfile(ruta_origen, ruta_destino) # copia las imágenes de la ruta incial a la ruta final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c768dd-149e-48d4-85ef-0dc6bdb9a92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d4338-95ce-4ce4-828a-6fb26d0b3182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9d5cf-a0c2-4962-b808-b1e1cd129ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0b4967-0b21-4bea-a7dd-96dfc0bc0206",
   "metadata": {},
   "source": [
    "A partir de aqui, se va a trabajar con la nueva carpeta de imágenes y su nueva distribución para evitar errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f5be-2c05-498e-88e7-da98e1210f1c",
   "metadata": {},
   "source": [
    "## Preparación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd3214-3749-4449-a6ce-2150370b3359",
   "metadata": {},
   "source": [
    "Se prepara el modelo para poder trabajar con las imágenes de train, test y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f44c95-c38d-4885-a5e7-fe86df3e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/paola311/clasificaci-n-de-im-genes-cnn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def preparar_modelo(ruta, batch_size):\n",
    "\n",
    "    '''\n",
    "    Función que configura los generadores de datos para entrenar, validar y probar un modelo de aprendizaje automático con imágenes.\n",
    "    -----------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    ----------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    dir_general = ruta #ubicacion donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Añadir esta carpeta a one drive en TFG\n",
    "\n",
    "    dir_train = os.path.join(dir_general, 'train')\n",
    "    dir_validation = os.path.join(dir_general, 'val')\n",
    "    dir_test = os.path.join(dir_general, 'test')\n",
    "    \n",
    "    # Preprocesamiento de imágenes\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    #Iterador que recorre el directorio de imágenes\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dir_train,\n",
    "        target_size=(340, 340), #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        class_mode='binary')\n",
    "    \n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        dir_validation,\n",
    "        target_size=(340, 340), #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        class_mode='binary')\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dir_test,\n",
    "        target_size=(340, 340), #cambiar a (150,150) si no se usa como AlexNet\n",
    "        batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "        class_mode='binary')\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2a919-5a84-4a53-94f1-ad964d37c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=20 #ejemplo de batch size\n",
    "\n",
    "train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d31e2-5b84-48e0-add1-06484c34f7d2",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como funciona el modelo más simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edc6db-723d-4830-8618-9e9ac1fe251b",
   "metadata": {},
   "source": [
    "Se obtiene la matriz de confusión para un primer modelo muy simple para, así poder comprobar como estos resultados mejoran al introducir capas ocultas, modificar parámetros..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0d8bc-a780-43f7-afa1-1b4ebfbe668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se trabaja con el modelo más simple (posteriormente denominado Simple1)\n",
    "\n",
    "input_shape=(340,340,3)\n",
    "\n",
    "model = keras.Sequential( \n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5), \n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurona, sigmoide\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad93d8-8ea8-4134-b9ee-436c775e8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 5 épocas (patience)\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499cd3b-fe4e-4a3a-87d7-791e7f119711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920a58c-c342-4cdc-905e-6fb20cc1cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred>0.5 #para convertirlo en un problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81208df-f1dd-43c4-8faf-2e511a32a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión con sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad04e18-b7e3-4eb4-84f9-1c49fc4dd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765b599-fb6c-466a-85f0-69781acfa59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON SKLEARN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"neumonía\" , \"no neumonía\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión neumonía-no neumonía\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b896f-e060-488a-a228-64ba1e0fd5b3",
   "metadata": {},
   "source": [
    "Como se puede observar, los resultados en este primer modelo tan simple, sin ninguna capa oculta, son bastante malos ya que, poniendo esto en un caso clínico real, significaría que 230 pacientes con neumonía hubieran sido diagnosticados como no neumonía y 246 pacientes sin neumonía hubieran sido diagnosticados con neumonía, lo que supondría serios problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5654c9-4f71-4980-9ade-721a48531aec",
   "metadata": {},
   "source": [
    "## Creación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5c91f-3b3e-403c-820b-56c4cd7ecfa7",
   "metadata": {},
   "source": [
    "Se crea una función para calcular las distintas métricas que servirán para la posterior evaluación de cada modelo que se realice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b62f0ad-3bf5-43b6-b2a6-ae64737f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "'''import numpy as np\n",
    "import tensorflow as tf'''\n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    '''\n",
    "    Funcicón que calcula distintas métricas para la evaluación del modelo.\n",
    "    -----------------------------------------------------\n",
    "    Parámetros: \n",
    "    - y_test: array de etiquetas verdaderas del conjunto de prueba\n",
    "    - y_pred: array de etiquetas predichas por el modelo\n",
    "    ----------------------------------------\n",
    "    Return: \n",
    "    - accuracy: float que indica la proporción de predicciones correctas\n",
    "    - precision: float que indica la proporción de predicciones positivas correctas\n",
    "    - recall: float que indica la proporción de positivos detectados\n",
    "    - f1: float que indica la media armónica de precisión y exhaustividad para evaluar de una forma más equilibrada el rendimiento del modelo\n",
    "    - specificity: float que indica la proporción de negativos detectados\n",
    "    - fpr: float que indica la tasa de falsos positivos, es decir, la proporción de negativos incorrectamente clasificadas como positivos, \n",
    "    respecto al total de casos negativos reales.\n",
    "    - fnr: float que indica la tasa de falsos negativos, es decir, la proporción de positivos incorrectamente clasificadas como negativos, \n",
    "    respecto al total de casos positivos reales.\n",
    "    - auc: float que se emplea para evaluar la capacidad de distinción entre clases positivas y negativas de un modelo de clasificación \n",
    "    binaria. Un 1 significa que es capaz de distinguir perfectamente entre clases, un 0.5 significa una clasificación aleatoria y un 0 indica \n",
    "    que ninguna clase ha sido correctamente clasificada.\n",
    "    '''\n",
    "    y_pred_bin=y_pred>0.5 #para convertirlo en un problema binario\n",
    "    \n",
    "    #se obtienen los verdaderos negativos, falsos positivos, falsos negativos y verdaderos positivos a partir de la matriz de confusión \n",
    "    #con .ravel() se convierte la matriz en un array unidimensional\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_bin).ravel() \n",
    "\n",
    "    #se calculan cada una de las métricas empleando su correspondiente fórmula\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn) #tasa de falsos positivos\n",
    "    fnr = fn / (fn + tp) #tasa de falsos negativos\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, specificity, fpr, fnr, auc] #se devuleve como una lista para poder trabajar correctmante con las métricas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e775dc-426e-447b-bc1b-35d52330027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59a0d8-8fe2-4590-b50d-d3e1dd996e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e81a3-d57f-49a8-8307-1f4812bed084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1b32f5-76dc-483e-bb31-8c6e0d468c1f",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fdfaa-3ae7-4085-8522-1d295e2ca373",
   "metadata": {},
   "source": [
    "Para realizar una comparación entre distintas arquitecturas y distintos batch_size, en primer lugar, se generan diferentes modelos de arquitectura de red neuronal variando las capas, el número de capas, etc y, después se entrenan y evalúan los modelos generados con distintos batch sizes. Para esto, se emplean las métricas previamente definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236828d2-67b4-423a-98cf-e733615ff575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def establecer_arquitectura(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) según el tipo que se introduzca como parámetro.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(150,150,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), #cambiar a menos de 0,5 \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model #model.summary??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee64d9-9253-478c-b436-425bfd047ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0f380-66aa-4989-a4ef-88253c46d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba con AlexNet\n",
    "def establecer_arquitectura(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) según el tipo que se introduzca como parámetro.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(340,340,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), #cambiar a menos de 0,5 \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model #model.summary??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d75050-68d1-4754-8c29-3cdacb6d2b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295f26a-f714-48b2-86a2-3e9de05aa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet\n",
    "\n",
    "# Layer 1: Convolutional layer with 96 filters of size 16x16x3\n",
    "model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu', input_shape=(340,340,3)))\n",
    "    \n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "    \n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'))\n",
    "    \n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "    \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Layer 3-5: 3 more convolutional layers with similar structure as Layer 1\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "    \n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "    \n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "    \n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "    \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Layer 6: Fully connected layer with 4096 neurons\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dense(100, activation=\"relu\"))  \n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1, activation=\"sigmoid\"))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23540689-dbd3-4581-ba68-c5f9ff3108c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6ccec-d183-4b76-8ea6-81c69b3b2d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9de14-9bb1-4794-b690-8d2a5164e9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce17fe-abf7-4859-8cbb-4baa86a918c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b7f36-6297-43d4-a8a8-93964cc84ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRUEBA/EJECUTAR 2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch(ruta,epochs,batch_sizes,modelos):\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas arquitecturas de modelo y distintos batch size introducidos como parámetros. \n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    \"establecer_arquitectura(modelo)\"\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "            #ENTRENA\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "    \n",
    "            #se calculan las métricas\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "            #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "            #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "            #cambiar .append por .concat\n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bac317-110d-4f8c-b027-b9caee5b376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate 0,001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8be533-a397-4df4-8e10-1f131bb07c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "arq_batch(ruta,epochs,batch_sizes,modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50072-e379-42a4-8b45-433ce620d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdfc7f-173b-46f0-b974-88f4e4f099b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#PRUEBA/EJECUTAR\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "\n",
    "#se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "#modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "compara_arqu_batch=pd.DataFrame()\n",
    "\n",
    "epochs=20\n",
    "\n",
    "#bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "for modelo in modelos:\n",
    "    print(f\"Comparando modelo {modelo}...\")\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "\n",
    "        #SE PREPARA EL MODELO\n",
    "        dir_general = 'C:/Users/nuria/Downloads/TFG/data' #ubicacion donde yo tengo metida la carpeta data (cambiar en caso necesario) y añadir esta carpeta a one drive en TFG\n",
    "\n",
    "        dir_train = os.path.join(dir_general, 'train')\n",
    "        dir_validation = os.path.join(dir_general, 'val')\n",
    "        dir_test = os.path.join(dir_general, 'test')\n",
    "\n",
    "        # Preprocesamiento de imágenes\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        #Iterador que recorre el directorio de imágenes\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            dir_train,\n",
    "            target_size=(150, 150), #todas las imágenes se redimensionen a 150x150 píxeles, de forma que, si existen tamaños diferentes entre ellas, se uniforman\n",
    "            batch_size=batch_size, # se itera para distintos valores de batch size\n",
    "            class_mode='binary')\n",
    "        \n",
    "        validation_generator = validation_datagen.flow_from_directory(\n",
    "            dir_validation,\n",
    "            target_size=(150, 150), #todas las imágenes se redimensionen a 150x150 píxeles, de forma que, si existen tamaños diferentes entre ellas, se uniforman\n",
    "            batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "            class_mode='binary')\n",
    "        \n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            dir_test,\n",
    "            target_size=(150, 150), #todas las imágenes se redimensionen a 150x150 píxeles, de forma que, si existen tamaños diferentes entre ellas, se uniforman\n",
    "            batch_size=batch_size, #lo más grande posible que no cause problemas de memoria \n",
    "            class_mode='binary')\n",
    "        \n",
    "        #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "        model = establecer_arquitectura(modelo)\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\"]) #cambias loss\n",
    "\n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "        model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3))\n",
    "\n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        \n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf165ac-313e-4ee2-ae91-2ba544fea8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#se fijan las columnas A y B como índices. \n",
    "compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "compara_arqu_batch_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa112d-b0a8-49ec-88e0-7a277b14ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, se puede deducir que, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52955cda-cfa5-49dc-ae72-33c901dc30ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea38f30-5183-48e3-9678-713040bb57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "\n",
    "#se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "#modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "compara_arqu_batch=pd.DataFrame()\n",
    "\n",
    "epochs=5\n",
    "\n",
    "#bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "for modelo in modelos:\n",
    "    print(f\"Comparando modelo {modelo}...\")\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "        \n",
    "        #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "        model = establecer_arquitectura(modelo)\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\"]) #cambias loss\n",
    "\n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "        model.fit(train_generator, batch_size=batch_size, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3))\n",
    "\n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184a38d-61b1-4ed9-a293-db79ba086e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compara_arqu_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90df82-9a99-422b-8cc2-7237d372c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, se puede apreciar que la primera arquitectura es la peor de todas (algo que era de esperar) y la mejor opcion es \n",
    "# el Simple 2 ya que, en general (exceptuando para una batch size de 8) obtiene mejores resultados.\n",
    "#Dentro del Simple 2, el mejor valor de batch size es el de 32 ya que es el que presenta mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ed9a0-e739-4669-9391-305a3d45dacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c7252-e239-45b8-bc01-6df22183405c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b8a3-f70f-41ff-822a-b956996a6623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d15853-36f9-4980-b52a-7b824f0a700b",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura \"Simple2\" y un batchsize de 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c884c-043f-451a-b8a2-34f801293780",
   "metadata": {},
   "source": [
    "A partir de los resultados obtenidos previamente, se comparan distintos valores de número de neuronas para determinar con cuál funciona mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563679f-a18b-4449-a256-59ec9f249590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antes hay que ejecutar la funcion preparar modelo y la funcion de metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bc8de-be58-4b81-93ad-b5426cd4b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple2\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)\n",
    "    \n",
    "    \n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "\n",
    "    \n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "                [\n",
    "                    keras.Input(shape=input_shape),\n",
    "                    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                    layers.Flatten(), #convierte imágenes en vectores\n",
    "                    layers.Dense(neurona, activation=\"relu\"), #se va cambiando el valor de \"neurona\" para cada uno de los valores que estan en la lista num_neuronas\n",
    "                    layers.Dropout(0.2),\n",
    "                    layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "    \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "    \n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36fa74-69d2-4500-9d22-868cf9b384bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=32\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39219b-71fb-4a5f-a059-fc752d5d661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERO DE NEURONAS CON EL MODELO SIMPLE3\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)\n",
    "    \n",
    "    \n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "    \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1bd8c-b211-430f-afe2-325d392c7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=32\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0edbb1-1791-4c52-a44f-93e489f1f7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b5ed7-9981-4ae5-b9ef-3942a2808157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ce7a87-bc74-4333-a5ca-902cd12eb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple2 AlexNet\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)\n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "\n",
    "    \n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "    \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "    \n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "    \n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a24f46-4382-4420-9ff7-d15217bbd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Modelo con 512 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 294s 1s/step - loss: 0.4323 - accuracy: 0.8740 - recall: 0.9151 - auc: 0.9140 - val_loss: 0.4703 - val_accuracy: 0.8122 - val_recall: 0.9985 - val_auc: 0.9576\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.1973 - accuracy: 0.9247 - recall: 0.9546 - auc: 0.9695 - val_loss: 0.2083 - val_accuracy: 0.9264 - val_recall: 0.9327 - val_auc: 0.9742\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 284s 1s/step - loss: 0.1700 - accuracy: 0.9424 - recall: 0.9609 - auc: 0.9775 - val_loss: 7.2650 - val_accuracy: 0.3799 - val_recall: 0.1506 - val_auc: 0.6798\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.1666 - accuracy: 0.9376 - recall: 0.9590 - auc: 0.9780 - val_loss: 0.1513 - val_accuracy: 0.9434 - val_recall: 0.9503 - val_auc: 0.9828\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.1405 - accuracy: 0.9477 - recall: 0.9689 - auc: 0.9832 - val_loss: 0.1594 - val_accuracy: 0.9424 - val_recall: 0.9430 - val_auc: 0.9845\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.1253 - accuracy: 0.9528 - recall: 0.9689 - auc: 0.9870 - val_loss: 0.3961 - val_accuracy: 0.8986 - val_recall: 0.9942 - val_auc: 0.9510\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 286s 1s/step - loss: 0.1372 - accuracy: 0.9528 - recall: 0.9707 - auc: 0.9826 - val_loss: 0.2746 - val_accuracy: 0.9210 - val_recall: 0.9269 - val_auc: 0.9676\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 289s 1s/step - loss: 0.1357 - accuracy: 0.9442 - recall: 0.9645 - auc: 0.9850 - val_loss: 0.2403 - val_accuracy: 0.8997 - val_recall: 0.9854 - val_auc: 0.9726\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.1119 - accuracy: 0.9592 - recall: 0.9718 - auc: 0.9888 - val_loss: 0.1433 - val_accuracy: 0.9530 - val_recall: 0.9766 - val_auc: 0.9853\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 305s 1s/step - loss: 0.0999 - accuracy: 0.9629 - recall: 0.9777 - auc: 0.9914 - val_loss: 0.1365 - val_accuracy: 0.9488 - val_recall: 0.9839 - val_auc: 0.9853\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.1039 - accuracy: 0.9602 - recall: 0.9733 - auc: 0.9896 - val_loss: 0.1895 - val_accuracy: 0.9370 - val_recall: 0.9912 - val_auc: 0.9757\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 318s 1s/step - loss: 0.1035 - accuracy: 0.9570 - recall: 0.9751 - auc: 0.9914 - val_loss: 0.2211 - val_accuracy: 0.9381 - val_recall: 0.9722 - val_auc: 0.9632\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.0892 - accuracy: 0.9672 - recall: 0.9806 - auc: 0.9925 - val_loss: 0.1546 - val_accuracy: 0.9466 - val_recall: 0.9898 - val_auc: 0.9837\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.1024 - accuracy: 0.9637 - recall: 0.9770 - auc: 0.9903 - val_loss: 0.5996 - val_accuracy: 0.8431 - val_recall: 0.7924 - val_auc: 0.9640\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 300s 1s/step - loss: 0.0897 - accuracy: 0.9637 - recall: 0.9792 - auc: 0.9921 - val_loss: 0.4420 - val_accuracy: 0.8858 - val_recall: 0.9868 - val_auc: 0.9336\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0942 - accuracy: 0.9640 - recall: 0.9770 - auc: 0.9918 - val_loss: 0.1780 - val_accuracy: 0.9349 - val_recall: 0.9781 - val_auc: 0.9797\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 293s 1s/step - loss: 0.0816 - accuracy: 0.9709 - recall: 0.9832 - auc: 0.9934 - val_loss: 0.1641 - val_accuracy: 0.9445 - val_recall: 0.9795 - val_auc: 0.9815\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.1068 - accuracy: 0.9637 - recall: 0.9806 - auc: 0.9887 - val_loss: 0.6277 - val_accuracy: 0.7919 - val_recall: 0.7281 - val_auc: 0.9503\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 301s 1s/step - loss: 0.1289 - accuracy: 0.9530 - recall: 0.9718 - auc: 0.9855 - val_loss: 0.5151 - val_accuracy: 0.8602 - val_recall: 0.9956 - val_auc: 0.9267\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 304s 1s/step - loss: 0.1027 - accuracy: 0.9632 - recall: 0.9799 - auc: 0.9900 - val_loss: 0.1988 - val_accuracy: 0.9296 - val_recall: 0.9927 - val_auc: 0.9812\n",
      "74/74 [==============================] - 41s 557ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_2420\\1355991842.py:85: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 1024 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 307s 1s/step - loss: 0.4463 - accuracy: 0.8759 - recall: 0.9199 - auc: 0.9139 - val_loss: 0.2467 - val_accuracy: 0.9221 - val_recall: 0.9269 - val_auc: 0.9684\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.1919 - accuracy: 0.9298 - recall: 0.9557 - auc: 0.9702 - val_loss: 0.1715 - val_accuracy: 0.9413 - val_recall: 0.9503 - val_auc: 0.9773\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.2063 - accuracy: 0.9237 - recall: 0.9495 - auc: 0.9683 - val_loss: 0.2140 - val_accuracy: 0.9253 - val_recall: 0.9825 - val_auc: 0.9754\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.1553 - accuracy: 0.9394 - recall: 0.9590 - auc: 0.9800 - val_loss: 0.3062 - val_accuracy: 0.8933 - val_recall: 0.9868 - val_auc: 0.9637\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 298s 1s/step - loss: 0.1456 - accuracy: 0.9426 - recall: 0.9645 - auc: 0.9822 - val_loss: 0.2983 - val_accuracy: 0.8901 - val_recall: 0.8626 - val_auc: 0.9773\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 307s 1s/step - loss: 0.1348 - accuracy: 0.9509 - recall: 0.9689 - auc: 0.9843 - val_loss: 0.1453 - val_accuracy: 0.9466 - val_recall: 0.9825 - val_auc: 0.9841\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 314s 1s/step - loss: 0.1308 - accuracy: 0.9509 - recall: 0.9707 - auc: 0.9844 - val_loss: 0.1999 - val_accuracy: 0.9285 - val_recall: 0.9298 - val_auc: 0.9775\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.1203 - accuracy: 0.9568 - recall: 0.9722 - auc: 0.9870 - val_loss: 0.1396 - val_accuracy: 0.9488 - val_recall: 0.9474 - val_auc: 0.9899\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 293s 1s/step - loss: 0.1119 - accuracy: 0.9584 - recall: 0.9737 - auc: 0.9892 - val_loss: 0.1411 - val_accuracy: 0.9498 - val_recall: 0.9766 - val_auc: 0.9828\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1459s 6s/step - loss: 0.1121 - accuracy: 0.9573 - recall: 0.9726 - auc: 0.9879 - val_loss: 0.1122 - val_accuracy: 0.9584 - val_recall: 0.9751 - val_auc: 0.9901\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 266s 1s/step - loss: 0.0899 - accuracy: 0.9645 - recall: 0.9792 - auc: 0.9926 - val_loss: 0.1893 - val_accuracy: 0.9466 - val_recall: 0.9825 - val_auc: 0.9717\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0977 - accuracy: 0.9669 - recall: 0.9806 - auc: 0.9897 - val_loss: 0.1572 - val_accuracy: 0.9477 - val_recall: 0.9737 - val_auc: 0.9782\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.0794 - accuracy: 0.9690 - recall: 0.9817 - auc: 0.9937 - val_loss: 0.1171 - val_accuracy: 0.9605 - val_recall: 0.9825 - val_auc: 0.9879\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.1325 - accuracy: 0.9506 - recall: 0.9700 - auc: 0.9848 - val_loss: 0.1932 - val_accuracy: 0.9413 - val_recall: 0.9401 - val_auc: 0.9770\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.1199 - accuracy: 0.9541 - recall: 0.9715 - auc: 0.9872 - val_loss: 0.1596 - val_accuracy: 0.9530 - val_recall: 0.9532 - val_auc: 0.9872\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 281s 1s/step - loss: 0.0948 - accuracy: 0.9629 - recall: 0.9781 - auc: 0.9923 - val_loss: 0.6822 - val_accuracy: 0.8314 - val_recall: 0.9971 - val_auc: 0.9174\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.0968 - accuracy: 0.9650 - recall: 0.9781 - auc: 0.9910 - val_loss: 0.1756 - val_accuracy: 0.9413 - val_recall: 0.9532 - val_auc: 0.9807\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 282s 1s/step - loss: 0.0764 - accuracy: 0.9725 - recall: 0.9850 - auc: 0.9948 - val_loss: 0.1179 - val_accuracy: 0.9530 - val_recall: 0.9854 - val_auc: 0.9894\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 272s 1s/step - loss: 0.0669 - accuracy: 0.9762 - recall: 0.9876 - auc: 0.9953 - val_loss: 0.1158 - val_accuracy: 0.9573 - val_recall: 0.9751 - val_auc: 0.9894\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 271s 1s/step - loss: 0.0600 - accuracy: 0.9778 - recall: 0.9868 - auc: 0.9971 - val_loss: 0.1416 - val_accuracy: 0.9552 - val_recall: 0.9839 - val_auc: 0.9848\n",
      "74/74 [==============================] - 36s 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_2420\\1355991842.py:85: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024.0</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Loss  Accuracy  Precision  Recall    F1  Specificity  \\\n",
       "Número de neuronas                                                         \n",
       "512.0               0.16      0.61       0.73    0.75  0.74         0.24   \n",
       "1024.0              0.14      0.60       0.73    0.73  0.73         0.26   \n",
       "\n",
       "                     fpr   fnr   AUC  \n",
       "Número de neuronas                    \n",
       "512.0               0.76  0.25  0.49  \n",
       "1024.0              0.74  0.27  0.50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neuronas=[512, 1024] #lista con distintos valores de neuronas para probar AÑADIR 2048\n",
    "epochs=20\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=16\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48cb3f-7e05-4106-8555-daf0dde2a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple3 AlexNet\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa para distintas valores de neuronas introducidos como parámetros a partir del modelo y el batch size\n",
    "    seleccionado previamente.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros;\n",
    "    - num_neuronas:\n",
    "    - epochs:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test)\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función\n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test)\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size)\n",
    "    \n",
    "    \n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "    \n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "        model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "    \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": int(neurona), \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "    #compara_neuronas_def['Número de neuronas'] = compara_neuronas_def['Número de neuronas'].astype(int) #para convertr la columna Numero neuronas a entero y no aparezca como decimales\n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        #PONER int(neurona) si salen como decimanles o poner lo que esta comentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0dd62-ee02-48af-af94-827756ce2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=32\n",
    "\n",
    "neuronas(num_neuronas, epochs, ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d446ca-df2b-4da0-b805-4b7dc74f6590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468728b2-6258-43f3-bad3-9908f078173b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cb3a0-ebd8-4985-aa5f-1937a6a2323a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69135d-32db-43c6-a4c1-ecb8d049d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a63ed6-7c60-40cd-8dd8-fc5e12c81516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499e1b1-61a8-4d16-9a66-d57c56170d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4fa1344-69d6-4800-8201-9fa62b2be003",
   "metadata": {},
   "source": [
    "Por lo tanto, se puede apreciar que, el mejor modelo se corresponde con 64 neuronas en la capa oculta ya que, \n",
    "tiene un valor mayor en la gran parte de métricas (aunque en loss deberia ser menor) CAMBIAR EN CASO NECESARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70ad44-41bf-4c21-897f-5dfa8f83fe0d",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como funciona el modelo elegido finalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0aa3-f29f-4b6a-bd79-4aec32a7e8dd",
   "metadata": {},
   "source": [
    "Finalmente, se obtiene la matriz de confusión para el modelo final obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215b28e-359b-45d2-9bd3-07a0919a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMBIAR TODO LO QUE HAY A CONTINUACION POR EL MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4a642-c3d4-4064-a4b0-0e2b18044a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batchsize=20\n",
    "preparar_modelo(ruta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab559147-c68c-4bdf-8678-466cbdc88038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se trabaja con el modelo simple1\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "model = keras.Sequential( #funcion establecer arquitectura(simple...)\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        #se necesitan mas capas\n",
    "        layers.Dropout(0.5), #probar otros valores (este es muy alto)\n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurina, sigmoide\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746296f1-e216-486d-aabd-80d626ac8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009464a-c8a2-4e3a-a033-0b0aa6465ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ad034-109d-42ea-84b4-950095a5bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred>0.5 #para convertirlo en un problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00f04a-bdf6-458f-b926-3a6ff26d7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión con sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd24bd6-2635-472a-b10e-facbf5705f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d5d03-8012-46fe-bac0-d9e7cff004d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON SKLEARN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"neumonía\" , \"no neumonía\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión neumonía-no neumonía\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82d04a-c14b-4970-bc4c-f5c2924c6baf",
   "metadata": {},
   "source": [
    "Se puede comprobar como han mejorado los resultados respecto al modelo más simple ya que..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115865-dddc-4ec1-bb3a-efa3419117a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b2ecb-81e3-40a9-9fcb-eec582cd18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARTICULO METIDO EN EL RESUMEN DE LA MEMORIA\n",
    "#https://www.sciencedirect.com/science/article/pii/S001048252030247X?via%3Dihub#bib1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
