{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c296a9ed-5af7-4b30-91c5-7015aefef326",
   "metadata": {},
   "source": [
    "## Preparación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902767b-c1ec-49f2-87c3-74dda3dd4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLICAR UN POCO LOS PASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f44c95-c38d-4885-a5e7-fe86df3e6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/paola311/clasificaci-n-de-im-genes-cnn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "dir_general = 'C:/Users/nuria/Downloads/TFG/data' #ubicacion donde yo tengo metida la carpeta data (cambiar en caso necesario) y añadir esta carpeta a one drive en TFG\n",
    "\n",
    "dir_train = os.path.join(dir_general, 'train')\n",
    "dir_validation = os.path.join(dir_general, 'val')\n",
    "dir_test = os.path.join(dir_general, 'test')\n",
    "\n",
    "# Preprocesamiento de imágenes\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Iterador que recorre el directorio de imágenes\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20, #no se si esto lo deberia quitar de aqui al emplearlo luego aparte\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    dir_validation,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20, #lo más grande posible que no cause problemas de memoria \n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    dir_test,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20, #lo más grande posible que no cause problemas de memoria \n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7c9f6-1908-4a50-94ea-5c00e3fb5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Ejemplo para ver como se accede a las imágenes y etiquetas\n",
    "for imagenes, etiquetas in train_generator:\n",
    "    print(\"Imágenes:\", imagenes[1]) #si no pongo [1] sale de 20 en 20 porque el batch size es 20\n",
    "    print(\"Etiquetas:\", etiquetas[1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b0c505-d630-413b-b7d9-d3572ea24002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 82945     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,337\n",
      "Trainable params: 102,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#DROPOUT DE 0.5\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "model = keras.Sequential( #funcion establecer arquitectura(simple...)\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        #se necesitan mas capas\n",
    "        layers.Dropout(0.5), #probar otros valores (este es muy alto)\n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurina, sigmoide\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50dfdaf1-1092-42d1-bf88-34bc3f64ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 82945     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,337\n",
      "Trainable params: 102,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#SE CAMBIA EL DROPOUT DE 0.5 A 0.2\n",
    "input_shape=(150,150,3)\n",
    "\n",
    "model2 = keras.Sequential( #funcion establecer arquitectura(simple...)\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        #se necesitan mas capas\n",
    "        layers.Dropout(0.2), #probar otros valores (este es muy alto)\n",
    "        layers.Dense(1, activation=\"sigmoid\"), #una unica neurina, sigmoide\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b534dd-b6ac-46a5-bdcc-a6304cb9f422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b3d9a-d343-471f-b3bd-f2ebad3f7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad61f8-2147-49e3-ac4b-00605ac7983e",
   "metadata": {},
   "source": [
    "## Métrica F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd30fb-9811-4bc5-9614-f2aadad5274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ESTE PUNTO SE PODRIA BORRA PORQUE CREO QUE AL FINAL NO LO USO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e528ac-f519-4d2b-b4c6-4d54f07bf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/43345909/when-using-mectrics-in-model-compile-in-keras-report-valueerror-unknown-metr\n",
    "#En esta version de keras no hay un f1 disponible por lo que he de crearlo yo misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17115f48-ffc0-4d0a-8ac1-9d828e2c1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para saber como acceder a y_test e y_pred\n",
    "'''y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3d5897-c0e5-43c8-aae0-7653c6051d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONA\n",
    "from keras import backend as K\n",
    "\n",
    "def metrica_f1(y_true, y_pred):\n",
    "    \n",
    "    '''K.epsilon() se utiliza para evitar la división por cero, sumando un valor (pequeño) constante a los denominadores.\n",
    "    k.round() se emplea para redondear a valores binarios (0 o 1) de tal forma que, se está aplicando un umbral para convertir las probabilidades \n",
    "    de predicción en una clasificación binaria. En el caso de un problema de clasificación binaria, como determinar si una radiografía muestra \n",
    "    neumonía o no, el modelo neuronal puede proporcionar una probabilidad como salida, donde un valor cercano a 1 indica alta confianza en \n",
    "    la clase positiva (neumonía) y un valor cercano a 0 indica alta confianza en la clase negativa (no neumonía).\n",
    "    Cualquier probabilidad mayor que 0.5 se considerará  como predicción de la clase positiva, y cualquier probabilidad menor o igual a 0.5 \n",
    "    se considerará como predicción de la clase negativa. \n",
    "    Esto es comúnmente usado en problemas de clasificación binaria para convertir las probabilidades continuas en etiquetas de clase discretas'''\n",
    "    precision = K.sum(y_true * K.round(y_pred)) / (K.sum(K.round(y_pred)) + K.epsilon()) \n",
    "    recall = K.sum(y_true * K.round(y_pred)) / (K.sum(y_true) + K.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))  #fórmula de f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffac2c3-1ca2-4637-9ff9-6d1f1f2a8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta forma de hacerlo no funciona , BORRAR\n",
    "'''from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    sensibilidad = recall_score(y_test, y_pred)\n",
    "    puntaje = f1_score(y_test, y_pred)\n",
    "    return (exactitud,precision,sensibilidad,puntaje)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5654c9-4f71-4980-9ade-721a48531aec",
   "metadata": {},
   "source": [
    "## Creación de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b62f0ad-3bf5-43b6-b2a6-ae64737f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "'''import numpy as np\n",
    "import tensorflow as tf'''\n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    y_pred=y_pred>0.5 #para convertirlo en un problema binario\n",
    "    \n",
    "    #se obtienen los verdaderos negativos, falsos positivos, falsos negativos y verdaderos positivos a partir de la matriz de confusión \n",
    "    #con .ravel() se convierte la matriz en un array unidimensional\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() \n",
    "\n",
    "    #se calculan cada una de las métricas empleando su correspondiente fórmula\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn) #tasa de falsos positivos\n",
    "    fnr = fn / (fn + tp) #tasa de falsos negativos\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, specificity, fpr, fnr, auc] #se devuleve como una lista para poder trabajar correctmante con las métricas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e775dc-426e-447b-bc1b-35d52330027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e59a0d8-8fe2-4590-b50d-d3e1dd996e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5961538461538461"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas(y_test, y_pred)[0]#accedo a accuracy solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e81a3-d57f-49a8-8307-1f4812bed084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02344f74-ed76-464e-bcb4-6d6d12fbecdb",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f95f941-1c9c-4c98-8573-8e7bf42a18f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 94s 358ms/step - loss: 0.0561 - accuracy: 0.9799 - recall: 0.9871 - val_loss: 0.0296 - val_accuracy: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#DROPOUT = 0.5\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_size = 20 #jugar un poco con este parametro (potencias de 2) (cuanto mayor sea el valor menos tarda)\n",
    "epochs = 1\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\"]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "h=model.fit(train_generator, batch_size=batch_size, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b7f0dc-7ec0-4256-bfa8-5407c2180da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "261/261 [==============================] - 100s 378ms/step - loss: 0.2040 - accuracy: 0.9151 - recall: 0.9672 - auc: 0.9646 - precision: 0.9222 - metrica_f1: 0.9444 - val_loss: 0.7408 - val_accuracy: 0.6250 - val_recall: 1.0000 - val_auc: 0.9688 - val_precision: 0.5714 - val_metrica_f1: 0.7273\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 106s 407ms/step - loss: 0.0975 - accuracy: 0.9630 - recall: 0.9770 - auc: 0.9910 - precision: 0.9733 - metrica_f1: 0.9743 - val_loss: 0.3279 - val_accuracy: 0.7500 - val_recall: 1.0000 - val_auc: 1.0000 - val_precision: 0.6667 - val_metrica_f1: 0.8000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 105s 403ms/step - loss: 0.0746 - accuracy: 0.9735 - recall: 0.9845 - auc: 0.9945 - precision: 0.9800 - metrica_f1: 0.9818 - val_loss: 0.1858 - val_accuracy: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000 - val_precision: 0.8000 - val_metrica_f1: 0.8889\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 108s 415ms/step - loss: 0.0477 - accuracy: 0.9812 - recall: 0.9871 - auc: 0.9978 - precision: 0.9876 - metrica_f1: 0.9867 - val_loss: 0.7931 - val_accuracy: 0.6875 - val_recall: 1.0000 - val_auc: 1.0000 - val_precision: 0.6154 - val_metrica_f1: 0.7619\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 107s 410ms/step - loss: 0.0498 - accuracy: 0.9808 - recall: 0.9874 - auc: 0.9979 - precision: 0.9868 - metrica_f1: 0.9864 - val_loss: 0.0393 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_metrica_f1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bec7411450>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROPOUT = 0.2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_size = 20 #jugar un poco cn este parametro (potencias de 2) (cuanto mayor sea el valor menos tarda)\n",
    "epochs = 5\n",
    "\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\",\"Precision\",metrica_f1]) #cambias loss\n",
    "\n",
    "# con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "model2.fit(train_generator, batch_size=batch_size, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b65e0-f3f1-42b1-b4db-53a5459c2450",
   "metadata": {},
   "source": [
    "## Evaluación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d97b1deb-49ce-4a1a-bf66-019409c682e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05612298473715782]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#otra forma de acceder a loss (igualando a h el model.fit anterior)\n",
    "los=h.history['loss']\n",
    "los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d828d72-9902-4bb8-a92a-e75941d6ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 7s 224ms/step\n",
      "Test loss: 0.9566270112991333\n",
      "Test accuracy: 0.5961538461538461\n",
      "Test Precision: 0.6292134831460674\n",
      "Test Recall: 0.8615384615384616\n",
      "Test F1: 0.7272727272727273\n",
      "Test Specificity: 0.15384615384615385\n",
      "Test fpr: 0.8461538461538461\n",
      "Test fnr: 0.13846153846153847\n",
      "Test AUC: 0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)\n",
    "\n",
    "metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", metricas[0])\n",
    "print(\"Test Precision:\", metricas[1])\n",
    "print(\"Test Recall:\", metricas[2])\n",
    "print(\"Test F1:\", metricas[3])\n",
    "print(\"Test Specificity:\", metricas[4])\n",
    "print(\"Test fpr:\", metricas[5])\n",
    "print(\"Test fnr:\", metricas[6])\n",
    "print(\"Test AUC:\", metricas[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a929cca-2032-48a3-ad25-ce496d4273da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1651761531829834\n",
      "Test accuracy: 0.7628205418586731\n",
      "Test Recall: 0.9948717951774597\n",
      "Test AUC: 0.863067090511322\n",
      "Test Precision: 0.7265917658805847\n",
      "Test F1: 0.8381282091140747\n"
     ]
    }
   ],
   "source": [
    "# DUDA cada vez que se ejecuta sale una cosa distinta, porque?\n",
    "#DROPOUT = 0.2\n",
    "score = model2.evaluate(test_generator, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Test Recall:\", score[2])\n",
    "print(\"Test AUC:\", score[3])\n",
    "print(\"Test Precision:\", score[4])\n",
    "print(\"Test F1:\", score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ec990-2df1-4f50-a0de-85198c88cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, teniendo en cuenta estos resultados, es mejor el dropout de 0.2 que el de 0.5 por lo tanto, a partir de \n",
    "#ahora se va a trabajar con un dropot de 0.2 (CREO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b32f5-76dc-483e-bb31-8c6e0d468c1f",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236828d2-67b4-423a-98cf-e733615ff575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se emplea un dropot de 0.2 ya que hemos hecho una comparacion previa y se obtenian mejores resultados con uno de 0.2 que con \n",
    "#uno de 0.5\n",
    "\n",
    "def establecer_arquitectura(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) según el tipo que se introduzca como parámetro.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(150,150,3)\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), #cambiar a menos de 0,5 \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model #model.summary??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea38f30-5183-48e3-9678-713040bb57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 142s 538ms/step - loss: 0.2161 - accuracy: 0.9145 - recall: 0.9662 - val_loss: 0.6887 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 141s 540ms/step - loss: 0.1001 - accuracy: 0.9628 - recall: 0.9768 - val_loss: 0.3130 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 140s 535ms/step - loss: 0.0751 - accuracy: 0.9734 - recall: 0.9840 - val_loss: 0.3063 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 140s 535ms/step - loss: 0.0602 - accuracy: 0.9789 - recall: 0.9853 - val_loss: 0.2794 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 141s 538ms/step - loss: 0.0445 - accuracy: 0.9841 - recall: 0.9907 - val_loss: 0.1299 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 13s 407ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 142s 538ms/step - loss: 0.2458 - accuracy: 0.8969 - recall: 0.9554 - val_loss: 0.2739 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 139s 532ms/step - loss: 0.1013 - accuracy: 0.9617 - recall: 0.9760 - val_loss: 0.4866 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 140s 535ms/step - loss: 0.0872 - accuracy: 0.9657 - recall: 0.9794 - val_loss: 0.3671 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 139s 533ms/step - loss: 0.0632 - accuracy: 0.9745 - recall: 0.9837 - val_loss: 0.1300 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 138s 528ms/step - loss: 0.0509 - accuracy: 0.9826 - recall: 0.9889 - val_loss: 0.0942 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "32/32 [==============================] - 13s 396ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 142s 538ms/step - loss: 0.2168 - accuracy: 0.9135 - recall: 0.9551 - val_loss: 0.3580 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 140s 537ms/step - loss: 0.1011 - accuracy: 0.9643 - recall: 0.9770 - val_loss: 0.2560 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 139s 532ms/step - loss: 0.0786 - accuracy: 0.9724 - recall: 0.9825 - val_loss: 0.4358 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 140s 534ms/step - loss: 0.0622 - accuracy: 0.9785 - recall: 0.9866 - val_loss: 0.1945 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 140s 537ms/step - loss: 0.0530 - accuracy: 0.9810 - recall: 0.9866 - val_loss: 0.0686 - val_accuracy: 0.9375 - val_recall: 0.8750\n",
      "32/32 [==============================] - 13s 402ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 142s 536ms/step - loss: 0.2027 - accuracy: 0.9197 - recall: 0.9615 - val_loss: 0.4027 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 140s 536ms/step - loss: 0.1014 - accuracy: 0.9628 - recall: 0.9791 - val_loss: 0.1791 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 140s 535ms/step - loss: 0.0774 - accuracy: 0.9711 - recall: 0.9822 - val_loss: 1.0172 - val_accuracy: 0.6250 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 141s 541ms/step - loss: 0.0574 - accuracy: 0.9799 - recall: 0.9874 - val_loss: 0.1989 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 146s 559ms/step - loss: 0.0512 - accuracy: 0.9820 - recall: 0.9892 - val_loss: 0.1475 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 13s 408ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 141s 534ms/step - loss: 0.2304 - accuracy: 0.9030 - recall: 0.9574 - val_loss: 0.5528 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 140s 534ms/step - loss: 0.0941 - accuracy: 0.9661 - recall: 0.9806 - val_loss: 0.2958 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 139s 533ms/step - loss: 0.0762 - accuracy: 0.9741 - recall: 0.9832 - val_loss: 0.7595 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 140s 536ms/step - loss: 0.0593 - accuracy: 0.9803 - recall: 0.9868 - val_loss: 0.1649 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 139s 534ms/step - loss: 0.0426 - accuracy: 0.9841 - recall: 0.9897 - val_loss: 0.0414 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "32/32 [==============================] - 13s 408ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 143s 540ms/step - loss: 0.2527 - accuracy: 0.8976 - recall: 0.9517 - val_loss: 0.2737 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 140s 536ms/step - loss: 0.1121 - accuracy: 0.9576 - recall: 0.9768 - val_loss: 0.4588 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 140s 534ms/step - loss: 0.0849 - accuracy: 0.9697 - recall: 0.9837 - val_loss: 0.2919 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 140s 534ms/step - loss: 0.0685 - accuracy: 0.9728 - recall: 0.9848 - val_loss: 0.1159 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 138s 528ms/step - loss: 0.0602 - accuracy: 0.9760 - recall: 0.9868 - val_loss: 0.1218 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 13s 388ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 136s 516ms/step - loss: 0.2266 - accuracy: 0.9156 - recall: 0.9515 - val_loss: 0.5714 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 124s 476ms/step - loss: 0.0887 - accuracy: 0.9670 - recall: 0.9791 - val_loss: 0.4581 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 126s 484ms/step - loss: 0.0611 - accuracy: 0.9772 - recall: 0.9837 - val_loss: 0.0804 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 130s 498ms/step - loss: 0.0561 - accuracy: 0.9793 - recall: 0.9871 - val_loss: 0.1503 - val_accuracy: 0.9375 - val_recall: 0.8750\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 129s 494ms/step - loss: 0.0383 - accuracy: 0.9850 - recall: 0.9892 - val_loss: 0.0253 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "32/32 [==============================] - 14s 434ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 127s 483ms/step - loss: 0.2040 - accuracy: 0.9181 - recall: 0.9548 - val_loss: 0.4810 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 128s 490ms/step - loss: 0.0962 - accuracy: 0.9655 - recall: 0.9768 - val_loss: 0.1437 - val_accuracy: 0.9375 - val_recall: 0.8750\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 128s 491ms/step - loss: 0.0815 - accuracy: 0.9728 - recall: 0.9819 - val_loss: 0.4249 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 993s 4s/step - loss: 0.0530 - accuracy: 0.9789 - recall: 0.9845 - val_loss: 0.4321 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 109s 416ms/step - loss: 0.0370 - accuracy: 0.9862 - recall: 0.9894 - val_loss: 0.5047 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "32/32 [==============================] - 10s 318ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 119s 453ms/step - loss: 0.2331 - accuracy: 0.9114 - recall: 0.9548 - val_loss: 0.2488 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 122s 467ms/step - loss: 0.1035 - accuracy: 0.9618 - recall: 0.9755 - val_loss: 0.3408 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 122s 467ms/step - loss: 0.0778 - accuracy: 0.9726 - recall: 0.9806 - val_loss: 0.3863 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 119s 456ms/step - loss: 0.0562 - accuracy: 0.9808 - recall: 0.9874 - val_loss: 0.1546 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 118s 454ms/step - loss: 0.0592 - accuracy: 0.9776 - recall: 0.9855 - val_loss: 0.1862 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "32/32 [==============================] - 11s 342ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 124s 470ms/step - loss: 0.2037 - accuracy: 0.9222 - recall: 0.9569 - val_loss: 0.3209 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 120s 459ms/step - loss: 0.0949 - accuracy: 0.9649 - recall: 0.9786 - val_loss: 0.1533 - val_accuracy: 0.9375 - val_recall: 0.8750\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 121s 464ms/step - loss: 0.0651 - accuracy: 0.9745 - recall: 0.9809 - val_loss: 0.6746 - val_accuracy: 0.6250 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 121s 464ms/step - loss: 0.0417 - accuracy: 0.9849 - recall: 0.9899 - val_loss: 0.1104 - val_accuracy: 0.9375 - val_recall: 0.8750\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 123s 469ms/step - loss: 0.0392 - accuracy: 0.9852 - recall: 0.9907 - val_loss: 0.0913 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 11s 357ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 123s 464ms/step - loss: 0.2414 - accuracy: 0.9005 - recall: 0.9373 - val_loss: 0.3047 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 121s 462ms/step - loss: 0.1134 - accuracy: 0.9590 - recall: 0.9706 - val_loss: 0.1461 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 123s 472ms/step - loss: 0.0797 - accuracy: 0.9734 - recall: 0.9799 - val_loss: 0.6059 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 123s 471ms/step - loss: 0.0806 - accuracy: 0.9735 - recall: 0.9806 - val_loss: 0.0756 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 122s 466ms/step - loss: 0.0433 - accuracy: 0.9833 - recall: 0.9876 - val_loss: 0.0980 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "32/32 [==============================] - 11s 339ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 121s 462ms/step - loss: 0.2507 - accuracy: 0.9020 - recall: 0.9492 - val_loss: 0.4499 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 119s 456ms/step - loss: 0.1111 - accuracy: 0.9630 - recall: 0.9750 - val_loss: 0.2592 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 122s 468ms/step - loss: 0.0990 - accuracy: 0.9674 - recall: 0.9770 - val_loss: 0.0413 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 120s 461ms/step - loss: 0.0662 - accuracy: 0.9783 - recall: 0.9855 - val_loss: 0.1476 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 121s 463ms/step - loss: 0.0502 - accuracy: 0.9822 - recall: 0.9871 - val_loss: 0.0767 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 12s 369ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 123s 464ms/step - loss: 0.3106 - accuracy: 0.8744 - recall: 0.9574 - val_loss: 0.5764 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 120s 461ms/step - loss: 0.1247 - accuracy: 0.9557 - recall: 0.9755 - val_loss: 0.3048 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 119s 455ms/step - loss: 0.0909 - accuracy: 0.9691 - recall: 0.9796 - val_loss: 0.4451 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 119s 454ms/step - loss: 0.0639 - accuracy: 0.9789 - recall: 0.9866 - val_loss: 0.3004 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 121s 464ms/step - loss: 0.0548 - accuracy: 0.9789 - recall: 0.9871 - val_loss: 0.5416 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "32/32 [==============================] - 12s 373ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 122s 461ms/step - loss: 0.2523 - accuracy: 0.9016 - recall: 0.9530 - val_loss: 0.4193 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 119s 454ms/step - loss: 0.1091 - accuracy: 0.9641 - recall: 0.9757 - val_loss: 0.4822 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 120s 461ms/step - loss: 0.0952 - accuracy: 0.9655 - recall: 0.9750 - val_loss: 0.8330 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 119s 456ms/step - loss: 0.0639 - accuracy: 0.9780 - recall: 0.9848 - val_loss: 0.3217 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 119s 457ms/step - loss: 0.0581 - accuracy: 0.9780 - recall: 0.9840 - val_loss: 0.1960 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 11s 356ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 122s 463ms/step - loss: 0.2629 - accuracy: 0.8850 - recall: 0.9538 - val_loss: 0.2996 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 120s 461ms/step - loss: 0.1170 - accuracy: 0.9586 - recall: 0.9716 - val_loss: 0.4748 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 121s 464ms/step - loss: 0.1097 - accuracy: 0.9641 - recall: 0.9755 - val_loss: 0.2376 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 120s 461ms/step - loss: 0.0750 - accuracy: 0.9758 - recall: 0.9845 - val_loss: 0.5039 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 124s 475ms/step - loss: 0.0496 - accuracy: 0.9818 - recall: 0.9886 - val_loss: 0.2967 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "32/32 [==============================] - 12s 367ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\1013186771.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "\n",
    "#se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "#modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "compara_arqu_batch=pd.DataFrame()\n",
    "\n",
    "epochs=5\n",
    "\n",
    "#bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "for modelo in modelos:\n",
    "    print(f\"Comparando modelo {modelo}...\")\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "        \n",
    "        #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "        model = establecer_arquitectura(modelo)\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\"]) #cambias loss\n",
    "\n",
    "        #ENTRENA\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "        model.fit(train_generator, batch_size=batch_size, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3))\n",
    "\n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "\n",
    "        #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "        #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "\n",
    "        #cambiar .append por .concat\n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f184a38d-61b1-4ed9-a293-db79ba086e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.090848</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.628518</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.725894</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.506410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>0.573718</td>\n",
       "      <td>0.618321</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.708972</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.488034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.840987</td>\n",
       "      <td>0.568910</td>\n",
       "      <td>0.617934</td>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.702104</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.487607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simple1</td>\n",
       "      <td>32</td>\n",
       "      <td>1.229759</td>\n",
       "      <td>0.597756</td>\n",
       "      <td>0.627523</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.731551</td>\n",
       "      <td>0.132479</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.504701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simple1</td>\n",
       "      <td>64</td>\n",
       "      <td>1.415055</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622018</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.725134</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.494444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simple2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.488181</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.622980</td>\n",
       "      <td>0.889744</td>\n",
       "      <td>0.732841</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.110256</td>\n",
       "      <td>0.496154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Simple2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.528218</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.629764</td>\n",
       "      <td>0.889744</td>\n",
       "      <td>0.737513</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.110256</td>\n",
       "      <td>0.508974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Simple2</td>\n",
       "      <td>20</td>\n",
       "      <td>2.025165</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.505556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Simple2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.698808</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.634892</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.132479</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.094872</td>\n",
       "      <td>0.518803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Simple2</td>\n",
       "      <td>64</td>\n",
       "      <td>1.504409</td>\n",
       "      <td>0.607372</td>\n",
       "      <td>0.633517</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.737406</td>\n",
       "      <td>0.149573</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.515812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Simple3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.750229</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.631295</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.742072</td>\n",
       "      <td>0.123932</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.511966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Simple3</td>\n",
       "      <td>16</td>\n",
       "      <td>1.401318</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.726486</td>\n",
       "      <td>0.149573</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.505556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Simple3</td>\n",
       "      <td>20</td>\n",
       "      <td>1.667302</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.623468</td>\n",
       "      <td>0.912821</td>\n",
       "      <td>0.740895</td>\n",
       "      <td>0.081197</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.087179</td>\n",
       "      <td>0.497009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Simple3</td>\n",
       "      <td>32</td>\n",
       "      <td>1.302958</td>\n",
       "      <td>0.578526</td>\n",
       "      <td>0.614004</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.722281</td>\n",
       "      <td>0.081197</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.479060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Simple3</td>\n",
       "      <td>64</td>\n",
       "      <td>1.708965</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.628829</td>\n",
       "      <td>0.894872</td>\n",
       "      <td>0.738624</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.105128</td>\n",
       "      <td>0.507265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Red  BatchSize      Loss  Accuracy  Precision    Recall        F1  \\\n",
       "0   Simple1          8  1.090848  0.594551   0.628518  0.858974  0.725894   \n",
       "1   Simple1         16  0.998152  0.573718   0.618321  0.830769  0.708972   \n",
       "2   Simple1         20  0.840987  0.568910   0.617934  0.812821  0.702104   \n",
       "3   Simple1         32  1.229759  0.597756   0.627523  0.876923  0.731551   \n",
       "4   Simple1         64  1.415055  0.588141   0.622018  0.869231  0.725134   \n",
       "5   Simple2          8  1.488181  0.594551   0.622980  0.889744  0.732841   \n",
       "6   Simple2         16  1.528218  0.604167   0.629764  0.889744  0.737513   \n",
       "7   Simple2         20  2.025165  0.604167   0.627907  0.900000  0.739726   \n",
       "8   Simple2         32  1.698808  0.615385   0.634892  0.905128  0.746300   \n",
       "9   Simple2         64  1.504409  0.607372   0.633517  0.882051  0.737406   \n",
       "10  Simple3          8  1.750229  0.608974   0.631295  0.900000  0.742072   \n",
       "11  Simple3         16  1.401318  0.594551   0.628037  0.861538  0.726486   \n",
       "12  Simple3         20  1.667302  0.600962   0.623468  0.912821  0.740895   \n",
       "13  Simple3         32  1.302958  0.578526   0.614004  0.876923  0.722281   \n",
       "14  Simple3         64  1.708965  0.604167   0.628829  0.894872  0.738624   \n",
       "\n",
       "    Specificity       fpr       fnr       AUC  \n",
       "0      0.153846  0.846154  0.141026  0.506410  \n",
       "1      0.145299  0.854701  0.169231  0.488034  \n",
       "2      0.162393  0.837607  0.187179  0.487607  \n",
       "3      0.132479  0.867521  0.123077  0.504701  \n",
       "4      0.119658  0.880342  0.130769  0.494444  \n",
       "5      0.102564  0.897436  0.110256  0.496154  \n",
       "6      0.128205  0.871795  0.110256  0.508974  \n",
       "7      0.111111  0.888889  0.100000  0.505556  \n",
       "8      0.132479  0.867521  0.094872  0.518803  \n",
       "9      0.149573  0.850427  0.117949  0.515812  \n",
       "10     0.123932  0.876068  0.100000  0.511966  \n",
       "11     0.149573  0.850427  0.138462  0.505556  \n",
       "12     0.081197  0.918803  0.087179  0.497009  \n",
       "13     0.081197  0.918803  0.123077  0.479060  \n",
       "14     0.119658  0.880342  0.105128  0.507265  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compara_arqu_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b8a3-f70f-41ff-822a-b956996a6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, se puede apreciar que la primera arquitectura es la peor de todas (algo que era de esperar) y la mejor opcion es \n",
    "# el Simple 2 ya que, en general (exceptuando para una batch size de 8) obtiene mejores resultados.\n",
    "#Dentro del Simple 2, el mejor valor de batch size es el de 32 ya que es el que presenta mejores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15853-36f9-4980-b52a-7b824f0a700b",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura Simple2 y un batchsize de 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563679f-a18b-4449-a256-59ec9f249590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antes hay que ejecutar train generatos y la funcion de metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520bc8de-be58-4b81-93ad-b5426cd4b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 32 neuronas en su capa oculta...\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 97s 370ms/step - loss: 0.2697 - accuracy: 0.8892 - recall: 0.9585 - val_loss: 0.2821 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 104s 397ms/step - loss: 0.1366 - accuracy: 0.9526 - recall: 0.9711 - val_loss: 0.2648 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 105s 402ms/step - loss: 0.1116 - accuracy: 0.9628 - recall: 0.9770 - val_loss: 0.5137 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 104s 398ms/step - loss: 0.1007 - accuracy: 0.9711 - recall: 0.9804 - val_loss: 0.1297 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 104s 398ms/step - loss: 0.0951 - accuracy: 0.9682 - recall: 0.9757 - val_loss: 0.3667 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "32/32 [==============================] - 10s 303ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\614870970.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 64 neuronas en su capa oculta...\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 106s 404ms/step - loss: 0.2955 - accuracy: 0.8729 - recall: 0.9688 - val_loss: 0.5925 - val_accuracy: 0.7500 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 105s 402ms/step - loss: 0.1477 - accuracy: 0.9496 - recall: 0.9690 - val_loss: 0.1750 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 269s 1s/step - loss: 0.1220 - accuracy: 0.9588 - recall: 0.9732 - val_loss: 0.6564 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 104s 398ms/step - loss: 0.1050 - accuracy: 0.9657 - recall: 0.9760 - val_loss: 0.2635 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 105s 401ms/step - loss: 0.0903 - accuracy: 0.9735 - recall: 0.9812 - val_loss: 0.5154 - val_accuracy: 0.6875 - val_recall: 1.0000\n",
      "32/32 [==============================] - 10s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\614870970.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 128 neuronas en su capa oculta...\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 110s 419ms/step - loss: 0.2938 - accuracy: 0.8894 - recall: 0.9523 - val_loss: 0.3293 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 108s 412ms/step - loss: 0.1106 - accuracy: 0.9641 - recall: 0.9775 - val_loss: 0.1658 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 109s 418ms/step - loss: 0.0799 - accuracy: 0.9734 - recall: 0.9827 - val_loss: 0.2382 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 109s 419ms/step - loss: 0.0583 - accuracy: 0.9793 - recall: 0.9861 - val_loss: 0.0855 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 110s 421ms/step - loss: 0.0516 - accuracy: 0.9816 - recall: 0.9879 - val_loss: 0.1324 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 10s 311ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\614870970.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 156 neuronas en su capa oculta...\n",
      "Epoch 1/5\n",
      "261/261 [==============================] - 115s 436ms/step - loss: 0.2884 - accuracy: 0.9080 - recall: 0.9559 - val_loss: 0.3025 - val_accuracy: 0.8125 - val_recall: 1.0000\n",
      "Epoch 2/5\n",
      "261/261 [==============================] - 113s 433ms/step - loss: 0.0983 - accuracy: 0.9664 - recall: 0.9775 - val_loss: 0.2533 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "261/261 [==============================] - 113s 432ms/step - loss: 0.0708 - accuracy: 0.9753 - recall: 0.9845 - val_loss: 0.1219 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 4/5\n",
      "261/261 [==============================] - 113s 434ms/step - loss: 0.0581 - accuracy: 0.9797 - recall: 0.9861 - val_loss: 0.1625 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "Epoch 5/5\n",
      "261/261 [==============================] - 113s 434ms/step - loss: 0.0421 - accuracy: 0.9829 - recall: 0.9889 - val_loss: 0.1001 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "32/32 [==============================] - 10s 310ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_7748\\614870970.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "num_neuronas=[32, 64, 128, 156] #lista con distintos valores de neuronas para probar\n",
    "#se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "#valor de neuronas en la capa oculta\n",
    "compara_neuronas=pd.DataFrame()\n",
    "input_shape=(150,150,3)\n",
    "epochs=5\n",
    "for neurona in num_neuronas:\n",
    "    print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "\n",
    "    #se emplea el modelo Simple2 que es el que se ha determinado previamente como \"mejor\"\n",
    "    model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), #se va cambiando el valor de \"neurona\" para cada uno de los valores que estan en la lista num_neuronas\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "    #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "    #un problema de clasificación binaria\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\"]) #cambias loss\n",
    "\n",
    "    #ENTRENA\n",
    "    # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 3 épocas (patience)\n",
    "    #se emplea un batch size de 32 que es el que ha dado mejores resultados antes\n",
    "    model.fit(train_generator, batch_size=32, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_loss', patience=3))\n",
    "\n",
    "    #se calculan las métricas\n",
    "    y_test=test_generator.labels\n",
    "    y_pred=model.predict(test_generator)\n",
    "    calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "    #se calcula loss a partir de la evaluación del modelo\n",
    "    loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "\n",
    "    #esto es en caso de querer meter todos estos parametros dentro de metricas (cambiando tambien la linea de arriba, en lugar de metricas loss, accuracy...)\n",
    "    #metricas = f\"Loss: {loss}, Accuracy: {accuracy}, Recall: {recall}, AUC: {AUC}, Precision: {precision}\"\n",
    "\n",
    "    #cambiar .append por .concat\n",
    "    #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "    #(comparando las métricas)\n",
    "    compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65c360a4-ffb8-413a-a82a-7d69e426884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.250637</td>\n",
       "      <td>0.584936</td>\n",
       "      <td>0.617594</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.726505</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.485897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.462056</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.622540</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.733404</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.495299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128.0</td>\n",
       "      <td>1.193642</td>\n",
       "      <td>0.578526</td>\n",
       "      <td>0.620038</td>\n",
       "      <td>0.841026</td>\n",
       "      <td>0.713819</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.158974</td>\n",
       "      <td>0.491026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156.0</td>\n",
       "      <td>1.486128</td>\n",
       "      <td>0.580128</td>\n",
       "      <td>0.616364</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.721277</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.483761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Número de neuronas      Loss  Accuracy  Precision    Recall        F1  \\\n",
       "0                32.0  1.250637  0.584936   0.617594  0.882051  0.726505   \n",
       "1                64.0  1.462056  0.594551   0.622540  0.892308  0.733404   \n",
       "2               128.0  1.193642  0.578526   0.620038  0.841026  0.713819   \n",
       "3               156.0  1.486128  0.580128   0.616364  0.869231  0.721277   \n",
       "\n",
       "   Specificity       fpr       fnr       AUC  \n",
       "0     0.089744  0.910256  0.117949  0.485897  \n",
       "1     0.098291  0.901709  0.107692  0.495299  \n",
       "2     0.141026  0.858974  0.158974  0.491026  \n",
       "3     0.098291  0.901709  0.130769  0.483761  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compara_neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896a523-aac0-42e2-a434-b971f7592f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por lo tanto, se puede apreciar que, el mejor modelo se corresponde con 64 neuronas en la capa oculta ya que, \n",
    "#tiene un valor mayor en la gran parte de métricas (aunque en loss deberia ser menor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70ad44-41bf-4c21-897f-5dfa8f83fe0d",
   "metadata": {},
   "source": [
    "## Trabajando con las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4009464a-c8a2-4e3a-a033-0b0aa6465ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 14s 418ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test=test_generator.labels\n",
    "y_pred=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3ad034-109d-42ea-84b4-950095a5bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred>0.5 #para convertirlo en un problema binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f00f04a-bdf6-458f-b926-3a6ff26d7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión con sklearn? SI\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred) #.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac568af-3f3b-48b4-9c8f-e6c54d5b3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear las metricas a mano a partir de esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd24bd6-2635-472a-b10e-facbf5705f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23, 211],\n",
       "       [ 30, 360]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6952b-3400-4119-987b-414f1fefaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cada vez que ejecuto dan resultados distintos en la matriz de confusión\n",
    "#DUDA: no entiendo muy bien como funciona esto porque da resultados muy malos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3d5d03-8012-46fe-bac0-d9e7cff004d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAGaCAYAAACMk3DyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbCklEQVR4nO3dd1gU59oG8HtpS18p0gSxAEYD2EAFjRWDNRBPji2JkhhjJ0YQYwWNSjR2jcaTGLEGPbFEozGxcmKwAHZFYxQUFcRY6H3n+4OPSVaKs+4qIPfvuua62Jl33nlm68NbZmSCIAggIiIiegad6g6AiIiIagcmDURERCQJkwYiIiKShEkDERERScKkgYiIiCRh0kBERESSMGkgIiIiSfSqOwAiIqLaID8/H4WFhVqpy8DAAIaGhlqp62Vi0kBERPQM+fn5aOxsirT0Eq3UZ2dnh6SkpFqXODBpICIieobCwkKkpZfgVkIjmJtp1rOfmaWEc9tkFBYWMmkgIiJ6VZmayWBqJtOoDiU02786MWkgIiKSqERQokTDOzaVCErtBFMNOHuCiIiIJGFLAxERkURKCFBCs6YGTfevTkwaiIiIJFJCCU07FzSvofqwe4KIiIgkYdJAREQkUYkgaGVRx5o1a+Dp6Qlzc3OYm5vDx8cHP//8s7g9KCgIMplMZenQoYNKHQUFBZgwYQKsra1hYmKCt956C3fu3FH7/Jk0EBERSVQ2pkHTRR2Ojo744osvEB8fj/j4eHTv3h0BAQG4fPmyWKZXr15ITU0Vl/3796vUMXHiROzatQvR0dE4fvw4srOz0a9fP5SUqHexKo5pICIiqsH69++v8njevHlYs2YNTp48iddffx0AIJfLYWdnV+H+GRkZWLduHTZt2gQ/Pz8AwObNm+Hk5IRDhw7B399fcixsaSAiIpJICQElGi5lLQ2ZmZkqS0FBwTOPX1JSgujoaOTk5MDHx0dcf+zYMdjY2MDNzQ0jR45Eenq6uC0hIQFFRUV48803xXUODg5wd3dHbGysWufPpIGIiEgibXZPODk5QaFQiEtkZGSlx7148SJMTU0hl8sxevRo7Nq1Cy1atAAA9O7dG1u2bMGRI0ewePFixMXFoXv37mISkpaWBgMDA1hYWKjUaWtri7S0NLXOn90TRERE1SAlJQXm5ubiY7lcXmnZZs2a4dy5c3jy5Al27NiB4cOHIyYmBi1atMCgQYPEcu7u7vDy8oKzszP27duHAQMGVFqnIAiQydS7pDWTBiIiIomeZ/ZDRXUAEGdDSGFgYAAXFxcAgJeXF+Li4rB8+XKsXbu2XFl7e3s4Ozvj+vXrAErvqFlYWIjHjx+rtDakp6fD19dXrdjZPUFERCSRUkuLpgRBqHQMxMOHD5GSkgJ7e3sAQNu2baGvr4+DBw+KZVJTU3Hp0iW1kwa2NBAREdVg06ZNQ+/eveHk5ISsrCxER0fj2LFjOHDgALKzsxEREYF//etfsLe3R3JyMqZNmwZra2u8/fbbAACFQoERI0YgJCQEVlZWsLS0RGhoKDw8PMTZFFKxpYGoDpg0aRIaNGiAlJSU6g7llXfs2DEYGBhg9+7d1R0KaSgxMRGmpqZYsWKFuE7TmRNlizru37+P999/H82aNUOPHj1w6tQpHDhwAD179oSuri4uXryIgIAAuLm5Yfjw4XBzc8OJEydgZmYm1rF06VIEBgZi4MCB6NixI4yNjbF3717o6uqq96QIVGOtX79eACAAEI4ePVpuu1KpFJo2bSoAELp06fJcx/jqq6+E9evXq7XP0aNHK41JW8LDw4VX5e05ffp0wcnJSdDV1RUUCoXW63/Wc7Vz505BoVAI58+f1/qxSVVqaqpgZ2cnrFq1qrpDIQ3l5OQIr7/+uhAaGioIgiBkZGQIAIQLV2yEpBQ7jZYLV2wEAEJGRkY1n6X62NJQC5iZmWHdunXl1sfExODGjRsq2aS6Vq9ejaioKLX2adOmDU6cOIE2bdo893Hrih9//BHz5s3DsGHDEBMTg0OHDmn9GB999BFOnDhR4babN29i1KhR2LFjBzw9PbV+bPpbSUkJhgwZgmHDhmHcuHHVHQ5paPTo0XB3d8fChQurO5QahWMaaoFBgwZhy5Yt+Oqrr1RG2q5btw4+Pj7IzMx8KXEUFRVBJpPB3Ny83HXNqWKXLl0CAAQHB8PGxuaFHMPR0RGOjo4VbmvSpInKRV7oxdHV1cXRo0erOwzSko0bN1a4XhsDGWvvPS45pqFWGDJkCADg+++/F9dlZGRgx44d+PDDDyvcZ/bs2Wjfvj0sLS1hbm6ONm3aYN26dRD+MVWoUaNGuHz5MmJiYsSbnDRq1AhAab+sTCbDpk2bEBISggYNGkAul+PPP/8Utx07dgwAkJycXO5mKf9cnmXfvn1o1aoV5HI5GjdujEWLFlVYThAErF69Gq1atYKRkREsLCzwzjvv4ObNm1KeRly9ehVDhgyBra0t5HI5GjZsiGHDhqmMQL506RICAgJgYWEBQ0NDtGrVChs2bFCpp+z8v//+e0yfPh0ODg4wNzeHn58frl27pvL8zpgxA0DpRVRkMhkiIiIAQOXvf2rUqBGCgoLEx7m5uQgNDUXjxo1haGgIS0tLeHl5qbwXIiIiyj3PSqUSCxcuxGuvvQa5XA4bGxsMGzas3A1qunbtCnd3d8TFxeGNN96AsbExmjRpgi+++AJK5bO/2mQyGcaPH49NmzahefPmMDY2RsuWLfHTTz+VK3v9+nUMHToUNjY2kMvlaN68Ob766iuVMlFRUZDJZEhOTlZZ//R77p+xnzhxAr6+vjAyMkKjRo2wfv16AKXvqzZt2sDY2BgeHh44cOBAuZiOHz+OHj16wMzMDMbGxvD19cW+ffsqjOno0aMYM2YMrK2tYWVlhQEDBuDevXvlns+uXbuqrJPyWayKOq/R7du38d5776k8x4sXL5b0WjZq1Aj9+vXDgQMH0KZNGxgZGeG1117Dd999V65sWloaRo0aBUdHRxgYGKBx48aYPXs2iouLxTIVvWbA398X/2zhDAoKgqmpKa5evQp/f3+YmJjA3t4eX3zxBQDg5MmT6NSpE0xMTODm5lbuMwlo97NbFlPZ9+E/KSFDiYaLEupdG6EmYUtDLWBubo533nkH3333HUaNGgWgNIHQ0dHBoEGDsGzZsnL7JCcnY9SoUWjYsCGA0g/dhAkTcPfuXcyaNQsAsGvXLrzzzjtQKBRYvXo1gPIXF5k6dSp8fHzw9ddfQ0dHBzY2NuWuIGZvb1+uefzBgwd477330KBBgyrP7fDhwwgICICPjw+io6NRUlKChQsX4v79++XKjho1ClFRUQgODsaCBQvw6NEjzJkzB76+vjh//jxsbW0rPc758+fRqVMnWFtbY86cOXB1dUVqair27NmDwsJCyOVyXLt2Db6+vrCxscGKFStgZWWFzZs3IygoCPfv30dYWJhKndOmTUPHjh3x7bffIjMzE1OmTEH//v2RmJgIXV1d7Nq1C1999RXWrVuHAwcOQKFQVNoiUJlJkyZh06ZNmDt3Llq3bo2cnBxcunQJDx8+rHK/MWPG4D//+Q/Gjx+Pfv36ITk5GTNnzsSxY8dw5swZWFtbi2XT0tLw7rvvIiQkBOHh4di1axemTp0KBwcHDBs27Jkx7tu3D3FxcZgzZw5MTU2xcOFCvP3227h27RqaNGkCALhy5Qp8fX3RsGFDLF68GHZ2dvjll18QHByMv/76C+Hh4Wo9L/+M/YMPPkBYWBgcHR2xcuVKfPjhh0hJScEPP/yAadOmQaFQYM6cOQgMDMTNmzfh4OAAoLR7r2fPnvD09MS6desgl8uxevVq9O/fH99//73KBXOA0m6gvn37YuvWrUhJScHkyZPx3nvv4ciRI1XGKOWzKOU8n/UaPXjwAL6+vigsLMTnn3+ORo0a4aeffkJoaChu3Lghfsarcv78eYSEhOCzzz6Dra0tvv32W4wYMQIuLi7o3LmzGEu7du2go6ODWbNmoWnTpjhx4gTmzp2L5ORkMWlTV1FREQYMGIDRo0dj8uTJ2Lp1K6ZOnYrMzEzs2LEDU6ZMEV/joKAguLu7o23btgCg9c8uVaGax1RQFcoGQsbFxYmDDy9duiQIgiB4e3sLQUFBgiAIwuuvv17lQMiSkhKhqKhImDNnjmBlZSUolUpxW2X7lh2vc+fOlW6rbCBkTk6O0K5dO8He3l5ITk6u8hzbt28vODg4CHl5eeK6zMxMwdLSUmVw34kTJwQAwuLFi1X2T0lJEYyMjISwsLAqj9O9e3ehXr16Qnp6eqVlBg8eLMjlcuH27dsq63v37i0YGxsLT548EQTh7/Pv06ePSrnt27cLAIQTJ06I68oGKT548EClLAAhPDy8XAzOzs7C8OHDxcfu7u5CYGBglef29EDIxMREAYAwduxYlXKnTp0SAAjTpk0T13Xp0kUAIJw6dUqlbIsWLQR/f/8qj1t2Hra2tkJmZqa4Li0tTdDR0REiIyPFdf7+/oKjo2O5gV/jx48XDA0NhUePHgmC8Pd7PikpSaVcRe+5stjj4+PFdQ8fPhR0dXUFIyMj4e7du+L6c+fOCQCEFStWiOs6dOgg2NjYCFlZWeK64uJiwd3dXXB0dBQ/J2UxPf18Lly4UAAgpKamqsT0vJ/Fykh9jT777LMKy40ZM0aQyWTCtWvXqjyOs7OzYGhoKNy6dUtcl5eXJ1haWgqjRo0S140aNUowNTVVKScIgrBo0SIBgHD58mVBECr/nkhKShIAqAzAHj58uABA2LFjh7iuqKhIqF+/vgBAOHPmjLi+7DWeNGmSuO5FfHaHDx8uODs7i4/LBkLGX7YVrt6212iJv2zLgZD0YnXp0gVNmzbFd999h4sXLyIuLq7SrgkAOHLkCPz8/KBQKKCrqwt9fX3MmjULDx8+VKuP+1//+pdacZaUlGDQoEFITEzE/v374ezsXGnZnJwcxMXFYcCAATA0NBTXm5mZlbur208//QSZTIb33nsPxcXF4mJnZ4eWLVuWawL9p9zcXMTExGDgwIGoX79+peWOHDmCHj16wMnJSWV9UFAQcnNzy7WmvPXWWyqPywYa3rp1q9JjqKtdu3b4+eef8dlnn+HYsWPIy8t75j5l/er/7OYoq6t58+Y4fPiwyno7Ozu0a9dOZZ2np6fk8+jWrZvKYFxbW1vY2NiI++fn5+Pw4cN4++23YWxsrPL69enTB/n5+Th58qSkYz3N3t5e/G8TACwtLWFjY4NWrVqJLQoA0Lx5cwB/vzY5OTk4deoU3nnnHZiamorldHV18f777+POnTvlmquf9/WW8llUKpUqz8vTtyuW8hodOXIELVq0KFcuKCgIgiA8s0UEAFq1aiW2iACAoaEh3NzcVI7z008/oVu3bnBwcFCJuXfv3gBKW3Ceh0wmQ58+fcTHenp6cHFxgb29PVq3bi2uL3uNnz73l/XZ1bRromyprZg01BIymQwffPABNm/ejK+//hpubm544403Kix7+vRp8W5m33zzDX7//XfExcVh+vTpACDph6dM2RXFpBo9ejQOHDiAH374Aa1ataqy7OPHj6FUKiu8nevT6+7fvw9BEGBrawt9fX2V5eTJk/jrr7+qPE5JSckzuwYePnxY4fmW/fg83SVgZWWl8risa0ed5/dZVqxYgSlTpmD37t3o1q0bLC0tERgYKF4etiJlcVZ2Ls86D6D0XKSex7P2f/jwIYqLi7Fy5cpyr13Zj0RVr19VLC0ty60zMDAot97AwABAaQIDlL4nBEF44a+31M/inDlzVJ6Xpk2bVnnssuP/89jqvn8rIuU49+/fx969e8u9lmW3aH7e19LY2Fjlnweg4teybH3Zawm8nM8ur3FSimMaapGgoCDMmjULX3/9NebNm1dpuejoaOjr6+Onn35S+RA+z8Vm1LmZSUREBL799lusX79e5RaslbGwsIBMJqvwLmtPr7O2toZMJsNvv/1W4U1dqrrRi6WlJXR1dcsNAnyalZUVUlNTy60vG+z2z3EAmpLL5RVeAvbpLzcTExPMnj0bs2fPxv3798VWh/79++Pq1asV1l32hZiamlouUbp3755Wz0MKCwsL8T/4yqYiNm7cGADE9+vTz83z/hBVFZOOjs4Lf72lfhY//vhj9OvXT3xc1fu5Mi/r/WttbQ1PT89Kv4PKfqhf1msJvJxzLxsgq42Wgtrc0sCkoRZp0KABJk+ejKtXr2L48OGVlpPJZNDT01MZ0JOXl4dNmzaVK6vOf5RVWbduHWbPno05c+aUaxavjImJCdq1a4edO3fiyy+/FL9ksrKysHfvXpWy/fr1wxdffIG7d+9i4MCBasVmZGSELl264L///S/mzZtX6RdIjx49sGvXLty7d0+laXvjxo0wNjbW6jTTRo0a4cKFCyrrjhw5guzs7Er3sbW1RVBQEM6fP49ly5YhNzcXxsbG5cp1794dALB582Z4e3uL6+Pi4pCYmCj+l/uyGBsbo1u3bjh79iw8PT3F//orUjZa/cKFC2jWrJm4fs+ePVqNycTEBO3bt8fOnTuxaNEiGBkZASjtJti8eTMcHR3h5uam8XGkfhYdHBxU3nPPo0ePHoiMjMSZM2dUrqGyceNGyGQydOvWTaP6y/Tr1w/79+9H06ZNy91q+Z/++Vr6+/uL67X9WgIv97OrFGRQCpr96Gu6f3Vi0lDLlE1Bqkrfvn2xZMkSDB06FB9//DEePnyIRYsWVfjfi4eHB6Kjo7Ft2zY0adIEhoaG8PDwUCumEydOYPTo0ejYsSN69uxZrn+6qg/s559/jl69eqFnz54ICQlBSUkJFixYABMTEzx69Egs17FjR3z88cf44IMPEB8fj86dO8PExASpqak4fvw4PDw8MGbMmEqPs2TJEnTq1Ant27fHZ599BhcXF9y/fx979uzB2rVrYWZmhvDwcLG/dtasWbC0tMSWLVuwb98+LFy4EAqFQq3npSrvv/8+Zs6ciVmzZqFLly64cuUKVq1aVe4Y7du3R79+/eDp6QkLCwskJiZi06ZN8PHxqTBhAEpvofvxxx9j5cqV0NHRQe/evcXZE05OTvj000+1dh5SLV++HJ06dcIbb7yBMWPGoFGjRsjKysKff/6JvXv3iv3t3t7eaNasGUJDQ1FcXAwLCwvs2rULx48f13pMkZGR6NmzJ7p164bQ0FAYGBhg9erVuHTpEr7//nu1bxlcEXU+i5r69NNPsXHjRvTt2xdz5swRb428evVqjBkzRitJEFDalXLw4EH4+voiODgYzZo1Q35+PpKTk7F//358/fXXcHR0hJ2dHfz8/BAZGQkLCws4Ozvj8OHD2Llzp1bi+KeX8dktS8brOiYNr6Du3bvju+++w4IFC9C/f380aNAAI0eOhI2NDUaMGKFSdvbs2UhNTcXIkSORlZUFZ2fncnPkn+XatWsoLi7G77//Dh8fn3LbhSrmo/fs2RO7d+/GjBkzMGjQINjZ2WHs2LHIy8vD7NmzVcquXbsWHTp0wNq1a7F69WoolUo4ODigY8eO5QZ/Pa1ly5Y4ffo0wsPDMXXqVGRlZcHOzg7du3cX//Nt1qwZYmNjMW3aNIwbNw55eXlo3rw51q9fL7n1RKrJkycjMzMTUVFRWLRoEdq1a4ft27cjICBApVz37t2xZ88eLF26FLm5uWjQoAGGDRv2zNaCNWvWoGnTpli3bh2++uorKBQK9OrVC5GRkRX2W79oLVq0wJkzZ/D5559jxowZSE9PR7169eDq6qoy+E1XVxd79+7F+PHjMXr0aMjlcgwePBirVq1C3759tRpTly5dcOTIEYSHhyMoKAhKpRItW7bEnj17VLoKNKHOZ1FT9evXR2xsLKZOnSpOVWzSpAkWLlyISZMmae049vb2iI+Px+eff44vv/wSd+7cgZmZGRo3boxevXqptD5s2rQJEyZMwJQpU1BSUiJOZ/Xy8tJaPMDL+eyWJV11vXtCJlT1jU5ERETIzMyEQqHAkUtOMDXTbA5BdpYS3d1TkJGRoXKV39qAsyeIiIhIEnZPEBERSSRoYSCkwIGQREREr766PqaB3RNEREQkCVsaiIiIJCoRdFCi4R0YSmrx9AMmDURERBIpIYNSw0Z6JWpv1sCkgaBUKnHv3j2YmZlp5YI2RETVTRAEZGVlwcHBATo67InXFiYNhHv37pW7OxwR0asgJSXlmTerU0ddHwjJpIHE2xp3Qh/oQb+ao6FX3Z+rWj+7EJGGlHn5uDf5C5XbtmuDdsY0sHuCarGyLgk96ENPxqSBXiwdI8NnFyLSEna5aheTBiIiIolKB0JqeJdLdk8QERG9+pTQQUkdnj3BIaVEREQkCVsaiIiIJOJASCIiIpJECZ06fXEndk8QERGRJGxpICIikqhEkKFEw1tba7p/dWLSQEREJFGJFmZPlLB7goiIiF51bGkgIiKSSCnoQKnh7AklZ08QERG9+tg9QURERCQBWxqIiIgkUkLz2Q9K7YRSLZg0EBERSaSdizvV3kb+2hs5ERERvVRsaSAiIpJIO/eeqL3/rzNpICIikkgJGZTQdExD7b0iZO1Nd4iIiOilYksDERGRROyeICIiIkm0c3Gn2ps01N7IiYiI6KViSwMREZFESkEGpaYXd+KtsYmIiF59Si10T/DiTkRERPTKY9JAREQkUdmtsTVd1LFmzRp4enrC3Nwc5ubm8PHxwc8//yxuFwQBERERcHBwgJGREbp27YrLly+r1FFQUIAJEybA2toaJiYmeOutt3Dnzh21z59JAxERkUQlkGllUYejoyO++OILxMfHIz4+Ht27d0dAQICYGCxcuBBLlizBqlWrEBcXBzs7O/Ts2RNZWVliHRMnTsSuXbsQHR2N48ePIzs7G/369UNJSYlasTBpICIiqsH69++PPn36wM3NDW5ubpg3bx5MTU1x8uRJCIKAZcuWYfr06RgwYADc3d2xYcMG5ObmYuvWrQCAjIwMrFu3DosXL4afnx9at26NzZs34+LFizh06JBasTBpICIikkib3ROZmZkqS0FBwTOPX1JSgujoaOTk5MDHxwdJSUlIS0vDm2++KZaRy+Xo0qULYmNjAQAJCQkoKipSKePg4AB3d3exjFRMGoiIiCQqgTa6KEo5OTlBoVCIS2RkZKXHvXjxIkxNTSGXyzF69Gjs2rULLVq0QFpaGgDA1tZWpbytra24LS0tDQYGBrCwsKi0jFSccklERFQNUlJSYG5uLj6Wy+WVlm3WrBnOnTuHJ0+eYMeOHRg+fDhiYmLE7TKZ6jgJQRDKrXualDJPY9JAREQk0fPMfqioDgDibAgpDAwM4OLiAgDw8vJCXFwcli9fjilTpgAobU2wt7cXy6enp4utD3Z2digsLMTjx49VWhvS09Ph6+urVuzsniAiIpKo7IZVmi6aEgQBBQUFaNy4Mezs7HDw4EFxW2FhIWJiYsSEoG3bttDX11cpk5qaikuXLqmdNLClgYiIqAabNm0aevfuDScnJ2RlZSE6OhrHjh3DgQMHIJPJMHHiRMyfPx+urq5wdXXF/PnzYWxsjKFDhwIAFAoFRowYgZCQEFhZWcHS0hKhoaHw8PCAn5+fWrEwaSAiIpJIgAxKNa+zUFEd6rh//z7ef/99pKamQqFQwNPTEwcOHEDPnj0BAGFhYcjLy8PYsWPx+PFjtG/fHr/++ivMzMzEOpYuXQo9PT0MHDgQeXl56NGjB6KioqCrq6tWLDJBEAS19qBXTmZmJhQKBboiAHoy/eoOh15xf3zrVd0hUB2gzMvHnfERyMjIkDxuoCpl35OTY/tCbqrZ92RBdhG+9N2ntdheJo5pICIiIknYPUFERCQRb41NREREkpRo4dbYmu5fnWpv5ERERPRSsaWBiIhIInZPEBERkSRK6ECpYSO9pvtXp9obOREREb1UbGkgIiKSqESQoUTD7gVN969OTBqIiIgkqutjGtg9QURERJKwpYGIiEgiQQu3xha0cJfL6sKkgYiISKISyFCi4Q2rNN2/OtXedIeIiIheKrY0EBERSaQUNB/IqKzF95Zm0kBERCSRUgtjGjTdvzrV3siJiIjopWJLAxERkURKyKDUcCCjpvtXJyYNREREEtX1K0Kye4KIiIgkYUsDERGRRHV9ICSTBiIiIomU0MK9J2rxmIbam+4QERHRS8WWBiIiIokELcyeEGpxSwOTBiIiIol4a2wiIiIiCdjSQEREJBFnTxAREZEk7J4gIiIikoAtDURERBLx3hNEREQkCbsniIiIiCRgSwMREZFEbGkgIiIikoBJQy30yy+/YP369dUdBhFRnVPW0qDpUluxe6KWOX/+PD766CP8+uuv1R1KnTBo/H107JMBJ5cCFObr4Eq8MdbNs8edG4ZimfdC0tA14AnqOxShqFCGPy8aYf0Xdrh21qQaI6eazGJ/KszOPIZBaj6UBjrIb2qKB+84osju7/eVacJjKP73AIa3cqGbXYxbs1qgoKGxSj2KmAcwO/UQ8tu50M1X4s8VraA05tf6i8TuCao1Hj9+jHfffRfR0dFo3rx5dYdTJ3j65GBvlDUm9nPF1MFNoKsrYP73NyE3KhHL3L0px1fTG2BUdzeEBLogLcUAkd/fhMKyuBojp5rM+FoWnnSzwe1pzXFnkhugFOC45A/ICv5+X8kKlchzMcWDAQ0qrUdWqESOuwKP+ti/jLCJ2NJQm1hYWODSpUvVHUadMv3dJiqPF3/aENsvXYarZx4unTIFABzdZaFS5j8RDug99BEat8jDueNmLy1Wqj3ufuqm8vj+B43Q9NPzMLyVizy30vdMlo8VAEDvr4JK63nS0xYAYHQ18wVFSk8ToPl1FgTthFItXrmWhq5duyI4OBhhYWGwtLSEnZ0dIiIixO0ZGRn4+OOPYWNjA3Nzc3Tv3h3nz58XtwcFBSEwMFClzokTJ6Jr164qx5gwYQImTpwICwsL2Nra4j//+Q9ycnLwwQcfwMzMDE2bNsXPP/+sUk9MTAzatWsHuVwOe3t7fPbZZyguLlapt6rYAUAmk2H37t3i4ylTpsDNzQ3GxsZo0qQJZs6ciaKioud+/qhqJual/wlmPdGtcLuevhJ93nuI7Awd3Lxi9DJDo1pMJ7f0fVViwv/jarq6PqbhlUsaAGDDhg0wMTHBqVOnsHDhQsyZMwcHDx6EIAjo27cv0tLSsH//fiQkJKBNmzbo0aMHHj16pPYxrK2tcfr0aUyYMAFjxozBv//9b/j6+uLMmTPw9/fH+++/j9zcXADA3bt30adPH3h7e+P8+fNYs2YN1q1bh7lz50qKvTJmZmaIiorClStXsHz5cnzzzTdYunRplbEXFBQgMzNTZSEpBHwccQ+XTpng1jXVhKC9XyZ2X7+IvUkX8fbIB5g6uCkyH/EHgCQQBNTfnoJcV1MUNmCiSTXbK5k0eHp6Ijw8HK6urhg2bBi8vLxw+PBhHD16FBcvXsR///tfeHl5wdXVFYsWLUK9evXwww8/qHWMli1bYsaMGXB1dcXUqVNhZGQEa2trjBw5Eq6urpg1axYePnyICxcuAABWr14NJycnrFq1Cq+99hoCAwMxe/ZsLF68GEql8pmxV2bGjBnw9fVFo0aN0L9/f4SEhGD79u1Vxh4ZGQmFQiEuTk5Oap17XTVu/l00bp6HyLENy20797sJxvZ0w6dvuSD+mDmmr70FhRVbfOjZbLbehvxOHtJGNnl2Yap2bGl4BXl6eqo8tre3R3p6OhISEpCdnQ0rKyuYmpqKS1JSEm7cuPHcx9DV1YWVlRU8PDzEdba2pX2N6enpAIDExET4+PhAJvv7zdKxY0dkZ2fjzp07z4y9Mj/88AM6deoEOzs7mJqaYubMmbh9+3aVsU+dOhUZGRnikpKSIuGM67axc+/A581MhL3TFH+lGpTbXpCni3vJclw9Y4KlIU4oKQZ6DVGv9Yrqnvpbb8Pk3BOkhDZDsWX59xXVPHU9aXgl20/19fVVHstkMiiVSiiVStjb2+PYsWPl9qlXrx4AQEdHB4KgOkylojECFR3jn+vKkoOyVgRBEFQShrJ1/yxbVewVOXnyJAYPHozZs2fD398fCoUC0dHRWLx4cYXly8jlcsjl8irLUBkB4+bdhW+vDEx+xwX3U6Q9bzIZoC+vzcOd6IUSBNhsvQ3Ts0+QMrkZiuvz80i1wyuZNFSmTZs2SEtLg56eHho1alRhmfr165eboXDu3LlyP+bqatGiBXbs2KGSPMTGxsLMzAwNGlQ+paoqv//+O5ydnTF9+nRx3a1btzSKk1SNn38X3d5+jIgPGiMvWwcW9UsTyJwsXRTm60BuVIKhn6TjxK/meHRfH+aWxeg3/CGs7Yvw29561Rs81Vg2W27D7NQj3BvvAqWhLnQzSt9XSiNdCAalDcA62cXQf1QIvSeFAAD9tHwAQLFCHyWK0u8j3Ywi6GUUQT+9dIaF/E4elIa6KLI0gNK0Tn29vzR1/ToNdepd5efnBx8fHwQGBmLBggVo1qwZ7t27h/379yMwMBBeXl7o3r07vvzyS2zcuBE+Pj7YvHkzLl26hNatW2t07LFjx2LZsmWYMGECxo8fj2vXriE8PByTJk2Cjs7z9RK5uLjg9u3biI6Ohre3N/bt24ddu3ZpFCep6h/0EACwaKdq99WiiU44uN0SSqUMji4FmPnvZJhbliDrsS7+OG+MkLddcOsPw4qqJEK9Yw8AAE5fXlNZn/ZBI2R2tAYAmJ5/Arv1yeI2h//cBAA87G+PhwEN/r+edFjtTRXLOC28Vq4e0i5BkEHQ8Edf0/2rU51KGmQyGfbv34/p06fjww8/xIMHD2BnZ4fOnTuLYxD8/f0xc+ZMhIWFIT8/Hx9++CGGDRuGixcvanTsBg0aYP/+/Zg8eTJatmwJS0tLjBgxAjNmzHjuOgMCAvDpp59i/PjxKCgoQN++fTFz5sxy0zTp+fk7tKxye1GBDj7/qNHLCYZeGX986/XMMpkdrZ/5w/8woIGYQBC9DDLh6Q58qnMyMzOhUCjQFQHQk2nWDUP0LFJ+MIk0pczLx53xEcjIyIC5ubnG9ZV9T/r8OAF6JpqNQSnOKcCJgJVai+1leiVnTxAREb0I1TF7IjIyEt7e3jAzM4ONjQ0CAwNx7Zpq11ZQUBBkMpnK0qFDB5UyBQUFmDBhAqytrWFiYoK33npLZfaeFEwaiIiIarCYmBiMGzcOJ0+exMGDB1FcXIw333wTOTk5KuV69eqF1NRUcdm/f7/K9okTJ2LXrl2Ijo7G8ePHkZ2djX79+qGkpARS1akxDURERJqojoGQBw4cUHm8fv162NjYICEhAZ07dxbXy+Vy2NnZVVhHRkYG1q1bh02bNsHPzw8AsHnzZjg5OeHQoUPw9/eXFAtbGoiIiCTSZvfE05fzLyio/OZk/5SRkQEAsLS0VFl/7Ngx2NjYwM3NDSNHjlS5MGBCQgKKiorw5ptviuscHBzg7u6O2NhYyefPpIGIiKgaODk5qVzSPzIy8pn7CIKASZMmoVOnTnB3dxfX9+7dG1u2bMGRI0ewePFixMXFoXv37mIikpaWBgMDA1hYqN6V19bWFmlpaZJjZvcEERGRRNrsnkhJSVGZPSHlSr3jx4/HhQsXcPz4cZX1gwYNEv92d3eHl5cXnJ2dsW/fPgwYMKCKWMpfrbgqTBqIiIgkErRwRciypMHc3FytKZcTJkzAnj178L///Q+Ojo5VlrW3t4ezszOuX78OALCzs0NhYSEeP36s0tqQnp4OX19fyTGwe4KIiKgGEwQB48ePx86dO3HkyBE0btz4mfs8fPgQKSkpsLe3BwC0bdsW+vr6OHjwoFgmNTUVly5dUitpYEsDERGRRAIATS+JqO7u48aNw9atW/Hjjz/CzMxMHIOgUChgZGSE7OxsRERE4F//+hfs7e2RnJyMadOmwdraGm+//bZYdsSIEQgJCYGVlRUsLS0RGhoKDw8PcTaFFEwaiIiIJFJCBhk0vGGVmvuvWbMGANC1a1eV9evXr0dQUBB0dXVx8eJFbNy4EU+ePIG9vT26deuGbdu2wczMTCy/dOlS6OnpYeDAgcjLy0OPHj0QFRUFXV1dybEwaSAiIqrBnnW3ByMjI/zyyy/PrMfQ0BArV67EypUrnzsWJg1EREQS8S6XREREJIlSkEGm4Y++prMvqhNnTxAREZEkbGkgIiKSSBC0MHtCw/2rE5MGIiIiier6mAZ2TxAREZEkbGkgIiKSqK63NDBpICIikoizJ4iIiIgkYEsDERGRRJw9QURERJKUJg2ajmnQUjDVgN0TREREJAlbGoiIiCTi7AkiIiKSRPj/RdM6ait2TxAREZEkbGkgIiKSiN0TREREJE0d759g9wQRERFJwpYGIiIiqbTQPQF2TxAREb366voVIdk9QURERJKwpYGIiEgizp4gIiIiaQSZ5mMSanHSwO4JIiIikoQtDURERBLV9YGQTBqIiIik4sWdiIiIiJ6NLQ1EREQScfaEBCtWrJBcYXBw8HMHQ0REVOPV4u4FTUlKGpYuXSqpMplMxqSBiIjoFSUpaUhKSnrRcRAREdV4db174rkHQhYWFuLatWsoLi7WZjxEREQ1l6ClpZZSO2nIzc3FiBEjYGxsjNdffx23b98GUDqW4YsvvtB6gERERFQzqJ00TJ06FefPn8exY8dgaGgorvfz88O2bdu0GhwREVHNItPSUjupPeVy9+7d2LZtGzp06ACZ7O8Tb9GiBW7cuKHV4IiIiGoUXtxJPQ8ePICNjU259Tk5OSpJBBEREb1a1E4avL29sW/fPvFxWaLwzTffwMfHR3uRERER1TR1fCCk2t0TkZGR6NWrF65cuYLi4mIsX74cly9fxokTJxATE/MiYiQiIqoZeGts9fj6+uL3339Hbm4umjZtil9//RW2trY4ceIE2rZt+yJiJCIiohrgue494eHhgQ0bNmg7FiIiohqNt8Z+DiUlJdi1axcSExMhk8nQvHlzBAQEQE+P978iIqJXWB2fPaH2r/ylS5cQEBCAtLQ0NGvWDADwxx9/oH79+tizZw88PDy0HiQRERFVP7XHNHz00Ud4/fXXcefOHZw5cwZnzpxBSkoKPD098fHHH7+IGImIiGqGsoGQmi61lNotDefPn0d8fDwsLCzEdRYWFpg3bx68vb21GhwREVFNIhNKF03rqK3Ubmlo1qwZ7t+/X259eno6XFxctBIUERER1TySWhoyMzPFv+fPn4/g4GBERESgQ4cOAICTJ09izpw5WLBgwYuJkoiIqCao4wMhJbU01KtXDxYWFrCwsED//v1x5coVDBw4EM7OznB2dsbAgQNx6dIl9O/f/0XHS0REVH2qYUxDZGQkvL29YWZmBhsbGwQGBuLatWuqYQkCIiIi4ODgACMjI3Tt2hWXL19WKVNQUIAJEybA2toaJiYmeOutt3Dnzh21YpHU0nD06FG1KiUiIiLtiImJwbhx4+Dt7Y3i4mJMnz4db775Jq5cuQITExMAwMKFC7FkyRJERUXBzc0Nc+fORc+ePXHt2jWYmZkBACZOnIi9e/ciOjoaVlZWCAkJQb9+/ZCQkABdXV1JsUhKGrp06fKcp0pERPQKqYbuiQMHDqg8Xr9+PWxsbJCQkIDOnTtDEAQsW7YM06dPx4ABAwAAGzZsgK2tLbZu3YpRo0YhIyMD69atw6ZNm+Dn5wcA2Lx5M5ycnHDo0CH4+/tLiuW5r8aUm5uL27dvo7CwUGW9p6fn81ZJRERUs2kxafjneEEAkMvlkMvlz9w9IyMDAGBpaQkASEpKQlpaGt58802Vurp06YLY2FiMGjUKCQkJKCoqUinj4OAAd3d3xMbGvrik4cGDB/jggw/w888/V7i9pKRE3SqJiIjqHCcnJ5XH4eHhiIiIqHIfQRAwadIkdOrUCe7u7gCAtLQ0AICtra1KWVtbW9y6dUssY2BgoHK5hLIyZftLoXbSMHHiRDx+/BgnT55Et27dsGvXLty/fx9z587F4sWL1a2OiIio9tBiS0NKSgrMzc3F1VJaGcaPH48LFy7g+PHj5bbJZKoDLAVBKLeuXCgSyvyT2knDkSNH8OOPP8Lb2xs6OjpwdnZGz549YW5ujsjISPTt21fdKomIiGoHLd4a29zcXCVpeJYJEyZgz549+N///gdHR0dxvZ2dHYDS1gR7e3txfXp6utj6YGdnh8LCQjx+/FiltSE9PR2+vr6SY1D74k45OTmwsbEBUNqf8uDBAwCld748c+aMutURERFRFQRBwPjx47Fz504cOXIEjRs3VtneuHFj2NnZ4eDBg+K6wsJCxMTEiAlB27Ztoa+vr1ImNTUVly5dUitpULuloVmzZrh27RoaNWqEVq1aYe3atWjUqBG+/vprlQyHiIjoVVMdl5EeN24ctm7dih9//BFmZmbiGASFQgEjIyPIZDJMnDgR8+fPh6urK1xdXTF//nwYGxtj6NChYtkRI0YgJCQEVlZWsLS0RGhoKDw8PMTZFFI815iG1NRUAKWDNvz9/bFlyxYYGBggKipK3eqIiIhqj2qYcrlmzRoAQNeuXVXWr1+/HkFBQQCAsLAw5OXlYezYsXj8+DHat2+PX3/9VbxGAwAsXboUenp6GDhwIPLy8tCjRw9ERUVJvkYDAMgEQdDo9HNzc3H16lU0bNgQ1tbWmlRF1SQzMxMKhQJdEQA9mX51h0OvuD++9aruEKgOUObl4874CGRkZKg1bqAyZd+TDRfMhY6Rocax3Z4yQ2uxvUzPfZ2GMsbGxmjTpo02YiEiIqIaTFLSMGnSJMkVLlmy5LmDISIiqslk0MKYBq1EUj0kJQ1nz56VVJk6cz2p5pHJ5ZCxe4JesKQ+31Z3CFQHZGYpYfHsYqQm3rCKiIhIKi1ep6E20nhMAxERUZ1RDbMnahK1L+5EREREdRNbGoiIiKSq4y0NTBqIiIgkqo4rQtYk7J4gIiIiSZ4radi0aRM6duwIBwcH8V7dy5Ytw48//qjV4IiIiGoUQUtLLaV20rBmzRpMmjQJffr0wZMnT1BSUgIAqFevHpYtW6bt+IiIiGoOJg3qWblyJb755htMnz5d5SYXXl5euHjxolaDIyIioppD7YGQSUlJaN26dbn1crkcOTk5WgmKiIioJuJASDU1btwY586dK7f+559/RosWLbQRExERUc1UdkVITZdaSu2WhsmTJ2PcuHHIz8+HIAg4ffo0vv/+e0RGRuLbb3lNeSIioleV2knDBx98gOLiYoSFhSE3NxdDhw5FgwYNsHz5cgwePPhFxEhERFQz8OJO6hs5ciRGjhyJv/76C0qlEjY2NtqOi4iIqMap62MaNLoipLW1tbbiICIiohpO7aShcePGkMkqH8Rx8+ZNjQIiIiKqsdg9oZ6JEyeqPC4qKsLZs2dx4MABTJ48WVtxERER1Txa6J6oU0nDJ598UuH6r776CvHx8RoHRERERDWT1m5Y1bt3b+zYsUNb1REREdU8dfwy0lq7NfYPP/wAS0tLbVVHRERU83BMg3pat26tMhBSEASkpaXhwYMHWL16tVaDIyIioppD7aQhMDBQ5bGOjg7q16+Prl274rXXXtNWXERERDUOr9OghuLiYjRq1Aj+/v6ws7N7UTERERFRDaTWQEg9PT2MGTMGBQUFLyoeIiIiqqHUnj3Rvn17nD179kXEQkREVLNx9oR6xo4di5CQENy5cwdt27aFiYmJynZPT0+tBUdERFSTcEyDRB9++CGWLVuGQYMGAQCCg4PFbTKZDIIgQCaToaSkRPtREhERUbWTnDRs2LABX3zxBZKSkl5kPERERDVbLW4p0JTkpEEQSp8lZ2fnFxYMERFRjVbHL+6k1kDIqu5uSURERK82tQZCurm5PTNxePTokUYBERER1VQcCKmG2bNnQ6FQvKhYiIiIarY63j2hVtIwePBg2NjYvKhYiIiIqAaTnDRwPAMREdV17J6QqGz2BBERUZ3F7glplErli4yDiIiIaji1LyNNRERUZ7GlgYiIiKSo62Ma1L7LJREREdVNbGkgIiKSit0TREREJEkdTxrYPUFERESSsKWBiIhIIg6EJCIiImkELS1q+N///of+/fvDwcEBMpkMu3fvVtkeFBQEmUymsnTo0EGlTEFBASZMmABra2uYmJjgrbfewp07d9QLBEwaiIiIarScnBy0bNkSq1atqrRMr169kJqaKi779+9X2T5x4kTs2rUL0dHROH78OLKzs9GvXz+UlJSoFQu7J4iIiCSqju6J3r17o3fv3lWWkcvlsLOzq3BbRkYG1q1bh02bNsHPzw8AsHnzZjg5OeHQoUPw9/eXHAtbGoiIiKTSYvdEZmamylJQUPDcYR07dgw2NjZwc3PDyJEjkZ6eLm5LSEhAUVER3nzzTXGdg4MD3N3dERsbq9ZxmDQQERFVAycnJygUCnGJjIx8rnp69+6NLVu24MiRI1i8eDHi4uLQvXt3MQlJS0uDgYEBLCwsVPaztbVFWlqaWsdi9wQREZFUWrxOQ0pKCszNzcXVcrn8uaobNGiQ+Le7uzu8vLzg7OyMffv2YcCAAZWHIQiQyWRqHYstDURERBLJtLQAgLm5ucryvEnD0+zt7eHs7Izr168DAOzs7FBYWIjHjx+rlEtPT4etra1adTNpICIieoU8fPgQKSkpsLe3BwC0bdsW+vr6OHjwoFgmNTUVly5dgq+vr1p1s3uCiIhIqmq4jHR2djb+/PNP8XFSUhLOnTsHS0tLWFpaIiIiAv/6179gb2+P5ORkTJs2DdbW1nj77bcBAAqFAiNGjEBISAisrKxgaWmJ0NBQeHh4iLMppGLSQEREJFF1TLmMj49Ht27dxMeTJk0CAAwfPhxr1qzBxYsXsXHjRjx58gT29vbo1q0btm3bBjMzM3GfpUuXQk9PDwMHDkReXh569OiBqKgo6OrqqhULkwYiIqIarGvXrhCEyjONX3755Zl1GBoaYuXKlVi5cqVGsTBpICIikqqO3+WSSQMREZE6avGPvqY4e4KIiIgkYUsDERGRRHX91thMGoiIiKSq42Ma2D1BREREkrClgYiISCJ2TxAREZE07J4gIiIieja2NBAREUnE7gkiIiKSht0TRERERM/GlgYiIiKp6nhLA5MGIiIiier6mAZ2TxAREZEkbGkgIiKSit0TREREJIVMECATNPvV13T/6sTuCSIiIpKELQ21lFKpxJIlS9CjRw+0bt26usN5ZfV99z76vZcOmwYFAIDb142wZUUDxMfU+/8SAt775C56D3kAU0Uxrp0zxVeznHHrunG1xUw1394NVti30Rr3UwwAAM7N8vHup2nw7p4llrl9XY51cx1w4aQpBGVpmelfJ8PGsQgAUFggwzdzHHBstwUK8mVo3Skb4yPvoL5DUbWcU51Rx7sn2NJQS82YMQMxMTHw9PSs7lBeaX+lGeC7BU4IDngdwQGv49wJc4T/5zqcXXMBAP8elYq3R6RhdbgzggNex6MH+pi/6RqMTEqqOXKqyerbF+HDafew8uc/sPLnP9CyYxYiPmiM5GuGAIB7yQaYFOgKJ5d8fPnDn1hz6BqGTrwPA8O/f22+Dm+A2AMKTF2TjCW7/0Rerg5mDWuCEr71Xqiy2ROaLrUVk4ZaaPfu3Th27Bi2bdsGXV3d6g7nlXbqsAXijtXD3SQj3E0ywoZFTsjP1cFrrXMACHj7w/uI/soBv/9iiVt/GGNxaBPIjZTo9tbD6g6darAOb2aiXY8sODYtgGPTAnzwWRoMTZS4mlDaQhX1hT3adc/ERzNT4eKRB3vnQrT3y0Q962IAQE6mDn753hIjZ91Dm87ZcPHIw5SVt5B81RBnfzOrzlOjVxyThlooMDAQsbGxMDZmE/jLpKMjoEu/h5AbKZF4xhR2TgWwtCnCmd8UYpmiQh1cPGWG5m2zqqiJ6G8lJcCx3fVQkKuD5l45UCqB04fN0aBJAaYNaYKBHq8juK8rYn/++312/YIxiot00LbL3+8zK7tiOL+WjytxJtVxGnWHoKWllqrWpKFr164IDg5GWFgYLC0tYWdnh4iICJUyt2/fRkBAAExNTWFubo6BAwfi/v37ldaZnJwMmUyGnTt3olu3bjA2NkbLli1x4sQJlXKxsbHo3LkzjIyM4OTkhODgYOTk5IjbZTIZdu/erbJPvXr1EBUVpXKc7du344033oCRkRG8vb3xxx9/IC4uDl5eXjA1NUWvXr3w4MEDsQ6lUok5c+bA0dERcrkcrVq1woEDB9SKPyoqCvXq1RMf37hxAwEBAbC1tYWpqSm8vb1x6NChSp+jgoICZGZmqixUuUbNcrHrUjz2XovDhHnJ+Hy0K27/aQSL+qV9x4//0lcp//gvfVjWZ78yVS0p0RABLh7o16glVnzmhFnrkuDsVoAnf+khL0cX21bZwKtbFiK/v4mOvTIw56NGuHCiNCF4lK4HfQMlzOqp9kVYWBfh8QMOVXuR2D1RzTZs2AATExOcOnUKCxcuxJw5c3Dw4EEAgCAICAwMxKNHjxATE4ODBw/ixo0bGDRo0DPrnT59OkJDQ3Hu3Dm4ublhyJAhKC4ubdq7ePEi/P39MWDAAFy4cAHbtm3D8ePHMX78eLXjDw8Px4wZM3DmzBno6elhyJAhCAsLw/Lly/Hbb7/hxo0bmDVrllh++fLlWLx4MRYtWoQLFy7A398fb731Fq5fvy45/qdlZ2ejT58+OHToEM6ePQt/f3/0798ft2/frrB8ZGQkFAqFuDg5Oal93nXJnZuGGNvXHRMHtMC+zTYIWXQTDV3y/i7w1BeATAYIguzlBkm1jmPTAqw+eA3Lf/oD/Yb9hUWfOOPWH3IIytLtPv6ZGPDxAzR1z8OgCelo75eJfRutq6xTEGQA33r0AlV70uDp6Ynw8HC4urpi2LBh8PLywuHDhwEAhw4dwoULF7B161a0bdsW7du3x6ZNmxATE4O4uLgq6w0NDUXfvn3h5uaG2bNn49atW/jzzz8BAF9++SWGDh2KiRMnwtXVFb6+vlixYgU2btyI/Px8teIPDQ2Fv78/mjdvjk8++QRnzpzBzJkz0bFjR7Ru3RojRozA0aNHxfKLFi3ClClTMHjwYDRr1gwLFixAq1atsGzZMsnxP61ly5YYNWoUPDw84Orqirlz56JJkybYs2dPheWnTp2KjIwMcUlJSVHrnOua4iIdpN4yxPWLplj/pROSEo0R+EEaHj8obWGweKpVoZ5VER7/xf/2qGr6BgIaNC6EW8s8fDgtFY1b5GH3t/VhblkCXT0Bzm6q30VOrvlIv1v6nrO0KUZRoQ6ynqiOaXryUA8W1hX/c0Fawu6J6vX06H97e3ukp6cDABITE+Hk5KTyn3CLFi1Qr149JCYmSq7X3t4eAMR6ExISEBUVBVNTU3Hx9/eHUqlEUlLSc8dva2sLAPDw8FBZV3bczMxM3Lt3Dx07dlSpo2PHjuXOp6r4n5aTk4OwsDDxuTE1NcXVq1crbWmQy+UwNzdXWUgNstIv/LQUOR6l66P1G3937+jpK+HRPguJCRyMRuorKtSBvoEAt5a5uHNDrrLt7k25ON3S1TMXevpKnPnf3++zh/f1cOuqIVp454BenLrePVHt/w7p66v2B8tkMiiVpe1zgiBAJivf1lbZ+srqLStbVq9SqcSoUaMQHBxcbr+GDRuK+whPXbWrqKh8P3VFx3l6Xdlxny5X1flUFf/TJk+ejF9++QWLFi2Ci4sLjIyM8M4776CwsLDC8iRdUGgK4mLq4a97BjAyLUGX/g/h2SETM4KaAZBh13e2GDz2Hu4lyXE32RCDx95DQZ4Oju6xqu7QqQb7LtIe3t0zUd+hCHnZOjj2Yz1ciDXF3C03AAD/HpuO+aOd4d4hGy19sxF/1BwnDyrw5Q+lrY0m5kr4D3mE/8x2gLlFMczqleCbzx3Q6LV8tH6Dg3Dpxan2pKEqLVq0wO3bt5GSkiK2Nly5cgUZGRlo3rz5c9fbpk0bXL58GS4uLpWWqV+/PlJTU8XH169fR25u7nMfEwDMzc3h4OCA48ePo3PnzuL62NhYtGvX7rnr/e233xAUFIS3334bQOkYh+TkZI1ipVIW1kUIW3IDFvWLkJuli6SrxpgR1Axnj5eOZP/vWnvIDZUY//ktmCqKcfWcKaYNa4a8HE6Fpco9eaCHLyc441G6HozNStC4eT7mbrmBtl2yAQAde2cg+Is7iF5lizUzHeHYpAAzv0mCe/u/WxFGR9yFrq6AeaMboTBPB606ZWH2hpvgLOwXrI5f3KlGJw1+fn7w9PTEu+++i2XLlqG4uBhjx45Fly5d4OXl9dz1TpkyBR06dMC4ceMwcuRImJiYIDExEQcPHsTKlSsBAN27d8eqVavQoUMHKJVKTJkypVyryPOYPHkywsPD0bRpU7Rq1Qrr16/HuXPnsGXLlueu08XFBTt37kT//v0hk8kwc+bMSlslSD1LP2vyjBIybF7uiM3LHV9KPPRqmLTk2eOI/Ic8gv+QR5VuNzAUMG7eXYybd1eboZEEtbl7QVPVPqahKmXTHi0sLNC5c2f4+fmhSZMm2LZtm0b1enp6IiYmBtevX8cbb7yB1q1bY+bMmeLYAQBYvHgxnJyc0LlzZwwdOhShoaFauS5CcHAwQkJCEBISAg8PDxw4cAB79uyBq6vrc9e5dOlSWFhYwNfXF/3794e/vz/atGmjcaxERET/JBOe7rinOiczMxMKhQLd5AOhJ9O8NYWoKgeSTlV3CFQHZGYpYeF2ExkZGVoZ7F32Pdn233Ohp2+oUV3FRflI+O8MrcX2MtXo7gkiIqKaRBuzH2pz90aN7p4gIiKimoMtDURERFJx9gQRERFJIVOWLprWUVuxe4KIiIgkYUsDERGRVOyeICIiIik4e4KIiIhIArY0EBERSSUIpYumddRSTBqIiIgkYvcEERERkQRsaSAiIpKKsyeIiIhICnZPEBEREUnAlgYiIiKpOHuCiIiIpGD3BBEREdVY//vf/9C/f384ODhAJpNh9+7dKtsFQUBERAQcHBxgZGSErl274vLlyyplCgoKMGHCBFhbW8PExARvvfUW7ty5o3YsTBqIiIikErS0qCEnJwctW7bEqlWrKty+cOFCLFmyBKtWrUJcXBzs7OzQs2dPZGVliWUmTpyIXbt2ITo6GsePH0d2djb69euHkpIStWJh9wQREZFE2uyeyMzMVFkvl8shl8vLle/duzd69+5dYV2CIGDZsmWYPn06BgwYAADYsGEDbG1tsXXrVowaNQoZGRlYt24dNm3aBD8/PwDA5s2b4eTkhEOHDsHf319y7GxpICIiqgZOTk5QKBTiEhkZqXYdSUlJSEtLw5tvvimuk8vl6NKlC2JjYwEACQkJKCoqUinj4OAAd3d3sYxUbGkgIiKSSimULprWASAlJQXm5ubi6opaGZ4lLS0NAGBra6uy3tbWFrdu3RLLGBgYwMLColyZsv2lYtJAREQklRavCGlubq6SNGhCJpOpHkIQyq0rF4aEMk9j9wQREVEtZWdnBwDlWgzS09PF1gc7OzsUFhbi8ePHlZaRikkDERGRRDL8PRjyuRctxtO4cWPY2dnh4MGD4rrCwkLExMTA19cXANC2bVvo6+urlElNTcWlS5fEMlKxe4KIiKgGy87Oxp9//ik+TkpKwrlz52BpaYmGDRti4sSJmD9/PlxdXeHq6or58+fD2NgYQ4cOBQAoFAqMGDECISEhsLKygqWlJUJDQ+Hh4SHOppCKSQMREZFU1XAZ6fj4eHTr1k18PGnSJADA8OHDERUVhbCwMOTl5WHs2LF4/Pgx2rdvj19//RVmZmbiPkuXLoWenh4GDhyIvLw89OjRA1FRUdDV1VUrFpkg1OKLYJNWZGZmQqFQoJt8IPRk+tUdDr3iDiSdqu4QqA7IzFLCwu0mMjIytDLYsOx7slP3COjpGWpUV3FxPo4fidBabC8TxzQQERGRJOyeICIikkqLUy5rIyYNREREEskEATINe/U13b86sXuCiIiIJGFLAxERkVTK/180raOWYtJAREQkEbsniIiIiCRgSwMREZFUnD1BREREklTDFSFrEnZPEBERkSRsaSAiIpKo7E6VmtZRWzFpICIikordE0RERETPxpYGIiIiiWTK0kXTOmorJg1ERERSsXuCiIiI6NnY0kBERCQVL+5EREREUvDeE0REREQSsKWBiIhIqjo+EJJJAxERkVQCAE2nTNbenIHdE0RERCQNWxqIiIgkqusDIZk0EBERSSVAC2MatBJJtWD3BBEREUnClgYiIiKpOHuCiIiIJFECkGmhjlqK3RNEREQkCVsaiIiIJOLsCSIiIpKmjo9pYPcEERERScKWBiIiIqnqeEsDkwYiIiKp6njSwO4JIiIikoQtDURERFLV8es0MGkgIiKSqK5PuWT3BBEREUnClgYiIiKp6vhASCYNREREUikFQKbhj76y9iYN7J4gIiIiSdjSQEREJBW7J4iIiEgaLSQNYNJAtZjw/x+AYqGomiOhuiAzqxZPUqdaIzO79H0m1OL/6msiJg2ErKwsAMBvhbuqORKqCyzcqjsCqkuysrKgUCi0VyG7J6iuc3BwQEpKCszMzCCTaXqps7ojMzMTTk5OSElJgbm5eXWHQ68wvtfUJwgCsrKy4ODgoN2KlQI07l6oxbMnmDQQdHR04OjoWN1h1Frm5ub8IqeXgu819Wi1hYEAcMolERGRdIJSO4saIiIiIJPJVBY7O7u/QxIEREREwMHBAUZGRujatSsuX76s7TMHwKSBiIhIurIxDZouanr99deRmpoqLhcvXhS3LVy4EEuWLMGqVasQFxcHOzs79OzZUxyvpk3sniB6TnK5HOHh4ZDL5dUdCr3i+F57NWVmZqo8lsvllb7Genp6Kq0LZQRBwLJlyzB9+nQMGDAAALBhwwbY2tpi69atGDVqlFZjZksD0XOSy+WIiIjgFzm9cHyv1SBKQTsLACcnJygUCnGJjIys9LDXr1+Hg4MDGjdujMGDB+PmzZsAgKSkJKSlpeHNN98Uy8rlcnTp0gWxsbFaP322NBAREUmlxSmXT8+GqSwpbN++PTZu3Ag3Nzfcv38fc+fOha+vLy5fvoy0tDQAgK2trco+tra2uHXrlmZxVoBJAxERUTWQOhumd+/e4t8eHh7w8fFB06ZNsWHDBnTo0AEAyk2XFwThhUyhZ/cEUQ31yy+/YP369dUdBpEKpVKJRYsW4ezZs9UdSvUQoIWBkJqFYGJiAg8PD1y/fl0c51DW4lAmPT29XOuDNjBpIKqBzp8/j48++kj8L4KoppgxYwZiYmLg6elZ3aFUj2qaPfFPBQUFSExMhL29PRo3bgw7OzscPHhQ3F5YWIiYmBj4+vpqerblsHuCqIZ5/Pgx3n33XURHR6N58+bVHQ6RaPfu3Th27BgOHToEXV3d6g6nzggNDUX//v3RsGFDpKenY+7cucjMzMTw4cMhk8kwceJEzJ8/H66urnB1dcX8+fNhbGyMoUOHaj0WJg1ENYyFhQUuXbpU3WEQlRMYGIjAwMDqDqN6KZUANLzpmlK9/e/cuYMhQ4bgr7/+Qv369dGhQwecPHkSzs7OAICwsDDk5eVh7NixePz4Mdq3b49ff/0VZmZmmsVZAXZPUK3UtWtXBAcHIywsDJaWlrCzs0NERIS4PSMjAx9//DFsbGxgbm6O7t274/z58+L2oKCgcl9+EydORNeuXVWOMWHCBEycOBEWFhawtbXFf/7zH+Tk5OCDDz6AmZkZmjZtip9//lmlnpiYGLRr1w5yuRz29vb47LPPUFxcLDl2oHRQ0+7du8XHU6ZMgZubG4yNjdGkSRPMnDkTRUW8K+nzkvIa3L59GwEBATA1NYW5uTkGDhyI+/fvV1pncnIyZDIZdu7ciW7dusHY2BgtW7bEiRMnVMrFxsaic+fOMDIygpOTE4KDg5GTkyNuf/q1B4B69eohKipK5Tjbt2/HG2+8ASMjI3h7e+OPP/5AXFwcvLy8YGpqil69euHBgwdiHUqlEnPmzIGjoyPkcjlatWqFAwcOqBV/VFQU6tWrJz6+ceMGAgICYGtrC1NTU3h7e+PQoUPPevprt2ronoiOjsa9e/dQWFiIu3fvYseOHWjRooW4XSaTISIiAqmpqcjPz0dMTAzc3d21feYAmDRQLbZhwwaYmJjg1KlTWLhwIebMmYODBw9CEAT07dsXaWlp2L9/PxISEtCmTRv06NEDjx49UvsY1tbWOH36NCZMmIAxY8bg3//+N3x9fXHmzBn4+/vj/fffR25uLgDg7t276NOnD7y9vXH+/HmsWbMG69atw9y5cyXFXhkzMzNERUXhypUrWL58Ob755hssXbpU/SeNRFW9BoIgIDAwEI8ePUJMTAwOHjyIGzduYNCgQc+sd/r06QgNDcW5c+fg5uaGIUOGiEnjxYsX4e/vjwEDBuDChQvYtm0bjh8/jvHjx6sdf3h4OGbMmIEzZ85AT08PQ4YMQVhYGJYvX47ffvsNN27cwKxZs8Tyy5cvx+LFi7Fo0SJcuHAB/v7+eOutt3D9+nXJ8T8tOzsbffr0waFDh3D27Fn4+/ujf//+uH37ttrnQ7WEQFQLdenSRejUqZPKOm9vb2HKlCnC4cOHBXNzcyE/P19le9OmTYW1a9cKgiAIw4cPFwICAlS2f/LJJ0KXLl0qPUZxcbFgYmIivP/+++K61NRUAYBw4sQJQRAEYdq0aUKzZs0EpVIplvnqq68EU1NToaSk5JmxlwEg7Nq1q9LzX7hwodC2bdtKt1PVnvUa/Prrr4Kurq5w+/Ztcfvly5cFAMLp06crrDMpKUkAIHz77bfl9klMTBQEQRDef/994eOPP1bZ77fffhN0dHSEvLw8QRAqfu0VCoWwfv36So/z/fffCwCEw4cPi+siIyOFZs2aiY8dHByEefPmlTvnsWPHSo5//fr1gkKhqPD8y7Ro0UJYuXJllWVqo4yMDAGA4Gf9odDLZrRGi5/1hwIAISMjo7pPS21saaBa6+nR2/b29khPT0dCQgKys7NhZWUFU1NTcUlKSsKNGzee+xi6urqwsrKCh4eHuK5sSlN6ejoAIDExET4+Pirzozt27Ijs7GzcuXPnmbFX5ocffkCnTp1gZ2cHU1NTzJw5k//Naaiq1yAxMRFOTk5wcnISt7do0QL16tVDYmKi5Hrt7e0B/P3+SEhIQFRUlMr70t/fH0qlEklJSc8df9n78On3ZtlxMzMzce/ePXTs2FGljo4dO5Y7n6rif1pOTg7CwsLE58bU1BRXr159td+bWrwiZG3EgZBUa+nr66s8lslkUCqVUCqVsLe3x7Fjx8rtU9Yfq6OjA+GpfsWKxghUdIx/ritLDpT/P7BJqOCCKmXH+ef6ymKvyMmTJzF48GDMnj0b/v7+UCgUiI6OxuLFiyssT9JU9RpU9DpWtb6yep9+fyiVSowaNQrBwcHl9mvYsKG4j7rvzbLjPL3u6feUlAsAVRX/0yZPnoxffvkFixYtgouLC4yMjPDOO++gsLCwwvJU+zFpoFdOmzZtkJaWBj09PTRq1KjCMvXr1y83Q+HcuXPlfkjU1aJFC+zYsUPlyzg2NhZmZmZo0KDBc9X5+++/w9nZGdOnTxfXvYjLw9LfWrRogdu3byMlJUVsbbhy5QoyMjI0mgbbpk0bXL58GS4uLpWWqV+/PlJTU8XH169fF8fMPC9zc3M4ODjg+PHj6Ny5s7g+NjYW7dq1e+56f/vtNwQFBeHtt98GUDrGITk5WaNYazpBUEJQ89bWFdVRW7F7gl45fn5+8PHxQWBgIH755RckJycjNjYWM2bMQHx8PACge/fuiI+Px8aNG3H9+nWEh4drZZrj2LFjkZKSggkTJuDq1av48ccfER4ejkmTJkFH5/k+bi4uLrh9+zaio6Nx48YNrFixArt27dI4Vqqcn58fPD098e677+LMmTM4ffo0hg0bhi5dusDLy+u5650yZQpOnDiBcePG4dy5c7h+/Tr27NmDCRMmiGW6d++OVatW4cyZM4iPj8fo0aM1TmaB0laBBQsWYNu2bbh27Ro+++wznDt3Dp988slz1+ni4oKdO3fi3LlzOH/+PIYOHVppq8QrQ9BC14Sm966oRkwa6JUjk8mwf/9+dO7cGR9++CHc3NwwePBgJCcni32//v7+mDlzJsLCwuDt7Y2srCwMGzZM42M3aNAA+/fvx+nTp9GyZUuMHj0aI0aMwIwZM567zoCAAHz66acYP348WrVqhdjYWMycOVPjWKlyZdMeLSws0LlzZ/j5+aFJkybYtm2bRvV6enoiJiYG169fxxtvvIHWrVtj5syZ4tgBAFi8eDGcnJzQuXNnDB06FKGhoTA2Ntb0lBAcHIyQkBCEhITAw8MDBw4cwJ49e+Dq6vrcdS5duhQWFhbw9fVF//794e/vjzZt2mgcK9VcMuHpzjMiIiJSkZmZCYVCgR6K96EnM9CormKhEIczNiEjI0PSDatqEo5pICIikkqpBGQadsFwTAMRERG96tjSQEREJFXp9be0UEftxKSBiIhIIkGphKBh9wSnXBIREdErjy0NREREUrF7goiIiCRRCoCs7iYN7J4gIiIiSZg0EJGKiIgItGrVSnwcFBSEwMDAlx5HcnIyZDIZzp07V2mZRo0aYdmyZZLrjIqKEm9apomyK0ZSHSQIpddZ0GhhSwMRvUBBQUGQyWTiXTabNGmC0NBQ5OTkvPBjL1++HFFRUZLKSvmhJ6rNBKWglaW24pgGolqiV69eWL9+PYqKivDbb7/ho48+Qk5ODtasWVOubFFRkVZucgQACoVCK/UQUe3HlgaiWkIul8POzg5OTk4YOnQo3n33XbGJvKxL4bvvvkOTJk0gl8shCAIyMjLw8ccfw8bGBubm5ujevTvOnz+vUu8XX3wBW1tbmJmZYcSIEcjPz1fZ/nT3hFKpxIIFC+Di4gK5XI6GDRti3rx5AIDGjRsDAFq3bg2ZTIauXbuK+61fvx7NmzeHoaEhXnvtNaxevVrlOKdPn0br1q1haGgILy8vnD17Vu3naMmSJfDw8ICJiQmcnJwwduxYZGdnlyu3e/duuLm5wdDQED179kRKSorK9r1796Jt27YwNDREkyZNMHv2bBQXF6sdD72CNO6aUPIy0kT08hkZGaGoqEh8/Oeff2L79u3YsWOH2D3Qt29fpKWlYf/+/UhISECbNm3Qo0cPPHr0CACwfft2hIeHY968eYiPj4e9vX25H/OnTZ06FQsWLMDMmTNx5coVbN26Vbx76OnTpwEAhw4dQmpqKnbu3AkA+OabbzB9+nTMmzcPiYmJmD9/PmbOnIkNGzYAAHJyctCvXz80a9YMCQkJiIiIQGhoqNrPiY6ODlasWIFLly5hw4YNOHLkCMLCwlTK5ObmYt68ediwYQN+//13ZGZmYvDgweL2X375Be+99x6Cg4Nx5coVrF27FlFRUWJiRHVbXe+egEBENd7w4cOFgIAA8fGpU6cEKysrYeDAgYIgCEJ4eLigr68vpKeni2UOHz4smJubC/n5+Sp1NW3aVFi7dq0gCILg4+MjjB49WmV7+/bthZYtW1Z47MzMTEEulwvffPNNhXEmJSUJAISzZ8+qrHdychK2bt2qsu7zzz8XfHx8BEEQhLVr1wqWlpZCTk6OuH3NmjUV1vVPzs7OwtKlSyvdvn37dsHKykp8vH79egGAcPLkSXFdYmKiAEA4deqUIAiC8MYbbwjz589XqWfTpk2Cvb29+BiAsGvXrkqPS6+ejIwMAYDQVfa24KczUKOlq+xtAYCQkZFR3aelNo5pIKolfvrpJ5iamqK4uBhFRUUICAjAypUrxe3Ozs6oX7+++DghIQHZ2dmwsrJSqScvLw83btwAACQmJmL06NEq2318fHD06NEKY0hMTERBQQF69OghOe4HDx4gJSUFI0aMwMiRI8X1xcXF4niJxMREtGzZEsbGxipxqOvo0aOYP38+rly5gszMTBQXFyM/Px85OTkwMTEBAOjp6cHLy0vc57XXXkO9evWQmJiIdu3aISEhAXFxcSotCyUlJcjPz0dubq5KjFT3FAsFGncvFKPo2YVqKCYNRLVEt27dsGbNGujr68PBwaHcQMeyH8UySqUS9vb2OHbsWLm6nnfaoZGRkdr7KJWlX7DffPMN2rdvr7JNV1cXACBoYQrarVu30KdPH4wePRqff/45LC0tcfz4cYwYMUKlGwconTL5tLJ1SqUSs2fPxoABA8qVMTQ01DhOqp0MDAxgZ2eH42n7tVKfnZ0dDAwMtFLXy8SkgaiWMDExgYuLi+Tybdq0QVpaGvT09NCoUaMKyzRv3hwnT57EsGHDxHUnT56stE5XV1cYGRnh8OHD+Oijj8ptL/sSLCkpEdfZ2tqiQYMGuHnzJt59990K623RogU2bdqEvLw8MTGpKo6KxMfHo7i4GIsXL4aOTulwre3bt5crV1xcjPj4eLRr1w4AcO3aNTx58gSvvfYagNLn7dq1a2o91/TqMzQ0RFJSEgoLC7VSn4GBQa1MQpk0EL2i/Pz84OPjg8DAQCxYsADNmjXDvXv3sH//fgQGBsLLywuffPIJhg8fDi8vL3Tq1AlbtmzB5cuX0aRJkwrrNDQ0xJQpUxAWFgYDAwN07NgRDx48wOXLlzFixAjY2NjAyMgIBw4cgKOjIwwNDaFQKBAREYHg4GCYm5ujd+/eKCgoQHx8PB4/foxJkyZh6NChmD59OkaMGIEZM2YgOTkZixYtUut8mzZtiuLiYqxcuRL9+/fH77//jq+//rpcOX19fUyYMAErVqyAvr4+xo8fjw4dOohJxKxZs9CvXz84OTnh3//+N3R0dHDhwgVcvHgRc+fOVf+FoFeGoaFhrfyh1ybOniB6RclkMuzfvx+dO3fGhx9+CDc3NwwePBjJycnibIdBgwZh1qxZmDJlCtq2bYtbt25hzJgxVdY7c+ZMhISEYNasWWjevDkGDRqE9PR0AKXjBVasWIG1a9fCwcEBAQEBAICPPvoI3377LaKiouDh4YEuXbogKipKnKJpamqKvXv34sqVK2jdujWmT5+OBQsWqHW+rVq1wpIlS7BgwQK4u7tjy5YtiIyMLFfO2NgYU6ZMwdChQ+Hj4wMjIyNER0eL2/39/fHTTz/h4MGD8Pb2RocOHbBkyRI4OzurFQ/Rq0gmaKMzkYiIiF55bGkgIiIiSZg0EBERkSRMGoiIiEgSJg1EREQkCZMGIiIikoRJAxEREUnCpIGIiIgkYdJAREREkjBpICIiIkmYNBAREZEkTBqIiIhIkv8DkDK8FjLFMLMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PERCEPTRON SKLEARN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "matriz_conf = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"neumonía\" , \"no neumonía\"])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión neumonía-no neumonía\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c199df-1c39-4da7-8eb9-0fc1adfb6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npv ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7b115-2715-4fe4-a866-6b0f6cc2b83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614038a-c640-4264-afd3-61b2e5e2355f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115865-dddc-4ec1-bb3a-efa3419117a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b2ecb-81e3-40a9-9fcb-eec582cd18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARTICULO METIDO EN EL RESUMEN DE LA MEMORIA\n",
    "#https://www.sciencedirect.com/science/article/pii/S001048252030247X?via%3Dihub#bib1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
