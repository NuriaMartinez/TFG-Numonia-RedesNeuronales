{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7176c0-5ed5-4850-a27a-b820414ff96d",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"40%\" src=\"pics/Universidad Burgos.png\">\n",
    "<img style=\"float:right\" width=\"16%\" src=\"pics/person1_bacteria_2.jpeg\">\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Trabajo Fin de Grado\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Detección de neumonía mediante aprendizaje automático a partir de radiografías de tórax</h2>\n",
    "\n",
    "### Nuria Martínez Queralt\n",
    "\n",
    "### Grado en Ingeniería de la Salud \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33e68c-4e8b-4305-91c2-cff54089bbf4",
   "metadata": {},
   "source": [
    "En este notebook se han llevado a cabo una serie de tareas para la realización del TFG, el cual consiste en la identificación de neumonía a partir de radiografías de tórax empleando una red neuronal. Para esto, se deben probar distintos modelos hasta llegar al modelo más óptimo de red neuronal para este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296a9ed-5af7-4b30-91c5-7015aefef326",
   "metadata": {},
   "source": [
    "## Redistribución de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1466b-002c-4d9e-8c11-fe752738fabe",
   "metadata": {},
   "source": [
    "Debido a que la distribución inicial obtenida a partir del dataset descargado de internet: \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\" incluye únicamente 16 imágenes en la carpeta de validación (\"val\") y, esto supone un problema para la obtención de buenos resultados a la hora de construir nuestra red neuronal, antes de empezar a trabajar con las imágenes, se debe crear una función para obtener un nuevo dataset con nuevas carpetas \"train\", \"test\" y \"val\" y una nueva distribución de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607cb8f4-f897-4551-a114-31b2c1dcf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def buscar_imagen(directorio_padre, nombre_imagen):\n",
    "    '''\n",
    "    Función empleada para encontrar una imagen concreta (a partir de su nombre) dentro de cualquiera de las subcarpetas del directorio_padre.\n",
    "    ---------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_padre: ruta donde se encuentra la carpeta principal con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    - nombre_imagen: nombre de la imágen a la que se desea acceder \n",
    "    ----------------------------------------------------------\n",
    "    Return:\n",
    "    - ruta_imagen: ruta completa de la imágen a la que se desea acceder \n",
    "    '''\n",
    "    # Subcarpetas principales en las que buscar\n",
    "    subcarpetas_principales = ['train', 'test', 'val']\n",
    "    # Subcarpetas adicionales en las que buscar dentro de cada subcarpeta principal (donde se encuentran las imágenes)\n",
    "    subcarpetas_adicionales = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Se itera sobre las subcarpetas principales\n",
    "    for subcarpeta_principal in subcarpetas_principales:\n",
    "        # Se itera sobre las subcarpetas adicionales dentro de cada subcarpeta principal\n",
    "        for subcarpeta_adicional in subcarpetas_adicionales:\n",
    "            # Se obtiene la ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(directorio_padre, subcarpeta_principal, subcarpeta_adicional, nombre_imagen)\n",
    "            # verificar si la imagen existe en la subcarpeta actual\n",
    "            if os.path.exists(ruta_imagen):\n",
    "                return ruta_imagen  # devolver la ruta de la imagen si se encuentra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806f2df1-fbcf-46be-bc11-a7a80fd7b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def redestribucion_imagenes(directorio_principal):\n",
    "\n",
    "    '''\n",
    "    Función empleada para redistribuir las imágenes ubicadas en distintas subcarpetas dentro de la carpeta data en una carpeta nueva con las\n",
    "    mismas subcarpetas pero con un porcentaje distinto de imágenes en cada subcarpeta. La distribución quedaría de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    De igual forma, la distribución de las carpetas \"PNEUMONIA\" y \"NORMAL\" también queda de forma proporcional.\n",
    "    --------------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_principal: ruta donde se encuentra la carpeta data con cada una de las subcarpetas con las imágenes de radiografías de tórax\n",
    "    -------------------------------------------------------------------\n",
    "    Return: \n",
    "    - nada\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    En primer lugar, se crea un csv con dos columnas ''nombres_ficheros'' y ''clases'' compuesto por todas las imágenes existentes en el directorio_padre.\n",
    "    En la columna ''nombres_ficheros'', debe aparecer el nombre de TODAS las imágenes que existen dentro de cada subcarpeta y en la columna ''clases'',\n",
    "    debe aparecer 0 o 1 en función si se trata de una imagen de la carpeta NORMAL o PNEUMONIA respectivamente.\n",
    "    '''\n",
    "\n",
    "    directorio_padre = os.path.join(directorio_principal, 'data') #se accede a la ruta de la carpeta data\n",
    "    \n",
    "    # Listas vacias para almacenar los nombres de las imágenes y las clases (0 o 1 en función de si es normal o neumonía respectivamente)\n",
    "    nombres_ficheros = []\n",
    "    clases = []\n",
    "    \n",
    "    # Se recorren las carpetas de train, test y val\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(directorio_padre, subcarpeta) #ruta a cada una de las subcarpetas\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase) #ruta a cada una de las clases dentro de las subcarpetas\n",
    "            for nombre_fichero in os.listdir(ruta_clase):\n",
    "                nombres_ficheros.append(nombre_fichero)\n",
    "                clases.append(0 if clase == 'NORMAL' else 1)\n",
    "    \n",
    "    # Se crea el DataFrame con los datos\n",
    "    df_todas = pd.DataFrame({'nombre_fichero': nombres_ficheros,'clase': clases})\n",
    "    \n",
    "    # Se guarda el DataFrame en un archivo CSV dentro de la carpeta creada ''Datos''\n",
    "    ruta_datos=os.path.join('.', 'Datos') #se crea la ruta a la nueva carpeta ''Datos'' en el directorio actual\n",
    "    os.makedirs(ruta_datos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "    ruta_csv = os.path.join(ruta_datos, 'dataset_info.csv') #el nuevo dataframe se guarda dentro del directorio padre\n",
    "    df_todas.to_csv(ruta_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    '''\n",
    "    A partir del csv anterior y, con ayuda de la función ''train_test_split'' de skitlearn, se divide el csv anterior en dos \n",
    "    subgrupos de train y test en proporción 80, 20 para poder usar el 80% de las imágenes para train y el 20% para test.\n",
    "    También se emplea el parámetro ''stratify'' para que exista una proporción de clases en cada uno de los grupos, es decir, en ''NORMAL\" y \"PNEUMONIA\".\n",
    "    '''\n",
    "    \n",
    "    # random_state=42 se emplea para que cada vez que se ejecute el código, se obtenga la misma división de datos. El valor 42 es un valor que se usa\n",
    "    # comunmente en este caso pero se puede emplear cualquie otro valor entero.\n",
    "    train_df, test_df = train_test_split(df_todas, test_size=0.2, stratify=df_todas['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV dentro de la carpeta ''Datos''\n",
    "    ruta_train_csv = os.path.join(ruta_datos, 'train_dataset_info.csv') #el nuevo dataframe se guarda dentro de la carpeta Datos\n",
    "    ruta_test_csv = os.path.join(ruta_datos, 'test_dataset_info.csv') #el nuevo dataframe se guarda dentro de la carpeta Datos\n",
    "    train_df.to_csv(ruta_train_csv, index=False, encoding='utf-8')\n",
    "    test_df.to_csv(ruta_test_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    '''\n",
    "    A continuación, se coge el conjunto de datos obtenido previamente de train, es decir, el csv \"train_df\" y se repite el mismo\n",
    "    proceso pero, esta vez dividiendo este conjunto de datos para train y val en un 80% y 20% respectivamente.\n",
    "    De tal forma que, finalemnte se obtenga el conjunto de test que represeneta el 20% del total (obtenido previamente), el conjunto de train\n",
    "    que representa el 80% del 80% del total ya que, inicialmente nos hemos quedado con el 80% pero luego, de este 80%, el 20% va destinado al conjunto\n",
    "    de validación. Por lo que, finalmete quedarían distribuidos de la siguiente manera:\n",
    "    - test: 20% del total\n",
    "    - train: 64% del total\n",
    "    - val: 16% del total\n",
    "    '''\n",
    "\n",
    "    # Se emplea train_test_split para dividir el conjunto de datos de entrenamiento en train (80%) y val (20%)\n",
    "    train_def_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['clase'], random_state=42)\n",
    "    \n",
    "    # Se guardan los nuevos conjuntos de datos en archivos CSV dentro de la carpeta ''Datos''\n",
    "    ruta_train_final_csv = os.path.join(ruta_datos, 'train_final_dataset_info.csv') #el nuevo dataframe se guarda dentro de la carpeta ''Datos''\n",
    "    ruta_val_csv = os.path.join(ruta_datos, 'val_dataset_info.csv') #el nuevo dataframe se guarda dentro de la carpeta ''Datos''\n",
    "    train_def_df.to_csv(ruta_train_final_csv, index=False, encoding='utf-8')\n",
    "    val_df.to_csv(ruta_val_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    '''\n",
    "    Finalmente, se crea una nueva carpeta denominada data_nuevo dentro del directorio principal. Dentro de esta carpeta se crean 3 subcarpetas \n",
    "    (\"train\", \"test\" y \"val\") que corresponderian con los dataframes obtenidos hasta ahora: train_def_df, val_df y test_df y, dentro de estas 3 \n",
    "    subcarpetas, se crean 2 carpetas \"NORMAL\" y \"PNEUMONIA\" que corresponden con las clases determinadas en cada dataframe, 0 en caso de \n",
    "    \"NORMAL\" y 1 para \"PNEUMONIA\". Dentro de estas dos carpetas para (\"train\", \"test\" y \"val\") se encontrarán las imagenes correspondientes \n",
    "    para cada caso según los dataframes obtenidos.\n",
    "    \n",
    "    La función ''os.makedirs'', verifica si la carpeta ruta_subcarpeta ya existe. Si existe, no se hace nada y el programa continúa su ejecución \n",
    "    sin lanzar un error. Si no existe, la función os.makedirs() la crea junto con cualquier carpeta intermedia necesaria en la ruta especificada.\n",
    "    '''\n",
    "\n",
    "    # Se crea la nueva carpeta dentro del directorio principal\n",
    "    ruta_principal_nueva = os.path.join(directorio_principal, 'data_nuevo') \n",
    "\n",
    "    # Se crean las carpetas 'train', 'test' y 'val' dentro de la nueva carpeta principal\n",
    "    for subcarpeta in ['train', 'test', 'val']:\n",
    "        ruta_subcarpeta = os.path.join(ruta_principal_nueva, subcarpeta)\n",
    "        os.makedirs(ruta_subcarpeta, exist_ok=True) \n",
    "        \n",
    "        # Se crean las subcarpetas 'NORMAL' y 'PNEUMONIA' dentro de cada subcarpeta ('train', 'test' y 'val')\n",
    "        for clase in ['NORMAL', 'PNEUMONIA']:\n",
    "            ruta_clase = os.path.join(ruta_subcarpeta, clase)\n",
    "            os.makedirs(ruta_clase, exist_ok=True)\n",
    "    \n",
    "                \n",
    "    # Se copian los archivos CSV a las subcarpetas correspondientes\n",
    "    for df, nombre_carpeta in [(train_def_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "        for index, row in df.iterrows(): #se itera sobre cada dataframe fila a fila\n",
    "            clase = 'NORMAL' if row['clase'] == 0 else 'PNEUMONIA'\n",
    "            nombre_archivo = row['nombre_fichero']\n",
    "    \n",
    "            # ruta de origen donde se busca la imagen concreta a partir de la función realizada previamente\n",
    "            # esta ruta se refiere a donde esta la imagen que se desea guardar en la carpeta destino originalmente para poder copiarla\n",
    "            ruta_origen=buscar_imagen(directorio_padre, nombre_archivo)\n",
    "            \n",
    "            # ruta donde se desa guardar (y redestribuir de la forma correcta) las imágenes\n",
    "            ruta_destino = os.path.join(ruta_principal_nueva, nombre_carpeta, clase, nombre_archivo)\n",
    "            \n",
    "            shutil.copyfile(ruta_origen, ruta_destino) # copia las imágenes de la ruta incial a la ruta final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c371aab4-b02f-4ce2-b902-03be9c426b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_principal = 'C:/Users/nuria/Downloads/TFG' #ruta donde se encuentra la carpeta data en mi caso y donde se va a crear la nueva carpeta data_nuevo\n",
    "redestribucion_imagenes(directorio_principal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b4967-0b21-4bea-a7dd-96dfc0bc0206",
   "metadata": {},
   "source": [
    "A partir de aqui, se va a trabajar con la nueva carpeta de imágenes y su nueva distribución para evitar errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f5be-2c05-498e-88e7-da98e1210f1c",
   "metadata": {},
   "source": [
    "## Preparación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd3214-3749-4449-a6ce-2150370b3359",
   "metadata": {},
   "source": [
    "Se prepara el modelo para poder trabajar con las imágenes de train, test y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f44c95-c38d-4885-a5e7-fe86df3e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "def preparar_modelo(ruta, batch_size,target_size):\n",
    "\n",
    "    '''\n",
    "    Función que configura los generadores de datos para entrenar, validar y probar un modelo de aprendizaje automático con imágenes.\n",
    "    -----------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo.\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. Este valor deberá coincidir\n",
    "    con el input_shape empleado posteriormente dependiendo de cada caso.\n",
    "    ----------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    \n",
    "    dir_general = ruta \n",
    "    \n",
    "    dir_train = os.path.join(dir_general, 'train') # se accede a la ruta concreta de la carpeta ''train'' dentro de data_nuevo\n",
    "    dir_validation = os.path.join(dir_general, 'val') # se accede a la ruta concreta de la carpeta ''val'' dentro de data_nuevo\n",
    "    dir_test = os.path.join(dir_general, 'test') # se accede a la ruta concreta de la carpeta ''test'' dentro de data_nuevo\n",
    "    \n",
    "    # Preprocesamiento de imágenes\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de entrenamiento\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dir_train,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size, \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=True) # el conjunto de datos se barajará aleatoriamente para evitar sobreajuste \n",
    "\n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de validación\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        dir_validation,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size, \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False) \n",
    "\n",
    "    #Iterador que recorre el directorio de imágenes del conjunto de prueba\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dir_test,\n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', #clase binaria\n",
    "        classes=['NORMAL','PNEUMONIA'], #se indican las clases\n",
    "        shuffle=False) \n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5654c9-4f71-4980-9ade-721a48531aec",
   "metadata": {},
   "source": [
    "## Creación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5c91f-3b3e-403c-820b-56c4cd7ecfa7",
   "metadata": {},
   "source": [
    "Se crea una función para calcular las distintas métricas que servirán para la posterior evaluación de cada modelo que se realice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62f0ad-3bf5-43b6-b2a6-ae64737f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np \n",
    "\n",
    "def metricas(y_test, y_pred):\n",
    "    '''\n",
    "    Función que calcula distintas métricas para la evaluación del modelo.\n",
    "    -----------------------------------------------------\n",
    "    Parámetros: \n",
    "    - y_test: array de etiquetas verdaderas del conjunto de prueba\n",
    "    - y_pred: array de etiquetas predichas por el modelo\n",
    "    ----------------------------------------\n",
    "    Return: \n",
    "    - accuracy: float que indica la proporción de predicciones correctas\n",
    "    - precision: float que indica la proporción de predicciones positivas correctas\n",
    "    - recall: float que indica la proporción de positivos detectados\n",
    "    - f1: float que indica la media armónica de precisión y exhaustividad para evaluar de una forma más equilibrada el rendimiento del modelo\n",
    "    - specificity: float que indica la proporción de negativos detectados\n",
    "    - fpr: float que indica la tasa de falsos positivos, es decir, la proporción de negativos incorrectamente clasificadas como positivos, \n",
    "    respecto al total de casos negativos reales.\n",
    "    - fnr: float que indica la tasa de falsos negativos, es decir, la proporción de positivos incorrectamente clasificadas como negativos, \n",
    "    respecto al total de casos positivos reales.\n",
    "    - auc: float que se emplea para evaluar la capacidad de distinción entre clases positivas y negativas de un modelo de clasificación \n",
    "    binaria. Un 1 significa que es capaz de distinguir perfectamente entre clases, un 0.5 significa una clasificación aleatoria y un 0 indica \n",
    "    que ninguna clase ha sido correctamente clasificada.\n",
    "    '''\n",
    "    \n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "    \n",
    "    #Se obtienen los verdaderos negativos, falsos positivos, falsos negativos y verdaderos positivos a partir de la matriz de confusión \n",
    "    #con .ravel() se convierte la matriz en un array unidimensional\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_bin).ravel() \n",
    "\n",
    "    #Se calculan cada una de las métricas empleando su correspondiente fórmula\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn) #tasa de falsos positivos\n",
    "    fnr = fn / (fn + tp) #tasa de falsos negativos\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, specificity, fpr, fnr, auc] #se devuleve como una lista para poder trabajar correctamente con las métricas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b32f5-76dc-483e-bb31-8c6e0d468c1f",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c1053-7fc4-4fa8-b4b4-f69100771f5b",
   "metadata": {},
   "source": [
    "Antes de realizar la comparación entre distintas arquitecturas y distintos batch_size, se han establecido diferentes modelos de arquitectura de red neuronal variando las capas, el número de capas, etc a partir de una red neuronal convolucional (CNN) propia realizada a partir del siguinete link: ''https://www.kaggle.com/code/paola311/clasificaci-n-de-im-genes-cnn''. Se trata de una arquitectura CNN comunmente aplicada como punto de partida para la clasificacion de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81631355-c81a-4aa2-9caf-d374da1919c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN propia\n",
    "\n",
    "def establecer_arquitectura_propia(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece tres tipos de modelos de red neuronal convolucional (CNN) a partir de una CNN propia.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(150,150,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y, se sabe de antemano que los resultados no van a ser buenos pero sirve de punto de partida.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa oculta de \n",
    "    100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la capa oculta\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee varias capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes) seguidas de capas de MaxPooling2D para reducir la dimensionalidad. Después del Flatten se encuentra una capa se encuentra \n",
    "    una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11984b2e-413b-4ff1-92f7-747b3d1bc7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x24871627610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establecer_arquitectura_propia('Simple1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525f7f5-659b-4a79-9b51-b2e5c6d1a826",
   "metadata": {},
   "source": [
    "## Realización de arquitectura CNN AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb5466-44a8-4991-8541-b983af11093a",
   "metadata": {},
   "source": [
    "Se ha repetido el mismo procedimiento, pero, esta vez con una CNN basada en el modelo de AlexNet para poder comprobar cual funciona mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c0f380-66aa-4989-a4ef-88253c46d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura CNN alexaNet\n",
    "def establecer_arquitectura_AlexaNet(tipo):\n",
    "\n",
    "    '''\n",
    "    Función que establece distintos tipos de modelos de red neuronal convolucional (CNN) a partir de la CNN de alexNet.\n",
    "    --------------------------------------------------------------\n",
    "    Parámetros\n",
    "    - tipo: str que indica el tipo de modelo al que se quiere acceder \n",
    "    -------------------------------------------------------------\n",
    "    Return\n",
    "    -model: modelo sequencial en keras según el tipo que se haya introducido como parámetro de entrada y que contiene toda la información necesaria \n",
    "    sobre la arquitectura del modelo\n",
    "    '''\n",
    "    \n",
    "    input_shape=(340,340,3) # se define el tamaño de entrada de las imágenes\n",
    "\n",
    "    '''\n",
    "    El modelo Simple1, se corresponde con un modelo que posee cinco capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes). La primera, segunda y quinta están seguidas de una capa de MaxPooling2D para reducir la dimensionalidad. \n",
    "    Después del Flatten se encuentra una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    Este modelo es muy simple y los resultados no van a ser buenos pero sirve de punto de partida.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    if tipo == \"Simple1\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dropout(0.2), \n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "    El modelo Simple2, se corresponde con un modelo que posee cinco capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes). La primera, segunda y quinta están seguidas de una capa de MaxPooling2D para reducir la dimensionalidad.\n",
    "    Después del Flatten se encuentra una capa oculta de 100 unidades y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple2\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la capa oculta\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "        '''\n",
    "    El modelo Simple3, se corresponde con un modelo que posee cinco capas convolucionales (con las que se obtienen características importantes\n",
    "    de las imágenes). La primera, segunda y quinta están seguidas de una capa de MaxPooling2D para reducir la dimensionalidad. \n",
    "    Después del Flatten se encuentra una capa se encuentra una capa oculta de 100 neuronas, una segunda capa oculta de 16 neuronas y una capa densa.\n",
    "    La función de activación sigmoide en la capa de salida produce una probabilidad entre 0 y 1 para la clasificación binaria.\n",
    "    '''\n",
    "\n",
    "    elif tipo == \"Simple3\":\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(100, activation=\"relu\"), #100 neuronas en la primera capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(16, activation=\"relu\"), #16 neuronas en la segunda capa\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "    else: #si no se cumple ninguna de las opciones anteriores, aparece un error\n",
    "        raise ValueError(\"Tipo de arquitectura no reconocida\")\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ce17fe-abf7-4859-8cbb-4baa86a918c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x24872ab6bc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establecer_arquitectura_AlexaNet(\"Simple1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6c14c-63ba-4378-a4bd-4c61b0df546f",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN propia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6aca24-eddf-41fd-93ee-bf9dba26ed02",
   "metadata": {},
   "source": [
    "Se crean dos funciones distintas (una para CNN propia y otra para CNN alexNet) para poder realizar una comparación entre distintas arquitecturas y distintos batch_size entrenando y evaluando los modelos generados con distintas arquitecturas y distintos batch sizes. Para realizar la comparación, se emplea la función de obtención de métricas previamente definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1b7f36-6297-43d4-a8a8-93964cc84ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_propia(ruta,epochs,batch_sizes,modelos,target_size, nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos):\n",
    "    '''\n",
    "    Función que entrena distintas arquitecturas de modelo y distintos batch size introducidos como parámetros a partir de la CNN propia \n",
    "    establecida previamente y devuelve una tabla comparativa con los distintos valores de métricas para cada caso.\n",
    "    También guarda en distintas carpetas los historicos con las métricas obtenidas tras cada entrenaminto para\n",
    "    cada modelo, los distintos modelos obtenidos según la arquitectura y el batch size y el dataframe final en formato csv.\n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá ser \n",
    "    (150,150) para coincidir con el input_shape del modelo de CNN propia.\n",
    "    - nombre_carpeta_hist: str. Nombre de la carpeta creada para guardar los csv de los históricos\n",
    "    - nombre_carpeta_resultados: str. Nombre de la carpeta creada para guardar el dataframe final en formato csv.\n",
    "    - nombre_carpeta_modelos: str. Nombre de la carpeta creada para guardar los distintos modelos\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size introducidos como parámetro\n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_propia(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "            #ENTRENAMIENTO DEL MODELO\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) \n",
    "\n",
    "            #SE GUARDAN LOS DISTINTOS HISTÓRICOS EN UNA CARPETA\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            ruta_historicos = os.path.join('.', nombre_carpeta_hist) #se crea la ruta a la nueva carpeta de Historicos en el directorio actual\n",
    "            os.makedirs(ruta_historicos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "            #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "            subcarpeta_historicos = os.path.join(ruta_historicos,'historico_propia_arqu_batchsize') \n",
    "            os.makedirs(subcarpeta_historicos, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "            nombre_historico = f'hist_propia_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los csv donde esta el historico correspondiente\n",
    "            ruta_historico = os.path.join(subcarpeta_historicos, nombre_historico) #se define la ruta donde se econtrará cada modelo\n",
    "            historico.to_csv(ruta_historico, index=False, encoding='utf-8') #se crea el csv de cada historico\n",
    "\n",
    "            #SE GUARDAN LOS DISTINTOS MODELOS EN UNA CARPETA\n",
    "            ruta_modelos = os.path.join('.', nombre_carpeta_modelos) #se crea la ruta a la nueva carpeta de Modelos en el directorio actual\n",
    "            os.makedirs(ruta_modelos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "            #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "            subcarpeta_modelo = os.path.join(ruta_modelos, 'modelo_propia_arqu_batchsize')\n",
    "            os.makedirs(subcarpeta_modelo, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "            nombre_modelo = f'modelo_propia_{modelo}_{batch_size}.h5' #se define el nombre de cada uno de los archivos que contienen los modelos\n",
    "            ruta_modelo = os.path.join(subcarpeta_modelo, nombre_modelo) #se define la ruta donde se econtrará cada modelo\n",
    "            model.save(ruta_modelo) #se guarda el modelo\n",
    "        \n",
    "            #se calculan las métricas a partir de la función creada previamente\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "        \n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "\n",
    "    #SE GUARDA EL DATAFRAME FINAL EN UNA CARPETA EN FORMATO CSV\n",
    "    ruta_resultados = os.path.join('.', nombre_carpeta_resultados) #se crea la ruta a la nueva carpeta de Resultados en el directorio actual\n",
    "    os.makedirs(ruta_resultados, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "    ruta_resultado_final = os.path.join(ruta_resultados, 'compara_propia_arqu_batch_def.csv') #se define la ruta donde se econtrará el dataframe\n",
    "    compara_arqu_batch_def.to_csv(ruta_resultado_final, index=False, encoding='utf-8') #se crea el csv del dataframe\n",
    "\n",
    "\n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f8be533-a397-4df4-8e10-1f131bb07c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 79s 166ms/step - loss: 0.2838 - accuracy: 0.8839 - recall: 0.9411 - auc: 0.9335 - val_loss: 0.1682 - val_accuracy: 0.9434 - val_recall: 0.9722 - val_auc: 0.9710\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.1468 - accuracy: 0.9464 - recall: 0.9700 - auc: 0.9813 - val_loss: 0.1540 - val_accuracy: 0.9498 - val_recall: 0.9664 - val_auc: 0.9759\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.1199 - accuracy: 0.9560 - recall: 0.9729 - auc: 0.9876 - val_loss: 0.1705 - val_accuracy: 0.9424 - val_recall: 0.9503 - val_auc: 0.9755\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.1080 - accuracy: 0.9629 - recall: 0.9788 - auc: 0.9890 - val_loss: 0.1880 - val_accuracy: 0.9360 - val_recall: 0.9342 - val_auc: 0.9784\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 95s 202ms/step - loss: 0.0824 - accuracy: 0.9696 - recall: 0.9795 - auc: 0.9939 - val_loss: 0.1945 - val_accuracy: 0.9285 - val_recall: 0.9635 - val_auc: 0.9664\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 94s 200ms/step - loss: 0.0538 - accuracy: 0.9808 - recall: 0.9887 - auc: 0.9978 - val_loss: 0.2845 - val_accuracy: 0.9360 - val_recall: 0.9357 - val_auc: 0.9692\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 99s 210ms/step - loss: 0.0508 - accuracy: 0.9797 - recall: 0.9883 - auc: 0.9969 - val_loss: 0.3038 - val_accuracy: 0.9338 - val_recall: 0.9240 - val_auc: 0.9707\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 98s 209ms/step - loss: 0.0382 - accuracy: 0.9888 - recall: 0.9934 - auc: 0.9978 - val_loss: 0.2241 - val_accuracy: 0.9349 - val_recall: 0.9547 - val_auc: 0.9700\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 97s 207ms/step - loss: 0.0278 - accuracy: 0.9896 - recall: 0.9938 - auc: 0.9992 - val_loss: 0.2625 - val_accuracy: 0.9392 - val_recall: 0.9503 - val_auc: 0.9664\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 99s 210ms/step - loss: 0.0218 - accuracy: 0.9923 - recall: 0.9949 - auc: 0.9991 - val_loss: 0.3010 - val_accuracy: 0.9360 - val_recall: 0.9459 - val_auc: 0.9643\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 97s 207ms/step - loss: 0.0254 - accuracy: 0.9923 - recall: 0.9952 - auc: 0.9978 - val_loss: 0.2782 - val_accuracy: 0.9360 - val_recall: 0.9430 - val_auc: 0.9685\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 97s 206ms/step - loss: 0.0178 - accuracy: 0.9936 - recall: 0.9952 - auc: 0.9993 - val_loss: 0.2723 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9635\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 98s 209ms/step - loss: 0.0162 - accuracy: 0.9941 - recall: 0.9963 - auc: 0.9996 - val_loss: 0.3262 - val_accuracy: 0.9296 - val_recall: 0.9693 - val_auc: 0.9683\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 103s 220ms/step - loss: 0.0162 - accuracy: 0.9941 - recall: 0.9963 - auc: 0.9998 - val_loss: 0.3434 - val_accuracy: 0.9413 - val_recall: 0.9620 - val_auc: 0.9619\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.283799  0.883907  0.941112  0.933488  0.168159      0.943437   \n",
      "1   0.146787  0.946357  0.970007  0.981264  0.153966      0.949840   \n",
      "2   0.119903  0.955965  0.972933  0.987590  0.170523      0.942369   \n",
      "3   0.108003  0.962904  0.978786  0.989030  0.187966      0.935966   \n",
      "4   0.082439  0.969576  0.979517  0.993895  0.194526      0.928495   \n",
      "5   0.053828  0.980785  0.988661  0.997793  0.284465      0.935966   \n",
      "6   0.050821  0.979717  0.988296  0.996876  0.303801      0.933831   \n",
      "7   0.038165  0.988791  0.993416  0.997843  0.224101      0.934899   \n",
      "8   0.027772  0.989592  0.993782  0.999243  0.262482      0.939168   \n",
      "9   0.021761  0.992260  0.994879  0.999126  0.300973      0.935966   \n",
      "10  0.025445  0.992260  0.995245  0.997757  0.278150      0.935966   \n",
      "11  0.017845  0.993595  0.995245  0.999272  0.272331      0.938100   \n",
      "12  0.016220  0.994129  0.996342  0.999621  0.326183      0.929562   \n",
      "13  0.016157  0.994129  0.996342  0.999804  0.343407      0.941302   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.972222  0.970997  \n",
      "1     0.966374  0.975880  \n",
      "2     0.950292  0.975522  \n",
      "3     0.934211  0.978423  \n",
      "4     0.963450  0.966429  \n",
      "5     0.935673  0.969186  \n",
      "6     0.923977  0.970685  \n",
      "7     0.954678  0.969954  \n",
      "8     0.950292  0.966397  \n",
      "9     0.945906  0.964294  \n",
      "10    0.942982  0.968452  \n",
      "11    0.959064  0.963502  \n",
      "12    0.969298  0.968252  \n",
      "13    0.961988  0.961913  \n",
      "147/147 [==============================] - 22s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 102s 431ms/step - loss: 0.2491 - accuracy: 0.8973 - recall: 0.9546 - auc: 0.9481 - val_loss: 0.1614 - val_accuracy: 0.9370 - val_recall: 0.9649 - val_auc: 0.9753\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 98s 417ms/step - loss: 0.1377 - accuracy: 0.9504 - recall: 0.9751 - auc: 0.9830 - val_loss: 0.1829 - val_accuracy: 0.9338 - val_recall: 0.9532 - val_auc: 0.9727\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 99s 422ms/step - loss: 0.1204 - accuracy: 0.9554 - recall: 0.9755 - auc: 0.9874 - val_loss: 0.2090 - val_accuracy: 0.9274 - val_recall: 0.9196 - val_auc: 0.9785\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 102s 433ms/step - loss: 0.1037 - accuracy: 0.9653 - recall: 0.9788 - auc: 0.9895 - val_loss: 0.2628 - val_accuracy: 0.9093 - val_recall: 0.9942 - val_auc: 0.9696\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 101s 428ms/step - loss: 0.0747 - accuracy: 0.9733 - recall: 0.9850 - auc: 0.9950 - val_loss: 0.1722 - val_accuracy: 0.9370 - val_recall: 0.9518 - val_auc: 0.9788\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 95s 406ms/step - loss: 0.0593 - accuracy: 0.9770 - recall: 0.9868 - auc: 0.9965 - val_loss: 0.2952 - val_accuracy: 0.9178 - val_recall: 0.9883 - val_auc: 0.9647\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 93s 395ms/step - loss: 0.0503 - accuracy: 0.9840 - recall: 0.9920 - auc: 0.9971 - val_loss: 0.2107 - val_accuracy: 0.9306 - val_recall: 0.9737 - val_auc: 0.9738\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 93s 396ms/step - loss: 0.0330 - accuracy: 0.9883 - recall: 0.9938 - auc: 0.9992 - val_loss: 0.3547 - val_accuracy: 0.9157 - val_recall: 0.9912 - val_auc: 0.9570\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 94s 399ms/step - loss: 0.0341 - accuracy: 0.9888 - recall: 0.9931 - auc: 0.9987 - val_loss: 0.2096 - val_accuracy: 0.9338 - val_recall: 0.9591 - val_auc: 0.9725\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 94s 400ms/step - loss: 0.0290 - accuracy: 0.9907 - recall: 0.9956 - auc: 0.9989 - val_loss: 0.2403 - val_accuracy: 0.9402 - val_recall: 0.9532 - val_auc: 0.9727\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 94s 402ms/step - loss: 0.0126 - accuracy: 0.9968 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.2971 - val_accuracy: 0.9456 - val_recall: 0.9474 - val_auc: 0.9716\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 93s 395ms/step - loss: 0.0223 - accuracy: 0.9925 - recall: 0.9949 - auc: 0.9996 - val_loss: 0.2614 - val_accuracy: 0.9445 - val_recall: 0.9766 - val_auc: 0.9659\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 92s 392ms/step - loss: 0.0111 - accuracy: 0.9965 - recall: 0.9982 - auc: 0.9999 - val_loss: 0.3194 - val_accuracy: 0.9360 - val_recall: 0.9795 - val_auc: 0.9598\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 94s 401ms/step - loss: 0.0104 - accuracy: 0.9960 - recall: 0.9971 - auc: 0.9999 - val_loss: 0.2842 - val_accuracy: 0.9338 - val_recall: 0.9708 - val_auc: 0.9642\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 94s 400ms/step - loss: 0.0189 - accuracy: 0.9936 - recall: 0.9967 - auc: 0.9992 - val_loss: 0.3100 - val_accuracy: 0.9317 - val_recall: 0.9444 - val_auc: 0.9605\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.249093  0.897251  0.954645  0.948050  0.161433      0.937033   \n",
      "1   0.137729  0.950360  0.975128  0.983009  0.182897      0.933831   \n",
      "2   0.120378  0.955431  0.975494  0.987397  0.208994      0.927428   \n",
      "3   0.103667  0.965306  0.978786  0.989524  0.262846      0.909285   \n",
      "4   0.074663  0.973312  0.985004  0.994975  0.172173      0.937033   \n",
      "5   0.059346  0.977048  0.986832  0.996493  0.295241      0.917823   \n",
      "6   0.050266  0.983987  0.991953  0.997081  0.210747      0.930630   \n",
      "7   0.033049  0.988257  0.993782  0.999161  0.354731      0.915688   \n",
      "8   0.034135  0.988791  0.993050  0.998662  0.209555      0.933831   \n",
      "9   0.028958  0.990659  0.995611  0.998872  0.240325      0.940235   \n",
      "10  0.012612  0.996797  0.998537  0.999893  0.297053      0.945571   \n",
      "11  0.022342  0.992527  0.994879  0.999622  0.261387      0.944504   \n",
      "12  0.011120  0.996531  0.998171  0.999931  0.319373      0.935966   \n",
      "13  0.010383  0.995997  0.997074  0.999922  0.284233      0.933831   \n",
      "14  0.018929  0.993595  0.996708  0.999228  0.309976      0.931697   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.964912  0.975282  \n",
      "1     0.953216  0.972722  \n",
      "2     0.919591  0.978544  \n",
      "3     0.994152  0.969553  \n",
      "4     0.951754  0.978798  \n",
      "5     0.988304  0.964698  \n",
      "6     0.973684  0.973814  \n",
      "7     0.991228  0.956967  \n",
      "8     0.959064  0.972459  \n",
      "9     0.953216  0.972685  \n",
      "10    0.947368  0.971569  \n",
      "11    0.976608  0.965851  \n",
      "12    0.979532  0.959752  \n",
      "13    0.970760  0.964167  \n",
      "14    0.944444  0.960469  \n",
      "74/74 [==============================] - 20s 269ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 93s 488ms/step - loss: 0.2776 - accuracy: 0.8863 - recall: 0.9550 - auc: 0.9368 - val_loss: 0.1668 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9763\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 94s 497ms/step - loss: 0.1584 - accuracy: 0.9424 - recall: 0.9671 - auc: 0.9789 - val_loss: 0.1580 - val_accuracy: 0.9413 - val_recall: 0.9678 - val_auc: 0.9763\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 92s 490ms/step - loss: 0.1282 - accuracy: 0.9522 - recall: 0.9704 - auc: 0.9857 - val_loss: 0.1519 - val_accuracy: 0.9434 - val_recall: 0.9678 - val_auc: 0.9793\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 93s 497ms/step - loss: 0.1003 - accuracy: 0.9634 - recall: 0.9799 - auc: 0.9910 - val_loss: 0.1710 - val_accuracy: 0.9445 - val_recall: 0.9518 - val_auc: 0.9793\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 93s 494ms/step - loss: 0.0826 - accuracy: 0.9757 - recall: 0.9850 - auc: 0.9933 - val_loss: 0.1783 - val_accuracy: 0.9392 - val_recall: 0.9766 - val_auc: 0.9751\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0715 - accuracy: 0.9754 - recall: 0.9854 - auc: 0.9952 - val_loss: 0.1908 - val_accuracy: 0.9424 - val_recall: 0.9532 - val_auc: 0.9767\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 93s 496ms/step - loss: 0.0507 - accuracy: 0.9811 - recall: 0.9879 - auc: 0.9972 - val_loss: 0.1950 - val_accuracy: 0.9402 - val_recall: 0.9635 - val_auc: 0.9783\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 93s 496ms/step - loss: 0.0490 - accuracy: 0.9813 - recall: 0.9894 - auc: 0.9981 - val_loss: 0.2137 - val_accuracy: 0.9392 - val_recall: 0.9561 - val_auc: 0.9720\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 93s 496ms/step - loss: 0.0392 - accuracy: 0.9869 - recall: 0.9912 - auc: 0.9983 - val_loss: 0.2062 - val_accuracy: 0.9381 - val_recall: 0.9635 - val_auc: 0.9709\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 90s 480ms/step - loss: 0.0250 - accuracy: 0.9917 - recall: 0.9945 - auc: 0.9996 - val_loss: 0.2155 - val_accuracy: 0.9392 - val_recall: 0.9620 - val_auc: 0.9649\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 89s 476ms/step - loss: 0.0169 - accuracy: 0.9957 - recall: 0.9974 - auc: 0.9998 - val_loss: 0.2780 - val_accuracy: 0.9296 - val_recall: 0.9722 - val_auc: 0.9607\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 90s 477ms/step - loss: 0.0101 - accuracy: 0.9984 - recall: 0.9989 - auc: 0.9999 - val_loss: 0.3021 - val_accuracy: 0.9402 - val_recall: 0.9635 - val_auc: 0.9583\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 89s 474ms/step - loss: 0.0084 - accuracy: 0.9987 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9370 - val_recall: 0.9737 - val_auc: 0.9580\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.277644  0.886309  0.955011  0.936795  0.166761      0.940235   \n",
      "1   0.158354  0.942354  0.967081  0.978920  0.157997      0.941302   \n",
      "2   0.128228  0.952228  0.970373  0.985706  0.151948      0.943437   \n",
      "3   0.100317  0.963437  0.979883  0.991048  0.170979      0.944504   \n",
      "4   0.082590  0.975714  0.985004  0.993260  0.178329      0.939168   \n",
      "5   0.071494  0.975447  0.985369  0.995216  0.190783      0.942369   \n",
      "6   0.050749  0.981052  0.987930  0.997217  0.194955      0.940235   \n",
      "7   0.049044  0.981318  0.989393  0.998083  0.213685      0.939168   \n",
      "8   0.039237  0.986923  0.991222  0.998343  0.206241      0.938100   \n",
      "9   0.024966  0.991727  0.994514  0.999597  0.215508      0.939168   \n",
      "10  0.016940  0.995730  0.997440  0.999795  0.278003      0.929562   \n",
      "11  0.010127  0.998399  0.998903  0.999930  0.302150      0.940235   \n",
      "12  0.008443  0.998666  0.998903  0.999969  0.317770      0.937033   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.951754  0.976270  \n",
      "1     0.967836  0.976282  \n",
      "2     0.967836  0.979298  \n",
      "3     0.951754  0.979275  \n",
      "4     0.976608  0.975146  \n",
      "5     0.953216  0.976730  \n",
      "6     0.963450  0.978321  \n",
      "7     0.956140  0.972049  \n",
      "8     0.963450  0.970937  \n",
      "9     0.961988  0.964854  \n",
      "10    0.972222  0.960737  \n",
      "11    0.963450  0.958275  \n",
      "12    0.973684  0.958044  \n",
      "59/59 [==============================] - 18s 308ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 84s 708ms/step - loss: 0.2981 - accuracy: 0.8820 - recall: 0.9653 - auc: 0.9230 - val_loss: 0.1666 - val_accuracy: 0.9296 - val_recall: 0.9737 - val_auc: 0.9765\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 79s 673ms/step - loss: 0.1435 - accuracy: 0.9445 - recall: 0.9700 - auc: 0.9827 - val_loss: 0.1544 - val_accuracy: 0.9424 - val_recall: 0.9547 - val_auc: 0.9780\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 80s 675ms/step - loss: 0.1212 - accuracy: 0.9557 - recall: 0.9762 - auc: 0.9873 - val_loss: 0.1863 - val_accuracy: 0.9306 - val_recall: 0.9284 - val_auc: 0.9796\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 80s 676ms/step - loss: 0.1107 - accuracy: 0.9613 - recall: 0.9770 - auc: 0.9884 - val_loss: 0.1615 - val_accuracy: 0.9402 - val_recall: 0.9722 - val_auc: 0.9759\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 79s 674ms/step - loss: 0.0952 - accuracy: 0.9656 - recall: 0.9792 - auc: 0.9918 - val_loss: 0.1682 - val_accuracy: 0.9456 - val_recall: 0.9693 - val_auc: 0.9734\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 79s 674ms/step - loss: 0.0896 - accuracy: 0.9690 - recall: 0.9824 - auc: 0.9924 - val_loss: 0.1796 - val_accuracy: 0.9424 - val_recall: 0.9737 - val_auc: 0.9762\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 79s 668ms/step - loss: 0.0659 - accuracy: 0.9776 - recall: 0.9868 - auc: 0.9957 - val_loss: 0.1877 - val_accuracy: 0.9445 - val_recall: 0.9488 - val_auc: 0.9760\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 78s 663ms/step - loss: 0.0566 - accuracy: 0.9792 - recall: 0.9865 - auc: 0.9971 - val_loss: 0.1866 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9741\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 79s 673ms/step - loss: 0.0483 - accuracy: 0.9856 - recall: 0.9927 - auc: 0.9974 - val_loss: 0.1906 - val_accuracy: 0.9434 - val_recall: 0.9693 - val_auc: 0.9709\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 80s 681ms/step - loss: 0.0454 - accuracy: 0.9824 - recall: 0.9883 - auc: 0.9979 - val_loss: 0.2196 - val_accuracy: 0.9360 - val_recall: 0.9781 - val_auc: 0.9690\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 80s 679ms/step - loss: 0.0334 - accuracy: 0.9885 - recall: 0.9931 - auc: 0.9987 - val_loss: 0.2014 - val_accuracy: 0.9392 - val_recall: 0.9576 - val_auc: 0.9715\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 79s 672ms/step - loss: 0.0278 - accuracy: 0.9904 - recall: 0.9938 - auc: 0.9995 - val_loss: 0.2254 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9630\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 80s 677ms/step - loss: 0.0214 - accuracy: 0.9939 - recall: 0.9956 - auc: 0.9997 - val_loss: 0.2429 - val_accuracy: 0.9424 - val_recall: 0.9737 - val_auc: 0.9614\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.298132  0.882039  0.965252  0.923007  0.166552      0.929562   \n",
      "1   0.143537  0.944489  0.970007  0.982678  0.154389      0.942369   \n",
      "2   0.121161  0.955698  0.976225  0.987264  0.186320      0.930630   \n",
      "3   0.110737  0.961302  0.976957  0.988400  0.161508      0.940235   \n",
      "4   0.095157  0.965572  0.979151  0.991809  0.168235      0.945571   \n",
      "5   0.089639  0.969042  0.982443  0.992383  0.179609      0.942369   \n",
      "6   0.065911  0.977582  0.986832  0.995722  0.187692      0.944504   \n",
      "7   0.056558  0.979183  0.986467  0.997137  0.186642      0.939168   \n",
      "8   0.048328  0.985588  0.992685  0.997354  0.190582      0.943437   \n",
      "9   0.045354  0.982386  0.988296  0.997949  0.219616      0.935966   \n",
      "10  0.033423  0.988524  0.993050  0.998712  0.201355      0.939168   \n",
      "11  0.027785  0.990392  0.993782  0.999451  0.225363      0.944504   \n",
      "12  0.021395  0.993862  0.995611  0.999717  0.242860      0.942369   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.973684  0.976470  \n",
      "1     0.954678  0.978010  \n",
      "2     0.928363  0.979601  \n",
      "3     0.972222  0.975851  \n",
      "4     0.969298  0.973436  \n",
      "5     0.973684  0.976192  \n",
      "6     0.948830  0.975961  \n",
      "7     0.957602  0.974135  \n",
      "8     0.969298  0.970873  \n",
      "9     0.978070  0.968998  \n",
      "10    0.957602  0.971523  \n",
      "11    0.961988  0.963017  \n",
      "12    0.973684  0.961358  \n",
      "37/37 [==============================] - 17s 447ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.3327 - accuracy: 0.8521 - recall: 0.9477 - auc: 0.9063 - val_loss: 0.1752 - val_accuracy: 0.9381 - val_recall: 0.9444 - val_auc: 0.9757\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.1552 - accuracy: 0.9405 - recall: 0.9660 - auc: 0.9807 - val_loss: 0.1487 - val_accuracy: 0.9477 - val_recall: 0.9620 - val_auc: 0.9790\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.1332 - accuracy: 0.9520 - recall: 0.9737 - auc: 0.9849 - val_loss: 0.2360 - val_accuracy: 0.9114 - val_recall: 0.9927 - val_auc: 0.9712\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.1206 - accuracy: 0.9544 - recall: 0.9726 - auc: 0.9867 - val_loss: 0.1479 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9798\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.1087 - accuracy: 0.9621 - recall: 0.9751 - auc: 0.9898 - val_loss: 0.1509 - val_accuracy: 0.9424 - val_recall: 0.9678 - val_auc: 0.9788\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.1085 - accuracy: 0.9578 - recall: 0.9766 - auc: 0.9898 - val_loss: 0.1631 - val_accuracy: 0.9402 - val_recall: 0.9459 - val_auc: 0.9822\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.0908 - accuracy: 0.9693 - recall: 0.9813 - auc: 0.9917 - val_loss: 0.1662 - val_accuracy: 0.9360 - val_recall: 0.9810 - val_auc: 0.9758\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.0752 - accuracy: 0.9744 - recall: 0.9857 - auc: 0.9942 - val_loss: 0.2004 - val_accuracy: 0.9360 - val_recall: 0.9810 - val_auc: 0.9740\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0673 - accuracy: 0.9749 - recall: 0.9854 - auc: 0.9958 - val_loss: 0.1576 - val_accuracy: 0.9509 - val_recall: 0.9576 - val_auc: 0.9813\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.0726 - accuracy: 0.9754 - recall: 0.9850 - auc: 0.9947 - val_loss: 0.1553 - val_accuracy: 0.9466 - val_recall: 0.9620 - val_auc: 0.9786\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0571 - accuracy: 0.9800 - recall: 0.9865 - auc: 0.9973 - val_loss: 0.1687 - val_accuracy: 0.9402 - val_recall: 0.9678 - val_auc: 0.9781\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.0419 - accuracy: 0.9875 - recall: 0.9923 - auc: 0.9974 - val_loss: 0.1801 - val_accuracy: 0.9381 - val_recall: 0.9635 - val_auc: 0.9755\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0355 - accuracy: 0.9877 - recall: 0.9934 - auc: 0.9985 - val_loss: 0.1966 - val_accuracy: 0.9456 - val_recall: 0.9518 - val_auc: 0.9752\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.0357 - accuracy: 0.9896 - recall: 0.9941 - auc: 0.9991 - val_loss: 0.1859 - val_accuracy: 0.9392 - val_recall: 0.9591 - val_auc: 0.9760\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.0271 - accuracy: 0.9925 - recall: 0.9952 - auc: 0.9992 - val_loss: 0.2021 - val_accuracy: 0.9456 - val_recall: 0.9605 - val_auc: 0.9748\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0184 - accuracy: 0.9955 - recall: 0.9967 - auc: 0.9997 - val_loss: 0.2208 - val_accuracy: 0.9466 - val_recall: 0.9547 - val_auc: 0.9759\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.332657  0.852148  0.947696  0.906315  0.175198      0.938100   \n",
      "1   0.155206  0.940486  0.965984  0.980739  0.148678      0.947705   \n",
      "2   0.133198  0.951962  0.973665  0.984892  0.236008      0.911419   \n",
      "3   0.120580  0.954363  0.972568  0.986747  0.147924      0.948773   \n",
      "4   0.108691  0.962103  0.975128  0.989789  0.150884      0.942369   \n",
      "5   0.108521  0.957833  0.976591  0.989778  0.163131      0.940235   \n",
      "6   0.090762  0.969309  0.981346  0.991711  0.166163      0.935966   \n",
      "7   0.075173  0.974379  0.985735  0.994232  0.200356      0.935966   \n",
      "8   0.067277  0.974913  0.985369  0.995810  0.157596      0.950907   \n",
      "9   0.072582  0.975447  0.985004  0.994705  0.155330      0.946638   \n",
      "10  0.057076  0.979984  0.986467  0.997333  0.168706      0.940235   \n",
      "11  0.041909  0.987457  0.992319  0.997405  0.180128      0.938100   \n",
      "12  0.035530  0.987724  0.993416  0.998517  0.196573      0.945571   \n",
      "13  0.035664  0.989592  0.994148  0.999105  0.185903      0.939168   \n",
      "14  0.027063  0.992527  0.995245  0.999166  0.202103      0.945571   \n",
      "15  0.018358  0.995463  0.996708  0.999745  0.220840      0.946638   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.944444  0.975666  \n",
      "1     0.961988  0.978952  \n",
      "2     0.992690  0.971228  \n",
      "3     0.960526  0.979752  \n",
      "4     0.967836  0.978761  \n",
      "5     0.945906  0.982208  \n",
      "6     0.980994  0.975825  \n",
      "7     0.980994  0.973988  \n",
      "8     0.957602  0.981266  \n",
      "9     0.961988  0.978593  \n",
      "10    0.967836  0.978099  \n",
      "11    0.963450  0.975487  \n",
      "12    0.951754  0.975190  \n",
      "13    0.959064  0.976039  \n",
      "14    0.960526  0.974805  \n",
      "15    0.954678  0.975860  \n",
      "19/19 [==============================] - 15s 778ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 103s 217ms/step - loss: 0.3304 - accuracy: 0.8652 - recall: 0.9375 - auc: 0.9171 - val_loss: 0.1788 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9709\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 107s 227ms/step - loss: 0.1805 - accuracy: 0.9319 - recall: 0.9579 - auc: 0.9733 - val_loss: 0.1751 - val_accuracy: 0.9381 - val_recall: 0.9751 - val_auc: 0.9742\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 104s 222ms/step - loss: 0.1302 - accuracy: 0.9541 - recall: 0.9715 - auc: 0.9851 - val_loss: 0.2612 - val_accuracy: 0.8997 - val_recall: 0.8801 - val_auc: 0.9782\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 104s 222ms/step - loss: 0.1172 - accuracy: 0.9565 - recall: 0.9718 - auc: 0.9874 - val_loss: 0.2279 - val_accuracy: 0.9200 - val_recall: 0.9781 - val_auc: 0.9634\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 103s 219ms/step - loss: 0.0736 - accuracy: 0.9733 - recall: 0.9835 - auc: 0.9957 - val_loss: 0.2045 - val_accuracy: 0.9392 - val_recall: 0.9474 - val_auc: 0.9735\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 104s 221ms/step - loss: 0.0641 - accuracy: 0.9781 - recall: 0.9857 - auc: 0.9954 - val_loss: 0.2486 - val_accuracy: 0.9317 - val_recall: 0.9342 - val_auc: 0.9711\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 107s 229ms/step - loss: 0.0560 - accuracy: 0.9773 - recall: 0.9865 - auc: 0.9976 - val_loss: 0.2195 - val_accuracy: 0.9434 - val_recall: 0.9678 - val_auc: 0.9659\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 104s 223ms/step - loss: 0.0434 - accuracy: 0.9832 - recall: 0.9909 - auc: 0.9985 - val_loss: 0.2415 - val_accuracy: 0.9392 - val_recall: 0.9503 - val_auc: 0.9687\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 104s 222ms/step - loss: 0.0200 - accuracy: 0.9928 - recall: 0.9963 - auc: 0.9997 - val_loss: 0.3779 - val_accuracy: 0.9360 - val_recall: 0.9649 - val_auc: 0.9571\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 106s 226ms/step - loss: 0.0208 - accuracy: 0.9925 - recall: 0.9967 - auc: 0.9995 - val_loss: 0.3377 - val_accuracy: 0.9413 - val_recall: 0.9488 - val_auc: 0.9573\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 103s 220ms/step - loss: 0.0310 - accuracy: 0.9899 - recall: 0.9949 - auc: 0.9981 - val_loss: 0.2555 - val_accuracy: 0.9392 - val_recall: 0.9620 - val_auc: 0.9692\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 102s 217ms/step - loss: 0.0300 - accuracy: 0.9883 - recall: 0.9931 - auc: 0.9993 - val_loss: 0.3636 - val_accuracy: 0.9349 - val_recall: 0.9678 - val_auc: 0.9530\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 102s 217ms/step - loss: 0.0138 - accuracy: 0.9952 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.3857 - val_accuracy: 0.9434 - val_recall: 0.9635 - val_auc: 0.9525\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.330407  0.865225  0.937454  0.917093  0.178797      0.942369   \n",
      "1   0.180491  0.931946  0.957937  0.973286  0.175134      0.938100   \n",
      "2   0.130164  0.954097  0.971470  0.985133  0.261189      0.899680   \n",
      "3   0.117220  0.956499  0.971836  0.987430  0.227857      0.919957   \n",
      "4   0.073573  0.973312  0.983541  0.995672  0.204524      0.939168   \n",
      "5   0.064134  0.978116  0.985735  0.995353  0.248635      0.931697   \n",
      "6   0.055992  0.977315  0.986467  0.997593  0.219499      0.943437   \n",
      "7   0.043390  0.983187  0.990856  0.998477  0.241476      0.939168   \n",
      "8   0.019987  0.992794  0.996342  0.999744  0.377917      0.935966   \n",
      "9   0.020795  0.992527  0.996708  0.999515  0.337668      0.941302   \n",
      "10  0.030995  0.989859  0.994879  0.998133  0.255521      0.939168   \n",
      "11  0.030023  0.988257  0.993050  0.999331  0.363645      0.934899   \n",
      "12  0.013773  0.995196  0.997805  0.999842  0.385663      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.972222  0.970887  \n",
      "1     0.975146  0.974207  \n",
      "2     0.880117  0.978177  \n",
      "3     0.978070  0.963352  \n",
      "4     0.947368  0.973456  \n",
      "5     0.934211  0.971136  \n",
      "6     0.967836  0.965851  \n",
      "7     0.950292  0.968674  \n",
      "8     0.964912  0.957065  \n",
      "9     0.948830  0.957328  \n",
      "10    0.961988  0.969243  \n",
      "11    0.967836  0.953049  \n",
      "12    0.963450  0.952485  \n",
      "147/147 [==============================] - 23s 154ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 98s 410ms/step - loss: 0.2852 - accuracy: 0.8807 - recall: 0.9426 - auc: 0.9335 - val_loss: 0.1742 - val_accuracy: 0.9392 - val_recall: 0.9488 - val_auc: 0.9733\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 99s 423ms/step - loss: 0.1596 - accuracy: 0.9384 - recall: 0.9590 - auc: 0.9793 - val_loss: 0.1637 - val_accuracy: 0.9424 - val_recall: 0.9708 - val_auc: 0.9748\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 99s 420ms/step - loss: 0.1207 - accuracy: 0.9544 - recall: 0.9718 - auc: 0.9878 - val_loss: 0.1647 - val_accuracy: 0.9456 - val_recall: 0.9766 - val_auc: 0.9743\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 99s 421ms/step - loss: 0.0875 - accuracy: 0.9682 - recall: 0.9806 - auc: 0.9935 - val_loss: 0.1702 - val_accuracy: 0.9392 - val_recall: 0.9488 - val_auc: 0.9772\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 100s 425ms/step - loss: 0.0825 - accuracy: 0.9725 - recall: 0.9843 - auc: 0.9932 - val_loss: 0.1802 - val_accuracy: 0.9392 - val_recall: 0.9401 - val_auc: 0.9782\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 99s 423ms/step - loss: 0.0595 - accuracy: 0.9800 - recall: 0.9872 - auc: 0.9971 - val_loss: 0.1875 - val_accuracy: 0.9381 - val_recall: 0.9532 - val_auc: 0.9741\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 99s 420ms/step - loss: 0.0499 - accuracy: 0.9827 - recall: 0.9901 - auc: 0.9977 - val_loss: 0.2109 - val_accuracy: 0.9424 - val_recall: 0.9693 - val_auc: 0.9701\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 99s 420ms/step - loss: 0.0289 - accuracy: 0.9909 - recall: 0.9945 - auc: 0.9989 - val_loss: 0.2723 - val_accuracy: 0.9370 - val_recall: 0.9722 - val_auc: 0.9621\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 98s 417ms/step - loss: 0.0295 - accuracy: 0.9901 - recall: 0.9938 - auc: 0.9991 - val_loss: 0.2647 - val_accuracy: 0.9445 - val_recall: 0.9561 - val_auc: 0.9658\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 100s 425ms/step - loss: 0.0211 - accuracy: 0.9931 - recall: 0.9960 - auc: 0.9992 - val_loss: 0.2935 - val_accuracy: 0.9402 - val_recall: 0.9474 - val_auc: 0.9702\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 101s 429ms/step - loss: 0.0255 - accuracy: 0.9901 - recall: 0.9952 - auc: 0.9995 - val_loss: 0.3466 - val_accuracy: 0.9402 - val_recall: 0.9825 - val_auc: 0.9577\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 100s 425ms/step - loss: 0.0160 - accuracy: 0.9939 - recall: 0.9978 - auc: 0.9993 - val_loss: 0.3217 - val_accuracy: 0.9434 - val_recall: 0.9474 - val_auc: 0.9649\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 100s 425ms/step - loss: 0.0100 - accuracy: 0.9965 - recall: 0.9996 - auc: 0.9999 - val_loss: 0.3473 - val_accuracy: 0.9434 - val_recall: 0.9605 - val_auc: 0.9600\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 99s 422ms/step - loss: 0.0119 - accuracy: 0.9957 - recall: 0.9978 - auc: 0.9994 - val_loss: 0.4117 - val_accuracy: 0.9317 - val_recall: 0.9722 - val_auc: 0.9486\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 99s 421ms/step - loss: 0.0296 - accuracy: 0.9893 - recall: 0.9949 - auc: 0.9989 - val_loss: 0.3589 - val_accuracy: 0.9392 - val_recall: 0.9605 - val_auc: 0.9576\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.285168  0.880705  0.942575  0.933457  0.174211      0.939168   \n",
      "1   0.159568  0.938351  0.959034  0.979340  0.163690      0.942369   \n",
      "2   0.120682  0.954363  0.971836  0.987850  0.164679      0.945571   \n",
      "3   0.087489  0.968241  0.980614  0.993492  0.170177      0.939168   \n",
      "4   0.082469  0.972511  0.984272  0.993177  0.180161      0.939168   \n",
      "5   0.059532  0.979984  0.987198  0.997144  0.187486      0.938100   \n",
      "6   0.049950  0.982653  0.990124  0.997657  0.210931      0.942369   \n",
      "7   0.028924  0.990926  0.994514  0.998903  0.272300      0.937033   \n",
      "8   0.029490  0.990125  0.993782  0.999141  0.264742      0.944504   \n",
      "9   0.021149  0.993061  0.995977  0.999194  0.293524      0.940235   \n",
      "10  0.025545  0.990125  0.995245  0.999492  0.346568      0.940235   \n",
      "11  0.015984  0.993862  0.997805  0.999333  0.321663      0.943437   \n",
      "12  0.010029  0.996531  0.999634  0.999944  0.347259      0.943437   \n",
      "13  0.011945  0.995730  0.997805  0.999424  0.411730      0.931697   \n",
      "14  0.029577  0.989325  0.994879  0.998918  0.358915      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.948830  0.973297  \n",
      "1     0.970760  0.974779  \n",
      "2     0.976608  0.974279  \n",
      "3     0.948830  0.977232  \n",
      "4     0.940058  0.978192  \n",
      "5     0.953216  0.974051  \n",
      "6     0.969298  0.970139  \n",
      "7     0.972222  0.962072  \n",
      "8     0.956140  0.965782  \n",
      "9     0.947368  0.970156  \n",
      "10    0.982456  0.957744  \n",
      "11    0.947368  0.964927  \n",
      "12    0.960526  0.959963  \n",
      "13    0.972222  0.948593  \n",
      "14    0.960526  0.957550  \n",
      "74/74 [==============================] - 20s 271ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 96s 508ms/step - loss: 0.3007 - accuracy: 0.8866 - recall: 0.9386 - auc: 0.9341 - val_loss: 0.1603 - val_accuracy: 0.9370 - val_recall: 0.9635 - val_auc: 0.9769\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 93s 496ms/step - loss: 0.1402 - accuracy: 0.9474 - recall: 0.9649 - auc: 0.9834 - val_loss: 0.1785 - val_accuracy: 0.9360 - val_recall: 0.9605 - val_auc: 0.9713\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 95s 506ms/step - loss: 0.1058 - accuracy: 0.9629 - recall: 0.9766 - auc: 0.9898 - val_loss: 0.1498 - val_accuracy: 0.9456 - val_recall: 0.9576 - val_auc: 0.9822\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0816 - accuracy: 0.9741 - recall: 0.9843 - auc: 0.9931 - val_loss: 0.1733 - val_accuracy: 0.9317 - val_recall: 0.9795 - val_auc: 0.9781\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 92s 490ms/step - loss: 0.0836 - accuracy: 0.9682 - recall: 0.9806 - auc: 0.9936 - val_loss: 0.1759 - val_accuracy: 0.9413 - val_recall: 0.9532 - val_auc: 0.9771\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 94s 498ms/step - loss: 0.0552 - accuracy: 0.9770 - recall: 0.9850 - auc: 0.9978 - val_loss: 0.1956 - val_accuracy: 0.9381 - val_recall: 0.9488 - val_auc: 0.9715\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 92s 492ms/step - loss: 0.0424 - accuracy: 0.9845 - recall: 0.9909 - auc: 0.9986 - val_loss: 0.2702 - val_accuracy: 0.9360 - val_recall: 0.9722 - val_auc: 0.9630\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 97s 515ms/step - loss: 0.0271 - accuracy: 0.9896 - recall: 0.9945 - auc: 0.9994 - val_loss: 0.2369 - val_accuracy: 0.9317 - val_recall: 0.9459 - val_auc: 0.9701\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 92s 491ms/step - loss: 0.0164 - accuracy: 0.9949 - recall: 0.9978 - auc: 0.9998 - val_loss: 0.3056 - val_accuracy: 0.9392 - val_recall: 0.9532 - val_auc: 0.9615\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 94s 502ms/step - loss: 0.0138 - accuracy: 0.9941 - recall: 0.9967 - auc: 0.9999 - val_loss: 0.2693 - val_accuracy: 0.9392 - val_recall: 0.9605 - val_auc: 0.9664\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 95s 504ms/step - loss: 0.0101 - accuracy: 0.9971 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9434 - val_recall: 0.9503 - val_auc: 0.9657\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 96s 513ms/step - loss: 0.0076 - accuracy: 0.9981 - recall: 0.9993 - auc: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9402 - val_recall: 0.9693 - val_auc: 0.9611\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 95s 504ms/step - loss: 0.0099 - accuracy: 0.9965 - recall: 0.9982 - auc: 0.9999 - val_loss: 0.3617 - val_accuracy: 0.9349 - val_recall: 0.9722 - val_auc: 0.9482\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.300672  0.886576  0.938552  0.934109  0.160300      0.937033   \n",
      "1   0.140169  0.947425  0.964887  0.983385  0.178462      0.935966   \n",
      "2   0.105815  0.962904  0.976591  0.989815  0.149776      0.945571   \n",
      "3   0.081596  0.974113  0.984272  0.993080  0.173324      0.931697   \n",
      "4   0.083605  0.968241  0.980614  0.993577  0.175871      0.941302   \n",
      "5   0.055179  0.977048  0.985004  0.997766  0.195571      0.938100   \n",
      "6   0.042430  0.984521  0.990856  0.998597  0.270190      0.935966   \n",
      "7   0.027090  0.989592  0.994514  0.999393  0.236944      0.931697   \n",
      "8   0.016403  0.994929  0.997805  0.999807  0.305608      0.939168   \n",
      "9   0.013758  0.994129  0.996708  0.999883  0.269256      0.939168   \n",
      "10  0.010122  0.997064  0.998537  0.999955  0.315700      0.943437   \n",
      "11  0.007642  0.998132  0.999268  0.999963  0.328681      0.940235   \n",
      "12  0.009866  0.996531  0.998171  0.999936  0.361706      0.934899   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.963450  0.976871  \n",
      "1     0.960526  0.971254  \n",
      "2     0.957602  0.982216  \n",
      "3     0.979532  0.978122  \n",
      "4     0.953216  0.977146  \n",
      "5     0.948830  0.971523  \n",
      "6     0.972222  0.962994  \n",
      "7     0.945906  0.970148  \n",
      "8     0.953216  0.961509  \n",
      "9     0.960526  0.966426  \n",
      "10    0.950292  0.965736  \n",
      "11    0.969298  0.961113  \n",
      "12    0.972222  0.948163  \n",
      "59/59 [==============================] - 19s 326ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 86s 718ms/step - loss: 0.2893 - accuracy: 0.8826 - recall: 0.9426 - auc: 0.9394 - val_loss: 0.1632 - val_accuracy: 0.9424 - val_recall: 0.9518 - val_auc: 0.9756\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 83s 704ms/step - loss: 0.1474 - accuracy: 0.9458 - recall: 0.9671 - auc: 0.9818 - val_loss: 0.1625 - val_accuracy: 0.9445 - val_recall: 0.9708 - val_auc: 0.9750\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 83s 702ms/step - loss: 0.1217 - accuracy: 0.9576 - recall: 0.9700 - auc: 0.9873 - val_loss: 0.1766 - val_accuracy: 0.9445 - val_recall: 0.9722 - val_auc: 0.9732\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 83s 702ms/step - loss: 0.1013 - accuracy: 0.9618 - recall: 0.9773 - auc: 0.9902 - val_loss: 0.1511 - val_accuracy: 0.9456 - val_recall: 0.9693 - val_auc: 0.9793\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 82s 699ms/step - loss: 0.0717 - accuracy: 0.9744 - recall: 0.9843 - auc: 0.9954 - val_loss: 0.1747 - val_accuracy: 0.9456 - val_recall: 0.9635 - val_auc: 0.9770\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 82s 696ms/step - loss: 0.0625 - accuracy: 0.9773 - recall: 0.9861 - auc: 0.9968 - val_loss: 0.2169 - val_accuracy: 0.9317 - val_recall: 0.9839 - val_auc: 0.9713\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 82s 698ms/step - loss: 0.0509 - accuracy: 0.9819 - recall: 0.9905 - auc: 0.9974 - val_loss: 0.1804 - val_accuracy: 0.9349 - val_recall: 0.9518 - val_auc: 0.9800\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 83s 701ms/step - loss: 0.0332 - accuracy: 0.9880 - recall: 0.9931 - auc: 0.9987 - val_loss: 0.2085 - val_accuracy: 0.9402 - val_recall: 0.9708 - val_auc: 0.9743\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 84s 708ms/step - loss: 0.0285 - accuracy: 0.9899 - recall: 0.9934 - auc: 0.9994 - val_loss: 0.2489 - val_accuracy: 0.9264 - val_recall: 0.9766 - val_auc: 0.9641\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 82s 696ms/step - loss: 0.0169 - accuracy: 0.9947 - recall: 0.9971 - auc: 0.9998 - val_loss: 0.2389 - val_accuracy: 0.9434 - val_recall: 0.9444 - val_auc: 0.9725\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 82s 693ms/step - loss: 0.0122 - accuracy: 0.9965 - recall: 0.9978 - auc: 0.9999 - val_loss: 0.2513 - val_accuracy: 0.9360 - val_recall: 0.9635 - val_auc: 0.9666\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 83s 703ms/step - loss: 0.0110 - accuracy: 0.9963 - recall: 0.9974 - auc: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9456 - val_recall: 0.9635 - val_auc: 0.9668\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 83s 708ms/step - loss: 0.0668 - accuracy: 0.9752 - recall: 0.9846 - auc: 0.9955 - val_loss: 0.1776 - val_accuracy: 0.9424 - val_recall: 0.9532 - val_auc: 0.9760\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 83s 703ms/step - loss: 0.0348 - accuracy: 0.9869 - recall: 0.9934 - auc: 0.9991 - val_loss: 0.2346 - val_accuracy: 0.9424 - val_recall: 0.9532 - val_auc: 0.9737\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 83s 706ms/step - loss: 0.0164 - accuracy: 0.9939 - recall: 0.9967 - auc: 0.9999 - val_loss: 0.2878 - val_accuracy: 0.9381 - val_recall: 0.9444 - val_auc: 0.9670\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 82s 696ms/step - loss: 0.0098 - accuracy: 0.9973 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.2947 - val_accuracy: 0.9456 - val_recall: 0.9547 - val_auc: 0.9655\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 83s 703ms/step - loss: 0.0084 - accuracy: 0.9971 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9381 - val_recall: 0.9591 - val_auc: 0.9565\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.289320  0.882573  0.942575  0.939434  0.163245      0.942369   \n",
      "1   0.147424  0.945823  0.967081  0.981812  0.162498      0.944504   \n",
      "2   0.121749  0.957566  0.970007  0.987349  0.176608      0.944504   \n",
      "3   0.101317  0.961836  0.977323  0.990188  0.151079      0.945571   \n",
      "4   0.071672  0.974379  0.984272  0.995420  0.174653      0.945571   \n",
      "5   0.062547  0.977315  0.986101  0.996802  0.216940      0.931697   \n",
      "6   0.050920  0.981852  0.990490  0.997425  0.180372      0.934899   \n",
      "7   0.033154  0.987990  0.993050  0.998724  0.208521      0.940235   \n",
      "8   0.028509  0.989859  0.993416  0.999352  0.248874      0.926361   \n",
      "9   0.016917  0.994662  0.997074  0.999830  0.238944      0.943437   \n",
      "10  0.012160  0.996531  0.997805  0.999874  0.251259      0.935966   \n",
      "11  0.010970  0.996264  0.997440  0.999953  0.287934      0.945571   \n",
      "12  0.066780  0.975180  0.984638  0.995453  0.177608      0.942369   \n",
      "13  0.034801  0.986923  0.993416  0.999128  0.234616      0.942369   \n",
      "14  0.016447  0.993862  0.996708  0.999855  0.287781      0.938100   \n",
      "15  0.009843  0.997331  0.998537  0.999944  0.294674      0.945571   \n",
      "16  0.008396  0.997064  0.998537  0.999963  0.320209      0.938100   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.951754  0.975617  \n",
      "1     0.970760  0.974964  \n",
      "2     0.972222  0.973236  \n",
      "3     0.969298  0.979275  \n",
      "4     0.963450  0.977047  \n",
      "5     0.983918  0.971266  \n",
      "6     0.951754  0.980046  \n",
      "7     0.970760  0.974271  \n",
      "8     0.976608  0.964106  \n",
      "9     0.944444  0.972508  \n",
      "10    0.963450  0.966649  \n",
      "11    0.963450  0.966802  \n",
      "12    0.953216  0.976019  \n",
      "13    0.953216  0.973699  \n",
      "14    0.944444  0.967048  \n",
      "15    0.954678  0.965455  \n",
      "16    0.959064  0.956473  \n",
      "37/37 [==============================] - 18s 473ms/step\n",
      "Entrenando modelo Simple2 y batch_size 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.3295 - accuracy: 0.8794 - recall: 0.9396 - auc: 0.9236 - val_loss: 0.1626 - val_accuracy: 0.9424 - val_recall: 0.9605 - val_auc: 0.9744\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 847s 15s/step - loss: 0.1372 - accuracy: 0.9477 - recall: 0.9674 - auc: 0.9837 - val_loss: 0.1805 - val_accuracy: 0.9370 - val_recall: 0.9342 - val_auc: 0.9791\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 71s 1s/step - loss: 0.1096 - accuracy: 0.9592 - recall: 0.9755 - auc: 0.9884 - val_loss: 0.1642 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9778\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 69s 1s/step - loss: 0.0900 - accuracy: 0.9664 - recall: 0.9788 - auc: 0.9931 - val_loss: 0.1562 - val_accuracy: 0.9413 - val_recall: 0.9649 - val_auc: 0.9766\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.0679 - accuracy: 0.9784 - recall: 0.9868 - auc: 0.9958 - val_loss: 0.2111 - val_accuracy: 0.9338 - val_recall: 0.9854 - val_auc: 0.9725\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 70s 1s/step - loss: 0.0674 - accuracy: 0.9765 - recall: 0.9857 - auc: 0.9963 - val_loss: 0.1664 - val_accuracy: 0.9445 - val_recall: 0.9576 - val_auc: 0.9784\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 68s 1s/step - loss: 0.0378 - accuracy: 0.9872 - recall: 0.9927 - auc: 0.9989 - val_loss: 0.1959 - val_accuracy: 0.9445 - val_recall: 0.9649 - val_auc: 0.9742\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 69s 1s/step - loss: 0.0339 - accuracy: 0.9867 - recall: 0.9912 - auc: 0.9991 - val_loss: 0.1884 - val_accuracy: 0.9466 - val_recall: 0.9591 - val_auc: 0.9765\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 70s 1s/step - loss: 0.0210 - accuracy: 0.9941 - recall: 0.9982 - auc: 0.9997 - val_loss: 0.2058 - val_accuracy: 0.9445 - val_recall: 0.9664 - val_auc: 0.9759\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 71s 1s/step - loss: 0.0173 - accuracy: 0.9944 - recall: 0.9967 - auc: 0.9998 - val_loss: 0.2378 - val_accuracy: 0.9477 - val_recall: 0.9693 - val_auc: 0.9659\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 70s 1s/step - loss: 0.0081 - accuracy: 0.9976 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9466 - val_recall: 0.9547 - val_auc: 0.9706\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 70s 1s/step - loss: 0.0091 - accuracy: 0.9984 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.2742 - val_accuracy: 0.9434 - val_recall: 0.9678 - val_auc: 0.9660\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.329547  0.879370  0.939649  0.923594  0.162612      0.942369   \n",
      "1   0.137224  0.947692  0.967447  0.983727  0.180487      0.937033   \n",
      "2   0.109551  0.959167  0.975494  0.988439  0.164219      0.940235   \n",
      "3   0.090029  0.966373  0.978786  0.993100  0.156231      0.941302   \n",
      "4   0.067922  0.978383  0.986832  0.995751  0.211054      0.933831   \n",
      "5   0.067351  0.976515  0.985735  0.996271  0.166357      0.944504   \n",
      "6   0.037759  0.987190  0.992685  0.998891  0.195908      0.944504   \n",
      "7   0.033851  0.986656  0.991222  0.999132  0.188418      0.946638   \n",
      "8   0.020975  0.994129  0.998171  0.999731  0.205811      0.944504   \n",
      "9   0.017254  0.994395  0.996708  0.999807  0.237840      0.947705   \n",
      "10  0.008085  0.997598  0.998903  0.999984  0.268419      0.946638   \n",
      "11  0.009147  0.998399  0.998537  0.999940  0.274236      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.960526  0.974386  \n",
      "1     0.934211  0.979055  \n",
      "2     0.951754  0.977790  \n",
      "3     0.964912  0.976643  \n",
      "4     0.985380  0.972514  \n",
      "5     0.957602  0.978400  \n",
      "6     0.964912  0.974167  \n",
      "7     0.959064  0.976475  \n",
      "8     0.966374  0.975880  \n",
      "9     0.969298  0.965866  \n",
      "10    0.954678  0.970645  \n",
      "11    0.967836  0.966007  \n",
      "19/19 [==============================] - 15s 753ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 99s 208ms/step - loss: 0.3515 - accuracy: 0.8578 - recall: 0.9375 - auc: 0.9030 - val_loss: 0.1751 - val_accuracy: 0.9370 - val_recall: 0.9503 - val_auc: 0.9727\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 102s 218ms/step - loss: 0.1962 - accuracy: 0.9295 - recall: 0.9583 - auc: 0.9692 - val_loss: 0.1581 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9776\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.1537 - accuracy: 0.9472 - recall: 0.9700 - auc: 0.9803 - val_loss: 0.1593 - val_accuracy: 0.9392 - val_recall: 0.9620 - val_auc: 0.9795\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.1188 - accuracy: 0.9538 - recall: 0.9685 - auc: 0.9878 - val_loss: 0.2075 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9695\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.0961 - accuracy: 0.9637 - recall: 0.9766 - auc: 0.9920 - val_loss: 0.1806 - val_accuracy: 0.9381 - val_recall: 0.9649 - val_auc: 0.9733\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.0864 - accuracy: 0.9666 - recall: 0.9762 - auc: 0.9931 - val_loss: 0.2655 - val_accuracy: 0.9253 - val_recall: 0.9518 - val_auc: 0.9579\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 102s 218ms/step - loss: 0.0629 - accuracy: 0.9752 - recall: 0.9850 - auc: 0.9969 - val_loss: 0.6610 - val_accuracy: 0.9200 - val_recall: 0.9751 - val_auc: 0.9209\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.0618 - accuracy: 0.9786 - recall: 0.9857 - auc: 0.9960 - val_loss: 0.2424 - val_accuracy: 0.9424 - val_recall: 0.9649 - val_auc: 0.9745\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 102s 218ms/step - loss: 0.0377 - accuracy: 0.9848 - recall: 0.9927 - auc: 0.9989 - val_loss: 0.3304 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9663\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 102s 216ms/step - loss: 0.0374 - accuracy: 0.9851 - recall: 0.9923 - auc: 0.9984 - val_loss: 0.3052 - val_accuracy: 0.9370 - val_recall: 0.9532 - val_auc: 0.9666\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 102s 216ms/step - loss: 0.0692 - accuracy: 0.9792 - recall: 0.9861 - auc: 0.9936 - val_loss: 0.2956 - val_accuracy: 0.9338 - val_recall: 0.9561 - val_auc: 0.9634\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.0286 - accuracy: 0.9928 - recall: 0.9967 - auc: 0.9987 - val_loss: 0.3538 - val_accuracy: 0.9413 - val_recall: 0.9664 - val_auc: 0.9540\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.0253 - accuracy: 0.9904 - recall: 0.9949 - auc: 0.9984 - val_loss: 0.3446 - val_accuracy: 0.9296 - val_recall: 0.9664 - val_auc: 0.9509\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.351543  0.857753  0.937454  0.903012  0.175137      0.937033   \n",
      "1   0.196194  0.929544  0.958303  0.969207  0.158102      0.940235   \n",
      "2   0.153698  0.947158  0.970007  0.980343  0.159326      0.939168   \n",
      "3   0.118755  0.953830  0.968544  0.987826  0.207483      0.937033   \n",
      "4   0.096074  0.963704  0.976591  0.991990  0.180624      0.938100   \n",
      "5   0.086391  0.966640  0.976225  0.993128  0.265542      0.925294   \n",
      "6   0.062864  0.975180  0.985004  0.996899  0.661000      0.919957   \n",
      "7   0.061772  0.978650  0.985735  0.996033  0.242386      0.942369   \n",
      "8   0.037677  0.984788  0.992685  0.998919  0.330411      0.940235   \n",
      "9   0.037406  0.985055  0.992319  0.998361  0.305184      0.937033   \n",
      "10  0.069161  0.979183  0.986101  0.993602  0.295645      0.933831   \n",
      "11  0.028565  0.992794  0.996708  0.998679  0.353784      0.941302   \n",
      "12  0.025271  0.990392  0.994879  0.998441  0.344553      0.929562   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.972699  \n",
      "1     0.951754  0.977582  \n",
      "2     0.961988  0.979486  \n",
      "3     0.967836  0.969489  \n",
      "4     0.964912  0.973260  \n",
      "5     0.951754  0.957880  \n",
      "6     0.975146  0.920940  \n",
      "7     0.964912  0.974499  \n",
      "8     0.961988  0.966256  \n",
      "9     0.953216  0.966591  \n",
      "10    0.956140  0.963358  \n",
      "11    0.966374  0.954011  \n",
      "12    0.966374  0.950905  \n",
      "147/147 [==============================] - 22s 151ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 97s 407ms/step - loss: 0.3644 - accuracy: 0.8404 - recall: 0.9334 - auc: 0.8909 - val_loss: 0.1802 - val_accuracy: 0.9264 - val_recall: 0.9781 - val_auc: 0.9727\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 96s 410ms/step - loss: 0.1827 - accuracy: 0.9285 - recall: 0.9631 - auc: 0.9724 - val_loss: 0.1884 - val_accuracy: 0.9370 - val_recall: 0.9678 - val_auc: 0.9690\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 96s 410ms/step - loss: 0.1405 - accuracy: 0.9501 - recall: 0.9759 - auc: 0.9810 - val_loss: 0.1725 - val_accuracy: 0.9381 - val_recall: 0.9664 - val_auc: 0.9754\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 97s 412ms/step - loss: 0.1184 - accuracy: 0.9602 - recall: 0.9762 - auc: 0.9874 - val_loss: 0.2089 - val_accuracy: 0.9338 - val_recall: 0.9722 - val_auc: 0.9692\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 96s 410ms/step - loss: 0.0996 - accuracy: 0.9634 - recall: 0.9817 - auc: 0.9907 - val_loss: 0.2169 - val_accuracy: 0.9360 - val_recall: 0.9795 - val_auc: 0.9746\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 95s 405ms/step - loss: 0.0764 - accuracy: 0.9720 - recall: 0.9868 - auc: 0.9955 - val_loss: 0.2072 - val_accuracy: 0.9413 - val_recall: 0.9561 - val_auc: 0.9746\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 96s 409ms/step - loss: 0.0655 - accuracy: 0.9746 - recall: 0.9879 - auc: 0.9959 - val_loss: 0.2661 - val_accuracy: 0.9392 - val_recall: 0.9649 - val_auc: 0.9664\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 96s 409ms/step - loss: 0.0500 - accuracy: 0.9805 - recall: 0.9890 - auc: 0.9971 - val_loss: 0.2304 - val_accuracy: 0.9381 - val_recall: 0.9635 - val_auc: 0.9727\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 96s 410ms/step - loss: 0.0411 - accuracy: 0.9851 - recall: 0.9923 - auc: 0.9981 - val_loss: 0.3130 - val_accuracy: 0.9360 - val_recall: 0.9605 - val_auc: 0.9637\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 96s 410ms/step - loss: 0.0418 - accuracy: 0.9861 - recall: 0.9912 - auc: 0.9985 - val_loss: 0.3528 - val_accuracy: 0.9317 - val_recall: 0.9605 - val_auc: 0.9543\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 98s 415ms/step - loss: 0.0588 - accuracy: 0.9792 - recall: 0.9883 - auc: 0.9962 - val_loss: 0.2719 - val_accuracy: 0.9381 - val_recall: 0.9635 - val_auc: 0.9632\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 97s 411ms/step - loss: 0.0240 - accuracy: 0.9909 - recall: 0.9949 - auc: 0.9996 - val_loss: 0.3986 - val_accuracy: 0.9285 - val_recall: 0.9737 - val_auc: 0.9464\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 97s 411ms/step - loss: 0.0292 - accuracy: 0.9872 - recall: 0.9923 - auc: 0.9993 - val_loss: 0.3306 - val_accuracy: 0.9392 - val_recall: 0.9518 - val_auc: 0.9669\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.364439  0.840406  0.933431  0.890851  0.180190      0.926361   \n",
      "1   0.182667  0.928476  0.963058  0.972409  0.188441      0.937033   \n",
      "2   0.140476  0.950093  0.975860  0.980999  0.172458      0.938100   \n",
      "3   0.118410  0.960235  0.976225  0.987390  0.208855      0.933831   \n",
      "4   0.099630  0.963437  0.981712  0.990709  0.216899      0.935966   \n",
      "5   0.076362  0.971978  0.986832  0.995467  0.207250      0.941302   \n",
      "6   0.065487  0.974646  0.987930  0.995884  0.266101      0.939168   \n",
      "7   0.050009  0.980518  0.989027  0.997077  0.230408      0.938100   \n",
      "8   0.041086  0.985055  0.992319  0.998108  0.313041      0.935966   \n",
      "9   0.041848  0.986122  0.991222  0.998486  0.352806      0.931697   \n",
      "10  0.058838  0.979183  0.988296  0.996218  0.271912      0.938100   \n",
      "11  0.024043  0.990926  0.994879  0.999613  0.398563      0.928495   \n",
      "12  0.029236  0.987190  0.992319  0.999270  0.330643      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.978070  0.972716  \n",
      "1     0.967836  0.968954  \n",
      "2     0.966374  0.975369  \n",
      "3     0.972222  0.969177  \n",
      "4     0.979532  0.974612  \n",
      "5     0.956140  0.974583  \n",
      "6     0.964912  0.966380  \n",
      "7     0.963450  0.972690  \n",
      "8     0.960526  0.963748  \n",
      "9     0.960526  0.954343  \n",
      "10    0.963450  0.963153  \n",
      "11    0.973684  0.946372  \n",
      "12    0.951754  0.966897  \n",
      "74/74 [==============================] - 20s 270ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 93s 491ms/step - loss: 0.3827 - accuracy: 0.8441 - recall: 0.9466 - auc: 0.8910 - val_loss: 0.2296 - val_accuracy: 0.9007 - val_recall: 0.8801 - val_auc: 0.9768\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 92s 491ms/step - loss: 0.2062 - accuracy: 0.9242 - recall: 0.9473 - auc: 0.9663 - val_loss: 0.1651 - val_accuracy: 0.9477 - val_recall: 0.9605 - val_auc: 0.9763\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 92s 488ms/step - loss: 0.1494 - accuracy: 0.9536 - recall: 0.9678 - auc: 0.9811 - val_loss: 0.1735 - val_accuracy: 0.9445 - val_recall: 0.9751 - val_auc: 0.9752\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 93s 493ms/step - loss: 0.1272 - accuracy: 0.9557 - recall: 0.9653 - auc: 0.9861 - val_loss: 0.1876 - val_accuracy: 0.9392 - val_recall: 0.9751 - val_auc: 0.9736\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 93s 493ms/step - loss: 0.1089 - accuracy: 0.9597 - recall: 0.9722 - auc: 0.9898 - val_loss: 0.1815 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9764\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 92s 491ms/step - loss: 0.0973 - accuracy: 0.9666 - recall: 0.9784 - auc: 0.9906 - val_loss: 0.1639 - val_accuracy: 0.9456 - val_recall: 0.9474 - val_auc: 0.9799\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0779 - accuracy: 0.9725 - recall: 0.9799 - auc: 0.9946 - val_loss: 0.1980 - val_accuracy: 0.9306 - val_recall: 0.9240 - val_auc: 0.9820\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 92s 490ms/step - loss: 0.0593 - accuracy: 0.9762 - recall: 0.9839 - auc: 0.9970 - val_loss: 0.2219 - val_accuracy: 0.9413 - val_recall: 0.9605 - val_auc: 0.9717\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0497 - accuracy: 0.9786 - recall: 0.9839 - auc: 0.9982 - val_loss: 0.3077 - val_accuracy: 0.9360 - val_recall: 0.9751 - val_auc: 0.9644\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 92s 488ms/step - loss: 0.0407 - accuracy: 0.9845 - recall: 0.9894 - auc: 0.9983 - val_loss: 0.2443 - val_accuracy: 0.9402 - val_recall: 0.9693 - val_auc: 0.9694\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 91s 485ms/step - loss: 0.0345 - accuracy: 0.9872 - recall: 0.9912 - auc: 0.9991 - val_loss: 0.2534 - val_accuracy: 0.9370 - val_recall: 0.9576 - val_auc: 0.9670\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0304 - accuracy: 0.9893 - recall: 0.9927 - auc: 0.9988 - val_loss: 0.3152 - val_accuracy: 0.9402 - val_recall: 0.9664 - val_auc: 0.9614\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 93s 492ms/step - loss: 0.0470 - accuracy: 0.9832 - recall: 0.9883 - auc: 0.9974 - val_loss: 0.2648 - val_accuracy: 0.9338 - val_recall: 0.9635 - val_auc: 0.9622\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 92s 490ms/step - loss: 0.0376 - accuracy: 0.9861 - recall: 0.9901 - auc: 0.9985 - val_loss: 0.3488 - val_accuracy: 0.9402 - val_recall: 0.9649 - val_auc: 0.9589\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 92s 488ms/step - loss: 0.0291 - accuracy: 0.9880 - recall: 0.9923 - auc: 0.9994 - val_loss: 0.3830 - val_accuracy: 0.9402 - val_recall: 0.9561 - val_auc: 0.9674\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 92s 489ms/step - loss: 0.0324 - accuracy: 0.9893 - recall: 0.9912 - auc: 0.9982 - val_loss: 0.3296 - val_accuracy: 0.9434 - val_recall: 0.9591 - val_auc: 0.9638\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 92s 490ms/step - loss: 0.0204 - accuracy: 0.9915 - recall: 0.9920 - auc: 0.9996 - val_loss: 0.3978 - val_accuracy: 0.9402 - val_recall: 0.9591 - val_auc: 0.9580\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.382698  0.844142  0.946598  0.890988  0.229647      0.900747   \n",
      "1   0.206234  0.924206  0.947330  0.966315  0.165078      0.947705   \n",
      "2   0.149391  0.953563  0.967813  0.981110  0.173524      0.944504   \n",
      "3   0.127208  0.955698  0.965252  0.986147  0.187590      0.939168   \n",
      "4   0.108885  0.959701  0.972202  0.989814  0.181529      0.943437   \n",
      "5   0.097298  0.966640  0.978420  0.990573  0.163872      0.945571   \n",
      "6   0.077923  0.972511  0.979883  0.994575  0.197991      0.930630   \n",
      "7   0.059326  0.976248  0.983906  0.996970  0.221941      0.941302   \n",
      "8   0.049682  0.978650  0.983906  0.998172  0.307696      0.935966   \n",
      "9   0.040687  0.984521  0.989393  0.998304  0.244287      0.940235   \n",
      "10  0.034456  0.987190  0.991222  0.999087  0.253353      0.937033   \n",
      "11  0.030443  0.989325  0.992685  0.998843  0.315223      0.940235   \n",
      "12  0.046961  0.983187  0.988296  0.997393  0.264802      0.933831   \n",
      "13  0.037570  0.986122  0.990124  0.998468  0.348836      0.940235   \n",
      "14  0.029132  0.987990  0.992319  0.999374  0.382970      0.940235   \n",
      "15  0.032389  0.989325  0.991222  0.998184  0.329583      0.943437   \n",
      "16  0.020405  0.991460  0.991953  0.999572  0.397756      0.940235   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.880117  0.976831  \n",
      "1     0.960526  0.976322  \n",
      "2     0.975146  0.975175  \n",
      "3     0.975146  0.973600  \n",
      "4     0.959064  0.976394  \n",
      "5     0.947368  0.979890  \n",
      "6     0.923977  0.981982  \n",
      "7     0.960526  0.971679  \n",
      "8     0.975146  0.964372  \n",
      "9     0.969298  0.969399  \n",
      "10    0.957602  0.966975  \n",
      "11    0.966374  0.961410  \n",
      "12    0.963450  0.962222  \n",
      "13    0.964912  0.958911  \n",
      "14    0.956140  0.967423  \n",
      "15    0.959064  0.963840  \n",
      "16    0.959064  0.957966  \n",
      "59/59 [==============================] - 19s 320ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 83s 692ms/step - loss: 0.4956 - accuracy: 0.8038 - recall: 0.9715 - auc: 0.8246 - val_loss: 0.2486 - val_accuracy: 0.9039 - val_recall: 0.9883 - val_auc: 0.9572\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 81s 689ms/step - loss: 0.2089 - accuracy: 0.9087 - recall: 0.9693 - auc: 0.9680 - val_loss: 0.2100 - val_accuracy: 0.9296 - val_recall: 0.9854 - val_auc: 0.9706\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 81s 690ms/step - loss: 0.1541 - accuracy: 0.9437 - recall: 0.9722 - auc: 0.9808 - val_loss: 0.1927 - val_accuracy: 0.9264 - val_recall: 0.9211 - val_auc: 0.9761\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 81s 690ms/step - loss: 0.1350 - accuracy: 0.9538 - recall: 0.9729 - auc: 0.9846 - val_loss: 0.3056 - val_accuracy: 0.9082 - val_recall: 0.9912 - val_auc: 0.9524\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 81s 688ms/step - loss: 0.1222 - accuracy: 0.9592 - recall: 0.9773 - auc: 0.9867 - val_loss: 0.1696 - val_accuracy: 0.9424 - val_recall: 0.9635 - val_auc: 0.9788\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 81s 688ms/step - loss: 0.0950 - accuracy: 0.9669 - recall: 0.9821 - auc: 0.9922 - val_loss: 0.1616 - val_accuracy: 0.9413 - val_recall: 0.9708 - val_auc: 0.9783\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 82s 692ms/step - loss: 0.0846 - accuracy: 0.9733 - recall: 0.9846 - auc: 0.9931 - val_loss: 0.1798 - val_accuracy: 0.9434 - val_recall: 0.9620 - val_auc: 0.9777\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 81s 689ms/step - loss: 0.0648 - accuracy: 0.9792 - recall: 0.9879 - auc: 0.9965 - val_loss: 0.2032 - val_accuracy: 0.9349 - val_recall: 0.9591 - val_auc: 0.9710\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 84s 714ms/step - loss: 0.0436 - accuracy: 0.9869 - recall: 0.9941 - auc: 0.9984 - val_loss: 0.2149 - val_accuracy: 0.9466 - val_recall: 0.9635 - val_auc: 0.9734\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 81s 691ms/step - loss: 0.0444 - accuracy: 0.9835 - recall: 0.9901 - auc: 0.9978 - val_loss: 0.2724 - val_accuracy: 0.9402 - val_recall: 0.9518 - val_auc: 0.9720\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 81s 690ms/step - loss: 0.0385 - accuracy: 0.9853 - recall: 0.9909 - auc: 0.9989 - val_loss: 0.2041 - val_accuracy: 0.9402 - val_recall: 0.9620 - val_auc: 0.9725\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 81s 686ms/step - loss: 0.0393 - accuracy: 0.9872 - recall: 0.9931 - auc: 0.9984 - val_loss: 0.2277 - val_accuracy: 0.9328 - val_recall: 0.9751 - val_auc: 0.9715\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 81s 690ms/step - loss: 0.0299 - accuracy: 0.9896 - recall: 0.9952 - auc: 0.9989 - val_loss: 0.3642 - val_accuracy: 0.9306 - val_recall: 0.9401 - val_auc: 0.9615\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 81s 688ms/step - loss: 0.0240 - accuracy: 0.9923 - recall: 0.9967 - auc: 0.9996 - val_loss: 0.3344 - val_accuracy: 0.9413 - val_recall: 0.9591 - val_auc: 0.9617\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 82s 691ms/step - loss: 0.0221 - accuracy: 0.9912 - recall: 0.9963 - auc: 0.9995 - val_loss: 0.3454 - val_accuracy: 0.9392 - val_recall: 0.9561 - val_auc: 0.9567\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.495630  0.803843  0.971470  0.824598  0.248558      0.903949   \n",
      "1   0.208907  0.908727  0.969276  0.968022  0.210035      0.929562   \n",
      "2   0.154063  0.943688  0.972202  0.980764  0.192695      0.926361   \n",
      "3   0.135038  0.953830  0.972933  0.984616  0.305582      0.908218   \n",
      "4   0.122237  0.959167  0.977323  0.986655  0.169562      0.942369   \n",
      "5   0.094992  0.966907  0.982078  0.992181  0.161642      0.941302   \n",
      "6   0.084597  0.973312  0.984638  0.993090  0.179784      0.943437   \n",
      "7   0.064764  0.979183  0.987930  0.996450  0.203158      0.934899   \n",
      "8   0.043559  0.986923  0.994148  0.998379  0.214902      0.946638   \n",
      "9   0.044418  0.983453  0.990124  0.997792  0.272388      0.940235   \n",
      "10  0.038510  0.985322  0.990856  0.998864  0.204078      0.940235   \n",
      "11  0.039332  0.987190  0.993050  0.998372  0.227652      0.932764   \n",
      "12  0.029872  0.989592  0.995245  0.998926  0.364154      0.930630   \n",
      "13  0.023953  0.992260  0.996708  0.999568  0.334437      0.941302   \n",
      "14  0.022060  0.991193  0.996342  0.999532  0.345433      0.939168   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.988304  0.957172  \n",
      "1     0.985380  0.970616  \n",
      "2     0.921053  0.976146  \n",
      "3     0.991228  0.952402  \n",
      "4     0.963450  0.978772  \n",
      "5     0.970760  0.978333  \n",
      "6     0.961988  0.977735  \n",
      "7     0.959064  0.970986  \n",
      "8     0.963450  0.973441  \n",
      "9     0.951754  0.971974  \n",
      "10    0.961988  0.972465  \n",
      "11    0.975146  0.971457  \n",
      "12    0.940058  0.961538  \n",
      "13    0.959064  0.961679  \n",
      "14    0.956140  0.956684  \n",
      "37/37 [==============================] - 17s 459ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.6306 - accuracy: 0.7521 - recall: 0.9484 - auc: 0.7261 - val_loss: 0.2181 - val_accuracy: 0.9157 - val_recall: 0.9167 - val_auc: 0.9692\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2051 - accuracy: 0.9221 - recall: 0.9554 - auc: 0.9667 - val_loss: 0.1750 - val_accuracy: 0.9317 - val_recall: 0.9298 - val_auc: 0.9783\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.1506 - accuracy: 0.9466 - recall: 0.9693 - auc: 0.9820 - val_loss: 0.1687 - val_accuracy: 0.9402 - val_recall: 0.9444 - val_auc: 0.9780\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.1372 - accuracy: 0.9549 - recall: 0.9744 - auc: 0.9838 - val_loss: 0.1825 - val_accuracy: 0.9381 - val_recall: 0.9868 - val_auc: 0.9758\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.1258 - accuracy: 0.9557 - recall: 0.9715 - auc: 0.9872 - val_loss: 0.1549 - val_accuracy: 0.9456 - val_recall: 0.9825 - val_auc: 0.9789\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.1062 - accuracy: 0.9610 - recall: 0.9744 - auc: 0.9902 - val_loss: 0.1908 - val_accuracy: 0.9253 - val_recall: 0.9211 - val_auc: 0.9797\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0964 - accuracy: 0.9648 - recall: 0.9781 - auc: 0.9921 - val_loss: 0.1844 - val_accuracy: 0.9338 - val_recall: 0.9737 - val_auc: 0.9753\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.0813 - accuracy: 0.9733 - recall: 0.9821 - auc: 0.9946 - val_loss: 0.1768 - val_accuracy: 0.9434 - val_recall: 0.9561 - val_auc: 0.9768\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.0569 - accuracy: 0.9824 - recall: 0.9912 - auc: 0.9969 - val_loss: 0.2136 - val_accuracy: 0.9456 - val_recall: 0.9649 - val_auc: 0.9705\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0506 - accuracy: 0.9824 - recall: 0.9890 - auc: 0.9972 - val_loss: 0.1877 - val_accuracy: 0.9381 - val_recall: 0.9444 - val_auc: 0.9786\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0496 - accuracy: 0.9829 - recall: 0.9912 - auc: 0.9977 - val_loss: 0.2287 - val_accuracy: 0.9402 - val_recall: 0.9635 - val_auc: 0.9675\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0397 - accuracy: 0.9883 - recall: 0.9931 - auc: 0.9985 - val_loss: 0.3014 - val_accuracy: 0.9434 - val_recall: 0.9561 - val_auc: 0.9635\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.0533 - accuracy: 0.9792 - recall: 0.9872 - auc: 0.9972 - val_loss: 0.2374 - val_accuracy: 0.9413 - val_recall: 0.9532 - val_auc: 0.9720\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.0271 - accuracy: 0.9901 - recall: 0.9956 - auc: 0.9990 - val_loss: 0.2765 - val_accuracy: 0.9456 - val_recall: 0.9620 - val_auc: 0.9673\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.0300 - accuracy: 0.9877 - recall: 0.9931 - auc: 0.9993 - val_loss: 0.3312 - val_accuracy: 0.9456 - val_recall: 0.9708 - val_auc: 0.9545\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0179 - accuracy: 0.9947 - recall: 0.9974 - auc: 0.9997 - val_loss: 0.2825 - val_accuracy: 0.9434 - val_recall: 0.9532 - val_auc: 0.9669\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.630580  0.752068  0.948427  0.726095  0.218127      0.915688   \n",
      "1   0.205069  0.922071  0.955377  0.966664  0.175030      0.931697   \n",
      "2   0.150550  0.946624  0.969276  0.981965  0.168744      0.940235   \n",
      "3   0.137184  0.954897  0.974396  0.983820  0.182452      0.938100   \n",
      "4   0.125777  0.955698  0.971470  0.987204  0.154872      0.945571   \n",
      "5   0.106208  0.961035  0.974396  0.990194  0.190799      0.925294   \n",
      "6   0.096376  0.964772  0.978054  0.992095  0.184363      0.933831   \n",
      "7   0.081326  0.973312  0.982078  0.994636  0.176776      0.943437   \n",
      "8   0.056892  0.982386  0.991222  0.996880  0.213605      0.945571   \n",
      "9   0.050578  0.982386  0.989027  0.997178  0.187669      0.938100   \n",
      "10  0.049611  0.982920  0.991222  0.997657  0.228687      0.940235   \n",
      "11  0.039676  0.988257  0.993050  0.998490  0.301361      0.943437   \n",
      "12  0.053280  0.979183  0.987198  0.997186  0.237429      0.941302   \n",
      "13  0.027068  0.990125  0.995611  0.998972  0.276512      0.945571   \n",
      "14  0.029965  0.987724  0.993050  0.999315  0.331177      0.945571   \n",
      "15  0.017930  0.994662  0.997440  0.999722  0.282465      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.916667  0.969238  \n",
      "1     0.929825  0.978345  \n",
      "2     0.944444  0.977975  \n",
      "3     0.986842  0.975805  \n",
      "4     0.982456  0.978882  \n",
      "5     0.921053  0.979668  \n",
      "6     0.973684  0.975343  \n",
      "7     0.956140  0.976767  \n",
      "8     0.964912  0.970538  \n",
      "9     0.944444  0.978567  \n",
      "10    0.963450  0.967455  \n",
      "11    0.956140  0.963468  \n",
      "12    0.953216  0.971991  \n",
      "13    0.961988  0.967313  \n",
      "14    0.970760  0.954485  \n",
      "15    0.953216  0.966929  \n",
      "19/19 [==============================] - 16s 824ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\2667561563.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(150,150)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "nombre_carpeta_hist= 'Historicos'\n",
    "nombre_carpeta_resultados= 'Resultados'\n",
    "nombre_carpeta_modelos= 'Modelos'\n",
    "tabla_arqu_batch_propia = arq_batch_propia(ruta,epochs, batch_sizes,modelos, \n",
    "                                           target_size, nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87723f42-a3fa-458e-9c5c-773124b41b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.18      0.93       0.98    0.93  0.95         0.94  0.06   \n",
       "        16         0.16      0.95       0.97    0.96  0.96         0.92  0.08   \n",
       "        20         0.15      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        32         0.20      0.92       0.98    0.92  0.94         0.94  0.06   \n",
       "        64         0.18      0.93       0.96    0.93  0.95         0.91  0.09   \n",
       "Simple2 8          0.27      0.89       0.98    0.86  0.92         0.96  0.04   \n",
       "        16         0.18      0.93       0.98    0.93  0.95         0.94  0.06   \n",
       "        20         0.15      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        32         0.17      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        64         0.19      0.93       0.98    0.93  0.95         0.94  0.06   \n",
       "Simple3 8          0.17      0.94       0.96    0.96  0.96         0.89  0.11   \n",
       "        16         0.15      0.94       0.96    0.97  0.96         0.88  0.12   \n",
       "        20         0.21      0.92       0.98    0.91  0.94         0.95  0.05   \n",
       "        32         0.17      0.94       0.96    0.96  0.96         0.89  0.11   \n",
       "        64         0.20      0.92       0.98    0.91  0.94         0.94  0.06   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.07  0.98  \n",
       "        16         0.04  0.98  \n",
       "        20         0.03  0.98  \n",
       "        32         0.08  0.98  \n",
       "        64         0.07  0.98  \n",
       "Simple2 8          0.14  0.98  \n",
       "        16         0.07  0.98  \n",
       "        20         0.04  0.98  \n",
       "        32         0.04  0.98  \n",
       "        64         0.07  0.98  \n",
       "Simple3 8          0.04  0.98  \n",
       "        16         0.03  0.98  \n",
       "        20         0.09  0.98  \n",
       "        32         0.04  0.98  \n",
       "        64         0.09  0.98  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50072-e379-42a4-8b45-433ce620d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49bc3227-0635-4649-8182-f24d0cc786c2",
   "metadata": {},
   "source": [
    "## Comparación de distintas arquitecturas de modelo y distintos batch_size con CNN AlexaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111bdae9-85fc-41c3-9576-e1f0532ec835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos,target_size, nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos):\n",
    "    '''\n",
    "    Función que entrena distintas arquitecturas de modelo y distintos batch size introducidos como parámetros a partir de la CNN basada en AlexNet \n",
    "    establecida previamente y devuelve una tabla comparativa con los distintos valores de métricas para cada caso. \n",
    "    También guarda en distintas carpetas los historicos con las métricas obtenidas tras cada entrenaminto para\n",
    "    cada modelo, los distintos modelos obtenidos según la arquitectura y el batch size y el dataframe final en formato csv.\n",
    "    ----------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - batch_sizes: lista con los distintos valores de batch size para probar en cada entrenamiento\n",
    "    - modelos: lista de nombres de cada uno de los modelos que se van a comparar obtenidos partir de la función realizada previamente \n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá ser \n",
    "    (340,340) para coincidir con el input_shape del modelo de CNN alexNet.\n",
    "    - nombre_carpeta_hist: str. Nombre de la carpeta creada para guardar los csv de los historicos\n",
    "    - nombre_carpeta_resultados: str. Nombre de la carpeta creada para guardar el dataframe final en formato csv.\n",
    "    - nombre_carpeta_modelos: str. Nombre de la carpeta creada para guardar los distintos modelos\n",
    "    --------------------------------------------------\n",
    "    Return:\n",
    "    - compara_arqu_batch_def: dataframe que contiene como índice las columnas referidas al modelo de arquitectura y al valor de batch size. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada arquitectura y cada batch size para la CNN basada en alexNet.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar los distintos \n",
    "    #modelos de arquitectura para distintos batch size (comparando las métricas)\n",
    "    compara_arqu_batch=pd.DataFrame()\n",
    "    \n",
    "\n",
    "    #bucle en el que se recorren cada uno de los modelos y los tamaños de batch_size \n",
    "    for modelo in modelos:\n",
    "        print(f\"Comparando modelo {modelo}...\")\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Entrenando modelo {modelo} y batch_size {batch_size}\")\n",
    "    \n",
    "            #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "            #un modelo de aprendizaje automático con imágenes\n",
    "            train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size,target_size)\n",
    "            \n",
    "            #se emplea la función establecer_arquitectura para determinar el modelo con el que se trabaja cada vez\n",
    "            model = establecer_arquitectura_AlexaNet(modelo)\n",
    "            \n",
    "            #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "            #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "            #un problema de clasificación binaria\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "            #ENTRENAMIENTO\n",
    "            # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "            history= model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "            historico = pd.DataFrame(history.history)\n",
    "            print(historico) \n",
    "\n",
    "        \n",
    "            #SE GUARDAN LOS DISTINTOS HISTÓRICOS EN UNA CARPETA\n",
    "            #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "            ruta_historicos = os.path.join('.', nombre_carpeta_hist) #se crea la ruta a la nueva carpeta de Historicos en el directorio actual\n",
    "            os.makedirs(ruta_historicos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "            #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "            subcarpeta_historicos = os.path.join(ruta_historicos,'historico_alexnet_arqu_batchsize') \n",
    "            os.makedirs(subcarpeta_historicos, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "            nombre_historico = f'hist_alexNet_{modelo}_{batch_size}.csv' #se define el nombre que van a tener cada uno de los csv donde esta el historico correspondiente\n",
    "            ruta_historico = os.path.join(subcarpeta_historicos, nombre_historico) #se define la ruta donde se econtrará cada modelo\n",
    "            historico.to_csv(ruta_historico, index=False, encoding='utf-8') #se crea el csv de cada historico\n",
    "\n",
    "            #SE GUARDAN LOS DISTINTOS MODELOS EN UNA CARPETA\n",
    "            ruta_modelos = os.path.join('.', nombre_carpeta_modelos) #se crea la ruta a la nueva carpeta de Modelos en el directorio actual\n",
    "            os.makedirs(ruta_modelos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "            #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "            subcarpeta_modelo = os.path.join(ruta_modelos, 'modelo_alexnet_arqu_batchsize')\n",
    "            os.makedirs(subcarpeta_modelo, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "            nombre_modelo = f'modelo_alexnet_{modelo}_{batch_size}.h5' #se define el nombre de cada uno de los archivos que contienen los modelos\n",
    "            ruta_modelo = os.path.join(subcarpeta_modelo, nombre_modelo) #se define la ruta donde se econtrará cada modelo\n",
    "            model.save(ruta_modelo) #se guarda el modelo\n",
    "\n",
    "            \n",
    "        \n",
    "            #se calculan las métricas a partir de la la función creada previamente\n",
    "            y_test=test_generator.labels\n",
    "            y_pred=model.predict(test_generator)\n",
    "            calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "            #se calcula loss a partir de la evaluación del modelo\n",
    "            loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "            \n",
    "            \n",
    "            #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "            #(comparando las métricas)\n",
    "            compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fijan las columnas Red y BatchSize como índices. \n",
    "    compara_arqu_batch.set_index([\"Red\",\"BatchSize\"], inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_arqu_batch_def = compara_arqu_batch.round(2) #se redondean los decimales a 2\n",
    "\n",
    "    #SE GUARDA EL DATAFRAME FINAL EN UNA CARPETA EN FORMATO CSV\n",
    "    ruta_resultados = os.path.join('.', nombre_carpeta_resultados) #se crea la ruta a la nueva carpeta de Resultados en el directorio actual\n",
    "    os.makedirs(ruta_resultados, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "    ruta_resultado_final = os.path.join(ruta_resultados, 'compara_alexNet_arqu_batch_def.csv') #se define la ruta donde se econtrará el dataframe\n",
    "    compara_arqu_batch_def.to_csv(ruta_resultado_final, index=False, encoding='utf-8') #se crea el csv del dataframe\n",
    "\n",
    "\n",
    "    \n",
    "    return compara_arqu_batch_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "562c7252-e239-45b8-bc01-6df22183405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple1...\n",
      "Entrenando modelo Simple1 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 292s 619ms/step - loss: 0.3272 - accuracy: 0.8738 - recall: 0.9170 - auc: 0.9250 - val_loss: 0.2906 - val_accuracy: 0.9050 - val_recall: 0.9181 - val_auc: 0.9584\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 293s 624ms/step - loss: 0.2110 - accuracy: 0.9250 - recall: 0.9543 - auc: 0.9644 - val_loss: 0.3288 - val_accuracy: 0.8613 - val_recall: 0.9927 - val_auc: 0.9672\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 278s 593ms/step - loss: 0.2074 - accuracy: 0.9258 - recall: 0.9528 - auc: 0.9672 - val_loss: 0.4616 - val_accuracy: 0.8517 - val_recall: 0.8129 - val_auc: 0.9709\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 280s 596ms/step - loss: 0.1788 - accuracy: 0.9359 - recall: 0.9601 - auc: 0.9747 - val_loss: 0.1898 - val_accuracy: 0.9381 - val_recall: 0.9854 - val_auc: 0.9766\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 268s 571ms/step - loss: 0.1672 - accuracy: 0.9367 - recall: 0.9590 - auc: 0.9787 - val_loss: 0.3056 - val_accuracy: 0.9039 - val_recall: 0.8830 - val_auc: 0.9745\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 279s 595ms/step - loss: 0.1504 - accuracy: 0.9469 - recall: 0.9678 - auc: 0.9813 - val_loss: 0.1371 - val_accuracy: 0.9509 - val_recall: 0.9635 - val_auc: 0.9842\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 268s 570ms/step - loss: 0.1481 - accuracy: 0.9458 - recall: 0.9649 - auc: 0.9807 - val_loss: 0.1742 - val_accuracy: 0.9370 - val_recall: 0.9839 - val_auc: 0.9786\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 280s 596ms/step - loss: 0.1443 - accuracy: 0.9490 - recall: 0.9678 - auc: 0.9830 - val_loss: 0.2084 - val_accuracy: 0.9424 - val_recall: 0.9854 - val_auc: 0.9709\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 276s 588ms/step - loss: 0.1163 - accuracy: 0.9576 - recall: 0.9751 - auc: 0.9893 - val_loss: 1.5007 - val_accuracy: 0.8815 - val_recall: 0.8655 - val_auc: 0.9458\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 272s 579ms/step - loss: 0.1205 - accuracy: 0.9570 - recall: 0.9744 - auc: 0.9874 - val_loss: 0.4470 - val_accuracy: 0.9061 - val_recall: 0.9942 - val_auc: 0.9399\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 270s 575ms/step - loss: 0.1201 - accuracy: 0.9557 - recall: 0.9740 - auc: 0.9882 - val_loss: 0.1886 - val_accuracy: 0.9477 - val_recall: 0.9459 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 274s 585ms/step - loss: 0.1205 - accuracy: 0.9602 - recall: 0.9759 - auc: 0.9864 - val_loss: 0.1840 - val_accuracy: 0.9434 - val_recall: 0.9430 - val_auc: 0.9834\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 268s 570ms/step - loss: 0.1086 - accuracy: 0.9624 - recall: 0.9762 - auc: 0.9891 - val_loss: 0.1736 - val_accuracy: 0.9466 - val_recall: 0.9898 - val_auc: 0.9769\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 283s 604ms/step - loss: 0.0906 - accuracy: 0.9669 - recall: 0.9799 - auc: 0.9934 - val_loss: 0.1687 - val_accuracy: 0.9520 - val_recall: 0.9693 - val_auc: 0.9770\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 274s 584ms/step - loss: 0.0955 - accuracy: 0.9650 - recall: 0.9781 - auc: 0.9909 - val_loss: 0.1213 - val_accuracy: 0.9594 - val_recall: 0.9766 - val_auc: 0.9883\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 267s 569ms/step - loss: 0.1065 - accuracy: 0.9621 - recall: 0.9770 - auc: 0.9909 - val_loss: 0.2095 - val_accuracy: 0.9498 - val_recall: 0.9766 - val_auc: 0.9756\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 280s 597ms/step - loss: 0.0973 - accuracy: 0.9656 - recall: 0.9777 - auc: 0.9911 - val_loss: 0.1795 - val_accuracy: 0.9509 - val_recall: 0.9547 - val_auc: 0.9848\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 272s 580ms/step - loss: 0.0781 - accuracy: 0.9714 - recall: 0.9817 - auc: 0.9934 - val_loss: 0.1336 - val_accuracy: 0.9541 - val_recall: 0.9693 - val_auc: 0.9855\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 268s 572ms/step - loss: 0.0857 - accuracy: 0.9725 - recall: 0.9846 - auc: 0.9918 - val_loss: 0.4021 - val_accuracy: 0.9007 - val_recall: 0.8743 - val_auc: 0.9794\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 282s 601ms/step - loss: 0.0720 - accuracy: 0.9741 - recall: 0.9824 - auc: 0.9937 - val_loss: 0.1557 - val_accuracy: 0.9488 - val_recall: 0.9620 - val_auc: 0.9874\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.327195  0.873766  0.916971  0.924983  0.290643      0.905016   \n",
      "1   0.210989  0.925007  0.954279  0.964381  0.328848      0.861259   \n",
      "2   0.207437  0.925807  0.952816  0.967156  0.461586      0.851654   \n",
      "3   0.178849  0.935949  0.960132  0.974667  0.189815      0.938100   \n",
      "4   0.167160  0.936749  0.959034  0.978727  0.305647      0.903949   \n",
      "5   0.150382  0.946891  0.967813  0.981321  0.137149      0.950907   \n",
      "6   0.148068  0.945823  0.964887  0.980669  0.174176      0.937033   \n",
      "7   0.144294  0.949026  0.967813  0.983019  0.208404      0.942369   \n",
      "8   0.116267  0.957566  0.975128  0.989292  1.500682      0.881537   \n",
      "9   0.120486  0.957032  0.974396  0.987435  0.446970      0.906083   \n",
      "10  0.120110  0.955698  0.974031  0.988178  0.188621      0.947705   \n",
      "11  0.120523  0.960235  0.975860  0.986424  0.184018      0.943437   \n",
      "12  0.108585  0.962370  0.976225  0.989130  0.173596      0.946638   \n",
      "13  0.090563  0.966907  0.979883  0.993445  0.168728      0.951974   \n",
      "14  0.095516  0.965039  0.978054  0.990920  0.121282      0.959445   \n",
      "15  0.106499  0.962103  0.976957  0.990949  0.209517      0.949840   \n",
      "16  0.097257  0.965572  0.977688  0.991060  0.179506      0.950907   \n",
      "17  0.078098  0.971444  0.981712  0.993443  0.133624      0.954109   \n",
      "18  0.085692  0.972511  0.984638  0.991820  0.402083      0.900747   \n",
      "19  0.071999  0.974113  0.982443  0.993730  0.155668      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.918129  0.958400  \n",
      "1     0.992690  0.967221  \n",
      "2     0.812865  0.970884  \n",
      "3     0.985380  0.976588  \n",
      "4     0.883041  0.974537  \n",
      "5     0.963450  0.984242  \n",
      "6     0.983918  0.978556  \n",
      "7     0.985380  0.970853  \n",
      "8     0.865497  0.945774  \n",
      "9     0.994152  0.939897  \n",
      "10    0.945906  0.986490  \n",
      "11    0.942982  0.983378  \n",
      "12    0.989766  0.976923  \n",
      "13    0.969298  0.977013  \n",
      "14    0.976608  0.988272  \n",
      "15    0.976608  0.975588  \n",
      "16    0.954678  0.984770  \n",
      "17    0.969298  0.985513  \n",
      "18    0.874269  0.979443  \n",
      "19    0.961988  0.987417  \n",
      "147/147 [==============================] - 37s 252ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 283s 1s/step - loss: 0.3254 - accuracy: 0.8842 - recall: 0.9294 - auc: 0.9260 - val_loss: 0.2896 - val_accuracy: 0.8837 - val_recall: 0.9020 - val_auc: 0.9475\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.2123 - accuracy: 0.9199 - recall: 0.9525 - auc: 0.9655 - val_loss: 0.8017 - val_accuracy: 0.7545 - val_recall: 1.0000 - val_auc: 0.9252\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.1857 - accuracy: 0.9330 - recall: 0.9568 - auc: 0.9718 - val_loss: 0.5373 - val_accuracy: 0.8303 - val_recall: 0.7909 - val_auc: 0.9410\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.1788 - accuracy: 0.9325 - recall: 0.9568 - auc: 0.9745 - val_loss: 0.4944 - val_accuracy: 0.7727 - val_recall: 0.7339 - val_auc: 0.8953\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 266s 1s/step - loss: 0.1650 - accuracy: 0.9410 - recall: 0.9649 - auc: 0.9771 - val_loss: 0.1295 - val_accuracy: 0.9541 - val_recall: 0.9649 - val_auc: 0.9868\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.1350 - accuracy: 0.9496 - recall: 0.9707 - auc: 0.9844 - val_loss: 0.2290 - val_accuracy: 0.9317 - val_recall: 0.9737 - val_auc: 0.9646\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.1264 - accuracy: 0.9509 - recall: 0.9700 - auc: 0.9863 - val_loss: 0.1335 - val_accuracy: 0.9477 - val_recall: 0.9708 - val_auc: 0.9861\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 282s 1s/step - loss: 0.1581 - accuracy: 0.9429 - recall: 0.9638 - auc: 0.9794 - val_loss: 0.1125 - val_accuracy: 0.9605 - val_recall: 0.9781 - val_auc: 0.9892\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 275s 1s/step - loss: 0.1162 - accuracy: 0.9570 - recall: 0.9729 - auc: 0.9881 - val_loss: 0.1528 - val_accuracy: 0.9530 - val_recall: 0.9751 - val_auc: 0.9766\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.1234 - accuracy: 0.9549 - recall: 0.9726 - auc: 0.9873 - val_loss: 0.1355 - val_accuracy: 0.9520 - val_recall: 0.9488 - val_auc: 0.9897\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 289s 1s/step - loss: 0.1091 - accuracy: 0.9645 - recall: 0.9781 - auc: 0.9882 - val_loss: 0.1242 - val_accuracy: 0.9562 - val_recall: 0.9751 - val_auc: 0.9865\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.1106 - accuracy: 0.9592 - recall: 0.9751 - auc: 0.9886 - val_loss: 0.2267 - val_accuracy: 0.9349 - val_recall: 0.9211 - val_auc: 0.9861\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 300s 1s/step - loss: 0.1114 - accuracy: 0.9602 - recall: 0.9766 - auc: 0.9883 - val_loss: 0.2113 - val_accuracy: 0.9413 - val_recall: 0.9898 - val_auc: 0.9668\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 298s 1s/step - loss: 0.1229 - accuracy: 0.9594 - recall: 0.9737 - auc: 0.9869 - val_loss: 0.1938 - val_accuracy: 0.9562 - val_recall: 0.9737 - val_auc: 0.9794\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 304s 1s/step - loss: 0.0920 - accuracy: 0.9664 - recall: 0.9788 - auc: 0.9915 - val_loss: 0.1335 - val_accuracy: 0.9626 - val_recall: 0.9825 - val_auc: 0.9860\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 302s 1s/step - loss: 0.0926 - accuracy: 0.9645 - recall: 0.9781 - auc: 0.9916 - val_loss: 0.1780 - val_accuracy: 0.9552 - val_recall: 0.9781 - val_auc: 0.9717\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.0960 - accuracy: 0.9658 - recall: 0.9813 - auc: 0.9927 - val_loss: 0.1371 - val_accuracy: 0.9509 - val_recall: 0.9722 - val_auc: 0.9866\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 302s 1s/step - loss: 0.0797 - accuracy: 0.9725 - recall: 0.9832 - auc: 0.9938 - val_loss: 0.1282 - val_accuracy: 0.9434 - val_recall: 0.9605 - val_auc: 0.9877\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 308s 1s/step - loss: 0.0835 - accuracy: 0.9674 - recall: 0.9802 - auc: 0.9930 - val_loss: 0.1552 - val_accuracy: 0.9488 - val_recall: 0.9795 - val_auc: 0.9824\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 312s 1s/step - loss: 0.0657 - accuracy: 0.9762 - recall: 0.9846 - auc: 0.9953 - val_loss: 0.1518 - val_accuracy: 0.9488 - val_recall: 0.9459 - val_auc: 0.9904\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.325365  0.884174  0.929407  0.926012  0.289588      0.883671   \n",
      "1   0.212254  0.919936  0.952451  0.965475  0.801660      0.754536   \n",
      "2   0.185725  0.933013  0.956840  0.971812  0.537316      0.830310   \n",
      "3   0.178826  0.932479  0.956840  0.974524  0.494449      0.772679   \n",
      "4   0.164950  0.941019  0.964887  0.977097  0.129466      0.954109   \n",
      "5   0.134992  0.949560  0.970739  0.984403  0.228991      0.931697   \n",
      "6   0.126400  0.950894  0.970007  0.986338  0.133522      0.947705   \n",
      "7   0.158123  0.942888  0.963789  0.979428  0.112466      0.960512   \n",
      "8   0.116161  0.957032  0.972933  0.988061  0.152816      0.953042   \n",
      "9   0.123420  0.954897  0.972568  0.987307  0.135546      0.951974   \n",
      "10  0.109060  0.964505  0.978054  0.988194  0.124229      0.956243   \n",
      "11  0.110592  0.959167  0.975128  0.988635  0.226735      0.934899   \n",
      "12  0.111379  0.960235  0.976591  0.988305  0.211316      0.941302   \n",
      "13  0.122901  0.959434  0.973665  0.986929  0.193847      0.956243   \n",
      "14  0.091952  0.966373  0.978786  0.991482  0.133481      0.962647   \n",
      "15  0.092616  0.964505  0.978054  0.991630  0.177971      0.955176   \n",
      "16  0.096013  0.965839  0.981346  0.992675  0.137089      0.950907   \n",
      "17  0.079741  0.972511  0.983175  0.993768  0.128248      0.943437   \n",
      "18  0.083520  0.967441  0.980249  0.993025  0.155167      0.948773   \n",
      "19  0.065726  0.976248  0.984638  0.995332  0.151803      0.948773   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.902047  0.947484  \n",
      "1     1.000000  0.925202  \n",
      "2     0.790936  0.941038  \n",
      "3     0.733918  0.895306  \n",
      "4     0.964912  0.986755  \n",
      "5     0.973684  0.964623  \n",
      "6     0.970760  0.986065  \n",
      "7     0.978070  0.989174  \n",
      "8     0.975146  0.976579  \n",
      "9     0.948830  0.989671  \n",
      "10    0.975146  0.986484  \n",
      "11    0.921053  0.986146  \n",
      "12    0.989766  0.966785  \n",
      "13    0.973684  0.979428  \n",
      "14    0.982456  0.986016  \n",
      "15    0.978070  0.971693  \n",
      "16    0.972222  0.986646  \n",
      "17    0.960526  0.987671  \n",
      "18    0.979532  0.982407  \n",
      "19    0.945906  0.990356  \n",
      "74/74 [==============================] - 38s 514ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 312s 2s/step - loss: 0.3308 - accuracy: 0.8754 - recall: 0.9188 - auc: 0.9264 - val_loss: 0.2424 - val_accuracy: 0.9125 - val_recall: 0.9137 - val_auc: 0.9630\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 310s 2s/step - loss: 0.1879 - accuracy: 0.9242 - recall: 0.9510 - auc: 0.9721 - val_loss: 0.1857 - val_accuracy: 0.9402 - val_recall: 0.9415 - val_auc: 0.9802\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 305s 2s/step - loss: 0.1809 - accuracy: 0.9317 - recall: 0.9568 - auc: 0.9736 - val_loss: 7.6962 - val_accuracy: 0.2732 - val_recall: 0.0044 - val_auc: 0.5402\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 302s 2s/step - loss: 0.1600 - accuracy: 0.9421 - recall: 0.9642 - auc: 0.9788 - val_loss: 0.3369 - val_accuracy: 0.8826 - val_recall: 0.9956 - val_auc: 0.9658\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 310s 2s/step - loss: 0.1499 - accuracy: 0.9448 - recall: 0.9642 - auc: 0.9818 - val_loss: 0.2265 - val_accuracy: 0.9093 - val_recall: 0.9912 - val_auc: 0.9751\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.1374 - accuracy: 0.9474 - recall: 0.9678 - auc: 0.9835 - val_loss: 0.3820 - val_accuracy: 0.8762 - val_recall: 0.9956 - val_auc: 0.9577\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 302s 2s/step - loss: 0.1271 - accuracy: 0.9557 - recall: 0.9707 - auc: 0.9856 - val_loss: 0.5689 - val_accuracy: 0.8100 - val_recall: 0.9912 - val_auc: 0.9210\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1224 - accuracy: 0.9538 - recall: 0.9722 - auc: 0.9868 - val_loss: 0.1653 - val_accuracy: 0.9392 - val_recall: 0.9898 - val_auc: 0.9818\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 298s 2s/step - loss: 0.1162 - accuracy: 0.9565 - recall: 0.9733 - auc: 0.9887 - val_loss: 3.1430 - val_accuracy: 0.8186 - val_recall: 0.9927 - val_auc: 0.6943\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 292s 2s/step - loss: 0.1173 - accuracy: 0.9602 - recall: 0.9748 - auc: 0.9868 - val_loss: 0.2933 - val_accuracy: 0.9029 - val_recall: 0.8874 - val_auc: 0.9756\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 298s 2s/step - loss: 0.0922 - accuracy: 0.9634 - recall: 0.9784 - auc: 0.9928 - val_loss: 0.2266 - val_accuracy: 0.9274 - val_recall: 0.9839 - val_auc: 0.9714\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 290s 2s/step - loss: 0.1145 - accuracy: 0.9565 - recall: 0.9740 - auc: 0.9890 - val_loss: 0.3340 - val_accuracy: 0.8943 - val_recall: 0.8655 - val_auc: 0.9794\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 300s 2s/step - loss: 0.1117 - accuracy: 0.9589 - recall: 0.9748 - auc: 0.9877 - val_loss: 0.2596 - val_accuracy: 0.9189 - val_recall: 0.9254 - val_auc: 0.9706\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 292s 2s/step - loss: 0.1004 - accuracy: 0.9624 - recall: 0.9751 - auc: 0.9909 - val_loss: 0.2425 - val_accuracy: 0.9424 - val_recall: 0.9942 - val_auc: 0.9661\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 286s 2s/step - loss: 0.0863 - accuracy: 0.9688 - recall: 0.9824 - auc: 0.9923 - val_loss: 0.1449 - val_accuracy: 0.9552 - val_recall: 0.9766 - val_auc: 0.9857\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.0722 - accuracy: 0.9722 - recall: 0.9821 - auc: 0.9941 - val_loss: 0.1844 - val_accuracy: 0.9477 - val_recall: 0.9795 - val_auc: 0.9801\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 287s 2s/step - loss: 0.0743 - accuracy: 0.9730 - recall: 0.9832 - auc: 0.9930 - val_loss: 0.1370 - val_accuracy: 0.9594 - val_recall: 0.9854 - val_auc: 0.9856\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 293s 2s/step - loss: 0.0620 - accuracy: 0.9768 - recall: 0.9850 - auc: 0.9956 - val_loss: 0.1724 - val_accuracy: 0.9466 - val_recall: 0.9693 - val_auc: 0.9803\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 285s 2s/step - loss: 0.0556 - accuracy: 0.9797 - recall: 0.9861 - auc: 0.9970 - val_loss: 0.1861 - val_accuracy: 0.9477 - val_recall: 0.9547 - val_auc: 0.9800\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 290s 2s/step - loss: 0.0520 - accuracy: 0.9832 - recall: 0.9887 - auc: 0.9965 - val_loss: 0.2137 - val_accuracy: 0.9509 - val_recall: 0.9766 - val_auc: 0.9694\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.330825  0.875367  0.918800  0.926359  0.242373      0.912487   \n",
      "1   0.187915  0.924206  0.950988  0.972110  0.185676      0.940235   \n",
      "2   0.180945  0.931679  0.956840  0.973609  7.696222      0.273212   \n",
      "3   0.160020  0.942087  0.964155  0.978820  0.336920      0.882604   \n",
      "4   0.149869  0.944756  0.964155  0.981821  0.226455      0.909285   \n",
      "5   0.137431  0.947425  0.967813  0.983527  0.381970      0.876201   \n",
      "6   0.127139  0.955698  0.970739  0.985611  0.568924      0.810032   \n",
      "7   0.122354  0.953830  0.972202  0.986774  0.165315      0.939168   \n",
      "8   0.116178  0.956499  0.973299  0.988723  3.142982      0.818570   \n",
      "9   0.117333  0.960235  0.974762  0.986767  0.293288      0.902882   \n",
      "10  0.092159  0.963437  0.978420  0.992783  0.226620      0.927428   \n",
      "11  0.114468  0.956499  0.974031  0.988976  0.334034      0.894344   \n",
      "12  0.111703  0.958900  0.974762  0.987714  0.259642      0.918890   \n",
      "13  0.100402  0.962370  0.975128  0.990866  0.242488      0.942369   \n",
      "14  0.086277  0.968775  0.982443  0.992341  0.144853      0.955176   \n",
      "15  0.072192  0.972244  0.982078  0.994143  0.184420      0.947705   \n",
      "16  0.074292  0.973045  0.983175  0.993010  0.136955      0.959445   \n",
      "17  0.062005  0.976781  0.985004  0.995557  0.172445      0.946638   \n",
      "18  0.055577  0.979717  0.986101  0.996969  0.186051      0.947705   \n",
      "19  0.051999  0.983187  0.988661  0.996492  0.213691      0.950907   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.913743  0.963026  \n",
      "1     0.941520  0.980191  \n",
      "2     0.004386  0.540205  \n",
      "3     0.995614  0.965791  \n",
      "4     0.991228  0.975129  \n",
      "5     0.995614  0.957724  \n",
      "6     0.991228  0.920972  \n",
      "7     0.989766  0.981829  \n",
      "8     0.992690  0.694349  \n",
      "9     0.887427  0.975623  \n",
      "10    0.983918  0.971387  \n",
      "11    0.865497  0.979382  \n",
      "12    0.925439  0.970587  \n",
      "13    0.994152  0.966080  \n",
      "14    0.976608  0.985709  \n",
      "15    0.979532  0.980081  \n",
      "16    0.985380  0.985643  \n",
      "17    0.969298  0.980312  \n",
      "18    0.954678  0.980049  \n",
      "19    0.976608  0.969446  \n",
      "59/59 [==============================] - 37s 615ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 296s 2s/step - loss: 0.3194 - accuracy: 0.8868 - recall: 0.9290 - auc: 0.9315 - val_loss: 0.2866 - val_accuracy: 0.8687 - val_recall: 0.9883 - val_auc: 0.9556\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.1959 - accuracy: 0.9234 - recall: 0.9517 - auc: 0.9690 - val_loss: 0.1873 - val_accuracy: 0.9392 - val_recall: 0.9459 - val_auc: 0.9771\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.2020 - accuracy: 0.9215 - recall: 0.9481 - auc: 0.9698 - val_loss: 0.6968 - val_accuracy: 0.7428 - val_recall: 0.9985 - val_auc: 0.9600\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.1402 - accuracy: 0.9429 - recall: 0.9645 - auc: 0.9837 - val_loss: 0.2998 - val_accuracy: 0.8901 - val_recall: 0.9971 - val_auc: 0.9739\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 289s 2s/step - loss: 0.1312 - accuracy: 0.9498 - recall: 0.9689 - auc: 0.9853 - val_loss: 0.4224 - val_accuracy: 0.7866 - val_recall: 1.0000 - val_auc: 0.9454\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 284s 2s/step - loss: 0.1143 - accuracy: 0.9584 - recall: 0.9766 - auc: 0.9878 - val_loss: 0.1489 - val_accuracy: 0.9498 - val_recall: 0.9839 - val_auc: 0.9826\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.1074 - accuracy: 0.9581 - recall: 0.9744 - auc: 0.9899 - val_loss: 0.2037 - val_accuracy: 0.9242 - val_recall: 0.9942 - val_auc: 0.9795\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.1033 - accuracy: 0.9632 - recall: 0.9777 - auc: 0.9897 - val_loss: 0.2581 - val_accuracy: 0.9018 - val_recall: 0.9971 - val_auc: 0.9850\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.0894 - accuracy: 0.9669 - recall: 0.9802 - auc: 0.9930 - val_loss: 0.4084 - val_accuracy: 0.8485 - val_recall: 0.9956 - val_auc: 0.9643\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.0942 - accuracy: 0.9645 - recall: 0.9792 - auc: 0.9921 - val_loss: 0.1717 - val_accuracy: 0.9520 - val_recall: 0.9751 - val_auc: 0.9783\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.1078 - accuracy: 0.9592 - recall: 0.9737 - auc: 0.9892 - val_loss: 0.2238 - val_accuracy: 0.9136 - val_recall: 0.9327 - val_auc: 0.9676\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 284s 2s/step - loss: 0.1144 - accuracy: 0.9568 - recall: 0.9733 - auc: 0.9874 - val_loss: 0.1643 - val_accuracy: 0.9456 - val_recall: 0.9942 - val_auc: 0.9870\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 301s 3s/step - loss: 0.1012 - accuracy: 0.9637 - recall: 0.9802 - auc: 0.9904 - val_loss: 0.1375 - val_accuracy: 0.9605 - val_recall: 0.9708 - val_auc: 0.9868\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 284s 2s/step - loss: 0.0901 - accuracy: 0.9650 - recall: 0.9784 - auc: 0.9918 - val_loss: 0.1486 - val_accuracy: 0.9594 - val_recall: 0.9766 - val_auc: 0.9823\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.0912 - accuracy: 0.9664 - recall: 0.9799 - auc: 0.9925 - val_loss: 0.1367 - val_accuracy: 0.9626 - val_recall: 0.9781 - val_auc: 0.9858\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 281s 2s/step - loss: 0.0784 - accuracy: 0.9720 - recall: 0.9843 - auc: 0.9941 - val_loss: 0.1954 - val_accuracy: 0.9466 - val_recall: 0.9386 - val_auc: 0.9849\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.0718 - accuracy: 0.9741 - recall: 0.9832 - auc: 0.9949 - val_loss: 0.6594 - val_accuracy: 0.8186 - val_recall: 0.7602 - val_auc: 0.9573\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.1047 - accuracy: 0.9621 - recall: 0.9748 - auc: 0.9897 - val_loss: 0.4460 - val_accuracy: 0.8911 - val_recall: 0.9868 - val_auc: 0.9194\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.1149 - accuracy: 0.9568 - recall: 0.9726 - auc: 0.9896 - val_loss: 0.2243 - val_accuracy: 0.9349 - val_recall: 0.9810 - val_auc: 0.9695\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.0784 - accuracy: 0.9696 - recall: 0.9824 - auc: 0.9931 - val_loss: 0.1919 - val_accuracy: 0.9349 - val_recall: 0.9284 - val_auc: 0.9862\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.319443  0.886843  0.929042  0.931467  0.286613      0.868730   \n",
      "1   0.195917  0.923405  0.951719  0.968988  0.187348      0.939168   \n",
      "2   0.202038  0.921537  0.948061  0.969790  0.696849      0.742796   \n",
      "3   0.140207  0.942888  0.964521  0.983671  0.299755      0.890075   \n",
      "4   0.131196  0.949827  0.968910  0.985278  0.422355      0.786553   \n",
      "5   0.114317  0.958367  0.976591  0.987796  0.148923      0.949840   \n",
      "6   0.107410  0.958100  0.974396  0.989949  0.203715      0.924226   \n",
      "7   0.103345  0.963171  0.977688  0.989667  0.258056      0.901814   \n",
      "8   0.089413  0.966907  0.980249  0.993002  0.408353      0.848453   \n",
      "9   0.094153  0.964505  0.979151  0.992118  0.171713      0.951974   \n",
      "10  0.107786  0.959167  0.973665  0.989204  0.223787      0.913554   \n",
      "11  0.114394  0.956765  0.973299  0.987367  0.164340      0.945571   \n",
      "12  0.101210  0.963704  0.980249  0.990362  0.137546      0.960512   \n",
      "13  0.090119  0.965039  0.978420  0.991806  0.148574      0.959445   \n",
      "14  0.091155  0.966373  0.979883  0.992543  0.136710      0.962647   \n",
      "15  0.078442  0.971978  0.984272  0.994076  0.195356      0.946638   \n",
      "16  0.071758  0.974113  0.983175  0.994921  0.659394      0.818570   \n",
      "17  0.104701  0.962103  0.974762  0.989738  0.445969      0.891142   \n",
      "18  0.114869  0.956765  0.972568  0.989568  0.224315      0.934899   \n",
      "19  0.078405  0.969576  0.982443  0.993086  0.191942      0.934899   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.988304  0.955577  \n",
      "1     0.945906  0.977062  \n",
      "2     0.998538  0.959995  \n",
      "3     0.997076  0.973901  \n",
      "4     1.000000  0.945389  \n",
      "5     0.983918  0.982563  \n",
      "6     0.994152  0.979500  \n",
      "7     0.997076  0.985025  \n",
      "8     0.995614  0.964311  \n",
      "9     0.975146  0.978327  \n",
      "10    0.932749  0.967568  \n",
      "11    0.994152  0.986984  \n",
      "12    0.970760  0.986799  \n",
      "13    0.976608  0.982294  \n",
      "14    0.978070  0.985808  \n",
      "15    0.938596  0.984932  \n",
      "16    0.760234  0.957308  \n",
      "17    0.986842  0.919438  \n",
      "18    0.980994  0.969541  \n",
      "19    0.928363  0.986204  \n",
      "37/37 [==============================] - 35s 927ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple1 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.3341 - accuracy: 0.8826 - recall: 0.9228 - auc: 0.9315 - val_loss: 0.7682 - val_accuracy: 0.7481 - val_recall: 0.9985 - val_auc: 0.9109\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.1927 - accuracy: 0.9303 - recall: 0.9612 - auc: 0.9693 - val_loss: 0.2168 - val_accuracy: 0.9178 - val_recall: 0.9430 - val_auc: 0.9652\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 276s 5s/step - loss: 0.1497 - accuracy: 0.9448 - recall: 0.9653 - auc: 0.9789 - val_loss: 1.2963 - val_accuracy: 0.4440 - val_recall: 0.2383 - val_auc: 0.9723\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.1377 - accuracy: 0.9493 - recall: 0.9700 - auc: 0.9838 - val_loss: 0.1486 - val_accuracy: 0.9445 - val_recall: 0.9781 - val_auc: 0.9834\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1338 - accuracy: 0.9490 - recall: 0.9704 - auc: 0.9848 - val_loss: 0.3666 - val_accuracy: 0.8677 - val_recall: 0.9956 - val_auc: 0.9668\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1219 - accuracy: 0.9544 - recall: 0.9715 - auc: 0.9871 - val_loss: 0.2375 - val_accuracy: 0.9114 - val_recall: 0.9181 - val_auc: 0.9620\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1081 - accuracy: 0.9576 - recall: 0.9722 - auc: 0.9877 - val_loss: 0.2136 - val_accuracy: 0.9242 - val_recall: 0.9181 - val_auc: 0.9755\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1116 - accuracy: 0.9594 - recall: 0.9751 - auc: 0.9881 - val_loss: 0.1801 - val_accuracy: 0.9488 - val_recall: 0.9810 - val_auc: 0.9749\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.0927 - accuracy: 0.9645 - recall: 0.9806 - auc: 0.9922 - val_loss: 0.1914 - val_accuracy: 0.9189 - val_recall: 0.9503 - val_auc: 0.9706\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1009 - accuracy: 0.9624 - recall: 0.9766 - auc: 0.9896 - val_loss: 0.2116 - val_accuracy: 0.9306 - val_recall: 0.9927 - val_auc: 0.9742\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.0925 - accuracy: 0.9656 - recall: 0.9802 - auc: 0.9912 - val_loss: 1.1369 - val_accuracy: 0.7866 - val_recall: 0.9985 - val_auc: 0.8224\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.0824 - accuracy: 0.9688 - recall: 0.9799 - auc: 0.9937 - val_loss: 0.5750 - val_accuracy: 0.8068 - val_recall: 0.9985 - val_auc: 0.9587\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0760 - accuracy: 0.9709 - recall: 0.9810 - auc: 0.9935 - val_loss: 0.1387 - val_accuracy: 0.9541 - val_recall: 0.9693 - val_auc: 0.9839\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0779 - accuracy: 0.9704 - recall: 0.9821 - auc: 0.9940 - val_loss: 0.1583 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9814\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 277s 5s/step - loss: 0.0857 - accuracy: 0.9690 - recall: 0.9810 - auc: 0.9934 - val_loss: 0.1396 - val_accuracy: 0.9509 - val_recall: 0.9518 - val_auc: 0.9889\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0585 - accuracy: 0.9800 - recall: 0.9898 - auc: 0.9965 - val_loss: 0.1734 - val_accuracy: 0.9456 - val_recall: 0.9810 - val_auc: 0.9770\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0474 - accuracy: 0.9816 - recall: 0.9890 - auc: 0.9974 - val_loss: 0.1156 - val_accuracy: 0.9648 - val_recall: 0.9795 - val_auc: 0.9884\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0510 - accuracy: 0.9840 - recall: 0.9920 - auc: 0.9965 - val_loss: 0.2019 - val_accuracy: 0.9456 - val_recall: 0.9825 - val_auc: 0.9776\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.0469 - accuracy: 0.9829 - recall: 0.9912 - auc: 0.9974 - val_loss: 0.1605 - val_accuracy: 0.9541 - val_recall: 0.9810 - val_auc: 0.9803\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0349 - accuracy: 0.9885 - recall: 0.9934 - auc: 0.9989 - val_loss: 0.2160 - val_accuracy: 0.9285 - val_recall: 0.9971 - val_auc: 0.9803\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.334079  0.882573  0.922824  0.931465  0.768192      0.748132   \n",
      "1   0.192689  0.930344  0.961229  0.969309  0.216752      0.917823   \n",
      "2   0.149691  0.944756  0.965252  0.978868  1.296298      0.443970   \n",
      "3   0.137711  0.949293  0.970007  0.983836  0.148606      0.944504   \n",
      "4   0.133786  0.949026  0.970373  0.984757  0.366580      0.867663   \n",
      "5   0.121886  0.954363  0.971470  0.987104  0.237454      0.911419   \n",
      "6   0.108084  0.957566  0.972202  0.987710  0.213580      0.924226   \n",
      "7   0.111643  0.959434  0.975128  0.988061  0.180143      0.948773   \n",
      "8   0.092668  0.964505  0.980614  0.992214  0.191431      0.918890   \n",
      "9   0.100927  0.962370  0.976591  0.989611  0.211573      0.930630   \n",
      "10  0.092453  0.965572  0.980249  0.991238  1.136923      0.786553   \n",
      "11  0.082433  0.968775  0.979883  0.993675  0.574997      0.806830   \n",
      "12  0.075993  0.970910  0.980980  0.993506  0.138685      0.954109   \n",
      "13  0.077879  0.970376  0.982078  0.993959  0.158273      0.944504   \n",
      "14  0.085690  0.969042  0.980980  0.993354  0.139620      0.950907   \n",
      "15  0.058538  0.979984  0.989759  0.996488  0.173424      0.945571   \n",
      "16  0.047407  0.981585  0.989027  0.997394  0.115642      0.964781   \n",
      "17  0.051005  0.983987  0.991953  0.996512  0.201925      0.945571   \n",
      "18  0.046877  0.982920  0.991222  0.997390  0.160546      0.954109   \n",
      "19  0.034943  0.988524  0.993416  0.998931  0.216021      0.928495   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.998538  0.910949  \n",
      "1     0.942982  0.965216  \n",
      "2     0.238304  0.972341  \n",
      "3     0.978070  0.983378  \n",
      "4     0.995614  0.966825  \n",
      "5     0.918129  0.962035  \n",
      "6     0.918129  0.975484  \n",
      "7     0.980994  0.974941  \n",
      "8     0.950292  0.970593  \n",
      "9     0.992690  0.974225  \n",
      "10    0.998538  0.822377  \n",
      "11    0.998538  0.958660  \n",
      "12    0.969298  0.983930  \n",
      "13    0.961988  0.981399  \n",
      "14    0.951754  0.988940  \n",
      "15    0.980994  0.976998  \n",
      "16    0.979532  0.988408  \n",
      "17    0.982456  0.977648  \n",
      "18    0.980994  0.980289  \n",
      "19    0.997076  0.980266  \n",
      "19/19 [==============================] - 34s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple2...\n",
      "Entrenando modelo Simple2 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 316s 671ms/step - loss: 0.3993 - accuracy: 0.8596 - recall: 0.9045 - auc: 0.9010 - val_loss: 0.3049 - val_accuracy: 0.9104 - val_recall: 0.9635 - val_auc: 0.9453\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 306s 653ms/step - loss: 0.2170 - accuracy: 0.9143 - recall: 0.9437 - auc: 0.9628 - val_loss: 0.2954 - val_accuracy: 0.8751 - val_recall: 0.9927 - val_auc: 0.9732\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 310s 660ms/step - loss: 0.1938 - accuracy: 0.9303 - recall: 0.9521 - auc: 0.9703 - val_loss: 0.4806 - val_accuracy: 0.8410 - val_recall: 0.9942 - val_auc: 0.9437\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 305s 650ms/step - loss: 0.1668 - accuracy: 0.9378 - recall: 0.9572 - auc: 0.9769 - val_loss: 0.1517 - val_accuracy: 0.9370 - val_recall: 0.9795 - val_auc: 0.9855\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 310s 661ms/step - loss: 0.1513 - accuracy: 0.9429 - recall: 0.9645 - auc: 0.9804 - val_loss: 0.2016 - val_accuracy: 0.9168 - val_recall: 0.9912 - val_auc: 0.9844\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 336s 717ms/step - loss: 0.1430 - accuracy: 0.9485 - recall: 0.9674 - auc: 0.9833 - val_loss: 0.1562 - val_accuracy: 0.9562 - val_recall: 0.9751 - val_auc: 0.9753\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 327s 698ms/step - loss: 0.1319 - accuracy: 0.9554 - recall: 0.9685 - auc: 0.9850 - val_loss: 0.1897 - val_accuracy: 0.9296 - val_recall: 0.9284 - val_auc: 0.9791\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 327s 697ms/step - loss: 0.1326 - accuracy: 0.9512 - recall: 0.9682 - auc: 0.9840 - val_loss: 0.1454 - val_accuracy: 0.9456 - val_recall: 0.9518 - val_auc: 0.9884\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 295s 628ms/step - loss: 0.1170 - accuracy: 0.9584 - recall: 0.9737 - auc: 0.9874 - val_loss: 0.1766 - val_accuracy: 0.9498 - val_recall: 0.9708 - val_auc: 0.9739\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 304s 647ms/step - loss: 0.1438 - accuracy: 0.9424 - recall: 0.9620 - auc: 0.9820 - val_loss: 0.1680 - val_accuracy: 0.9424 - val_recall: 0.9912 - val_auc: 0.9806\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 305s 650ms/step - loss: 0.1211 - accuracy: 0.9554 - recall: 0.9718 - auc: 0.9860 - val_loss: 0.1387 - val_accuracy: 0.9445 - val_recall: 0.9781 - val_auc: 0.9820\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 321s 684ms/step - loss: 0.1079 - accuracy: 0.9594 - recall: 0.9762 - auc: 0.9898 - val_loss: 0.1838 - val_accuracy: 0.9402 - val_recall: 0.9781 - val_auc: 0.9787\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 305s 650ms/step - loss: 0.1080 - accuracy: 0.9637 - recall: 0.9795 - auc: 0.9891 - val_loss: 0.1228 - val_accuracy: 0.9562 - val_recall: 0.9678 - val_auc: 0.9870\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 315s 670ms/step - loss: 0.0971 - accuracy: 0.9650 - recall: 0.9795 - auc: 0.9912 - val_loss: 0.2177 - val_accuracy: 0.9296 - val_recall: 0.9912 - val_auc: 0.9726\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 290s 619ms/step - loss: 0.0862 - accuracy: 0.9653 - recall: 0.9813 - auc: 0.9928 - val_loss: 0.1410 - val_accuracy: 0.9509 - val_recall: 0.9547 - val_auc: 0.9875\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 295s 628ms/step - loss: 0.0780 - accuracy: 0.9680 - recall: 0.9828 - auc: 0.9951 - val_loss: 0.2062 - val_accuracy: 0.9509 - val_recall: 0.9825 - val_auc: 0.9764\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 298s 636ms/step - loss: 0.0845 - accuracy: 0.9680 - recall: 0.9817 - auc: 0.9936 - val_loss: 0.1397 - val_accuracy: 0.9509 - val_recall: 0.9576 - val_auc: 0.9849\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 300s 640ms/step - loss: 0.0880 - accuracy: 0.9664 - recall: 0.9810 - auc: 0.9923 - val_loss: 0.5072 - val_accuracy: 0.9370 - val_recall: 0.9547 - val_auc: 0.9757\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.399287  0.859621  0.904535  0.901013  0.304914      0.910352   \n",
      "1   0.216970  0.914331  0.943672  0.962825  0.295422      0.875133   \n",
      "2   0.193777  0.930344  0.952085  0.970252  0.480596      0.840982   \n",
      "3   0.166755  0.937817  0.957206  0.976948  0.151747      0.937033   \n",
      "4   0.151285  0.942888  0.964521  0.980440  0.201567      0.916756   \n",
      "5   0.143001  0.948492  0.967447  0.983327  0.156209      0.956243   \n",
      "6   0.131877  0.955431  0.968544  0.984973  0.189664      0.929562   \n",
      "7   0.132579  0.951161  0.968179  0.983988  0.145442      0.945571   \n",
      "8   0.117039  0.958367  0.973665  0.987429  0.176649      0.949840   \n",
      "9   0.143759  0.942354  0.961960  0.981980  0.167993      0.942369   \n",
      "10  0.121064  0.955431  0.971836  0.985990  0.138710      0.944504   \n",
      "11  0.107921  0.959434  0.976225  0.989759  0.183791      0.940235   \n",
      "12  0.108002  0.963704  0.979517  0.989051  0.122823      0.956243   \n",
      "13  0.097063  0.965039  0.979517  0.991176  0.217670      0.929562   \n",
      "14  0.086171  0.965306  0.981346  0.992793  0.140986      0.950907   \n",
      "15  0.078047  0.967974  0.982809  0.995142  0.206174      0.950907   \n",
      "16  0.084517  0.967974  0.981712  0.993588  0.139740      0.950907   \n",
      "17  0.088027  0.966373  0.980980  0.992317  0.507229      0.937033   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.963450  0.945256  \n",
      "1     0.992690  0.973205  \n",
      "2     0.994152  0.943676  \n",
      "3     0.979532  0.985516  \n",
      "4     0.991228  0.984415  \n",
      "5     0.975146  0.975325  \n",
      "6     0.928363  0.979113  \n",
      "7     0.951754  0.988437  \n",
      "8     0.970760  0.973933  \n",
      "9     0.991228  0.980552  \n",
      "10    0.978070  0.982017  \n",
      "11    0.978070  0.978674  \n",
      "12    0.967836  0.986966  \n",
      "13    0.991228  0.972580  \n",
      "14    0.954678  0.987524  \n",
      "15    0.982456  0.976389  \n",
      "16    0.957602  0.984901  \n",
      "17    0.954678  0.975739  \n",
      "147/147 [==============================] - 40s 268ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 303s 1s/step - loss: 0.3434 - accuracy: 0.8687 - recall: 0.9144 - auc: 0.9170 - val_loss: 0.8184 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.9001\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.2011 - accuracy: 0.9239 - recall: 0.9503 - auc: 0.9681 - val_loss: 0.3799 - val_accuracy: 0.8581 - val_recall: 0.9868 - val_auc: 0.9357\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 299s 1s/step - loss: 0.1733 - accuracy: 0.9354 - recall: 0.9598 - auc: 0.9756 - val_loss: 0.3027 - val_accuracy: 0.8634 - val_recall: 0.9898 - val_auc: 0.9547\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.1554 - accuracy: 0.9421 - recall: 0.9609 - auc: 0.9791 - val_loss: 0.3854 - val_accuracy: 0.8709 - val_recall: 0.9942 - val_auc: 0.9609\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.1474 - accuracy: 0.9434 - recall: 0.9623 - auc: 0.9814 - val_loss: 0.1641 - val_accuracy: 0.9381 - val_recall: 0.9810 - val_auc: 0.9837\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.1383 - accuracy: 0.9528 - recall: 0.9707 - auc: 0.9832 - val_loss: 0.1675 - val_accuracy: 0.9317 - val_recall: 0.9883 - val_auc: 0.9841\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.1216 - accuracy: 0.9552 - recall: 0.9700 - auc: 0.9869 - val_loss: 0.1628 - val_accuracy: 0.9488 - val_recall: 0.9605 - val_auc: 0.9809\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.1252 - accuracy: 0.9538 - recall: 0.9748 - auc: 0.9855 - val_loss: 0.2087 - val_accuracy: 0.9296 - val_recall: 0.9269 - val_auc: 0.9838\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 286s 1s/step - loss: 0.1133 - accuracy: 0.9565 - recall: 0.9729 - auc: 0.9883 - val_loss: 0.1188 - val_accuracy: 0.9584 - val_recall: 0.9795 - val_auc: 0.9904\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 289s 1s/step - loss: 0.1044 - accuracy: 0.9589 - recall: 0.9744 - auc: 0.9902 - val_loss: 0.6714 - val_accuracy: 0.7385 - val_recall: 1.0000 - val_auc: 0.9496\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 285s 1s/step - loss: 0.0954 - accuracy: 0.9616 - recall: 0.9781 - auc: 0.9911 - val_loss: 0.2163 - val_accuracy: 0.9434 - val_recall: 0.9825 - val_auc: 0.9684\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.1013 - accuracy: 0.9634 - recall: 0.9795 - auc: 0.9904 - val_loss: 0.1725 - val_accuracy: 0.9488 - val_recall: 0.9722 - val_auc: 0.9801\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.1079 - accuracy: 0.9584 - recall: 0.9766 - auc: 0.9901 - val_loss: 0.1316 - val_accuracy: 0.9498 - val_recall: 0.9708 - val_auc: 0.9862\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.0863 - accuracy: 0.9656 - recall: 0.9792 - auc: 0.9929 - val_loss: 0.1792 - val_accuracy: 0.9466 - val_recall: 0.9781 - val_auc: 0.9780\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.0825 - accuracy: 0.9693 - recall: 0.9843 - auc: 0.9934 - val_loss: 0.1239 - val_accuracy: 0.9552 - val_recall: 0.9795 - val_auc: 0.9855\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.0772 - accuracy: 0.9706 - recall: 0.9854 - auc: 0.9943 - val_loss: 0.1628 - val_accuracy: 0.9466 - val_recall: 0.9868 - val_auc: 0.9861\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 293s 1s/step - loss: 0.0915 - accuracy: 0.9653 - recall: 0.9799 - auc: 0.9927 - val_loss: 0.2389 - val_accuracy: 0.9488 - val_recall: 0.9825 - val_auc: 0.9653\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.0873 - accuracy: 0.9690 - recall: 0.9824 - auc: 0.9930 - val_loss: 0.2202 - val_accuracy: 0.9445 - val_recall: 0.9766 - val_auc: 0.9707\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.0769 - accuracy: 0.9720 - recall: 0.9813 - auc: 0.9946 - val_loss: 0.1391 - val_accuracy: 0.9520 - val_recall: 0.9722 - val_auc: 0.9846\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.343355  0.868695  0.914411  0.916976  0.818391      0.735326   \n",
      "1   0.201142  0.923939  0.950256  0.968072  0.379862      0.858058   \n",
      "2   0.173290  0.935415  0.959766  0.975616  0.302679      0.863394   \n",
      "3   0.155438  0.942087  0.960863  0.979095  0.385432      0.870864   \n",
      "4   0.147401  0.943421  0.962326  0.981387  0.164098      0.938100   \n",
      "5   0.138309  0.952762  0.970739  0.983191  0.167496      0.931697   \n",
      "6   0.121603  0.955164  0.970007  0.986855  0.162797      0.948773   \n",
      "7   0.125214  0.953830  0.974762  0.985518  0.208730      0.929562   \n",
      "8   0.113280  0.956499  0.972933  0.988263  0.118789      0.958378   \n",
      "9   0.104381  0.958900  0.974396  0.990179  0.671422      0.738527   \n",
      "10  0.095372  0.961569  0.978054  0.991085  0.216330      0.943437   \n",
      "11  0.101290  0.963437  0.979517  0.990386  0.172498      0.948773   \n",
      "12  0.107892  0.958367  0.976591  0.990131  0.131571      0.949840   \n",
      "13  0.086287  0.965572  0.979151  0.992936  0.179176      0.946638   \n",
      "14  0.082491  0.969309  0.984272  0.993378  0.123941      0.955176   \n",
      "15  0.077191  0.970643  0.985369  0.994350  0.162808      0.946638   \n",
      "16  0.091536  0.965306  0.979883  0.992664  0.238877      0.948773   \n",
      "17  0.087265  0.969042  0.982443  0.993046  0.220225      0.944504   \n",
      "18  0.076866  0.971978  0.981346  0.994593  0.139059      0.951974   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.900050  \n",
      "1     0.986842  0.935675  \n",
      "2     0.989766  0.954704  \n",
      "3     0.994152  0.960945  \n",
      "4     0.980994  0.983727  \n",
      "5     0.988304  0.984086  \n",
      "6     0.960526  0.980907  \n",
      "7     0.926901  0.983826  \n",
      "8     0.979532  0.990442  \n",
      "9     1.000000  0.949587  \n",
      "10    0.982456  0.968405  \n",
      "11    0.972222  0.980130  \n",
      "12    0.970760  0.986201  \n",
      "13    0.978070  0.977989  \n",
      "14    0.979532  0.985461  \n",
      "15    0.986842  0.986079  \n",
      "16    0.982456  0.965268  \n",
      "17    0.976608  0.970740  \n",
      "18    0.972222  0.984554  \n",
      "74/74 [==============================] - 36s 486ms/step\n",
      "Entrenando modelo Simple2 y batch_size 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 294s 2s/step - loss: 0.3327 - accuracy: 0.8735 - recall: 0.9239 - auc: 0.9187 - val_loss: 0.2138 - val_accuracy: 0.9178 - val_recall: 0.9503 - val_auc: 0.9680\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 283s 2s/step - loss: 0.2166 - accuracy: 0.9239 - recall: 0.9503 - auc: 0.9612 - val_loss: 0.2438 - val_accuracy: 0.9050 - val_recall: 0.8830 - val_auc: 0.9742\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 283s 2s/step - loss: 0.1996 - accuracy: 0.9242 - recall: 0.9546 - auc: 0.9683 - val_loss: 0.2161 - val_accuracy: 0.9157 - val_recall: 0.9488 - val_auc: 0.9647\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.1670 - accuracy: 0.9370 - recall: 0.9568 - auc: 0.9763 - val_loss: 1.6408 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6872\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 292s 2s/step - loss: 0.1545 - accuracy: 0.9432 - recall: 0.9663 - auc: 0.9785 - val_loss: 1.3665 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.7887\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 283s 2s/step - loss: 0.1478 - accuracy: 0.9464 - recall: 0.9689 - auc: 0.9810 - val_loss: 0.1983 - val_accuracy: 0.9349 - val_recall: 0.9898 - val_auc: 0.9753\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 286s 2s/step - loss: 0.1265 - accuracy: 0.9549 - recall: 0.9707 - auc: 0.9852 - val_loss: 0.2691 - val_accuracy: 0.9200 - val_recall: 0.9898 - val_auc: 0.9694\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 296s 2s/step - loss: 0.1256 - accuracy: 0.9538 - recall: 0.9704 - auc: 0.9866 - val_loss: 0.1313 - val_accuracy: 0.9562 - val_recall: 0.9722 - val_auc: 0.9854\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 294s 2s/step - loss: 0.1326 - accuracy: 0.9506 - recall: 0.9711 - auc: 0.9838 - val_loss: 0.1195 - val_accuracy: 0.9530 - val_recall: 0.9839 - val_auc: 0.9877\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 295s 2s/step - loss: 0.1052 - accuracy: 0.9616 - recall: 0.9781 - auc: 0.9896 - val_loss: 0.2081 - val_accuracy: 0.9264 - val_recall: 0.9898 - val_auc: 0.9774\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 308s 2s/step - loss: 0.1043 - accuracy: 0.9613 - recall: 0.9799 - auc: 0.9901 - val_loss: 0.1995 - val_accuracy: 0.9434 - val_recall: 0.9898 - val_auc: 0.9737\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 291s 2s/step - loss: 0.1077 - accuracy: 0.9613 - recall: 0.9810 - auc: 0.9887 - val_loss: 0.1762 - val_accuracy: 0.9488 - val_recall: 0.9503 - val_auc: 0.9889\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 282s 2s/step - loss: 0.0938 - accuracy: 0.9674 - recall: 0.9810 - auc: 0.9930 - val_loss: 1.8953 - val_accuracy: 0.6041 - val_recall: 0.4576 - val_auc: 0.8998\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 285s 2s/step - loss: 0.0904 - accuracy: 0.9693 - recall: 0.9828 - auc: 0.9926 - val_loss: 0.1220 - val_accuracy: 0.9573 - val_recall: 0.9766 - val_auc: 0.9871\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 294s 2s/step - loss: 0.0933 - accuracy: 0.9648 - recall: 0.9792 - auc: 0.9916 - val_loss: 0.1236 - val_accuracy: 0.9552 - val_recall: 0.9781 - val_auc: 0.9882\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 282s 2s/step - loss: 0.0774 - accuracy: 0.9706 - recall: 0.9817 - auc: 0.9944 - val_loss: 0.1438 - val_accuracy: 0.9456 - val_recall: 0.9810 - val_auc: 0.9820\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.0690 - accuracy: 0.9749 - recall: 0.9868 - auc: 0.9956 - val_loss: 0.1735 - val_accuracy: 0.9338 - val_recall: 0.9898 - val_auc: 0.9853\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 285s 2s/step - loss: 0.0790 - accuracy: 0.9685 - recall: 0.9828 - auc: 0.9938 - val_loss: 0.1398 - val_accuracy: 0.9456 - val_recall: 0.9591 - val_auc: 0.9884\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 280s 1s/step - loss: 0.0735 - accuracy: 0.9717 - recall: 0.9835 - auc: 0.9953 - val_loss: 0.1619 - val_accuracy: 0.9509 - val_recall: 0.9825 - val_auc: 0.9802\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 289s 2s/step - loss: 0.0731 - accuracy: 0.9736 - recall: 0.9839 - auc: 0.9949 - val_loss: 0.1522 - val_accuracy: 0.9584 - val_recall: 0.9664 - val_auc: 0.9831\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.332703  0.873499  0.923921  0.918742  0.213782      0.917823   \n",
      "1   0.216596  0.923939  0.950256  0.961199  0.243794      0.905016   \n",
      "2   0.199601  0.924206  0.954645  0.968341  0.216115      0.915688   \n",
      "3   0.166993  0.937016  0.956840  0.976349  1.640757      0.729989   \n",
      "4   0.154473  0.943155  0.966350  0.978489  1.366454      0.731057   \n",
      "5   0.147775  0.946357  0.968910  0.980953  0.198301      0.934899   \n",
      "6   0.126540  0.954897  0.970739  0.985179  0.269116      0.919957   \n",
      "7   0.125641  0.953830  0.970373  0.986583  0.131332      0.956243   \n",
      "8   0.132581  0.950627  0.971105  0.983805  0.119497      0.953042   \n",
      "9   0.105207  0.961569  0.978054  0.989604  0.208051      0.926361   \n",
      "10  0.104340  0.961302  0.979883  0.990058  0.199538      0.943437   \n",
      "11  0.107653  0.961302  0.980980  0.988701  0.176246      0.948773   \n",
      "12  0.093785  0.967441  0.980980  0.992988  1.895325      0.604056   \n",
      "13  0.090351  0.969309  0.982809  0.992641  0.122022      0.957311   \n",
      "14  0.093314  0.964772  0.979151  0.991629  0.123632      0.955176   \n",
      "15  0.077426  0.970643  0.981712  0.994426  0.143771      0.945571   \n",
      "16  0.068980  0.974913  0.986832  0.995637  0.173531      0.933831   \n",
      "17  0.078986  0.968508  0.982809  0.993810  0.139841      0.945571   \n",
      "18  0.073511  0.971711  0.983541  0.995323  0.161853      0.950907   \n",
      "19  0.073114  0.973579  0.983906  0.994869  0.152210      0.958378   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.950292  0.967975  \n",
      "1     0.883041  0.974219  \n",
      "2     0.948830  0.964710  \n",
      "3     1.000000  0.687158  \n",
      "4     1.000000  0.788650  \n",
      "5     0.989766  0.975262  \n",
      "6     0.989766  0.969385  \n",
      "7     0.972222  0.985426  \n",
      "8     0.983918  0.987700  \n",
      "9     0.989766  0.977365  \n",
      "10    0.989766  0.973710  \n",
      "11    0.950292  0.988902  \n",
      "12    0.457602  0.899822  \n",
      "13    0.976608  0.987108  \n",
      "14    0.978070  0.988209  \n",
      "15    0.980994  0.982043  \n",
      "16    0.989766  0.985279  \n",
      "17    0.959064  0.988359  \n",
      "18    0.982456  0.980159  \n",
      "19    0.966374  0.983098  \n",
      "59/59 [==============================] - 36s 603ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.3312 - accuracy: 0.8706 - recall: 0.9100 - auc: 0.9216 - val_loss: 0.5782 - val_accuracy: 0.7492 - val_recall: 0.9927 - val_auc: 0.8665\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 280s 2s/step - loss: 0.2280 - accuracy: 0.9087 - recall: 0.9371 - auc: 0.9592 - val_loss: 0.2878 - val_accuracy: 0.8783 - val_recall: 0.9898 - val_auc: 0.9691\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 278s 2s/step - loss: 0.1688 - accuracy: 0.9405 - recall: 0.9620 - auc: 0.9766 - val_loss: 0.2050 - val_accuracy: 0.9189 - val_recall: 0.9094 - val_auc: 0.9808\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 280s 2s/step - loss: 0.1638 - accuracy: 0.9397 - recall: 0.9598 - auc: 0.9780 - val_loss: 1.1142 - val_accuracy: 0.7375 - val_recall: 1.0000 - val_auc: 0.8636\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 287s 2s/step - loss: 0.1713 - accuracy: 0.9386 - recall: 0.9612 - auc: 0.9758 - val_loss: 0.3702 - val_accuracy: 0.8794 - val_recall: 0.8728 - val_auc: 0.9468\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 290s 2s/step - loss: 0.1460 - accuracy: 0.9429 - recall: 0.9645 - auc: 0.9820 - val_loss: 0.3737 - val_accuracy: 0.8527 - val_recall: 0.9956 - val_auc: 0.9685\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 280s 2s/step - loss: 0.1250 - accuracy: 0.9514 - recall: 0.9707 - auc: 0.9861 - val_loss: 0.2501 - val_accuracy: 0.9050 - val_recall: 0.9927 - val_auc: 0.9739\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 279s 2s/step - loss: 0.1082 - accuracy: 0.9597 - recall: 0.9729 - auc: 0.9889 - val_loss: 0.1235 - val_accuracy: 0.9552 - val_recall: 0.9722 - val_auc: 0.9882\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 285s 2s/step - loss: 0.1121 - accuracy: 0.9581 - recall: 0.9759 - auc: 0.9886 - val_loss: 0.3745 - val_accuracy: 0.8367 - val_recall: 0.9605 - val_auc: 0.9130\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 281s 2s/step - loss: 0.1068 - accuracy: 0.9597 - recall: 0.9773 - auc: 0.9896 - val_loss: 0.1650 - val_accuracy: 0.9360 - val_recall: 0.9898 - val_auc: 0.9816\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 279s 2s/step - loss: 0.1117 - accuracy: 0.9597 - recall: 0.9781 - auc: 0.9887 - val_loss: 0.1885 - val_accuracy: 0.9200 - val_recall: 0.9912 - val_auc: 0.9856\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 280s 2s/step - loss: 0.1042 - accuracy: 0.9610 - recall: 0.9762 - auc: 0.9895 - val_loss: 0.1689 - val_accuracy: 0.9381 - val_recall: 0.9737 - val_auc: 0.9804\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.0901 - accuracy: 0.9645 - recall: 0.9810 - auc: 0.9922 - val_loss: 0.1407 - val_accuracy: 0.9573 - val_recall: 0.9810 - val_auc: 0.9831\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 285s 2s/step - loss: 0.0780 - accuracy: 0.9709 - recall: 0.9828 - auc: 0.9940 - val_loss: 0.1548 - val_accuracy: 0.9360 - val_recall: 0.9678 - val_auc: 0.9826\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 284s 2s/step - loss: 0.0874 - accuracy: 0.9666 - recall: 0.9810 - auc: 0.9930 - val_loss: 0.1754 - val_accuracy: 0.9477 - val_recall: 0.9810 - val_auc: 0.9781\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.0711 - accuracy: 0.9717 - recall: 0.9832 - auc: 0.9944 - val_loss: 0.1640 - val_accuracy: 0.9434 - val_recall: 0.9883 - val_auc: 0.9843\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 288s 2s/step - loss: 0.1047 - accuracy: 0.9626 - recall: 0.9792 - auc: 0.9892 - val_loss: 0.1974 - val_accuracy: 0.9445 - val_recall: 0.9444 - val_auc: 0.9861\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 280s 2s/step - loss: 0.0736 - accuracy: 0.9736 - recall: 0.9850 - auc: 0.9948 - val_loss: 0.1762 - val_accuracy: 0.9434 - val_recall: 0.9883 - val_auc: 0.9807\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.331183  0.870563  0.910022  0.921582  0.578163      0.749200   \n",
      "1   0.227959  0.908727  0.937088  0.959183  0.287793      0.878335   \n",
      "2   0.168828  0.940486  0.961960  0.976568  0.205013      0.918890   \n",
      "3   0.163801  0.939685  0.959766  0.977993  1.114151      0.737460   \n",
      "4   0.171311  0.938618  0.961229  0.975809  0.370213      0.879402   \n",
      "5   0.145982  0.942888  0.964521  0.981990  0.373728      0.852721   \n",
      "6   0.124955  0.951428  0.970739  0.986102  0.250079      0.905016   \n",
      "7   0.108181  0.959701  0.972933  0.988858  0.123497      0.955176   \n",
      "8   0.112120  0.958100  0.975860  0.988566  0.374463      0.836713   \n",
      "9   0.106809  0.959701  0.977323  0.989607  0.165009      0.935966   \n",
      "10  0.111672  0.959701  0.978054  0.988704  0.188504      0.919957   \n",
      "11  0.104186  0.961035  0.976225  0.989509  0.168935      0.938100   \n",
      "12  0.090057  0.964505  0.980980  0.992170  0.140658      0.957311   \n",
      "13  0.078048  0.970910  0.982809  0.994008  0.154784      0.935966   \n",
      "14  0.087416  0.966640  0.980980  0.993003  0.175423      0.947705   \n",
      "15  0.071102  0.971711  0.983175  0.994447  0.163964      0.943437   \n",
      "16  0.104654  0.962637  0.979151  0.989239  0.197363      0.944504   \n",
      "17  0.073594  0.973579  0.985004  0.994788  0.176178      0.943437   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.992690  0.866462  \n",
      "1     0.989766  0.969122  \n",
      "2     0.909357  0.980798  \n",
      "3     1.000000  0.863625  \n",
      "4     0.872807  0.946796  \n",
      "5     0.995614  0.968509  \n",
      "6     0.992690  0.973901  \n",
      "7     0.972222  0.988177  \n",
      "8     0.960526  0.912991  \n",
      "9     0.989766  0.981647  \n",
      "10    0.991228  0.985617  \n",
      "11    0.973684  0.980445  \n",
      "12    0.980994  0.983051  \n",
      "13    0.967836  0.982563  \n",
      "14    0.980994  0.978064  \n",
      "15    0.988304  0.984331  \n",
      "16    0.944444  0.986131  \n",
      "17    0.988304  0.980737  \n",
      "37/37 [==============================] - 35s 938ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple2 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.3954 - accuracy: 0.8591 - recall: 0.9016 - auc: 0.9117 - val_loss: 1.0139 - val_accuracy: 0.7279 - val_recall: 0.9971 - val_auc: 0.7532\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.2240 - accuracy: 0.9077 - recall: 0.9386 - auc: 0.9605 - val_loss: 0.4417 - val_accuracy: 0.7930 - val_recall: 0.9912 - val_auc: 0.9436\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1817 - accuracy: 0.9303 - recall: 0.9546 - auc: 0.9721 - val_loss: 0.3709 - val_accuracy: 0.8367 - val_recall: 0.9942 - val_auc: 0.9680\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.1575 - accuracy: 0.9378 - recall: 0.9638 - auc: 0.9791 - val_loss: 0.8297 - val_accuracy: 0.7513 - val_recall: 1.0000 - val_auc: 0.9033\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1556 - accuracy: 0.9376 - recall: 0.9583 - auc: 0.9798 - val_loss: 0.5243 - val_accuracy: 0.8367 - val_recall: 0.9985 - val_auc: 0.9332\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.1351 - accuracy: 0.9477 - recall: 0.9689 - auc: 0.9854 - val_loss: 0.2634 - val_accuracy: 0.9082 - val_recall: 0.9942 - val_auc: 0.9716\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.1219 - accuracy: 0.9552 - recall: 0.9667 - auc: 0.9872 - val_loss: 0.2562 - val_accuracy: 0.9029 - val_recall: 0.9927 - val_auc: 0.9761\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.1204 - accuracy: 0.9602 - recall: 0.9773 - auc: 0.9857 - val_loss: 0.4662 - val_accuracy: 0.8410 - val_recall: 0.9854 - val_auc: 0.9427\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.1136 - accuracy: 0.9576 - recall: 0.9733 - auc: 0.9888 - val_loss: 0.4713 - val_accuracy: 0.8698 - val_recall: 0.9868 - val_auc: 0.9158\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1049 - accuracy: 0.9618 - recall: 0.9744 - auc: 0.9903 - val_loss: 0.2044 - val_accuracy: 0.9285 - val_recall: 0.9825 - val_auc: 0.9783\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 268s 5s/step - loss: 0.0917 - accuracy: 0.9645 - recall: 0.9784 - auc: 0.9931 - val_loss: 0.9704 - val_accuracy: 0.7407 - val_recall: 1.0000 - val_auc: 0.8894\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.1017 - accuracy: 0.9618 - recall: 0.9766 - auc: 0.9903 - val_loss: 0.3053 - val_accuracy: 0.8570 - val_recall: 0.9620 - val_auc: 0.9340\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.1021 - accuracy: 0.9610 - recall: 0.9755 - auc: 0.9911 - val_loss: 0.5447 - val_accuracy: 0.8474 - val_recall: 0.9956 - val_auc: 0.9177\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.0826 - accuracy: 0.9725 - recall: 0.9846 - auc: 0.9926 - val_loss: 0.2731 - val_accuracy: 0.9370 - val_recall: 0.9956 - val_auc: 0.9666\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 266s 5s/step - loss: 0.0764 - accuracy: 0.9714 - recall: 0.9817 - auc: 0.9943 - val_loss: 0.1470 - val_accuracy: 0.9562 - val_recall: 0.9854 - val_auc: 0.9819\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.0694 - accuracy: 0.9765 - recall: 0.9865 - auc: 0.9952 - val_loss: 0.1653 - val_accuracy: 0.9573 - val_recall: 0.9649 - val_auc: 0.9823\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0625 - accuracy: 0.9795 - recall: 0.9890 - auc: 0.9950 - val_loss: 0.1981 - val_accuracy: 0.9445 - val_recall: 0.9678 - val_auc: 0.9715\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0655 - accuracy: 0.9765 - recall: 0.9883 - auc: 0.9964 - val_loss: 0.1675 - val_accuracy: 0.9360 - val_recall: 0.9898 - val_auc: 0.9852\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.0660 - accuracy: 0.9749 - recall: 0.9839 - auc: 0.9959 - val_loss: 0.1387 - val_accuracy: 0.9594 - val_recall: 0.9722 - val_auc: 0.9853\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0586 - accuracy: 0.9786 - recall: 0.9894 - auc: 0.9968 - val_loss: 0.1374 - val_accuracy: 0.9584 - val_recall: 0.9649 - val_auc: 0.9895\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.395354  0.859087  0.901609  0.911738  1.013887      0.727855   \n",
      "1   0.224021  0.907659  0.938552  0.960499  0.441656      0.792956   \n",
      "2   0.181733  0.930344  0.954645  0.972138  0.370876      0.836713   \n",
      "3   0.157489  0.937817  0.963789  0.979053  0.829716      0.751334   \n",
      "4   0.155596  0.937550  0.958303  0.979816  0.524333      0.836713   \n",
      "5   0.135099  0.947692  0.968910  0.985431  0.263440      0.908218   \n",
      "6   0.121850  0.955164  0.966715  0.987153  0.256175      0.902882   \n",
      "7   0.120389  0.960235  0.977323  0.985738  0.466236      0.840982   \n",
      "8   0.113643  0.957566  0.973299  0.988793  0.471339      0.869797   \n",
      "9   0.104930  0.961836  0.974396  0.990310  0.204372      0.928495   \n",
      "10  0.091707  0.964505  0.978420  0.993118  0.970411      0.740662   \n",
      "11  0.101669  0.961836  0.976591  0.990261  0.305290      0.856990   \n",
      "12  0.102125  0.961035  0.975494  0.991069  0.544676      0.847385   \n",
      "13  0.082624  0.972511  0.984638  0.992572  0.273057      0.937033   \n",
      "14  0.076432  0.971444  0.981712  0.994347  0.146968      0.956243   \n",
      "15  0.069425  0.976515  0.986467  0.995184  0.165324      0.957311   \n",
      "16  0.062458  0.979450  0.989027  0.995010  0.198098      0.944504   \n",
      "17  0.065499  0.976515  0.988296  0.996421  0.167516      0.935966   \n",
      "18  0.065994  0.974913  0.983906  0.995890  0.138727      0.959445   \n",
      "19  0.058577  0.978650  0.989393  0.996809  0.137394      0.958378   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.997076  0.753207  \n",
      "1     0.991228  0.943618  \n",
      "2     0.994152  0.968036  \n",
      "3     1.000000  0.903312  \n",
      "4     0.998538  0.933170  \n",
      "5     0.994152  0.971633  \n",
      "6     0.992690  0.976146  \n",
      "7     0.985380  0.942691  \n",
      "8     0.986842  0.915783  \n",
      "9     0.982456  0.978296  \n",
      "10    1.000000  0.889409  \n",
      "11    0.961988  0.933988  \n",
      "12    0.995614  0.917721  \n",
      "13    0.995614  0.966588  \n",
      "14    0.985380  0.981901  \n",
      "15    0.964912  0.982260  \n",
      "16    0.967836  0.971459  \n",
      "17    0.989766  0.985247  \n",
      "18    0.972222  0.985308  \n",
      "19    0.964912  0.989544  \n",
      "19/19 [==============================] - 33s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando modelo Simple3...\n",
      "Entrenando modelo Simple3 y batch_size 8\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 318s 675ms/step - loss: 0.4372 - accuracy: 0.8070 - recall: 0.9012 - auc: 0.8631 - val_loss: 0.2698 - val_accuracy: 0.8687 - val_recall: 0.9751 - val_auc: 0.9517\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 293s 624ms/step - loss: 0.2746 - accuracy: 0.8682 - recall: 0.9473 - auc: 0.9404 - val_loss: 0.2358 - val_accuracy: 0.9007 - val_recall: 0.8816 - val_auc: 0.9725\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 294s 626ms/step - loss: 0.2312 - accuracy: 0.9023 - recall: 0.9510 - auc: 0.9584 - val_loss: 0.2294 - val_accuracy: 0.9178 - val_recall: 0.9854 - val_auc: 0.9698\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 295s 628ms/step - loss: 0.1982 - accuracy: 0.9194 - recall: 0.9601 - auc: 0.9687 - val_loss: 0.9228 - val_accuracy: 0.3255 - val_recall: 0.0760 - val_auc: 0.8969\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 307s 654ms/step - loss: 0.1948 - accuracy: 0.9258 - recall: 0.9550 - auc: 0.9707 - val_loss: 0.1653 - val_accuracy: 0.9360 - val_recall: 0.9722 - val_auc: 0.9777\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 301s 642ms/step - loss: 0.1773 - accuracy: 0.9327 - recall: 0.9649 - auc: 0.9751 - val_loss: 0.2476 - val_accuracy: 0.9061 - val_recall: 0.8816 - val_auc: 0.9799\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 292s 623ms/step - loss: 0.1707 - accuracy: 0.9357 - recall: 0.9642 - auc: 0.9773 - val_loss: 0.2614 - val_accuracy: 0.9050 - val_recall: 0.9751 - val_auc: 0.9631\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 303s 646ms/step - loss: 0.1838 - accuracy: 0.9327 - recall: 0.9620 - auc: 0.9728 - val_loss: 0.1542 - val_accuracy: 0.9477 - val_recall: 0.9576 - val_auc: 0.9811\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 293s 624ms/step - loss: 0.1569 - accuracy: 0.9362 - recall: 0.9663 - auc: 0.9796 - val_loss: 0.1454 - val_accuracy: 0.9488 - val_recall: 0.9532 - val_auc: 0.9832\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 296s 631ms/step - loss: 0.1509 - accuracy: 0.9474 - recall: 0.9653 - auc: 0.9816 - val_loss: 0.1387 - val_accuracy: 0.9520 - val_recall: 0.9693 - val_auc: 0.9864\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 296s 631ms/step - loss: 0.1455 - accuracy: 0.9488 - recall: 0.9696 - auc: 0.9831 - val_loss: 0.1635 - val_accuracy: 0.9509 - val_recall: 0.9854 - val_auc: 0.9802\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 302s 644ms/step - loss: 0.1369 - accuracy: 0.9512 - recall: 0.9678 - auc: 0.9838 - val_loss: 0.1213 - val_accuracy: 0.9520 - val_recall: 0.9678 - val_auc: 0.9889\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 298s 636ms/step - loss: 0.1229 - accuracy: 0.9560 - recall: 0.9718 - auc: 0.9871 - val_loss: 0.1424 - val_accuracy: 0.9498 - val_recall: 0.9532 - val_auc: 0.9877\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 293s 625ms/step - loss: 0.1389 - accuracy: 0.9560 - recall: 0.9733 - auc: 0.9834 - val_loss: 0.1295 - val_accuracy: 0.9434 - val_recall: 0.9766 - val_auc: 0.9878\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 301s 641ms/step - loss: 0.1270 - accuracy: 0.9552 - recall: 0.9711 - auc: 0.9865 - val_loss: 0.1200 - val_accuracy: 0.9488 - val_recall: 0.9532 - val_auc: 0.9890\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 339s 723ms/step - loss: 0.1159 - accuracy: 0.9578 - recall: 0.9770 - auc: 0.9881 - val_loss: 0.1400 - val_accuracy: 0.9498 - val_recall: 0.9605 - val_auc: 0.9861\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 317s 675ms/step - loss: 0.1068 - accuracy: 0.9634 - recall: 0.9781 - auc: 0.9901 - val_loss: 0.1571 - val_accuracy: 0.9552 - val_recall: 0.9766 - val_auc: 0.9838\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 307s 655ms/step - loss: 0.1040 - accuracy: 0.9634 - recall: 0.9802 - auc: 0.9903 - val_loss: 0.6795 - val_accuracy: 0.9552 - val_recall: 0.9751 - val_auc: 0.9826\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 302s 643ms/step - loss: 0.1080 - accuracy: 0.9624 - recall: 0.9788 - auc: 0.9882 - val_loss: 0.1626 - val_accuracy: 0.9445 - val_recall: 0.9678 - val_auc: 0.9840\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 309s 660ms/step - loss: 0.0926 - accuracy: 0.9669 - recall: 0.9788 - auc: 0.9924 - val_loss: 0.1434 - val_accuracy: 0.9552 - val_recall: 0.9825 - val_auc: 0.9902\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.437222  0.807046  0.901244  0.863054  0.269777      0.868730   \n",
      "1   0.274594  0.868161  0.947330  0.940369  0.235765      0.900747   \n",
      "2   0.231156  0.902322  0.950988  0.958375  0.229443      0.917823   \n",
      "3   0.198202  0.919402  0.960132  0.968727  0.922769      0.325507   \n",
      "4   0.194753  0.925807  0.955011  0.970669  0.165296      0.935966   \n",
      "5   0.177332  0.932746  0.964887  0.975085  0.247561      0.906083   \n",
      "6   0.170720  0.935682  0.964155  0.977333  0.261392      0.905016   \n",
      "7   0.183830  0.932746  0.961960  0.972807  0.154174      0.947705   \n",
      "8   0.156940  0.936216  0.966350  0.979619  0.145375      0.948773   \n",
      "9   0.150923  0.947425  0.965252  0.981568  0.138739      0.951974   \n",
      "10  0.145510  0.948759  0.969642  0.983104  0.163518      0.950907   \n",
      "11  0.136888  0.951161  0.967813  0.983783  0.121310      0.951974   \n",
      "12  0.122887  0.955965  0.971836  0.987133  0.142426      0.949840   \n",
      "13  0.138889  0.955965  0.973299  0.983356  0.129499      0.943437   \n",
      "14  0.126981  0.955164  0.971105  0.986483  0.120036      0.948773   \n",
      "15  0.115932  0.957833  0.976957  0.988094  0.139954      0.949840   \n",
      "16  0.106761  0.963437  0.978054  0.990051  0.157126      0.955176   \n",
      "17  0.103996  0.963437  0.980249  0.990347  0.679546      0.955176   \n",
      "18  0.107994  0.962370  0.978786  0.988180  0.162603      0.944504   \n",
      "19  0.092616  0.966907  0.978786  0.992412  0.143368      0.955176   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.975146  0.951731  \n",
      "1     0.881579  0.972479  \n",
      "2     0.985380  0.969804  \n",
      "3     0.076023  0.896875  \n",
      "4     0.972222  0.977726  \n",
      "5     0.881579  0.979870  \n",
      "6     0.975146  0.963135  \n",
      "7     0.957602  0.981107  \n",
      "8     0.953216  0.983207  \n",
      "9     0.969298  0.986351  \n",
      "10    0.985380  0.980162  \n",
      "11    0.967836  0.988850  \n",
      "12    0.953216  0.987671  \n",
      "13    0.976608  0.987848  \n",
      "14    0.953216  0.988957  \n",
      "15    0.960526  0.986091  \n",
      "16    0.976608  0.983779  \n",
      "17    0.975146  0.982650  \n",
      "18    0.967836  0.984011  \n",
      "19    0.982456  0.990197  \n",
      "147/147 [==============================] - 40s 270ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 16\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 301s 1s/step - loss: 0.4157 - accuracy: 0.8255 - recall: 0.9162 - auc: 0.8802 - val_loss: 0.3369 - val_accuracy: 0.7930 - val_recall: 0.9985 - val_auc: 0.9654\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.2682 - accuracy: 0.9005 - recall: 0.9444 - auc: 0.9463 - val_loss: 0.2497 - val_accuracy: 0.8975 - val_recall: 0.9795 - val_auc: 0.9622\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 294s 1s/step - loss: 0.2325 - accuracy: 0.9122 - recall: 0.9407 - auc: 0.9587 - val_loss: 0.9288 - val_accuracy: 0.7471 - val_recall: 1.0000 - val_auc: 0.8698\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.2045 - accuracy: 0.9210 - recall: 0.9528 - auc: 0.9673 - val_loss: 0.2126 - val_accuracy: 0.9306 - val_recall: 0.9664 - val_auc: 0.9744\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.1912 - accuracy: 0.9298 - recall: 0.9557 - auc: 0.9718 - val_loss: 0.1408 - val_accuracy: 0.9381 - val_recall: 0.9722 - val_auc: 0.9842\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 298s 1s/step - loss: 0.1759 - accuracy: 0.9351 - recall: 0.9583 - auc: 0.9743 - val_loss: 0.2247 - val_accuracy: 0.9296 - val_recall: 0.9868 - val_auc: 0.9655\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.1512 - accuracy: 0.9482 - recall: 0.9685 - auc: 0.9800 - val_loss: 0.1537 - val_accuracy: 0.9392 - val_recall: 0.9518 - val_auc: 0.9841\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 302s 1s/step - loss: 0.1396 - accuracy: 0.9493 - recall: 0.9682 - auc: 0.9835 - val_loss: 0.1295 - val_accuracy: 0.9562 - val_recall: 0.9737 - val_auc: 0.9867\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 298s 1s/step - loss: 0.1460 - accuracy: 0.9541 - recall: 0.9693 - auc: 0.9821 - val_loss: 0.3454 - val_accuracy: 0.7887 - val_recall: 0.9956 - val_auc: 0.9607\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.1763 - accuracy: 0.9392 - recall: 0.9634 - auc: 0.9738 - val_loss: 0.1989 - val_accuracy: 0.9285 - val_recall: 0.9839 - val_auc: 0.9735\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 299s 1s/step - loss: 0.1388 - accuracy: 0.9541 - recall: 0.9704 - auc: 0.9828 - val_loss: 0.4612 - val_accuracy: 0.7951 - val_recall: 0.9985 - val_auc: 0.9673\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.1269 - accuracy: 0.9549 - recall: 0.9740 - auc: 0.9868 - val_loss: 0.1935 - val_accuracy: 0.9264 - val_recall: 0.9898 - val_auc: 0.9769\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.1132 - accuracy: 0.9581 - recall: 0.9788 - auc: 0.9879 - val_loss: 0.2659 - val_accuracy: 0.8911 - val_recall: 0.8860 - val_auc: 0.9543\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 294s 1s/step - loss: 0.1069 - accuracy: 0.9664 - recall: 0.9824 - auc: 0.9889 - val_loss: 0.1771 - val_accuracy: 0.9413 - val_recall: 0.9795 - val_auc: 0.9787\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.1007 - accuracy: 0.9645 - recall: 0.9821 - auc: 0.9910 - val_loss: 0.1116 - val_accuracy: 0.9584 - val_recall: 0.9708 - val_auc: 0.9906\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.0967 - accuracy: 0.9624 - recall: 0.9766 - auc: 0.9921 - val_loss: 0.1934 - val_accuracy: 0.9306 - val_recall: 0.9825 - val_auc: 0.9780\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 291s 1s/step - loss: 0.1092 - accuracy: 0.9610 - recall: 0.9766 - auc: 0.9879 - val_loss: 0.1917 - val_accuracy: 0.9370 - val_recall: 0.9883 - val_auc: 0.9798\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.0903 - accuracy: 0.9674 - recall: 0.9854 - auc: 0.9927 - val_loss: 0.6179 - val_accuracy: 0.7481 - val_recall: 0.9985 - val_auc: 0.9555\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 289s 1s/step - loss: 0.0871 - accuracy: 0.9672 - recall: 0.9821 - auc: 0.9934 - val_loss: 0.1278 - val_accuracy: 0.9424 - val_recall: 0.9722 - val_auc: 0.9879\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 293s 1s/step - loss: 0.0841 - accuracy: 0.9693 - recall: 0.9788 - auc: 0.9931 - val_loss: 0.1855 - val_accuracy: 0.9445 - val_recall: 0.9883 - val_auc: 0.9784\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.415655  0.825460  0.916240  0.880194  0.336933      0.792956   \n",
      "1   0.268208  0.900454  0.944404  0.946251  0.249699      0.897545   \n",
      "2   0.232528  0.912196  0.940746  0.958700  0.928781      0.747065   \n",
      "3   0.204472  0.921003  0.952816  0.967264  0.212637      0.930630   \n",
      "4   0.191196  0.929811  0.955742  0.971783  0.140824      0.938100   \n",
      "5   0.175936  0.935148  0.958303  0.974345  0.224684      0.929562   \n",
      "6   0.151191  0.948225  0.968544  0.979979  0.153670      0.939168   \n",
      "7   0.139650  0.949293  0.968179  0.983461  0.129474      0.956243   \n",
      "8   0.146016  0.954097  0.969276  0.982108  0.345359      0.788687   \n",
      "9   0.176251  0.939151  0.963424  0.973832  0.198883      0.928495   \n",
      "10  0.138802  0.954097  0.970373  0.982764  0.461161      0.795091   \n",
      "11  0.126880  0.954897  0.974031  0.986815  0.193522      0.926361   \n",
      "12  0.113186  0.958100  0.978786  0.987919  0.265876      0.891142   \n",
      "13  0.106920  0.966373  0.982443  0.988893  0.177099      0.941302   \n",
      "14  0.100747  0.964505  0.982078  0.991042  0.111578      0.958378   \n",
      "15  0.096739  0.962370  0.976591  0.992086  0.193398      0.930630   \n",
      "16  0.109247  0.961035  0.976591  0.987901  0.191697      0.937033   \n",
      "17  0.090299  0.967441  0.985369  0.992676  0.617851      0.748132   \n",
      "18  0.087087  0.967174  0.982078  0.993400  0.127786      0.942369   \n",
      "19  0.084051  0.969309  0.978786  0.993134  0.185528      0.944504   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.998538  0.965401  \n",
      "1     0.979532  0.962219  \n",
      "2     1.000000  0.869753  \n",
      "3     0.966374  0.974433  \n",
      "4     0.972222  0.984201  \n",
      "5     0.986842  0.965525  \n",
      "6     0.951754  0.984097  \n",
      "7     0.973684  0.986726  \n",
      "8     0.995614  0.960662  \n",
      "9     0.983918  0.973459  \n",
      "10    0.998538  0.967261  \n",
      "11    0.989766  0.976862  \n",
      "12    0.885965  0.954257  \n",
      "13    0.979532  0.978686  \n",
      "14    0.970760  0.990642  \n",
      "15    0.982456  0.977983  \n",
      "16    0.988304  0.979833  \n",
      "17    0.998538  0.955461  \n",
      "18    0.972222  0.987865  \n",
      "19    0.988304  0.978371  \n",
      "74/74 [==============================] - 36s 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 20\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 300s 2s/step - loss: 0.4246 - accuracy: 0.8297 - recall: 0.8969 - auc: 0.8792 - val_loss: 0.3892 - val_accuracy: 0.8026 - val_recall: 0.7383 - val_auc: 0.9566\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 285s 2s/step - loss: 0.2647 - accuracy: 0.8959 - recall: 0.9316 - auc: 0.9462 - val_loss: 0.2022 - val_accuracy: 0.9146 - val_recall: 0.9020 - val_auc: 0.9741\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 286s 2s/step - loss: 0.2250 - accuracy: 0.9143 - recall: 0.9407 - auc: 0.9602 - val_loss: 0.3741 - val_accuracy: 0.8794 - val_recall: 0.9912 - val_auc: 0.9561\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 291s 2s/step - loss: 0.1819 - accuracy: 0.9274 - recall: 0.9503 - auc: 0.9739 - val_loss: 0.4905 - val_accuracy: 0.8485 - val_recall: 0.9956 - val_auc: 0.9536\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.1784 - accuracy: 0.9381 - recall: 0.9609 - auc: 0.9734 - val_loss: 1.0745 - val_accuracy: 0.7353 - val_recall: 1.0000 - val_auc: 0.8572\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 294s 2s/step - loss: 0.1563 - accuracy: 0.9421 - recall: 0.9645 - auc: 0.9791 - val_loss: 0.1661 - val_accuracy: 0.9317 - val_recall: 0.9327 - val_auc: 0.9774\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.1502 - accuracy: 0.9424 - recall: 0.9653 - auc: 0.9820 - val_loss: 0.3912 - val_accuracy: 0.8474 - val_recall: 0.9985 - val_auc: 0.9579\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 292s 2s/step - loss: 0.1401 - accuracy: 0.9528 - recall: 0.9718 - auc: 0.9830 - val_loss: 0.1446 - val_accuracy: 0.9424 - val_recall: 0.9825 - val_auc: 0.9859\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 280s 1s/step - loss: 0.1287 - accuracy: 0.9528 - recall: 0.9737 - auc: 0.9848 - val_loss: 0.1587 - val_accuracy: 0.9445 - val_recall: 0.9561 - val_auc: 0.9833\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 284s 2s/step - loss: 0.1205 - accuracy: 0.9568 - recall: 0.9799 - auc: 0.9864 - val_loss: 0.2406 - val_accuracy: 0.9392 - val_recall: 0.9825 - val_auc: 0.9657\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 284s 2s/step - loss: 0.1406 - accuracy: 0.9490 - recall: 0.9744 - auc: 0.9829 - val_loss: 0.1626 - val_accuracy: 0.9445 - val_recall: 0.9620 - val_auc: 0.9799\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 284s 2s/step - loss: 0.1215 - accuracy: 0.9568 - recall: 0.9759 - auc: 0.9870 - val_loss: 0.3439 - val_accuracy: 0.8356 - val_recall: 0.8670 - val_auc: 0.9151\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 289s 2s/step - loss: 0.1164 - accuracy: 0.9584 - recall: 0.9773 - auc: 0.9872 - val_loss: 0.1450 - val_accuracy: 0.9488 - val_recall: 0.9561 - val_auc: 0.9848\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 290s 2s/step - loss: 0.1182 - accuracy: 0.9586 - recall: 0.9781 - auc: 0.9870 - val_loss: 0.1275 - val_accuracy: 0.9594 - val_recall: 0.9883 - val_auc: 0.9881\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 292s 2s/step - loss: 0.1113 - accuracy: 0.9584 - recall: 0.9777 - auc: 0.9890 - val_loss: 0.4998 - val_accuracy: 0.8175 - val_recall: 0.9985 - val_auc: 0.9508\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 281s 1s/step - loss: 0.1014 - accuracy: 0.9610 - recall: 0.9795 - auc: 0.9905 - val_loss: 0.1411 - val_accuracy: 0.9530 - val_recall: 0.9781 - val_auc: 0.9817\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.0918 - accuracy: 0.9645 - recall: 0.9810 - auc: 0.9926 - val_loss: 0.1545 - val_accuracy: 0.9552 - val_recall: 0.9737 - val_auc: 0.9863\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 284s 2s/step - loss: 0.0956 - accuracy: 0.9664 - recall: 0.9839 - auc: 0.9916 - val_loss: 0.1692 - val_accuracy: 0.9328 - val_recall: 0.9898 - val_auc: 0.9832\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 291s 2s/step - loss: 0.0892 - accuracy: 0.9704 - recall: 0.9865 - auc: 0.9927 - val_loss: 0.1750 - val_accuracy: 0.9456 - val_recall: 0.9620 - val_auc: 0.9783\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 288s 2s/step - loss: 0.1028 - accuracy: 0.9642 - recall: 0.9817 - auc: 0.9903 - val_loss: 0.1120 - val_accuracy: 0.9562 - val_recall: 0.9708 - val_auc: 0.9904\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.424573  0.829730  0.896854  0.879229  0.389239      0.802561   \n",
      "1   0.264733  0.895917  0.931602  0.946243  0.202205      0.914621   \n",
      "2   0.225013  0.914331  0.940746  0.960178  0.374070      0.879402   \n",
      "3   0.181875  0.927409  0.950256  0.973903  0.490538      0.848453   \n",
      "4   0.178416  0.938084  0.960863  0.973432  1.074545      0.735326   \n",
      "5   0.156333  0.942087  0.964521  0.979119  0.166083      0.931697   \n",
      "6   0.150228  0.942354  0.965252  0.982004  0.391164      0.847385   \n",
      "7   0.140078  0.952762  0.971836  0.982998  0.144602      0.942369   \n",
      "8   0.128712  0.952762  0.973665  0.984840  0.158653      0.944504   \n",
      "9   0.120543  0.956765  0.979883  0.986413  0.240636      0.939168   \n",
      "10  0.140586  0.949026  0.974396  0.982917  0.162551      0.944504   \n",
      "11  0.121459  0.956765  0.975860  0.986986  0.343907      0.835646   \n",
      "12  0.116439  0.958367  0.977323  0.987181  0.145042      0.948773   \n",
      "13  0.118187  0.958634  0.978054  0.986950  0.127525      0.959445   \n",
      "14  0.111299  0.958367  0.977688  0.989023  0.499767      0.817503   \n",
      "15  0.101410  0.961035  0.979517  0.990530  0.141109      0.953042   \n",
      "16  0.091829  0.964505  0.980980  0.992615  0.154509      0.955176   \n",
      "17  0.095581  0.966373  0.983906  0.991606  0.169226      0.932764   \n",
      "18  0.089154  0.970376  0.986467  0.992704  0.175018      0.945571   \n",
      "19  0.102766  0.964238  0.981712  0.990312  0.111982      0.956243   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.738304  0.956588  \n",
      "1     0.902047  0.974077  \n",
      "2     0.991228  0.956088  \n",
      "3     0.995614  0.953644  \n",
      "4     1.000000  0.857242  \n",
      "5     0.932749  0.977371  \n",
      "6     0.998538  0.957871  \n",
      "7     0.982456  0.985865  \n",
      "8     0.956140  0.983265  \n",
      "9     0.982456  0.965652  \n",
      "10    0.961988  0.979882  \n",
      "11    0.866959  0.915144  \n",
      "12    0.956140  0.984796  \n",
      "13    0.988304  0.988053  \n",
      "14    0.998538  0.950752  \n",
      "15    0.978070  0.981696  \n",
      "16    0.973684  0.986285  \n",
      "17    0.989766  0.983153  \n",
      "18    0.961988  0.978272  \n",
      "19    0.970760  0.990416  \n",
      "59/59 [==============================] - 36s 608ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 32\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 293s 2s/step - loss: 0.3565 - accuracy: 0.8495 - recall: 0.9100 - auc: 0.9067 - val_loss: 1.0958 - val_accuracy: 0.7311 - val_recall: 1.0000 - val_auc: 0.8706\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.2642 - accuracy: 0.9013 - recall: 0.9389 - auc: 0.9480 - val_loss: 1.3674 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.7497\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 285s 2s/step - loss: 0.2251 - accuracy: 0.9133 - recall: 0.9437 - auc: 0.9592 - val_loss: 1.0759 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8721\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 287s 2s/step - loss: 0.1809 - accuracy: 0.9285 - recall: 0.9612 - auc: 0.9723 - val_loss: 0.2961 - val_accuracy: 0.9018 - val_recall: 0.8977 - val_auc: 0.9599\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.1643 - accuracy: 0.9394 - recall: 0.9590 - auc: 0.9769 - val_loss: 0.2250 - val_accuracy: 0.9178 - val_recall: 0.9298 - val_auc: 0.9600\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.1381 - accuracy: 0.9472 - recall: 0.9660 - auc: 0.9829 - val_loss: 0.1925 - val_accuracy: 0.9200 - val_recall: 0.9825 - val_auc: 0.9790\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.1351 - accuracy: 0.9509 - recall: 0.9733 - auc: 0.9839 - val_loss: 0.2569 - val_accuracy: 0.8826 - val_recall: 0.9854 - val_auc: 0.9614\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.1319 - accuracy: 0.9549 - recall: 0.9759 - auc: 0.9836 - val_loss: 0.1450 - val_accuracy: 0.9402 - val_recall: 0.9854 - val_auc: 0.9872\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 293s 2s/step - loss: 0.1240 - accuracy: 0.9554 - recall: 0.9777 - auc: 0.9856 - val_loss: 0.1490 - val_accuracy: 0.9573 - val_recall: 0.9708 - val_auc: 0.9833\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 287s 2s/step - loss: 0.1157 - accuracy: 0.9562 - recall: 0.9737 - auc: 0.9883 - val_loss: 0.1867 - val_accuracy: 0.9413 - val_recall: 0.9386 - val_auc: 0.9864\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 293s 2s/step - loss: 0.1076 - accuracy: 0.9624 - recall: 0.9799 - auc: 0.9894 - val_loss: 0.5905 - val_accuracy: 0.8004 - val_recall: 0.9985 - val_auc: 0.9357\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 295s 2s/step - loss: 0.1105 - accuracy: 0.9570 - recall: 0.9751 - auc: 0.9877 - val_loss: 0.2344 - val_accuracy: 0.9072 - val_recall: 0.9532 - val_auc: 0.9568\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.1150 - accuracy: 0.9573 - recall: 0.9806 - auc: 0.9895 - val_loss: 0.2347 - val_accuracy: 0.9146 - val_recall: 0.9064 - val_auc: 0.9791\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.1100 - accuracy: 0.9565 - recall: 0.9755 - auc: 0.9891 - val_loss: 0.2529 - val_accuracy: 0.9285 - val_recall: 0.9123 - val_auc: 0.9827\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.1141 - accuracy: 0.9546 - recall: 0.9762 - auc: 0.9880 - val_loss: 0.1339 - val_accuracy: 0.9552 - val_recall: 0.9854 - val_auc: 0.9873\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 282s 2s/step - loss: 0.0963 - accuracy: 0.9629 - recall: 0.9821 - auc: 0.9916 - val_loss: 0.1400 - val_accuracy: 0.9530 - val_recall: 0.9883 - val_auc: 0.9838\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.0885 - accuracy: 0.9685 - recall: 0.9850 - auc: 0.9927 - val_loss: 0.2254 - val_accuracy: 0.9093 - val_recall: 0.9942 - val_auc: 0.9810\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 291s 2s/step - loss: 0.0838 - accuracy: 0.9666 - recall: 0.9850 - auc: 0.9941 - val_loss: 0.1685 - val_accuracy: 0.9466 - val_recall: 0.9459 - val_auc: 0.9865\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 283s 2s/step - loss: 0.0793 - accuracy: 0.9674 - recall: 0.9832 - auc: 0.9935 - val_loss: 0.1677 - val_accuracy: 0.9498 - val_recall: 0.9620 - val_auc: 0.9861\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 284s 2s/step - loss: 0.1516 - accuracy: 0.9445 - recall: 0.9770 - auc: 0.9792 - val_loss: 0.2062 - val_accuracy: 0.9349 - val_recall: 0.9883 - val_auc: 0.9742\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.356482  0.849480  0.910022  0.906695  1.095786      0.731057   \n",
      "1   0.264189  0.901254  0.938917  0.948039  1.367388      0.729989   \n",
      "2   0.225097  0.913264  0.943672  0.959173  1.075883      0.729989   \n",
      "3   0.180908  0.928476  0.961229  0.972275  0.296137      0.901814   \n",
      "4   0.164336  0.939418  0.959034  0.976869  0.225032      0.917823   \n",
      "5   0.138135  0.947158  0.965984  0.982894  0.192521      0.919957   \n",
      "6   0.135142  0.950894  0.973299  0.983872  0.256941      0.882604   \n",
      "7   0.131877  0.954897  0.975860  0.983647  0.145021      0.940235   \n",
      "8   0.123970  0.955431  0.977688  0.985569  0.149040      0.957311   \n",
      "9   0.115650  0.956232  0.973665  0.988280  0.186652      0.941302   \n",
      "10  0.107643  0.962370  0.979883  0.989365  0.590471      0.800427   \n",
      "11  0.110520  0.957032  0.975128  0.987703  0.234391      0.907151   \n",
      "12  0.114959  0.957299  0.980614  0.989515  0.234702      0.914621   \n",
      "13  0.109965  0.956499  0.975494  0.989139  0.252902      0.928495   \n",
      "14  0.114071  0.954630  0.976225  0.988041  0.133853      0.955176   \n",
      "15  0.096322  0.962904  0.982078  0.991647  0.140000      0.953042   \n",
      "16  0.088548  0.968508  0.985004  0.992723  0.225439      0.909285   \n",
      "17  0.083837  0.966640  0.985004  0.994136  0.168461      0.946638   \n",
      "18  0.079255  0.967441  0.983175  0.993459  0.167686      0.949840   \n",
      "19  0.151567  0.944489  0.976957  0.979189  0.206228      0.934899   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.870574  \n",
      "1     1.000000  0.749671  \n",
      "2     1.000000  0.872088  \n",
      "3     0.897661  0.959928  \n",
      "4     0.929825  0.959992  \n",
      "5     0.982456  0.979012  \n",
      "6     0.985380  0.961396  \n",
      "7     0.985380  0.987223  \n",
      "8     0.970760  0.983303  \n",
      "9     0.938596  0.986423  \n",
      "10    0.998538  0.935701  \n",
      "11    0.953216  0.956779  \n",
      "12    0.906433  0.979084  \n",
      "13    0.912281  0.982676  \n",
      "14    0.985380  0.987252  \n",
      "15    0.988304  0.983837  \n",
      "16    0.994152  0.980959  \n",
      "17    0.945906  0.986507  \n",
      "18    0.961988  0.986123  \n",
      "19    0.988304  0.974184  \n",
      "37/37 [==============================] - 35s 936ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Simple3 y batch_size 64\n",
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.3607 - accuracy: 0.8527 - recall: 0.8990 - auc: 0.9057 - val_loss: 0.8642 - val_accuracy: 0.5752 - val_recall: 0.5249 - val_auc: 0.6466\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 277s 5s/step - loss: 0.2669 - accuracy: 0.8986 - recall: 0.9265 - auc: 0.9453 - val_loss: 1.9879 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5849\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.2188 - accuracy: 0.9162 - recall: 0.9407 - auc: 0.9626 - val_loss: 1.8842 - val_accuracy: 0.7321 - val_recall: 0.9985 - val_auc: 0.6516\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 276s 5s/step - loss: 0.1840 - accuracy: 0.9335 - recall: 0.9525 - auc: 0.9724 - val_loss: 0.2800 - val_accuracy: 0.9093 - val_recall: 0.9152 - val_auc: 0.9646\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1753 - accuracy: 0.9362 - recall: 0.9565 - auc: 0.9754 - val_loss: 0.2377 - val_accuracy: 0.9050 - val_recall: 0.9108 - val_auc: 0.9611\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1515 - accuracy: 0.9480 - recall: 0.9674 - auc: 0.9799 - val_loss: 0.4629 - val_accuracy: 0.8207 - val_recall: 0.9971 - val_auc: 0.9597\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1404 - accuracy: 0.9536 - recall: 0.9711 - auc: 0.9821 - val_loss: 0.5331 - val_accuracy: 0.8047 - val_recall: 0.9985 - val_auc: 0.9553\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1262 - accuracy: 0.9557 - recall: 0.9729 - auc: 0.9861 - val_loss: 0.4812 - val_accuracy: 0.8346 - val_recall: 0.9956 - val_auc: 0.9538\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 276s 5s/step - loss: 0.1154 - accuracy: 0.9586 - recall: 0.9762 - auc: 0.9877 - val_loss: 0.2251 - val_accuracy: 0.9061 - val_recall: 0.9912 - val_auc: 0.9798\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.1084 - accuracy: 0.9637 - recall: 0.9792 - auc: 0.9884 - val_loss: 0.3860 - val_accuracy: 0.8132 - val_recall: 1.0000 - val_auc: 0.9777\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.0982 - accuracy: 0.9645 - recall: 0.9799 - auc: 0.9905 - val_loss: 0.3122 - val_accuracy: 0.9338 - val_recall: 0.9825 - val_auc: 0.9490\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.0980 - accuracy: 0.9632 - recall: 0.9802 - auc: 0.9915 - val_loss: 0.2869 - val_accuracy: 0.8837 - val_recall: 0.9971 - val_auc: 0.9752\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 276s 5s/step - loss: 0.1034 - accuracy: 0.9626 - recall: 0.9777 - auc: 0.9902 - val_loss: 0.8150 - val_accuracy: 0.7428 - val_recall: 1.0000 - val_auc: 0.9374\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.1028 - accuracy: 0.9632 - recall: 0.9799 - auc: 0.9898 - val_loss: 10.6470 - val_accuracy: 0.2721 - val_recall: 0.0029 - val_auc: 0.5154\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1453 - accuracy: 0.9461 - recall: 0.9674 - auc: 0.9812 - val_loss: 0.3744 - val_accuracy: 0.8655 - val_recall: 0.9927 - val_auc: 0.9617\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1072 - accuracy: 0.9624 - recall: 0.9751 - auc: 0.9895 - val_loss: 0.1534 - val_accuracy: 0.9424 - val_recall: 0.9357 - val_auc: 0.9887\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1088 - accuracy: 0.9640 - recall: 0.9784 - auc: 0.9887 - val_loss: 0.4219 - val_accuracy: 0.8698 - val_recall: 1.0000 - val_auc: 0.9614\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.0925 - accuracy: 0.9642 - recall: 0.9762 - auc: 0.9918 - val_loss: 1.1694 - val_accuracy: 0.7471 - val_recall: 1.0000 - val_auc: 0.8404\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.0781 - accuracy: 0.9733 - recall: 0.9865 - auc: 0.9940 - val_loss: 0.1143 - val_accuracy: 0.9648 - val_recall: 0.9810 - val_auc: 0.9896\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0673 - accuracy: 0.9752 - recall: 0.9879 - auc: 0.9952 - val_loss: 0.1164 - val_accuracy: 0.9584 - val_recall: 0.9664 - val_auc: 0.9902\n",
      "        loss  accuracy    recall       auc   val_loss  val_accuracy  \\\n",
      "0   0.360742  0.852682  0.899049  0.905739   0.864161      0.575240   \n",
      "1   0.266934  0.898586  0.926481  0.945284   1.987896      0.729989   \n",
      "2   0.218844  0.916200  0.940746  0.962553   1.884234      0.732124   \n",
      "3   0.184046  0.933547  0.952451  0.972445   0.279981      0.909285   \n",
      "4   0.175315  0.936216  0.956474  0.975436   0.237726      0.905016   \n",
      "5   0.151486  0.947958  0.967447  0.979937   0.462933      0.820704   \n",
      "6   0.140435  0.953563  0.971105  0.982114   0.533142      0.804696   \n",
      "7   0.126243  0.955698  0.972933  0.986070   0.481174      0.834578   \n",
      "8   0.115411  0.958634  0.976225  0.987729   0.225146      0.906083   \n",
      "9   0.108401  0.963704  0.979151  0.988438   0.385973      0.813234   \n",
      "10  0.098167  0.964505  0.979883  0.990531   0.312210      0.933831   \n",
      "11  0.097977  0.963171  0.980249  0.991542   0.286874      0.883671   \n",
      "12  0.103375  0.962637  0.977688  0.990170   0.815002      0.742796   \n",
      "13  0.102753  0.963171  0.979883  0.989814  10.646970      0.272145   \n",
      "14  0.145290  0.946090  0.967447  0.981232   0.374372      0.865528   \n",
      "15  0.107229  0.962370  0.975128  0.989473   0.153402      0.942369   \n",
      "16  0.108835  0.963971  0.978420  0.988680   0.421878      0.869797   \n",
      "17  0.092471  0.964238  0.976225  0.991838   1.169401      0.747065   \n",
      "18  0.078083  0.973312  0.986467  0.994025   0.114286      0.964781   \n",
      "19  0.067330  0.975180  0.987930  0.995208   0.116395      0.958378   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.524854  0.646621  \n",
      "1     1.000000  0.584876  \n",
      "2     0.998538  0.651602  \n",
      "3     0.915205  0.964618  \n",
      "4     0.910819  0.961139  \n",
      "5     0.997076  0.959680  \n",
      "6     0.998538  0.955305  \n",
      "7     0.995614  0.953803  \n",
      "8     0.991228  0.979792  \n",
      "9     1.000000  0.977709  \n",
      "10    0.982456  0.949001  \n",
      "11    0.997076  0.975155  \n",
      "12    1.000000  0.937438  \n",
      "13    0.002924  0.515351  \n",
      "14    0.992690  0.961685  \n",
      "15    0.935673  0.988717  \n",
      "16    1.000000  0.961364  \n",
      "17    1.000000  0.840438  \n",
      "18    0.980994  0.989613  \n",
      "19    0.966374  0.990240  \n",
      "19/19 [==============================] - 34s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\1255297898.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_arqu_batch=compara_arqu_batch.append({\"Red\": modelo, \"BatchSize\": batch_size, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#alexNet\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "batch_sizes=[8, 16, 20, 32, 64]  # distintos tamaños de batch size para probar\n",
    "modelos=[\"Simple1\", \"Simple2\", \"Simple3\"]  # Lista de nombres de modelos\n",
    "nombre_carpeta_hist= 'Historicos'\n",
    "nombre_carpeta_resultados= 'Resultados'\n",
    "nombre_carpeta_modelos= 'Modelos'\n",
    "tabla_arqu_batch_alexnet = arq_batch_AlexNet(ruta,epochs,batch_sizes,modelos, \n",
    "                                             target_size, nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7400968-2326-40c3-b7fa-b9d81426bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple1</th>\n",
       "      <th>8</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple2</th>\n",
       "      <th>8</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Simple3</th>\n",
       "      <th>8</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Loss  Accuracy  Precision  Recall    F1  Specificity   fpr  \\\n",
       "Red     BatchSize                                                               \n",
       "Simple1 8          0.21      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        16         0.22      0.94       0.98    0.94  0.96         0.94  0.06   \n",
       "        20         0.24      0.95       0.95    0.97  0.96         0.87  0.13   \n",
       "        32         0.21      0.94       0.97    0.95  0.96         0.93  0.07   \n",
       "        64         0.24      0.93       0.91    1.00  0.95         0.75  0.25   \n",
       "Simple2 8          0.17      0.94       0.97    0.96  0.96         0.91  0.09   \n",
       "        16         0.13      0.95       0.96    0.97  0.97         0.89  0.11   \n",
       "        20         0.20      0.93       0.96    0.95  0.95         0.90  0.10   \n",
       "        32         0.14      0.94       0.95    0.97  0.96         0.86  0.14   \n",
       "        64         0.19      0.94       0.97    0.95  0.96         0.92  0.08   \n",
       "Simple3 8          0.14      0.94       0.94    0.98  0.96         0.84  0.16   \n",
       "        16         0.19      0.94       0.93    0.99  0.96         0.80  0.20   \n",
       "        20         0.14      0.95       0.96    0.97  0.96         0.89  0.11   \n",
       "        32         0.22      0.93       0.92    0.99  0.95         0.76  0.24   \n",
       "        64         0.14      0.95       0.97    0.96  0.96         0.92  0.08   \n",
       "\n",
       "                    fnr   AUC  \n",
       "Red     BatchSize              \n",
       "Simple1 8          0.04  0.98  \n",
       "        16         0.06  0.98  \n",
       "        20         0.03  0.98  \n",
       "        32         0.05  0.98  \n",
       "        64         0.00  0.99  \n",
       "Simple2 8          0.04  0.98  \n",
       "        16         0.03  0.99  \n",
       "        20         0.05  0.98  \n",
       "        32         0.03  0.98  \n",
       "        64         0.05  0.98  \n",
       "Simple3 8          0.02  0.99  \n",
       "        16         0.01  0.99  \n",
       "        20         0.03  0.98  \n",
       "        32         0.01  0.97  \n",
       "        64         0.04  0.99  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_arqu_batch_alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a2a96-1b98-4f6e-849f-97a4ecb623f0",
   "metadata": {},
   "source": [
    "A partir de ahora, con los resultados obtenidos, se puede determinar que se va a trabajar con la CNN basada en alexNet, el modelo Simple3 y un batch size de 64. Todas las explicaciones se encuentran correctamente documentadas tanto en la memoria como en los anexos del TFG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c14476-66a8-40c7-9a36-ee0c3dbc3902",
   "metadata": {},
   "source": [
    "## Comparación de distintos valores de número de neuronas para la arquitectura \"Simple3\" CNN AlexaNet y un batchsize de 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73731a-d655-471e-9c50-b140eb09768f",
   "metadata": {},
   "source": [
    "A partir de los resultados obtenidos previamente, se comparan distintos valores de número de neuronas en las capas ocultas para determinar con cuál funciona mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b48cb3f-7e05-4106-8555-daf0dde2a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple3 AlexNet batch size=64\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def neuronas(num_neuronas, epochs, ruta, batch_size, target_size, nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos):\n",
    "\n",
    "    '''\n",
    "    Función que devuelve una tabla comparativa con las diferentes métricas para distintos valores de neuronas introducidos como parámetros \n",
    "    a partir del modelo y el batch size seleccionado previamente (modelo Simple3 AlexNet batch size=64).\n",
    "    También guarda en distintas carpetas los historicos con las métricas obtenidas tras cada entrenaminto para\n",
    "    cada modelo, los distintos modelos obtenidos según el número de neuronas y el dataframe final en formato csv.\n",
    "    ------------------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - num_neuronas: lista con los distintos valores de neuronas en las capas ocultas para probar en cada entrenamiento\n",
    "    - epochs: int. Número de épocas a entrenar \n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - batch_size: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje. Se emplea dentro de la función \n",
    "    \"preparar_modelo\" para determinar el tamaño del lote para cada uno de los generadores (train, val y test). En este caso será 64\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. En este caso deberá\n",
    "    ser (340,340) ya que se emplea la CNN de alexNet\n",
    "    - nombre_carpeta_hist: str. Nombre de la carpeta creada para guardar los csv de los historicos\n",
    "    - nombre_carpeta_resultados: str. Nombre de la carpeta creada para guardar el dataframe final en formato csv.\n",
    "    - nombre_carpeta_modelos: str. Nombre de la carpeta creada para guardar los distintos modelos\n",
    "    ----------------------------------------------------------------\n",
    "    Return:\n",
    "    - compara_neuronas_def: dataframe que contiene como índice las columnas referidas al número de neuronas. El dataframe \n",
    "    obtenido se observa como una tabla comparativa de diversas métricas para cada número de neuronas.\n",
    "    '''\n",
    "    \n",
    "    #se inicializa un dataframe vacío donde, posteriormente se van a añadir todos los componentes necesarios para comparar y determinar cual es el mejor\n",
    "    #valor de neuronas en la capa oculta\n",
    "    compara_neuronas=pd.DataFrame()\n",
    "    \n",
    "    input_shape=(340,340,3)\n",
    "\n",
    "    #se emplea la función preparar_modelo para configurar los generadores de datos para entrenar, validar y probar \n",
    "    #un modelo de aprendizaje automático con imágenes\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    \n",
    "    #bucle en el que se recorren cada uno los valores de neuronas para las capas ocultas\n",
    "    for neurona in num_neuronas:\n",
    "        print(f\"Modelo con {neurona} neuronas en su capa oculta...\")\n",
    "        #se emplea el modelo Simple3 y la CNN de alexNet que es con el que se han obtenido mejores resultados\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'),\n",
    "                layers.BatchNormalization(),\n",
    "                \n",
    "                layers.Flatten(), #convierte imágenes en vectores\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(neurona, activation=\"relu\"), \n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(1, activation=\"sigmoid\"), #produce una probabilidad entre 0 y 1 para la clasificación binaria\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        #se compila el modelo y se calculan las métricas con las que se quiere trabajar\n",
    "        #en este caso, en la función de pérdida \"loss\", se emplea la entropía cruzada binaria \"binary_crossentropy\" ya que se trata de \n",
    "        #un problema de clasificación binaria\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",\"Recall\",\"AUC\"]) \n",
    "    \n",
    "        #ENTRENAMIENTO\n",
    "        # con callbacks se detiene el entrenamiento si la pérdida en el conjunto de validación no mejora después de 10 épocas (patience)\n",
    "        history=model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=EarlyStopping(monitor='val_auc', patience=10,restore_best_weights=True))\n",
    "        historico = pd.DataFrame(history.history)\n",
    "        print(historico) \n",
    "        \n",
    "\n",
    "        #SE GUARDAN LOS DISTINTOS HISTÓRICOS EN UNA CARPETA\n",
    "        #se guarda el historico en un csv para guardar los valores de entrenamiento y validación (accuracy, recall, val_auc, val_los...)\n",
    "        ruta_historicos = os.path.join('.', nombre_carpeta_hist) #se crea la ruta a la nueva carpeta de Historicos en el directorio actual\n",
    "        os.makedirs(ruta_historicos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "        #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "        subcarpeta_historicos = os.path.join(ruta_historicos,'historico_neuronas') \n",
    "        os.makedirs(subcarpeta_historicos, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "        nombre_historico = f'historico_{neurona}.csv' #se define el nombre que van a tener cada uno de los csv donde esta el historico correspondiente\n",
    "        ruta_historico = os.path.join(subcarpeta_historicos, nombre_historico) #se define la ruta donde se econtrará cada modelo\n",
    "        historico.to_csv(ruta_historico, index=False, encoding='utf-8') #se crea el csv de cada historico\n",
    "\n",
    "        #SE GUARDAN LOS DISTINTOS MODELOS EN UNA CARPETA\n",
    "        ruta_modelos = os.path.join('.', nombre_carpeta_modelos) #se crea la ruta a la nueva carpeta de Modelos en el directorio actual\n",
    "        os.makedirs(ruta_modelos, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "        #se crea la ruta a la subcarpeta dentro de la nueva carpeta de modelos\n",
    "        subcarpeta_modelo = os.path.join(ruta_modelos, 'modelo_neuronas')\n",
    "        os.makedirs(subcarpeta_modelo, exist_ok=True) # se crea la nueva subcarpeta si esta no existe\n",
    "        nombre_modelo = f'modelo_{neurona}.h5' #se define el nombre de cada uno de los archivos que contienen los modelos\n",
    "        ruta_modelo = os.path.join(subcarpeta_modelo, nombre_modelo) #se define la ruta donde se econtrará cada modelo\n",
    "        model.save(ruta_modelo) #se guarda el modelo\n",
    "\n",
    "        \n",
    "        \n",
    "        #se calculan las métricas\n",
    "        y_test=test_generator.labels\n",
    "        y_pred=model.predict(test_generator)\n",
    "        calculo_metricas=metricas(y_test, y_pred) #se llama a la función creada previamente para calcular las métricas de cada modelo\n",
    "        #se calcula loss a partir de la evaluación del modelo\n",
    "        loss=model.evaluate(test_generator, verbose=0)[0]\n",
    "        \n",
    "        #se añaden todos los componentes necesarios para comparar los distintos modelos de arquitectura para distintos batch size \n",
    "        #(comparando las métricas)\n",
    "        compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n",
    "    \n",
    "    #se fija la columna \"Número de neuronas\" como índice. \n",
    "    compara_neuronas.set_index(\"Número de neuronas\", inplace=True) #inplace=True se pone para modificar el dataframe original ya que sino, no se modifica\n",
    "    compara_neuronas_def = compara_neuronas.round(2) #se redondean los decimales a 2\n",
    "\n",
    "    #SE GUARDA EL DATAFRAME FINAL EN UNA CARPETA EN FORMATO CSV\n",
    "    ruta_resultados = os.path.join('.', nombre_carpeta_resultados) #se crea la ruta a la nueva carpeta de Resultados en el directorio actual\n",
    "    os.makedirs(ruta_resultados, exist_ok=True) # se crea la nueva carpeta si esta no existe\n",
    "    ruta_resultado_final = os.path.join(ruta_resultados, 'compara_neuronas.csv') #se define la ruta donde se econtrará el dataframe\n",
    "    compara_neuronas_def.to_csv(ruta_resultado_final, index=False, encoding='utf-8') #se crea el csv del dataframe\n",
    "   \n",
    "    return compara_neuronas_def\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae0dd62-ee02-48af-af94-827756ce2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "Modelo con 512 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 252s 4s/step - loss: 0.4585 - accuracy: 0.8417 - recall: 0.8969 - auc: 0.8873 - val_loss: 0.9328 - val_accuracy: 0.7279 - val_recall: 0.9942 - val_auc: 0.8180\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 269s 5s/step - loss: 0.2342 - accuracy: 0.9111 - recall: 0.9356 - auc: 0.9569 - val_loss: 0.3750 - val_accuracy: 0.8164 - val_recall: 0.9357 - val_auc: 0.8971\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1953 - accuracy: 0.9271 - recall: 0.9539 - auc: 0.9685 - val_loss: 0.3121 - val_accuracy: 0.8773 - val_recall: 0.8509 - val_auc: 0.9668\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.1591 - accuracy: 0.9402 - recall: 0.9634 - auc: 0.9795 - val_loss: 0.4840 - val_accuracy: 0.8207 - val_recall: 0.9971 - val_auc: 0.9581\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1496 - accuracy: 0.9469 - recall: 0.9660 - auc: 0.9803 - val_loss: 1.8419 - val_accuracy: 0.7449 - val_recall: 1.0000 - val_auc: 0.7048\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1298 - accuracy: 0.9514 - recall: 0.9718 - auc: 0.9847 - val_loss: 0.2123 - val_accuracy: 0.9178 - val_recall: 0.9898 - val_auc: 0.9771\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 267s 5s/step - loss: 0.1185 - accuracy: 0.9578 - recall: 0.9755 - auc: 0.9861 - val_loss: 0.6595 - val_accuracy: 0.7631 - val_recall: 1.0000 - val_auc: 0.9486\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1233 - accuracy: 0.9565 - recall: 0.9766 - auc: 0.9856 - val_loss: 1.8781 - val_accuracy: 0.7321 - val_recall: 1.0000 - val_auc: 0.6532\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 266s 5s/step - loss: 0.1019 - accuracy: 0.9616 - recall: 0.9781 - auc: 0.9907 - val_loss: 0.2531 - val_accuracy: 0.9061 - val_recall: 0.9912 - val_auc: 0.9727\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 269s 5s/step - loss: 0.0876 - accuracy: 0.9666 - recall: 0.9813 - auc: 0.9924 - val_loss: 0.7091 - val_accuracy: 0.7321 - val_recall: 1.0000 - val_auc: 0.9687\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0837 - accuracy: 0.9674 - recall: 0.9821 - auc: 0.9937 - val_loss: 0.4513 - val_accuracy: 0.8687 - val_recall: 0.9956 - val_auc: 0.9414\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0765 - accuracy: 0.9701 - recall: 0.9846 - auc: 0.9944 - val_loss: 0.1008 - val_accuracy: 0.9626 - val_recall: 0.9825 - val_auc: 0.9920\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0713 - accuracy: 0.9773 - recall: 0.9883 - auc: 0.9937 - val_loss: 0.1543 - val_accuracy: 0.9402 - val_recall: 0.9942 - val_auc: 0.9895\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0658 - accuracy: 0.9746 - recall: 0.9872 - auc: 0.9959 - val_loss: 1.6199 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5652\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.0658 - accuracy: 0.9746 - recall: 0.9865 - auc: 0.9950 - val_loss: 0.2704 - val_accuracy: 0.9328 - val_recall: 0.9868 - val_auc: 0.9624\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0587 - accuracy: 0.9752 - recall: 0.9861 - auc: 0.9965 - val_loss: 0.2703 - val_accuracy: 0.9232 - val_recall: 0.9108 - val_auc: 0.9803\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0565 - accuracy: 0.9795 - recall: 0.9883 - auc: 0.9967 - val_loss: 0.3441 - val_accuracy: 0.9264 - val_recall: 0.9079 - val_auc: 0.9808\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0615 - accuracy: 0.9776 - recall: 0.9901 - auc: 0.9950 - val_loss: 0.3478 - val_accuracy: 0.9306 - val_recall: 0.9196 - val_auc: 0.9792\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0489 - accuracy: 0.9816 - recall: 0.9890 - auc: 0.9975 - val_loss: 0.1227 - val_accuracy: 0.9509 - val_recall: 0.9912 - val_auc: 0.9880\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0471 - accuracy: 0.9840 - recall: 0.9920 - auc: 0.9976 - val_loss: 0.2989 - val_accuracy: 0.9274 - val_recall: 0.9211 - val_auc: 0.9756\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.458471  0.841740  0.896854  0.887310  0.932843      0.727855   \n",
      "1   0.234174  0.911129  0.935625  0.956854  0.375050      0.816435   \n",
      "2   0.195335  0.927142  0.953914  0.968526  0.312139      0.877268   \n",
      "3   0.159111  0.940219  0.963424  0.979455  0.484015      0.820704   \n",
      "4   0.149611  0.946891  0.965984  0.980262  1.841916      0.744931   \n",
      "5   0.129788  0.951428  0.971836  0.984687  0.212289      0.917823   \n",
      "6   0.118501  0.957833  0.975494  0.986115  0.659508      0.763074   \n",
      "7   0.123301  0.956499  0.976591  0.985601  1.878065      0.732124   \n",
      "8   0.101883  0.961569  0.978054  0.990707  0.253088      0.906083   \n",
      "9   0.087637  0.966640  0.981346  0.992406  0.709140      0.732124   \n",
      "10  0.083710  0.967441  0.982078  0.993663  0.451315      0.868730   \n",
      "11  0.076502  0.970109  0.984638  0.994365  0.100836      0.962647   \n",
      "12  0.071325  0.977315  0.988296  0.993676  0.154282      0.940235   \n",
      "13  0.065806  0.974646  0.987198  0.995934  1.619911      0.729989   \n",
      "14  0.065805  0.974646  0.986467  0.995040  0.270443      0.932764   \n",
      "15  0.058693  0.975180  0.986101  0.996489  0.270288      0.923159   \n",
      "16  0.056478  0.979450  0.988296  0.996711  0.344138      0.926361   \n",
      "17  0.061466  0.977582  0.990124  0.995035  0.347834      0.930630   \n",
      "18  0.048872  0.981585  0.989027  0.997505  0.122672      0.950907   \n",
      "19  0.047061  0.983987  0.991953  0.997627  0.298950      0.927428   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.994152  0.817991  \n",
      "1     0.935673  0.897126  \n",
      "2     0.850877  0.966819  \n",
      "3     0.997076  0.958131  \n",
      "4     1.000000  0.704829  \n",
      "5     0.989766  0.977068  \n",
      "6     1.000000  0.948619  \n",
      "7     1.000000  0.653179  \n",
      "8     0.991228  0.972745  \n",
      "9     1.000000  0.968732  \n",
      "10    0.995614  0.941425  \n",
      "11    0.982456  0.992023  \n",
      "12    0.994152  0.989512  \n",
      "13    1.000000  0.565217  \n",
      "14    0.986842  0.962433  \n",
      "15    0.910819  0.980252  \n",
      "16    0.907895  0.980815  \n",
      "17    0.919591  0.979191  \n",
      "18    0.991228  0.988012  \n",
      "19    0.921053  0.975617  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\3823948845.py:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 1024 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.5957 - accuracy: 0.8212 - recall: 0.8789 - auc: 0.8600 - val_loss: 1.5228 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6172\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.2412 - accuracy: 0.9090 - recall: 0.9433 - auc: 0.9559 - val_loss: 0.3431 - val_accuracy: 0.8282 - val_recall: 0.9781 - val_auc: 0.9440\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 268s 5s/step - loss: 0.2108 - accuracy: 0.9202 - recall: 0.9488 - auc: 0.9654 - val_loss: 0.2842 - val_accuracy: 0.9018 - val_recall: 0.9561 - val_auc: 0.9324\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 266s 4s/step - loss: 0.1516 - accuracy: 0.9464 - recall: 0.9660 - auc: 0.9804 - val_loss: 0.2607 - val_accuracy: 0.9136 - val_recall: 0.9576 - val_auc: 0.9463\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 265s 4s/step - loss: 0.1453 - accuracy: 0.9437 - recall: 0.9663 - auc: 0.9823 - val_loss: 0.1835 - val_accuracy: 0.9274 - val_recall: 0.9386 - val_auc: 0.9754\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.1438 - accuracy: 0.9424 - recall: 0.9638 - auc: 0.9824 - val_loss: 0.2685 - val_accuracy: 0.9050 - val_recall: 0.8947 - val_auc: 0.9675\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.1199 - accuracy: 0.9557 - recall: 0.9733 - auc: 0.9865 - val_loss: 0.1275 - val_accuracy: 0.9530 - val_recall: 0.9839 - val_auc: 0.9880\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.1001 - accuracy: 0.9642 - recall: 0.9821 - auc: 0.9903 - val_loss: 0.2814 - val_accuracy: 0.9007 - val_recall: 0.8772 - val_auc: 0.9786\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 263s 4s/step - loss: 0.1015 - accuracy: 0.9642 - recall: 0.9806 - auc: 0.9903 - val_loss: 0.1902 - val_accuracy: 0.9232 - val_recall: 0.9956 - val_auc: 0.9876\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.1037 - accuracy: 0.9642 - recall: 0.9813 - auc: 0.9895 - val_loss: 0.1468 - val_accuracy: 0.9520 - val_recall: 0.9737 - val_auc: 0.9823\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 280s 5s/step - loss: 0.0960 - accuracy: 0.9629 - recall: 0.9806 - auc: 0.9918 - val_loss: 0.1881 - val_accuracy: 0.9338 - val_recall: 0.9927 - val_auc: 0.9790\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.0811 - accuracy: 0.9712 - recall: 0.9832 - auc: 0.9927 - val_loss: 0.1615 - val_accuracy: 0.9456 - val_recall: 0.9883 - val_auc: 0.9880\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.0707 - accuracy: 0.9733 - recall: 0.9861 - auc: 0.9952 - val_loss: 0.1610 - val_accuracy: 0.9434 - val_recall: 0.9795 - val_auc: 0.9789\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0658 - accuracy: 0.9736 - recall: 0.9865 - auc: 0.9954 - val_loss: 0.1951 - val_accuracy: 0.9232 - val_recall: 0.9825 - val_auc: 0.9769\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 271s 5s/step - loss: 0.0782 - accuracy: 0.9717 - recall: 0.9850 - auc: 0.9934 - val_loss: 0.1863 - val_accuracy: 0.9264 - val_recall: 0.9898 - val_auc: 0.9806\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 281s 5s/step - loss: 0.0585 - accuracy: 0.9792 - recall: 0.9898 - auc: 0.9965 - val_loss: 0.3611 - val_accuracy: 0.9200 - val_recall: 0.9693 - val_auc: 0.9496\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.0804 - accuracy: 0.9682 - recall: 0.9843 - auc: 0.9934 - val_loss: 1.0667 - val_accuracy: 0.7460 - val_recall: 1.0000 - val_auc: 0.8585\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.595687  0.821190  0.878932  0.860021  1.522787      0.729989   \n",
      "1   0.241248  0.908994  0.943307  0.955901  0.343064      0.828175   \n",
      "2   0.210752  0.920203  0.948793  0.965358  0.284181      0.901814   \n",
      "3   0.151633  0.946357  0.965984  0.980358  0.260748      0.913554   \n",
      "4   0.145253  0.943688  0.966350  0.982308  0.183480      0.927428   \n",
      "5   0.143789  0.942354  0.963789  0.982380  0.268490      0.905016   \n",
      "6   0.119857  0.955698  0.973299  0.986492  0.127498      0.953042   \n",
      "7   0.100110  0.964238  0.982078  0.990261  0.281403      0.900747   \n",
      "8   0.101547  0.964238  0.980614  0.990304  0.190190      0.923159   \n",
      "9   0.103659  0.964238  0.981346  0.989507  0.146837      0.951974   \n",
      "10  0.096001  0.962904  0.980614  0.991819  0.188139      0.933831   \n",
      "11  0.081131  0.971177  0.983175  0.992650  0.161490      0.945571   \n",
      "12  0.070675  0.973312  0.986101  0.995207  0.160967      0.943437   \n",
      "13  0.065810  0.973579  0.986467  0.995388  0.195116      0.923159   \n",
      "14  0.078151  0.971711  0.985004  0.993382  0.186252      0.926361   \n",
      "15  0.058519  0.979183  0.989759  0.996524  0.361149      0.919957   \n",
      "16  0.080372  0.968241  0.984272  0.993398  1.066705      0.745998   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     1.000000  0.617239  \n",
      "1     0.978070  0.944017  \n",
      "2     0.956140  0.932396  \n",
      "3     0.957602  0.946299  \n",
      "4     0.938596  0.975395  \n",
      "5     0.894737  0.967516  \n",
      "6     0.983918  0.988015  \n",
      "7     0.877193  0.978648  \n",
      "8     0.995614  0.987631  \n",
      "9     0.973684  0.982312  \n",
      "10    0.992690  0.978963  \n",
      "11    0.988304  0.987952  \n",
      "12    0.979532  0.978922  \n",
      "13    0.982456  0.976946  \n",
      "14    0.989766  0.980613  \n",
      "15    0.969298  0.949596  \n",
      "16    1.000000  0.858450  \n",
      "19/19 [==============================] - 35s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\3823948845.py:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 2048 neuronas en su capa oculta...\n",
      "Epoch 1/20\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.7061 - accuracy: 0.8425 - recall: 0.8899 - auc: 0.8733 - val_loss: 0.4008 - val_accuracy: 0.8453 - val_recall: 0.9766 - val_auc: 0.9308\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 282s 5s/step - loss: 0.2090 - accuracy: 0.9186 - recall: 0.9440 - auc: 0.9645 - val_loss: 0.7905 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.8924\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 285s 5s/step - loss: 0.1719 - accuracy: 0.9330 - recall: 0.9565 - auc: 0.9768 - val_loss: 2.1154 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5079\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1569 - accuracy: 0.9400 - recall: 0.9616 - auc: 0.9782 - val_loss: 0.6365 - val_accuracy: 0.7364 - val_recall: 1.0000 - val_auc: 0.9360\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 278s 5s/step - loss: 0.1551 - accuracy: 0.9416 - recall: 0.9667 - auc: 0.9784 - val_loss: 0.4970 - val_accuracy: 0.8164 - val_recall: 0.9971 - val_auc: 0.9478\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 279s 5s/step - loss: 0.1385 - accuracy: 0.9477 - recall: 0.9667 - auc: 0.9835 - val_loss: 1.1452 - val_accuracy: 0.7396 - val_recall: 1.0000 - val_auc: 0.8272\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1260 - accuracy: 0.9525 - recall: 0.9715 - auc: 0.9865 - val_loss: 1.6847 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.6272\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.1126 - accuracy: 0.9602 - recall: 0.9781 - auc: 0.9870 - val_loss: 0.3134 - val_accuracy: 0.8805 - val_recall: 0.9927 - val_auc: 0.9625\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 274s 5s/step - loss: 0.1093 - accuracy: 0.9597 - recall: 0.9806 - auc: 0.9882 - val_loss: 0.2607 - val_accuracy: 0.8911 - val_recall: 0.9547 - val_auc: 0.9467\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 273s 5s/step - loss: 0.1115 - accuracy: 0.9624 - recall: 0.9795 - auc: 0.9885 - val_loss: 0.5384 - val_accuracy: 0.7866 - val_recall: 0.7251 - val_auc: 0.9248\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.0965 - accuracy: 0.9634 - recall: 0.9777 - auc: 0.9904 - val_loss: 0.4686 - val_accuracy: 0.7972 - val_recall: 0.7705 - val_auc: 0.8954\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 270s 5s/step - loss: 0.0945 - accuracy: 0.9629 - recall: 0.9792 - auc: 0.9915 - val_loss: 0.3044 - val_accuracy: 0.8698 - val_recall: 0.9488 - val_auc: 0.9308\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 268s 5s/step - loss: 0.0933 - accuracy: 0.9666 - recall: 0.9832 - auc: 0.9912 - val_loss: 1.0050 - val_accuracy: 0.7396 - val_recall: 1.0000 - val_auc: 0.8821\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0962 - accuracy: 0.9629 - recall: 0.9770 - auc: 0.9919 - val_loss: 0.3689 - val_accuracy: 0.7673 - val_recall: 0.9985 - val_auc: 0.9576\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0860 - accuracy: 0.9672 - recall: 0.9835 - auc: 0.9933 - val_loss: 0.4822 - val_accuracy: 0.8570 - val_recall: 0.9898 - val_auc: 0.9447\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0730 - accuracy: 0.9746 - recall: 0.9865 - auc: 0.9939 - val_loss: 0.3136 - val_accuracy: 0.8751 - val_recall: 0.9781 - val_auc: 0.9476\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0732 - accuracy: 0.9709 - recall: 0.9850 - auc: 0.9948 - val_loss: 2.3127 - val_accuracy: 0.7300 - val_recall: 1.0000 - val_auc: 0.5356\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0749 - accuracy: 0.9746 - recall: 0.9887 - auc: 0.9938 - val_loss: 0.1858 - val_accuracy: 0.9178 - val_recall: 0.9825 - val_auc: 0.9797\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0799 - accuracy: 0.9688 - recall: 0.9802 - auc: 0.9941 - val_loss: 0.7977 - val_accuracy: 0.7737 - val_recall: 0.9985 - val_auc: 0.8906\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0646 - accuracy: 0.9765 - recall: 0.9876 - auc: 0.9948 - val_loss: 0.4317 - val_accuracy: 0.8698 - val_recall: 0.9532 - val_auc: 0.9111\n",
      "        loss  accuracy    recall       auc  val_loss  val_accuracy  \\\n",
      "0   0.706097  0.842541  0.889905  0.873340  0.400831      0.845251   \n",
      "1   0.208950  0.918602  0.944038  0.964474  0.790538      0.729989   \n",
      "2   0.171856  0.933013  0.956474  0.976820  2.115414      0.729989   \n",
      "3   0.156912  0.939952  0.961595  0.978249  0.636526      0.736393   \n",
      "4   0.155081  0.941553  0.966715  0.978380  0.496954      0.816435   \n",
      "5   0.138476  0.947692  0.966715  0.983474  1.145245      0.739594   \n",
      "6   0.126039  0.952495  0.971470  0.986456  1.684670      0.729989   \n",
      "7   0.112641  0.960235  0.978054  0.986996  0.313407      0.880470   \n",
      "8   0.109303  0.959701  0.980614  0.988155  0.260720      0.891142   \n",
      "9   0.111474  0.962370  0.979517  0.988529  0.538424      0.786553   \n",
      "10  0.096490  0.963437  0.977688  0.990418  0.468640      0.797225   \n",
      "11  0.094516  0.962904  0.979151  0.991467  0.304399      0.869797   \n",
      "12  0.093260  0.966640  0.983175  0.991181  1.005047      0.739594   \n",
      "13  0.096235  0.962904  0.976957  0.991904  0.368920      0.767343   \n",
      "14  0.086046  0.967174  0.983541  0.993342  0.482236      0.856990   \n",
      "15  0.073035  0.974646  0.986467  0.993871  0.313628      0.875133   \n",
      "16  0.073166  0.970910  0.985004  0.994845  2.312694      0.729989   \n",
      "17  0.074915  0.974646  0.988661  0.993821  0.185799      0.917823   \n",
      "18  0.079943  0.968775  0.980249  0.994083  0.797747      0.773746   \n",
      "19  0.064590  0.976515  0.987564  0.994771  0.431744      0.869797   \n",
      "\n",
      "    val_recall   val_auc  \n",
      "0     0.976608  0.930755  \n",
      "1     1.000000  0.892417  \n",
      "2     1.000000  0.507905  \n",
      "3     1.000000  0.936002  \n",
      "4     0.997076  0.947756  \n",
      "5     1.000000  0.827173  \n",
      "6     1.000000  0.627222  \n",
      "7     0.992690  0.962485  \n",
      "8     0.954678  0.946661  \n",
      "9     0.725146  0.924829  \n",
      "10    0.770468  0.895448  \n",
      "11    0.948830  0.930769  \n",
      "12    1.000000  0.882070  \n",
      "13    0.998538  0.957649  \n",
      "14    0.989766  0.944681  \n",
      "15    0.978070  0.947603  \n",
      "16    1.000000  0.535573  \n",
      "17    0.982456  0.979714  \n",
      "18    0.998538  0.890617  \n",
      "19    0.953216  0.911076  \n",
      "19/19 [==============================] - 32s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuria\\AppData\\Local\\Temp\\ipykernel_25060\\3823948845.py:115: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  compara_neuronas=compara_neuronas.append({\"Número de neuronas\": neurona, \"Loss\": loss, \"Accuracy\": calculo_metricas[0], \"Precision\": calculo_metricas[1], \"Recall\": calculo_metricas[2], \"F1\":calculo_metricas[3], \"Specificity\":calculo_metricas[4], \"fpr\":calculo_metricas[5], \"fnr\":calculo_metricas[6], \"AUC\": calculo_metricas[7]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "num_neuronas=[512, 1024, 2048] #lista con distintos valores de neuronas para probar\n",
    "epochs=20\n",
    "target_size=(340,340)\n",
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo'\n",
    "batch_size=64\n",
    "nombre_carpeta_hist= 'Historicos'\n",
    "nombre_carpeta_resultados= 'Resultados'\n",
    "nombre_carpeta_modelos= 'Modelos'\n",
    "table_neuronas_simple3_64 = neuronas(num_neuronas, epochs, ruta, batch_size, target_size, \n",
    "                                    nombre_carpeta_hist, nombre_carpeta_resultados, nombre_carpeta_modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fc46c5b-93f0-48ca-8bbc-365df29d7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Número de neuronas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512.0</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024.0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048.0</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Loss  Accuracy  Precision  Recall    F1  Specificity  \\\n",
       "Número de neuronas                                                         \n",
       "512.0               0.47      0.90       0.96    0.90  0.93         0.91   \n",
       "1024.0              0.15      0.94       0.95    0.98  0.96         0.85   \n",
       "2048.0              0.44      0.87       0.87    0.97  0.92         0.62   \n",
       "\n",
       "                     fpr   fnr   AUC  \n",
       "Número de neuronas                    \n",
       "512.0               0.09  0.10  0.97  \n",
       "1024.0              0.15  0.02  0.98  \n",
       "2048.0              0.38  0.03  0.93  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_neuronas_simple3_64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa1344-69d6-4800-8201-9fa62b2be003",
   "metadata": {},
   "source": [
    "Por lo tanto, se puede apreciar que, el mejor modelo se corresponde con el modelo realizado inicialmente con 100 y 16 neuronas en la última capa. Todas las explicaciones correspondientes se encuentran en la memoria y anexos del TFG.\n",
    "\n",
    "El modelo final elegido es: CNN alexNet, modelo Simple3, batch size = 64 y 100 y 16 neuronas en la última capa reespectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700f86e-79e7-4849-9ae5-ed2561c7baa5",
   "metadata": {},
   "source": [
    "## Visualización por medio de una gráfica de la evolución tanto en accuracy como en loss en el entrenamiento y la validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab157af6-1b68-47d2-a051-1bcfe7ddecd8",
   "metadata": {},
   "source": [
    "En cada una de las funciones realizadas previamente, donde se comparaban distintos modelos de CNN, distintas arquitecturas y distintos hiperparámetros, se han guardado los valores obtenidos del entrenamiento y validación (loss, accuracy, recall, auc, val_loss, val_accuracy, val_recall y val_auc) en diferentes csv dentro de la carpeta ''Historicos''. A partir de estos csv, se ha realizado una función para crear una gráfica con la columna loss y val_loss o auc y val_auc para visualizar el rendimiento del modelo a lo largo de tiempo tanto el de entrenamiento como el de validación. Con estas gráficas se puede observar si el modelo está aprendiendo correctamente o, por el contrario existe sobreajuste o subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cda88-63ee-4881-8a97-d15b3ada9661",
   "metadata": {},
   "source": [
    "#### Loss:\n",
    "- loss: mide el error del modelo en el conjunto de entrenameinto\n",
    "- val_loss: mide el error del modelo en el conjunto de validación\n",
    "\n",
    "Si ambas líneas descienden y se estabilizan, indica que el modelo está aprendiendo correctamente.\n",
    "Si la pérdida de validación empieza a aumentar mientras la pérdida de entrenamiento sigue disminuyendo, puede indicar sobreajuste.\n",
    "Si ambas líneas son altas y no descienden, puede indicar subajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e6803-9c06-4784-874e-2829b14996b0",
   "metadata": {},
   "source": [
    "#### AUC\n",
    "- auc: mide la capacidad del modelo para distinguir entre clases (un valor mayor indica un mejor modelo)\n",
    "- val_auc: mide la capacidad del modelo para distinguir entre clases en el conjunto de validación (un valor mayor indica un mejor modelo)\n",
    "\n",
    "Si ambas líneas ascienden y se estabilizan en valores altos, indica un buen rendimiento del modelo.\n",
    "Si el AUC de validación disminuye mientras el AUC de entrenamiento sigue aumentando, puede indicar sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c78584-3367-4376-aa81-6901cd088c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grafica(directorio_historico, metrica_entrenamiento, metrica_validacion):\n",
    "\n",
    "    '''\n",
    "    Función empleada para la obtención de una gráfica a partir de uno de los csv (dentro de la carpeta Históricos)\n",
    "    creados previamente para observar la evolución de dos métricas (loss o auc generalmente) durante el entrenamiento y la validación \n",
    "    del modelo, lo cual es útil para evaluar el rendimiento del modelo a lo largo de las épocas.\n",
    "    -----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - directorio_historico: directorio donde se encuentra el csv del que se desea obtener las gráficas.\n",
    "    - metrica_entrenamiento: metrica monitoreada durante el entrenamiento que se desea visualizar (loss o auc)\n",
    "    - metrica_validacion: metrica monitoreada durante la validación que se desea visualizar (val_loss o val_auc)\n",
    "    --------------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "    # Se cargan los datos desde el archivo CSV\n",
    "    df_mejor = pd.read_csv(directorio_historico) \n",
    "    \n",
    "    \n",
    "    # 'columna1' y 'columna2' son los nombres de las columnas que se van a graficar\n",
    "    columna1 = df_mejor[metrica_entrenamiento]\n",
    "    columna2 = df_mejor[metrica_validacion]\n",
    "    \n",
    "    # Se crea la gráfica para las dos columnas\n",
    "    plt.plot(columna1, label='Entrenamiento')\n",
    "    plt.plot(columna2, label='Validación')\n",
    "    \n",
    "    # Se añaden etiquetas al eje x, el eje y y el título de la gráfica\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metrica_entrenamiento) \n",
    "    plt.title('Gráfico evolución entrenamiento y validación')\n",
    "    \n",
    "    # Se añade la leyenda\n",
    "    plt.legend()\n",
    "    \n",
    "    # Se muestra la gráfica\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2a44a-ce51-47d6-9d9d-0c0b570102af",
   "metadata": {},
   "source": [
    "#### Gráfica con la métrica AUC para el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec538d6-0371-4d78-b4d5-f945f55bba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHGCAYAAACIDqqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACAcklEQVR4nO3dd3xTVf8H8E+SZnQPuqG0ZcieBWTKFAThEVEZD7IEBXEB+qioPOACJ+IC5JEhuBBRf4iIlCkCsgRBQTa0QEtpC90jTc7vj9ukTZuWjiQ3ST/v1yuv3tzccW5u2n5zzvecoxBCCBARERG5CaXcBSAiIiKyJQY3RERE5FYY3BAREZFbYXBDREREboXBDREREbkVBjdERETkVhjcEBERkVthcENERERuhcENERERuRUGN1Rr48ePR9OmTXH9+nW5i0IVuO+++9CmTRtkZGTIXRQiskKv16Nr164YMGAA9Hq93MVxeQxu6pBjx45h8uTJaNy4MTw9PeHp6YmmTZti6tSpOHToUI2O+cknn+CXX37BL7/8gpCQkHKvr127Fq1atYKnpycUCgWOHj2KefPmQaFQ1PZyXIZCocC8efPsdvyJEyciJiamwtcXLVqEAwcO4Oeff4a/v7/dymELJ06cwLx583Dx4kW5i+IwMTExmDhxol3PsXfvXsybNw83b96063nkdPHiRSgUCqxatcq8btWqVVAoFFX6PPXp0wd9+vSxW/ludfz//Oc/yMvLw3fffQe1Wm23ctQZguqEpUuXCg8PD9GqVSvx/vvvi61bt4pt27aJjz76SPTo0UMAEGfPnq3WMf/44w8RHBwsDh06ZPX1lJQUoVarxbBhw8TOnTvFvn37RE5OjkhMTBT79u2zxWW5BABi7ty5djv+2bNnxR9//GH1tX379ong4GBx/Phxu53fltatWycAiB07dshdFIf5448/qv27V11vv/22ACAuXLhg1/PI6cKFCwKAWLlypXldSkqK2Ldvn8jPz7/l/r179xa9e/e2W/n+/vtv8ffff1t9bf369aJhw4biypUrdjt/XeMha2RFDrFnzx5Mnz4dd999N7799ltoNBrza/369cNjjz2GdevWwdPTs9Lj5ObmwsvLy/y8Q4cOlTZFnT59Gnq9Hg8++CB69+5tXu/l5YUGDRrU4oqotMaNG1f4WteuXd26ubDsZ9IVdejQQe4iuK2QkBCrNcpyaNmyZYWvjRgxAiNGjHBgadwfm6XqgPnz50OlUuGTTz6xCGxKe+CBBxAZGWl+PnHiRPj4+OD48eMYOHAgfH190b9/fwBAfHw87rnnHjRo0AA6nQ5NmjTB1KlTkZqaarF/z549AQCjRo2CQqEwV8lW1Cz15Zdfolu3bvDx8YGPjw/at2+P5cuXW2yzYsUKtGvXDjqdDkFBQbj33ntx8uTJKr0PycnJmDp1Kho0aACNRoPY2Fi8/PLLKCoqAiC1eYeGhmLcuHHl9r158yY8PT0xa9Ys87qEhAQ8+OCDCA0NhVarRYsWLfDuu+/CaDRWWo6Krr+iKvRbvS/WmqXy8/Mxe/ZsxMbGQqPRoH79+njsscfKNUvExMRg6NCh2Lx5Mzp27AhPT080b94cK1asqPQaTAoLC/Haa6+hefPm0Gq1CAkJwaRJk8oFVFU5z6pVq/DAAw8AAPr27QuFQmHRzNCnTx+0bt0av/76K7p37w4vLy889NBDAIDMzEw888wzFtc7Y8YM5OTkWJRDoVDg8ccfx5o1a9CiRQt4eXmhXbt22Lhxo8V2Z8+exaRJk9C0aVN4eXmhfv36GDZsGI4fP26x3c6dO6FQKPDll1/iueeeQ0REBHx8fDBs2DBcu3YNWVlZeOSRRxAcHIzg4GBMmjQJ2dnZ5d6bss1StryeefPm4T//+Q8AIDY21vy+7ty5EwBgNBrx1ltvme9haGgoxo8fj8uXL1u95ya7d++GQqHAV199Ve611atXQ6FQ4ODBg1b3/fPPP6FQKMr9fgPAzz//DIVCgQ0bNgCo+r2wxtrvlBACb731FqKjo6HT6dCxY0f8/PPP5fbNz8/H008/jfbt28Pf3x9BQUHo1q0b/u///q/ctkajER9++CHat28PT09PBAQEoGvXruZrAKw3S6Wnp2P69OmoX78+NBoNGjVqhBdffBEFBQUW21X1c0ulyF11RPZVVFQkPD09Rbdu3aq134QJE4RarRYxMTFiwYIFYtu2beKXX34RQgjx0UcfiVdffVV8//33YufOneKzzz4Tbdu2Fc2aNROFhYVCCKmp5OOPPxYAxPz588W+ffvMVbJz584VZT96c+bMEQDEiBEjxLp168SWLVvEwoULxZw5c8zbzJ8/XwAQY8aMET/99JNYvXq1aNSokfD39xenT5+u9HqSkpJEVFSUiI6OFp988onYunWrePXVV4VWqxUTJ040bzdz5kzh6ekpMjIyLPZfvHixACCOHTsmhJCqu+vXry9CQkLE0qVLxebNm8Xjjz8uAIhHH33UYl+UaZaydv1CCLFy5cpyTQdVeV8mTJggoqOjzc+NRqMYNGiQ8PDwEHPmzBFbtmwR77zzjvD29hYdOnSwqKKPjo4WDRo0EC1bthSrV68Wv/zyi3jggQcEALFr165K31ODwSDuuusu4e3tLV5++WURHx8vPv30U1G/fn3RsmVLkZubW63zpKSkmO/xxx9/LPbt2yf27dsnUlJShBBSs0FQUJCIiooSH374odixY4fYtWuXyMnJEe3btxfBwcFi4cKFYuvWreL9998X/v7+ol+/fsJoNFrci5iYGNGlSxfxzTffiE2bNok+ffoIDw8Pce7cOfN2u3btEk8//bT49ttvxa5du8T3338vhg8fLjw9PcU///xj3m7Hjh0CgIiOjhYTJ04UmzdvFkuXLhU+Pj6ib9++4s477xTPPPOM2LJli3jzzTeFSqUSTzzxhMX7GB0dLSZMmGB+buvrSUxMFE888YQAIL777jvz+2r6jD/yyCMCgHj88cfN5Q8JCRFRUVHi+vXrlX4GOnToIHr06FFufefOnUXnzp1rtO/IkSNFaGio0Ov11boX1pqlrP1OmX7/Jk+eLH7++WexbNkyUb9+fREeHm7RLHXz5k0xceJEsWbNGrF9+3axefNm8cwzzwilUik+++wzizKPGzdOKBQKMWXKFPF///d/4ueffxavv/66eP/9983blG32ysvLE23bthXe3t7inXfeEVu2bBFz5swRHh4eYsiQIRbHr+rnlkowuHFzycnJAoAYPXp0udeKioqEXq83P0r/0ZwwYYIAIFasWFGl8yQkJAgA4v/+7//M60x/+NetW2exbdl/7ufPnxcqlUqMHTu2wuPfuHFDeHp6lvulT0hIEFqtVvz73/+utHxTp04VPj4+4tKlSxbr33nnHQHAHHgdO3ZMABDLli2z2K5Lly4iLi7O/Pz5558XAMT+/fsttnv00UeFQqEQp06dMq+raXBTlfdFiPLBzebNmwUA8dZbb1lst3bt2nLXFh0dLXQ6ncX7kpeXJ4KCgsTUqVMrPe9XX30lAIj169dbrD948KAAIBYvXlzt81SWc9O7d28BQGzbts1i/YIFC4RSqRQHDx60WP/tt98KAGLTpk3mdQBEWFiYyMzMNK9LTk4WSqVSLFiwoMJrLSoqEoWFhaJp06Zi5syZ5vWmz/iwYcMstp8xY4YAIJ588kmL9cOHDxdBQUEW68oGN/a4nopybk6ePCkAiOnTp1us379/vwAgXnjhhQrfEyFKPrNHjhwxrztw4IAAUC4AKOuDDz4QACx+V9LT04VWqxVPP/10hftVdC+qEtzcuHFD6HQ6ce+991occ8+ePQJApTk3pr+XkydPFh06dDCv//XXXwUA8eKLL1Z6vWWDm6VLlwoA4ptvvrHY7s033xQAxJYtW8zravq5rcvYLFWHxcXFQa1Wmx/vvvtuuW3uu+++cuvS09Mxa9YsNG/eHH5+ftDpdGjatCkAVLmJqLT4+HgYDAY89thjFW6zb98+5OXllau+j4qKQr9+/bBt27ZKz7Fx40b07dsXkZGRKCoqMj8GDx4MANi1axcAoE2bNoiLi8PKlSvN+548eRIHDhwwN4EAwPbt29GyZUt06dLF4jwTJ06EEALbt2+v0rVXpirvizWmc5d9rx544AF4e3uXe6/at2+Phg0bmp/rdDrcdtttuHTpUqXn2bhxIwICAjBs2DCL97R9+/YIDw83N3vU9jylBQYGol+/fuXK0bp1a7Rv396iHIMGDbJofjHp27cvfH19zc/DwsIQGhpqUY6ioiLMnz8fLVu2hEajgYeHBzQaDc6cOWP1Mz506FCL5y1atAAA3H333eXWp6enl2uasvf1VGTHjh0Ayn9WunTpghYtWtzy92rMmDEIDQ3Fxx9/bF734YcfIiQkBKNGjap037Fjx0Kr1Vr0bvrqq69QUFCASZMmmddV915UZt++fcjPz8fYsWMt1nfv3h3R0dHltl+3bh169OgBHx8feHh4QK1WY/ny5RbnNTVp1eT31NvbG/fff7/FetO9KPve1+Y+10UMbtxccHAwPD09rf4CfPnllzh48KBFu3BpXl5e8PPzs1gnhMDAgQPx1Vdf4T//+Q+2bduGI0eOmLuS5+XlVbuMpvyMypKM09LSAAARERHlXouMjDS/XpFr167hxx9/tAjm1Go1WrVqBQAW+UIPPfQQ9u3bh3/++QcAsHLlSmi1WowZM8aiPBWVpXR5a6Mq74s1aWlp8PDwKJdIqVAoEB4eXq5s9erVK3cMrVZ7y3t57do13Lx5ExqNptz7mpycbPGe1uY8pVl7z69du4Zjx46VK4Ovry+EEDUqx6xZszBnzhwMHz4cP/74I/bv34+DBw+iXbt2VssbFBRk8dyU21bR+vz8/Aqv0R7XU5Ha/l5ptVpMnToVX375JW7evInr16/jm2++wZQpU6DVaivdNygoCP/617+wevVqGAwGAFKOTJcuXcy/l0D170VVrjc8PLzca2XXfffddxg5ciTq16+Pzz//HPv27cPBgwfx0EMPWdy/69evQ6VSWT3mrcoSHh5eLv8uNDQUHh4eNvs9ravYW8rNqVQq9OvXD1u2bEFSUpLFHzFT9n5FY0BYS3r966+/cPjwYaxevdoi8fb06dM1LqPpn/Dly5cRFRVldRvTL3ZSUlK5165evYrg4OBKzxEcHIy2bdvi9ddft/p66WTqMWPGYNasWVi1ahVef/11rFmzBsOHD0dgYKBFeSoqi+l8FdHpdACAgoICi38AZf9pVeV9saZevXooKirC9evXLQIcIQSSk5PRuXPnKh+rMsHBwahXrx42b95s9fXS3zJtxdpn0hTAV5QEfavPhjWff/45xo8fj/nz51usT01NRUBAQLWPVx32uJ6KlP69KhtEV+X3CgAeffRRvPHGG1ixYgXy8/NRVFSEadOmVen8kyZNwrp16xAfH4+GDRvi4MGDWLJkicU2trwXputNTk4u91pycrJFYv7nn3+O2NhYrF271uJzVzbZNyQkBAaDAcnJyVaDxMrKsn//fgghLI6fkpKCoqIim97nuog1N3XA7NmzYTAYMG3atFqPfCmEACAFTaUtXbq0xsccOHAgVCpVuT9qpXXr1g2enp74/PPPLdZfvnwZ27dvN/fkqsjQoUPx119/oXHjxujUqVO5R+ngJjAwEMOHD8fq1auxceNGJCcnWzRJAUD//v1x4sQJ/PHHHxbrTb1E+vbtW2FZTH9Ajx07ZrH+xx9/tHhelffFGtN7Ufa9Wr9+PXJycm75XlXV0KFDkZaWBoPBYPU9bdasWbWPaQr2qvNtdOjQoTh37hzq1atntRyVDXBYEYVCUa7m4aeffsKVK1eqfazqssf1VPS+mpr4yn5WDh48iJMnT1bpsxIREYEHHngAixcvxtKlSzFs2DCL5sfKDBw4EPXr18fKlSuxcuVK6HQ6ixpSwLb3omvXrtDpdPjiiy8s1u/du7dc7bZCoYBGo7EIPJKTk8v1ljI1bdfk9zQ7Oxs//PCDxfrVq1ebX6eaY81NHdCjRw98/PHHeOKJJ9CxY0c88sgjaNWqFZRKJZKSkrB+/XoAKNcEZU2LFi3QqFEjzJ49G0II1KtXDxs2bMDWrVtrXL6YmBi88MILePXVV5GXl4cxY8bA398fJ06cQGpqKl5++WUEBARgzpw5eOGFFzB+/HiMGTMGaWlpePnll6HT6TB37txKz/HKK68gPj4e3bt3x5NPPolmzZohPz8fFy9exKZNm7B06VKLb64PPfQQ1q5di8cffxwNGjTAgAEDLI43c+ZMrF69GnfffTdeeeUVREdH46effsLixYvx6KOP4rbbbquwLEOGDEFQUBAmT56MV155BR4eHli1ahUSExOr/b5Yc+edd2LQoEF47rnnkJmZiR49euDYsWOYO3cuOnToYLWre02MHj0aX3zxBYYMGYKnnnoKXbp0gVqtxuXLl7Fjxw7cc889uPfee6t1zNatWwMAli1bBl9fX+h0OsTGxlqtkjeZMWMG1q9fjzvuuAMzZ85E27ZtYTQakZCQgC1btuDpp5/G7bffXq1yDB06FKtWrULz5s3Rtm1bHD58GG+//bZDxmeyx/W0adMGAPD+++9jwoQJUKvVaNasGZo1a4ZHHnkEH374IZRKJQYPHoyLFy9izpw5iIqKwsyZM6t0/KeeespcptL5areiUqkwfvx4LFy4EH5+fhgxYkS5UbRteS8CAwPxzDPP4LXXXsOUKVPwwAMPIDExEfPmzSvXrDR06FB89913mD59Ou6//34kJibi1VdfRUREBM6cOWPerlevXhg3bhxee+01XLt2DUOHDoVWq8WRI0fg5eWFJ554wmpZxo8fj48//hgTJkzAxYsX0aZNG/z222+YP38+hgwZUu5vDlWTfLnM5GhHjx4VkyZNErGxsUKr1QqdTieaNGkixo8fX64HyoQJE4S3t7fV45w4cULceeedwtfXVwQGBooHHnjA3FuqdK+gqvaWMlm9erXo3Lmz0Ol0wsfHR3To0MGi54MQQnz66aeibdu2QqPRCH9/f3HPPfdUOOpnWdevXxdPPvmkiI2NFWq1WgQFBYm4uDjx4osviuzsbIttDQaDiIqKqrQXxKVLl8S///1vUa9ePaFWq0WzZs3E22+/LQwGg8V2Zd8XIaQeJd27dxfe3t6ifv36Yu7cueLTTz+12qPlVu9L2d5SQkg9kZ577jkRHR0t1Gq1iIiIEI8++qi4ceOGxXbR0dHi7rvvLndtVR2tVa/Xi3feeUe0a9fOXL7mzZuLqVOnijNnztToPIsWLRKxsbFCpVJZ9H7p3bu3aNWqldVyZGdni5deekk0a9bM/Nlo06aNmDlzpkhOTjZvB0A89thj5fYv22Ppxo0bYvLkySI0NFR4eXmJnj17it27d5crb0WfcVMvnbI9nkyf/dJdrMue2x7XI4QQs2fPFpGRkUKpVFr0SDMYDOLNN98Ut912m1Cr1SI4OFg8+OCDIjExsdxxKxMTEyNatGhRrX2EEOL06dMCgAAg4uPjy71e1XtR1a7gRqNRLFiwQERFRQmNRiPatm0rfvzxR6ufxTfeeEPExMQIrVYrWrRoIf73v/9Z/ftlMBjEe++9J1q3bm2+X926dRM//vijeRtrx09LSxPTpk0TERERwsPDQ0RHR4vZs2eXG1G5OveZJAohitsZiIiIauDYsWNo164dPv74Y0yfPl3u4hCBwQ0REdXIuXPncOnSJbzwwgtISEjA2bNnXX46DHIPTCgmIqIaefXVV3HnnXciOzsb69atY2BDToM1N0RERORWWHNDREREboXBDREREbkVBjdERETkVurcIH5GoxFXr16Fr6+v1aHciYiIyPkIIZCVlYXIyEgolZXXzdS54Obq1avVmqeHiIiInEdiYuItR6iuc8GNaTK/xMTEKk03QERERPLLzMxEVFRUlSblrXPBjakpys/Pj8ENERGRi6lKSgkTiomIiMitMLghIiIit8LghoiIiNwKgxsiIiJyKwxuiIiIyK0wuCEiIiK3Imtw8+uvv2LYsGGIjIyEQqHADz/8cMt9du3ahbi4OOh0OjRq1AhLly61f0GJiIjIZcga3OTk5KBdu3b46KOPqrT9hQsXMGTIEPTq1QtHjhzBCy+8gCeffBLr16+3c0mJiIjIVcg6iN/gwYMxePDgKm+/dOlSNGzYEIsWLQIAtGjRAocOHcI777yD++67z06lJCIiIlfiUjk3+/btw8CBAy3WDRo0CIcOHYJer5epVERERORMXGr6heTkZISFhVmsCwsLQ1FREVJTUxEREVFun4KCAhQUFJifZ2Zm2r2cREREJB+XqrkBys8pIYSwut5kwYIF8Pf3Nz84IzgREZF7c6ngJjw8HMnJyRbrUlJS4OHhgXr16lndZ/bs2cjIyDA/EhMTHVFUIiKiOsNoFMgtLEJ6TiGu3sxDYnqurOVxqWapbt264ccff7RYt2XLFnTq1AlqtdrqPlqtFlqt1hHFIyIicjpGo0BWQREy8/TIyNMjM1+P7Pwi5BcZka83oEBvQL5eWs4vMqBAb0R+Ual1eiMKigzmZdN2puUCvRGFBqPFOSP9ddg7u79MVyxzcJOdnY2zZ8+an1+4cAFHjx5FUFAQGjZsiNmzZ+PKlStYvXo1AGDatGn46KOPMGvWLDz88MPYt28fli9fjq+++kquSyAiIrK7fL0Bmfn64gBFClQy84uDFVPQkldkDl7MP3P1yCooQnEGh0OoVQp4qORtGJI1uDl06BD69u1rfj5r1iwAwIQJE7Bq1SokJSUhISHB/HpsbCw2bdqEmTNn4uOPP0ZkZCQ++OADdgMnIpsyGgUKDUYUFEnfWE3fTAuKv8EWFpleMxYvGyyWS7+uAOCpUcFTrYKXRgWdWgVPTcmyl8YDnmrpdU+NyrytSmk9j5DcQ77egOtZBbieXSD9LH6kZpf8zMwvMgcvBUXGWx/0FrQeSvh7quHnqYaP1gM6tRI6tQo6D1XJsloFrVpZvK70emmd1vzTch+dR8myM3x2FUI4Mp6TX2ZmJvz9/ZGRkQE/Pz+5i0NENmKqes/Kl77Bmr7lZuZbW6dHVr70PKdAqpYvHayUrWKXg8ZDaQ6IzIGPlZ8eKgVUCgUUCgVUSumhUAAqhWlZUbyMkm0UxdsoK9imeDuthxLtogIQGeAp99tRbbmFRcgpMECjUkLtoYBapYRH8bXaS5HBiLScQqtBi+l5avFyVn5RtY+vUAB+OjX8PD2kIEWnLvnppYafzsMcvPiVft3TA346NXRqlXSgwlwg5SRg1AMGffHPIsBYVGpd8fNyy9a2NZTfT+sH3P2OTd/f6vz/dqmcGyJyHUajgN5oRJFBQG8wQm8QKDIaoS8qu96IIqOAvsgIvVGgqHidvtTrUiBSUhVvClSySq3LtlPVu0IhfePVqJTQqlXFP5XQeqig8VBCa/FQSdsWP9d4KCEEkKc3IK/QIP3UG5BbKOUv5BZK683LeoP5vIXFgVZGnvxjeEXX80LX2Hro1lh6hPnp5C5SORm5ehy4mI4DF9Jw6Px1tLr2A24YffCT8XYAJQGNRqWEh0oKdtQqJTQqBdQeSsvnxctqjzLPVUpoigMllVKBjFy9RRCTnltYrc+gxkOJEB8tQnylR3DpZW8N/L0sgxcfjQeUtqgVWTUEuHqk9sepjE+4zYOb6mBwQ1RHCSGQrzciu6AIuYVFyC6QvunmFBYhp6AIuQWGUq8ZzNvkltrGtH1BkRFFBilgKSwOVgxGeSqFtR5K+Hmq4avzKP6WK32jrWidj9bDamBiCmTUKvt+2y9NCIGCIqM50MkrLEJeobE4ICpCfqngKK/4UWQUMArpYTBCWjYKGIp/GgVKLZfaRkj3SNq+zDZCCk4z8vQ4kZSJS2m5uJSWi7WHpN6mjYK90bVxPXRtVA/dGtVDiK/jO21czyrAwYvp2H8+DfsvpOPUtSwIAfgjGx+oP0Jvj2MAgJ5FfTG3aCIKIXU6KTQYUWgAAEPFB68FpQKo56O1CFpCfEuelw5g/HQeDvtsmWUllwQ2QY0ApQegVAOq4p9KD0BV+qcaUKpKllUepfYp3q70tqbXtb6Ova4yGNwQuQkhBNJzCpGUkY8rN/Nw1fzIR1pOQbnAJaewCI6OP9SqkuYB0zfhkm/RCngolSXblPrGXBKUeMBXpzYvmwIV0+u+Oo+SqncXpFAozHkLziIrX49DF29g3/k0/H4+DX9dycD51BycT83Bl/ulnMgmoT7o1kiq1bk9Ngj1fGwf7Fy9mYcDF9Kx/4IUzJy/nlNumwFB1/Fm0ZuoV3gVQqUDDAUY47EDI6OzkTN8JQo9Q6XawCIpCNeXehQWCcvnhuLaxNLPDcaSdUYBf091uSAm0EvjFDknFUrcL/0Maw08ukfestgRgxsiF5GvNyApIx9Xb+aVC15M62qadOitUcFL6wEfrQe8NCp4l1qWfnrARytt4631gHfxNt4aD3hppYREUw8JiwDGQwl1ccCisnO+A9mHr06Nvs1D0bd5KAAgI0+PgxfSse98GvadS8PJ5EycTcnG2ZRsrPn9EgCgWZgvuhXX7HRtFIQAL021zimEwKW0XBy4kI7fL6ThwIV0XL6RZ7GNQiGd5/bYINzeqB565v8Kvy2zAX0uENAQitFfAlnXgPUPQXXlIPxW3wmM+hxo0Mk2b4yrSjwg/YzqIm857IwJxUROwGgUSM0pMAcqlgFMPpIy8pCaXVilY4X4ahEZ4In6ATpE+nsiMsATwb5a+GhV8NYUByelAhRPtco27fhUJ93MLcTv59Pxe3HNzj/JWRavKxRAi3A/qQmrcT10iQ2Cv6fluGRGo8DZ69nYf0FqZjpwIR0pWQUW26iUCrSO9EOX2CDcHlsPnWICpaDJUARsexnY+4G0YaO+wP0rAK8g6XnaOeDrfwPX/wFUGmDoe0CHB+32fji9TwcAlw8C9y4D2o2SuzTVUp3/3wxuiGzEaBTmHjgWY0/kWxl/wvyalBB7M1dfpR46XhoVIgM8ywUv0kOHcH8dtB7O06RBdU9adgH2X0jHvnNp2Hc+DWdTsi1eVyqAVpH+6Na4HkJ8tDh0KR0HLqTjRq5l4rRGpUS7KH9zMNMxOhA+2jKNDbnpwLeTgPM7pec9ngL6/VfK+yitIAv4bipw6ifpeZepwKDXpTyRukSfDyxoIPVsevIoEBQrd4mqhcFNJRjcUFXl6w24fEMaRvzyjVzcyLUMWMoOmlXb3jpKBRDmp7MIVuoHeJYKYHTw91Q7X9POlT+AnFRA51/q4QeovaSv7VSnXc8qwO/npUDn93NpOJ9aPlcGAHRqJeKiA9Elph5ubxSE9lEBleceJR0D1o4FbiZIn7V7PgZaj6h4e6MR+PUtYOcC6XlML+CBVYB3cM0vztUk/A6sGAR4hwLPnHa53092BSeqAiEErmcXIDE9FwnpuUhIy0NCeq75eXJmfo2O66lWWYxD4edp6s5ZfgwK03YBXhqE+mqhlnlUz2rR5wObnwMOr7L+utKjJNjR+pUJfso8rL2u8QGULvR+kFUhvloMaxeJYe0iAQDJGflSsHMuDem5hejYMBC3NwpC60h/aDyqeL+PrQM2PAEU5QGBMcDoL4GwVpXvo1QCfZ6XEmm/nwpc3A0s6wuM/gKIaFu7i3QVpmTiqC4uF9hUF4Mbcmt5hQYk3shFQlpxAFNcC2NaztdX3hTko/VAVJAXogI9Uc9HU2ZgLMuAxb+4106daBZKvwB8Mx5IPgZAIf3DKMwC8jOkhzBKA3nlpkmPGlFINUDeIUCvZ4D2Y2x5BSSTcH8dhneoj+Ed6ld/Z0MRsHUusO8j6Xnj/sB9n5bk11RFi6FAva1SHk76eWD5QOCej4A291e/PK7GnEx8u7zlcAAGN+SyTONwpOUU4HpWIa7ctKx5SUjPxfUySYllKRVAZIAnGgZ5oWGQlxTIFC83DPJCoJcTNgPJ7Z9NwA/TpCDGM0j659Kk1AR5QgCFOSWBTn4GUJBZ6vlNID+zktczAEMhAFHy/IdpUkJo/7muVZsjhBToKetAwGtvOalSfs2FX6XnPWcB/V6q2Xsb2gJ4eDuwfgpwdiuwfrIUqPef6773SgipWQpgcEPkaHqDEenFw5en5RQiNasAaTkFSM2WllOL16VmFyA9pxBFVRioxVfngeh6JcFLw1KPyABP12oKkpOhCNj+KrBnkfS8QWcpZ8G/geV2CgWg9ZEe/jX4dg5ITV6mwObY18Dud6Xzpp8D7v0E0HjX4kIcJPGA9M9TpQEmbAD8IuUukeu6ehRY+yCQkQiovYHhi4FWw2t3TM9A4N/fANtekT5be94Hkv8C7l8uveZu0s8DuanS5zGyvdylsTsGN+QQmfl6nE3JRlp2IVKzC4qDlkJcL7Wcml2Am7nVH2reT+eBYF8tIv09ywUvDYO84O9Vx3pE2ENWMvDtQ8Cl4kG/bn8UuPMVwKN645dUmVonPXzDgP7/BYJvk3IsTv4I3EwExnwN+EXY59y1JQRwYBnwywtS0xwAfH4fMOlnwDNA1qK5pD+/Bn58CijKl0bUHf2lVPNiC0oVcOfLQHgb4P8eB85tA/7Xz7bncBamJqnIDoCH40eUdjQGN2QXQgicTcnG9n9SsP2fFBy6dKPKw/GrlAoEeWtQz1tjHq68nrcGwb4lP0N8tKjno0E9b23VkxCpZi7slgKbnBQpyfeej4BW9zq2DO1GAwHRUp5E0lHpH9C/vwYi2jm2HLdSkA38+CTw13rpefOhwOVDQMoJqewPficFbXRrBj2wZQ6wf4n0vOlAYMT/7BMgtrkfCG4KfD1WquH4dIBUQ9hiqO3PJZfSycR1ALuCk83k6w3Ydy4N2/9JwY5TKeVGFA330yHMTwpWgouDk2AfLYKLJ4kzBS+BXhoOKucMjEZg7/tStb0wAqEtgZGrpX8Cckk/D3w5Ckg9LTVP3Pcp0HyIfOUp7fopYO04IPWU1FNs4GvA7dOAa38BK4dIeUUt/iU15blrXoetZF8H1k0ELv0mPb/jWaDPbPvnW+WkSue9uFt63vt5oPdzrpXnVZHF3YGUv6VRmlsMk7s0NcJxbirB4Ma2Lt/IxY7i2pm959Ishv/XeCjRtVE99GsWgr7NQxFdzwXyJEiSdwP4/lHg9M/S83ZjgLsXAhovecsFAHk3gXUTigduUwADXwW6PS5v19bj3wIbngT0OYBvhBTANOxa8vqFX6WmKUMh0PlhYMjbbt8Vt8au/CHl12RekWoK713q2H/GBj2w5SVg/1LpebO7pTLoXPj/RX4G8EY0AAE8fVpq7nVBDG4qweCmdvQGIw5fuoEdxbUzp69Zjj4a4a9D3+ah6NcsFN2b1IOXhi2fLufqUamb981LgEoLDHkL6DjBuf4ZG/TApv8Ah1dKzztOAO5+1/EjzhYVAvFzSv4Rxt4B3LcC8Akpv+1f30nNexBAvznAHc84tKgu4cgXwMaZgKEAqNdEyn0JaSZTWT4vLkshENwMGPMVUK+xPGWprbNbpeA6MAZ46k+5S1NjHMSPbCo1uwA7T13HjlMp+PX0dWTlF5lfUyqAuOhAKaBpHopmYb7sOu2qhJAG5Pv5OemfS0A0MPIzKQHR2ajU0hxBwU2BX14E/vgMuHFRKq+jerpkXJGaMC4XJ2r2ehro+2LFTU6tRwA514Gfn5V6nfmG1+05jkoz6KUE7APLpOe3DQZGfCIN5iiXDg8CIc2lWqTUU9KAf/evAJoOkK9MNWUe36Zr5du5EQY3VI7RKPDX1Qzs+Oc6tp9KwbHLNy2mFQj0UqNPM2mW4DuaBldtxt+/1ks9XbxDpV4uvhHSH3ff4mWtr3PVDNQ1hTnAxllSt2tA+udy7xLn7hKrUADdHpN60Hw7GbiwC/j0TmDsN9I6ezq3QxobJTcN0PpL/4ibDb71frdPBbKSgN/ek5qxvEOA2wbZt6zOLjsF+GYCkLBXet5ntpRj4wx5Lg06AY/slHKpLh8AvrgfGDAX6DHDtf5e1bFkYoDNUnIXx2nk6w3m3Jmdp6+XG/yuVaQf+jWXApp2DQKgqm7C79tNpG+tFVF7S8GOX2Rx0FMq8CkdCLGnie2lnpGaoVJOAAqlNJBZ9yed459LVSUflxKNM69IAwuO/gKI7m778xiNwG/vAttfByCA8LZSknV1JiAUAvjhUeDPrwAPT2DiRumfaF10+ZAUOGRdlabguPcT50kQL62oANj0DPDHaul5qxFSr0FXGG/JaADeaAgUZgPT9gDhreUuUY0x56YSDG4sFRQZ8M2hy/h4+1mLuZS8NSr0bBqMfs1D0adZKML8ahFU6POA18Ol5W6PS992s5KAzCRp/JSCjKofyzOwVLBTJhDyDJQSXtXexT+9pD8+Ko1rfctypL++k8aPKcyWatUeWAnE9JS7VDWTlQx8NRq4egRQqoF/fWjbKRvybkgzS5/5RXreYZyUGKz2rP6xDHqprGe3SsHY5C3y9kKTw4kNUu2XoVAax2j0l879HggBHFouNdsai4CwNlIeTkCU3CWrXPJxYGlPQOMLPH/JpXvqMeeGbklvMGL94cv4cPtZXLkpddkO99Ph7rYR6NssFJ1jA203R1LmVemn2kvqHls20CjMkf4xZSWV/MxMsnyelSQN4pV3Q3qknKj6+RUqKchRe1kPfsyv3WIbv0jAP8rxSav2UDYRNrqnNDKrb7i85aoN33Bg4iZpUsSTG6QpG9LOAH1fqn0t1NUjxUnWCYCHDhjyDtBxXM2Pp1IDD3wGfDYMuPoHsGaEFOA468CE9rD9NSmwcZXeSAoF0HkKENJC+ixcOy4FOmO+lLtklTM1STXo5NKBTXUxuKljigxGfH/kCj7YfgaJ6VJQE+qrxWN9m2B0lyj7TPqYlST99I2wXoOi8ZZ6IVTWE0EIaU6iyoKf/AygMFfqjluYCxiLRzsWBmmMkYLM2l+LQgn41ZeSbQOjy//0CXf+5pyMy8WJsAel5z1mSL13VG7w50DjJQUN218FflsoTduQdhYYvrRm3diFkJKVNz0rJVkHxkjNULYYPFDrA4xdByy/Uxq/54sHgEk/yZtE60jZydLPAXOdP7ApLaaHdN/+1xc4t12aKsSZm8sTTPk27j+fVGlu8NeMqsJgFPjxz6t4f9sZXEjNAQAE+2jwaJ8mGHt7Q+jUdozoTTU3tZlbR6GQmp08A6s+LLpBL9UK6XMtgx7zz1zrrxfmlN+mIEvK5yjKl+a3yUgsGWCsNJVWqqa2GvzESOWXs4ns7FZg/cNAXrqUCHvvUufMcagNpVL6hxncVEraPfF/JVM2VGd8j8Jc4KengT+Lv5k3GwIMX2LbEXK9g6VRi5cPlGoCvh4LPLje/YfHNxRJX0YAwKuevGWpicgO0heZ7GQpEbpxP7lLVLE6mEwMMLhxe0ajwKa/krBo6xmcTZHGpAn0UmNa78YY1y3aMePQZF6RfvrVcBLFmlKppX9EtvpnJASQfQ24cUkaA+bGJeDmxZLnGVekb/dpZ6WHNRpf6zU+/g2kAcs0PlINg4enbWuAjAZg11vArjcBCKnm4YHPqpcI62ra/1t6f9eOlZp+TFM2hLe59b5p54qbHv4qTrL+L9D9KfvUygXFAg9+C6y8WxoZ9/up0lg5zl4DWBt5N0qWdQGyFaPGFAqgyQDg6OfA2W3OG9xkJUt/m6CQJrqtQxjcuCkhBH75+xoWbT2Nf5KzAAD+nmo8ckcjTOgeAx+tA299ZnGzlKvnEygUJQnMDa1U8RqKgMzLZYKfUj+zrwGFWdI/zGt/3fp8Fnk/PtVcLpVLpPQAts6VqtABIG4icNebzl2VbisxPYAp24AvR0oB54q7gPuWA83uqnifkxul3kwFmVJX7ftXSIPz2VNEO2DUGqlp6u/vAZ8w4K433DcRPi9d+qkLcN3m0Cb9S4KbQa/LXRrrTOPbhLVyraY/G3DRTxVVRAiB7f+kYGH8afx9Vcox8dV6YHKvWDzUMxZ+OhmSYeWquXE0lYfU9BQYY/11fZ6UkGoOei6WBD9ZSSVNZObti5vHbMXDUxr4zpY9iFxBvcbAlK1STcyFX4GvxwADXwe6PmoZPBiKgO2vAHvel55HdZV6j9WmObU6GveVmgnXT5YSvX0jgJ4zHHNuR8tNk356Bclbjtpo1Eeq1bt+Uspj828gd4nKq6NNUgCDG7chhMCvZ1KxMP40/ky8CUDqzj2pRywe7tUI/l4y9vCxRc6NO1B7SkPJVzacvNEoBTimXB9zTlB2qRygGiwHNZbG5Qhr5bjrdSaegVJuy0+zpLFKfpkt9aQa/JbUfJl1TZoawZRH1fUx4M6XHd8zrs39Ug3fLy9ItW0+Ye4ZjOYW19y4Yr6NiVcQUD9OSsw/uw2ImyB3icozj0xct5KJAQY3bmHvWSmoOXRJasf2VKswvns0pt7RGEHeVRg92N4Y3FSdUin1otH6yF0S96NSA8M+kMZU2TIHOLQCSL8g1eBseFJKDtX4APd8DLQaLl85uz0m1eTt/RDY8LjUNOaKQ/5XxtQs5enCNTeAlHdz+SBwzgmDG30+kHRUWmbNDbmSAxfSsTD+FH4/L/2h0Hoo8WDXaEzr3Rghvk7S28Kgl76JAtKge0RyUiiA7k9I0zOsnwKc3yE9AGn8klFrnGMguQGvSLVJx78BvhkHTNgINIiTu1S24w7NUoAU3OxcAJzbKTVrOlP+UNJRaRwh7xAg0I07DlTAie4EVdXhSzewaOtp7D6TCgDQqJQY0yUK0/s2qd1IwvaQfQ2AkJJava3MlEwkh+Z3Aw9tBr4cLQ3932YkMGyR8wynr1RKNUg516Xg68sHgMnxrjsrdVnu0CwFSF3CPQOl3l9XDgENnWhiysRS49u4a2J6JRjcuJBjl29iYfxp7DwlzdGkVikwslMUHuvbBJEBNRgC3hFMTVK+ke7dtZVcT0Q7YPpeqdt3/Tjn+wfgoZFqklbdDST9Cay5VwpwqjNWj7MyBTfOPDFrVShVQKO+wN/fSWNIOVVwU3fzbQCA/21cxPrDl3HPx3uw89R1qJQKjOoUhe1P98Hr97Zx3sAGKJVv4+LdwMk9eQZKw9I7W2BjovUFxn4r9cC7eUmalTrfBiNtyy3PTWpuAKlpCpCSip2FEJY1N3UQgxsXsO9cGp7/7hiEAO5uE4Fts3rjzfvbIiqoBsPJOxqTiYlqxydU6unlFQwkHwPWPijNDebK3CXnBpDGuwGk+cdyUuUti8mNC1KTpkpjm6lCXBCDGyd37no2pn1+GHqDwNC2EfhwTAfEBDtJXkBV1JUxbojsqV5jaT4jtTdwYZc0yKDRKHepas5dcm4AaVDPsNYABHBuh9ylkZiapCLa143BOq1gcOPE0rILMGnlQWTk6dGxYQDeeaAdlEonrT6vCGtuiGyjfkdg1GopOf+vb6VZ3V2VqebG1buCm5hqb85ulbccJgm/Sz/rYBdwEwY3Tipfb8Ajaw4jIT0XUUGe+N/4Tvad3NJeSs8ITkS102SA1IsKAPZ9JI2F42qMRiD/prTsDjU3QEnezbntzlGjZqq5caYEZwdjcOOEhBB49ttjOHzpBvx0Hlg5sTPq+TjJuDXVxWYpIttqNxq48xVpectL0lxUriT/JiCKAwBX7y1lEtVVajLMSZFmd5dTfgaQckJabsCaG3Ii78WfxoY/r8JDqcDSB+PQJNRX7iLVjNFYatJMNksR2Uz3J4Euj0jL+xbLW5bqMuXbaHyl7u7uwENTMrmq3E1Tlw8BEFIPO3cYNqCGGNw4mW8PX8YH288CAOaPaIPuTYJlLlEt5KYBRj2A4tm0icg2FAqg9f3SsmkEcFdh7gbuJvk2Jua8G5m7hNfx8W1MGNw4kX3n0jD7u2MAgMf6NsbITlEyl6iWTE1SPqGOn4CQyN15F3/xMdWEuAp36gZeminvJnG/vGMR1eGZwEtjcOMkynb5fvrOSmaOdhXsKUVkP6Zk3MIsoKhA3rJUhzt1Ay8tKBYIagwYi4ALv8pTBqOhuFkKrLmRuwAEpOcU4qFVLt7l2xomExPZj85f6hYOlNSGuAJ36wZemtxdwlNOSMGuxhcIbSlPGZwEgxuZ5esNeGT1IVxKc/Eu39awGziR/SgUJbUfzjIyblW409QLZZWeikEIx5/f1CTVoJM071UdxuBGRqYu34cu3YCvq3f5tobNUkT2ZQoQXKrmxk0TigEgpqc05UFGApB21vHnZzKxGYMbGZXu8v2JK3f5rgibpYjsyyWDGzdNKAYAjTcQ3V1alqNpisnEZgxuZOJWXb4rwpobIvtyyWapG9JPd8y5AUo1TTk4uMm6Bty4CEAhNUvVcQxuZFC6y/f0Pm7Q5dsaITiAH5G9mbuDs+bGaTQuTiq++Bugz3PceU21NqEtpWTzOo7BjYOV7vJ9d9sIPDPQDbp8W5OfAehzpGUmFBPZh7lZyoVqbty1K7hJaAvANxIoygcu7XHceU3BTUPm2wAMbhyqdJfvDg0D8K67dPm2xtQk5RkIaLzkLQuRu/JysZobIUp6S7lrs5RCUapL+HbHnZfJxBYY3DiIW3f5tiarOLjxZZMUkd14m3JuXCS4KciUBrkD3LdZCnB83o0+H0g6Ki0zmRgAgxuHsNblO9idunxbw2RiIvtztd5SpnKqvQC1p7xlsadGvQGFEkg9BdxMsP/5kv4EDIWAdwgQGGv/87kABjcO4PZdvq1hcENkf+ZmKRfJuckt7inlrvk2Jp6BQIPO0rIjJtI0dwG/XWoWIwY39mbR5fteN+3ybQ3HuCGyP3PNTTpgNMpblqow59sEylsORzA1TZ1zZHDDJikTBjd2VK7Ld2c37PJdEXM3cPaUIrIbU3AjDED+TVmLUiXu3g28NFNS8fldgEFvv/MIUSq46Wq/87gYBjd2Ume6fFeEzVJE9uehAbR+0rIr5N24ezfw0iLaSz3CCjKBywftd54bF4Cc69K0DxHt7HceF8Pgxg7qVJfvirBZisgxXCmp2J1nBC9LqQIa95OW7dlrytQFPKI9oNbZ7zwuhsGNjdW5Lt/WFOaWVJFzAD8i+3KlKRjceUZwa0rPEm4vzLexisGNDdXJLt/WZBXn26i9OQw4kb250hQMdSnnBiipuUk6CmRft885OHifVQxubKhOdvm2xtwkFcluiUT25krdwetSzg0A+IYB4W2k5XN2GK04PxO49re0zODGguzBzeLFixEbGwudToe4uDjs3r270u0//vhjtGjRAp6enmjWrBlWr17toJJW7rczqXWzy7c1TCYmchxTLYgpcHBmuXWoK7iJPUcrvnwQgAACY6RAisw85Dz52rVrMWPGDCxevBg9evTAJ598gsGDB+PEiRNo2LBhue2XLFmC2bNn43//+x86d+6MAwcO4OGHH0ZgYCCGDRsmwxWU6Na4Hh7qEQudWlm3unxbw+CGyHFMzVLMuXFOTQYAv70n1dwYjYDShnUKbJKqkKw1NwsXLsTkyZMxZcoUtGjRAosWLUJUVBSWLFlidfs1a9Zg6tSpGDVqFBo1aoTRo0dj8uTJePPNNx1c8vJUSgX+O6wl/jOojnX5tobBDZHjuMrM4EKUapaqIzk3ANCgC6Dxle5P8p+2PTaTiSskW3BTWFiIw4cPY+DAgRbrBw4ciL1791rdp6CgADqdZVc3T09PHDhwAHq9HQdJqgYFc0wY3BA5kqvMDF6YAxgKpOW60BXcxEMDxN4hLduyacpoAC4fkpZZc1OObMFNamoqDAYDwsIs2wnDwsKQnJxsdZ9Bgwbh008/xeHDhyGEwKFDh7BixQro9Xqkplr/1lJQUIDMzEyLB9kZZwQnchwvF5kZ3NQkpdICGm95y+JoptGKbdklPOUkUJgFaHyA0Ja2O66bkD2huGxNhxCiwtqPOXPmYPDgwejatSvUajXuueceTJw4EQCgUlkfS2bBggXw9/c3P6Ki6ng+jCOw5obIcbxdZBC/0t3A61oNtym4STwA5GfY5pimJqkGnaQBA8mCbMFNcHAwVCpVuVqalJSUcrU5Jp6enlixYgVyc3Nx8eJFJCQkICYmBr6+vggOtt47afbs2cjIyDA/EhMTbX4tVEpRIZCdIi1zdGIi+zPV3OhzAH2evGWpTF3rBl5aYAxQr6k0B9j5XbY5JueTqpRswY1Go0FcXBzi4+Mt1sfHx6N79+6V7qtWq9GgQQOoVCp8/fXXGDp0KJQVZKBrtVr4+flZPMiOspMBCGmek7r4R4zI0bR+gFItLTtz7U1d7AZemrlpykZ5N0wmrpSszVKzZs3Cp59+ihUrVuDkyZOYOXMmEhISMG3aNABSrcv48ePN258+fRqff/45zpw5gwMHDmD06NH466+/MH/+fLkugcoyzQbuG27bLo9EZJ1C4RrdwetiN/DSSk/FIETtjpV1DbhxEYBCapaicmQd52bUqFFIS0vDK6+8gqSkJLRu3RqbNm1CdHQ0ACApKQkJCQnm7Q0GA959912cOnUKarUaffv2xd69exETEyPTFVA5nDCTyPG86knTnrhCzU1d6gZeWnQPKZk68zKQehoIqcWwIZeLx7cJbckpbioga3ADANOnT8f06dOtvrZq1SqL5y1atMCRI0ccUCqqMSYTEzmeK8wMbk4orqM1NxovIKaHNJjf2a21C27YJHVLbDcg2zJNmsnghshxXGFmcFOzVF0a46asxjbKu+HIxLfE4IZsy9QsxTFuiBzHFWYGr2szgltjyru5uAcozK3ZMYoKgKvFLRisuakQgxuyLTZLETmeK0zBUJe7gpuENAP8GkgjNV+yPhL/LV09ChgKAe8QIKiRTYvnThjckG2ZgxsmFBM5jEvk3LBZCgpF7buEm/Ntbq97gyFWA4Mbsh2jsVTOTYS8ZSGqS1xhCoa8Ot5bysTcJby2wQ2bpCrD4IZsJ+c6YCwCFErAx/oo00RkB86ec6PPA/TFOSZ1Pbhp1BtQqIC0M8CNS9XbVwgmE1cRgxuyHVMysU8YoFLLWxaiusQ8M7iT5tyYmqSUHtKIynWZzr+k1uVcNSfSvHERyEmRRqSOaG/rkrkVBjdkO0wmJpKHqVkq7wZgNMhbFmtKdwNnnkjNZwk31dpEtgfUOpsWyd0wuCHbMeXb+DLfhsihTE09wgjk3ZS1KFbV9QH8yjLl3ZzfJU02XFWJv0s/2SR1SwxuyHY49QKRPFTqkmH4nbFpqq5PvVBWeDupKbEwq2Qqhapgvk2VMbgh22GzFJF8vJw4qdhUpro6I3hZSiXQuJ+0XNWmqfxM4Nrf0jJ7St0SgxuyHQY3RPJx5ikY8m5IP9ksVaK6XcKvHAIggIBowDfcbsVyFwxuyHYY3BDJx5m7g3PqhfJMNTfJx4Csa7fenk1S1cLghmxDCAY3RHIyBQ5OnXPDmhsznxAgop20fG77rbfn4H3VwuCGbCPvBlCUJy1z0kwixzPn3KTLWw5rzDk3rLmxYGqautV4N0YDkHhQWm7Y1b5lchMMbsg2TN3APYM4/gKRHEzNUk6Zc8OaG6vMeTfbKh+fKOWk1LNK4wOEtnRM2VwcgxuyDU6YSSQvZ54ZnF3BrWvQWRqxOS8dSDpa8XamJqkGnQClyiFFc3UMbsg2zGPcsEmKSBZO3RWcM4JbpVIDsXdIy5V1CWcycbUxuCHbyORs4ESyctaZwYsKpSYVgDU31pRumqoIk4mrjcEN2QZHJyaSl7epWcrJghtTvo1CCegCZC2KUzLNM3X5QMl4QKVlpwA3LgBQSM1YVCUMbsg22A2cSF6mmpuiPKAwR96ylGZukgqURuYlSwENgeBm0rxg53eVf91UaxPasmSKDbolftLINhjcEMlL4wOotNKyM9XesBv4rZlnCbcyWjGbpGqEwQ3ZRlZxcMMxbojkoVA45xQM7AZ+a6bg5tx2aUDU0phMXCMMbqj2CrKB/AxpmTU3RPIx59040UB+7AZ+a9E9AA+dlLt4/Z+S9UUFwNUj0jJrbqqFwQ3VnmkAP40voPOTtyxEdZm5O7gT1dxwXqlbU3sCMT2l5dJNU0l/AoZC6b4GNZKnbC6KwQ3VHvNtiJyDUzZLFfcAYs5N5Rpbybsx59vcLjU7UpUxuKHaMwc3HOOGSFbOODM4a26qxjTezaW9Jb3dTMFNQ+bbVBeDG6o9jnFD5ByccQoGzgheNcFNAf+GUjPUxT1SYnFCqZobqhYGN1R7bJYicg5ezphQzK7gVaJQWHYJv3ERyEkBlGogor2cJXNJDG6o9kwJxb5sliKSlVPm3LDmpspKBzemLuCR7QG1TrYiuSoGN1R7bJYicg7MuXFtsXcASg8g/RxwbK20jk1SNcLghmqPzVJEzsHZcm4MRSVjYLHm5tZ0/iXBzLniiTQ5vk2NMLih2ikqBHKuS8usuSGSl2mcm7ybUmAht/ybJcucNLNqTE1TJqy5qREGN1Q7pnwblZbVzkRy8wwEoAAgrM8w7WimJildAKDykLUoLsPUJRwAAqIB33D5yuLCGNxQ7ZQe44aDTBHJS+UBeAZIy87QNMWpF6ovrA3gHSIts9amxhjcUO0wmZjIuXg5UVIxu4FXn1IJtLxHWm46UN6yuDDWE1LtsBs4kXPxqgeknXGO7uDsBl4zA18D2o4GGnSSuyQui8EN1Q57ShE5F2fqDs5u4DWj9gSiOstdCpfGZimqHTZLETkXUyDhFMENa25IHgxuqHZYc0PkXJwp58bULOUZKG85qM5hcEO1k1mcc8Pghsg5ONMUDKy5IZkwuKGaMxpKEooZ3BA5B6fKuWFXcJIHgxuquewUQBgAhQrwCZO7NEQElGqWcoaaG1NCMWtuyLEY3FDNZRXn2/iEAUqVvGUhIompliTHCWpuzDk3rLkhx2JwQzXHZGIi51O6WUoI+cphNJZMAcFmKXIwBjdUcwxuiJyPqQnIUAAUZstXjvybgDBKy6y5IQdjcEM1xzFuiJyPxhvw8JSW5UwqNiUTa3wBD4185aA6icEN1Zy5GzinXiByKubu4DIGN3nsKUXyYXBDNWdulmLNDZFT8S4Obpyh5obBDcmAwQ3VnLlZijk3RE7FVHMjZ3dwdgMnGTG4oZoRggP4ETkr01g3co5SzG7gJCMGN1QzeTeAonxp2Zc5N0ROxRlGKeaM4CQjBjdUM6YmKa9gwEMrb1mIyJJ5ZnA5m6U4rxTJh8EN1QzHuCFyXuYpGNLlK4Op5oYzgpMMGNxQzTC4IXJezjAzuHl0YtbckOMxuKGaYXBD5LyYc0N1HIMbqhkGN0TOyym6gjPnhuTD4IZqJosD+BE5LVPOTX4GYNA7/vxCsCs4yYrBDdWMqeaG3cCJnI9nAACFtCxHUnFBJmAskpbZLEUykD24Wbx4MWJjY6HT6RAXF4fdu3dXuv0XX3yBdu3awcvLCxEREZg0aRLS0mRsV66rOPUCkfNSquTtDm4KqNRegNrT8eenOk/W4Gbt2rWYMWMGXnzxRRw5cgS9evXC4MGDkZCQYHX73377DePHj8fkyZPx999/Y926dTh48CCmTJni4JLXcQVZ0jczgJNmEjkrLxmTinPZJEXykjW4WbhwISZPnowpU6agRYsWWLRoEaKiorBkyRKr2//++++IiYnBk08+idjYWPTs2RNTp07FoUOHHFzyOs40G7jWD9D6ylsWIrJOzu7gnBGcZCZbcFNYWIjDhw9j4MCBFusHDhyIvXv3Wt2ne/fuuHz5MjZt2gQhBK5du4Zvv/0Wd999tyOKTCacMJPI+ck5Mzi7gZPMZAtuUlNTYTAYEBYWZrE+LCwMycnJVvfp3r07vvjiC4waNQoajQbh4eEICAjAhx9+WOF5CgoKkJmZafGgWmI3cCLn5yVncMNu4CQv2ROKFQqFxXMhRLl1JidOnMCTTz6J//73vzh8+DA2b96MCxcuYNq0aRUef8GCBfD39zc/oqKibFr+OonBDZHzkzPnht3ASWayBTfBwcFQqVTlamlSUlLK1eaYLFiwAD169MB//vMftG3bFoMGDcLixYuxYsUKJCUlWd1n9uzZyMjIMD8SExNtfi11jmmMG18GN0ROS86cG3OzFGtuSB6yBTcajQZxcXGIj4+3WB8fH4/u3btb3Sc3NxdKpWWRVSoVAKnGxxqtVgs/Pz+LB9USa26InJ+cUzDkMqGY5CVrs9SsWbPw6aefYsWKFTh58iRmzpyJhIQEczPT7NmzMX78ePP2w4YNw3fffYclS5bg/Pnz2LNnD5588kl06dIFkZH8R+sw5oRijnFD5LTM49zImVDMmhuSh4ecJx81ahTS0tLwyiuvICkpCa1bt8amTZsQHR0NAEhKSrIY82bixInIysrCRx99hKeffhoBAQHo168f3nzzTbkuoW4ydQXnGDdEzsuUcyNLV/DiGcE9Ax1/biIAClFRe46byszMhL+/PzIyMthEVRP6fOD14pyoZy+w2pnIWWVcBt5rBSjVwJzrQAUdNezi3eZAVhLwyE4gsoPjzkturTr/v2XvLUUuJqu41sZDx29lRM7M1CRk1JeMKO4IQrArOMmOwQ1VT+lkYkd+EySi6lF7AmpvadmReTeFOYChQFpmV3CSCYMbqh5TzQ27gRM5P3N3cAcGN6YxblRaQOPtuPMSlcLghqqHUy8QuQ45pmAo3Q2ctbskEwY3VD0c44bIdZinYHBgjyl2AycnwOCGqscc3HCMGyKnJ0d3cHYDJyfA4IaqxxzccIwbIqcnx+SZnBGcnACDG6oeNksRuQ5Zc27YLEXyYXBDVWcoArKLJzplsxSR85NjZnDTudgNnGTE4IaqLicFEEZAoQK8Q+QuDRHdihwzg+ex5obkx+CGqs7UJOUbAShV8paFiG5NjpnBmXNDToDBDVUdx7ghci2yJBSz5obkx+CGqs48GziDGyKXYAowCjKBokLHnNPcFZw1NyQfBjdUday5IXItugApRw5wXO0Nm6XICTC4oapjN3Ai16JUlgQZjhilWJ8H6HOlZQY3JKMaBTcZGRlIT08vtz49PR2ZmZm1LhQ5KQY3RK7HkXk3pnwbpQeg9bP/+YgqUKPgZvTo0fj666/Lrf/mm28wevToWheKnFSWqbcUgxsil+HIKRhM3cA9OWkmyatGwc3+/fvRt2/fcuv79OmD/fv317pQ5ISEYM0NkSsyj1Jcvrbd5phvQ06iRsFNQUEBioqKyq3X6/XIy8urdaHICeWmAYbi3ha+nFeKyGU4cmZwdgMnJ1Gj4KZz585YtmxZufVLly5FXFxcrQtFTshUa+MdCnho5C0LEVWdI6dgMDdLcUZwkpdHTXZ6/fXXMWDAAPz555/o378/AGDbtm04ePAgtmzZYtMCkpPgbOBErsmRUzCw5oacRI1qbnr06IF9+/YhKioK33zzDX788Uc0adIEx44dQ69evWxdRnIG5jFuOGEmkUtx5BQM5uCGOTckrxrV3ABA+/bt8cUXX9iyLOTMmExM5JrM49w4IrgxJRSz5obkVaPgJiEhodLXGzZsWKPCkBPLKp56gcnERK5Frq7gRDKqUXATExMDRSVjGBgMhhoXiJwUm6WIXFPpQfyEsO/4M+wKTk6iRsHNkSNHLJ7r9XocOXIECxcuxOuvv26TgpGTYbMUkWsy5dwIA5B/0749mZhQTE6iRsFNu3btyq3r1KkTIiMj8fbbb2PEiBG1Lhg5GXNww5obIpfioQU0vkBhlhR8OCK4YbMUycymE2fedtttOHjwoC0PSc4gPxMozJaW2RWcyPWYmonsmXdTVCgFUKXPRySTGtXclJ0cUwiBpKQkzJs3D02bNrVJwciJmGptdP6AxlveshBR9XkHAzcv2bfHVN4N6adCCegC7HceoiqoUXATEBBQLqFYCIGoqCirE2qSi2MyMZFrc8QUDKbAyTMQUNq0UYCo2moU3OzYscPiuVKpREhICJo0aQIPjxoPnUPOytQNnMnERK7JEVMwsBs4OZEaRSK9e/cGAJw4cQIJCQkoLCzEjRs3cPr0aQDAv/71L9uVkORnapbiGDdErskROTccwI+cSI2Cm/Pnz2PEiBE4duwYFAoFhBAAYG6q4jg3bobNUkSuzRFTMHDqBXIiNWoYfeqppxATE4Nr167By8sLf/31F3799Vd06tQJO3futHERSXYc44bItZUeyM9ezDk3DG5IfjWqudm3bx+2b9+OkJAQKJVKqFQq9OzZEwsWLMCTTz5ZbpA/cnGZzLkhcmmOmILB1FuKNTfkBGpUc2MwGODj4wMACA4OxtWr0jf76OhonDp1ynalI+dgbpZicEPkkhzSLMWpF8h51KjmpnXr1jh27BgaNWqE22+/HW+99RY0Gg2WLVuGRo0a2bqMJCd9XkkvCAY3RK7JIc1SnHqBnEeNgpuXXnoJOTk5AIDXXnsNQ4cORa9evVCvXj2sXbvWpgUkmZm6gau9ODAXkasyBRyF2YA+H1DrbH8OdgUnJ1Kj4GbQoEHm5UaNGuHEiRNIT09HYGBgpbOFkwsq3Q2c95bINen8AaUHYCySam/87dDzkV3ByYnYbBjJoKAgBjbuiD2liFyfQmH/UYrZFZycCMfIpspxjBsi92DPvBtDEZB/U1pmsxQ5AQY3VDlzN3COTkzk0kzBTY4dghtTYANIc0sRyYzBDVWONTdE7sGeNTemY+r8ARXnFyT5MbihyjHnhsg9mMe6sUPODbuBk5NhcEOV44zgRO7BnjODsxs4ORkGN1Qxgx7ISpaWfRncELk0c86NPWpu2A2cnAuDG6pY9jUAQhofwztE7tIQUW14m3Ju0m1/bHYDJyfD4IYqZh7ALxJQ8qNC5NLsOc4Na27IyfA/FlXMnEzMbuBELs+eM4Obc27YDZycA4Mbqhh7ShG5D1OtSl46YDTa9thsliInw+CGKsYxbojchym4EUbLQfdsgV3ByckwuKGKsRs4kfvw0ABaP2nZ1t3BTcdjV3ByEgxuqGKlZwQnItdnr+7geay5IefC4IYqxmYpIvfibYeB/IxGIO+GtMycG3ISDG7IOqOx1KSZbJYicgv26A6ef1PK4wHYLEVOg8ENWZebBhj1ABSAb7jcpSEiW7DHFAymWhuNr5TXQ+QEGNyQdaYmKZ9QQKWWtyxEZBumZqMcGwY35gH8WGtDzoPBDVnHMW6I3I89ZgbnGDfkhBjckHVMJiZyP+acGzvU3DDfhpyI7MHN4sWLERsbC51Oh7i4OOzevbvCbSdOnAiFQlHu0apVKweWuI4wjXHDbuBE7sMeUzCwGzg5IVmDm7Vr12LGjBl48cUXceTIEfTq1QuDBw9GQkKC1e3ff/99JCUlmR+JiYkICgrCAw884OCS1wFsliJyP152mBmcOTfkhGQNbhYuXIjJkydjypQpaNGiBRYtWoSoqCgsWbLE6vb+/v4IDw83Pw4dOoQbN25g0qRJDi55HcBmKSL3422HruCceoGckGzBTWFhIQ4fPoyBAwdarB84cCD27t1bpWMsX74cAwYMQHR0tD2KWLdxjBsi92NqltLnAoW5tjkmZwQnJ+Qh14lTU1NhMBgQFhZmsT4sLAzJycm33D8pKQk///wzvvzyy0q3KygoQEFBgfl5ZmZmzQpclwjBZikid6T1BZRqaQyr3DRA41X7Y7LmhpyQ7AnFCoXC4rkQotw6a1atWoWAgAAMHz680u0WLFgAf39/8yMqKqo2xa0b8jMAfY60zIRiIvehUNi+Ozi7gpMTki24CQ4OhkqlKldLk5KSUq42pywhBFasWIFx48ZBo6l8RMzZs2cjIyPD/EhMTKx12d2eqdbGM9A23+yIyHnYuju4OaGYNTfkPGQLbjQaDeLi4hAfH2+xPj4+Ht27d6903127duHs2bOYPHnyLc+j1Wrh5+dn8aBbyDLNBs4mKSK3Y54Z3AbBjRClcm5Yc0POQ7acGwCYNWsWxo0bh06dOqFbt25YtmwZEhISMG3aNABSrcuVK1ewevVqi/2WL1+O22+/Ha1bt5aj2O6P+TZE7suWNTcFmYCxqPi4DG7Iecga3IwaNQppaWl45ZVXkJSUhNatW2PTpk3m3k9JSUnlxrzJyMjA+vXr8f7778tR5LqBwQ2R+7Jlzo0p30btBag9a388IhuRNbgBgOnTp2P69OlWX1u1alW5df7+/sjNtVEXRrLOHNxwjBsit2PLmhs2SZGTkr23FDkhc3DDnlJEbsecc2PDmhs2SZGTYXBD5bFZish9mZulbDAFA4MbclIMbqg8Tr1A5L68bDgFA7uBk5NicEOWCnOB/JvSMmtuiNyPLWcGZ84NOSkGN2Qpq3hOKbU3oOWYQERux1TLkncDMBpqdyzOCE5OisENWTI3SUVKQ7UTkXsxByJCCnBqg/NKkZNicEOWOBs4kXtTqQGdv7Rc2+7gpv3ZLEVOhsENWSpdc0NE7slWeTemmh82S5GTYXBDltgNnMj92WogP3YFJyfF4IYsMbghcn+2mIJBCHYFJ6fF4IYsZXHqBSK3Z4uaG30uYCiQlplzQ06GwQ1ZMtXc+HLqBSK3ZZ6CoRbBjSkwUmkBjXfty0RkQwxuqIRBD2SnSMusuSFyX7Zoliqdb8NhI8jJMLihElnJAASg0rANncid2aJZit3AyYkxuKES5iapcEDJjwaR27JFV3B2Aycnxv9gVIITZhLVDeaam1rMDM6pF8iJMbihEuwGTlQ3eJeaGVyImh2DUy+QE2NwQyWyOPUCUZ1gCkiK8qUu3TXBGcHJiTG4oRKmZilfBjdEbk3jI3XhBmqed8MB/MiJMbihEmyWIqobFIpS3cFr2GOKUy+QE2NwQyUyOToxUZ1hCkpqHNyw5oacF4MbkhiNpXJuODoxkdurbXdwU1dw5tyQE2JwQ5Kc64CxCFAoAZ8wuUtDRPZW24H8zDU3gbYpD5ENMbghiSmZ2CcMUKnlLQsR2V9tpmDQl+plxWYpckIMbkjCbuBEdUttam5M3cCVHoDWz3ZlIrIRBjck4WzgRHVLbWYGLz2vFCfNJCfE4IYknHqBqG6pTc0Nu4GTk2NwQ9Lw6wn7peWAKHnLQkSOUZucG3YDJyfH4IaAC78CCXsBlQZoNULu0hCRI9SmK7h56gX2lCLnxODGlgpzgOun5C5F9QgB7JgvLcdNAvzZLEVUJ5hqXfJvAoai6u3LZilycgxubOXKYeCDjsDXYwGDXu7SVN257UDi74CHDug5U+7SEJGjeAYCKE4GNtXEVBVnBCcnx+DGVuo1BYx6IO0M8MdquUtTNaVrbTpN5sjERHWJygPwDJCWq5tUXLq3FJETYnBjKzo/oPfz0vLOBUBBlrzlqYoz8cCVQ4CHJ9BzhtylISJHq2neTR5rbsi5MbixpU6TgKDG0lQGez+UuzSVEwLY8bq03OVhwCdU3vIQkePVtDs4c27IyTG4sSWVGhgwV1re+yGQmSRveSpz6mcg6Sig9gZ6PCV3aYhIDjXtDs6u4OTkGNzYWot/AQ26SPOu7Fwgd2msMxpLcm1un1ryB46I6hZzzU01E4o5Izg5OQY3tqZQAANfk5aPrAFSTspbHmv+2QhcOw5ofIHuT8hdGiKSi3kKhmrU3BQVAgWZxfszuCHnxODGHhreDrQYBggjsHWe3KWxZDSW1Ch1fZR/nIjqspo0S5lqbRRKQBdg8yIR2QKDG3vpP0+aMff0ZuDCbrlLU+LED0DKCUDrD3SbLndpiEhONUkoNm2rCwCU/BdCzomfTHsJbiKN+AsA8XOkGhO5GQ3Azjek5W6Pceh0orrO3BW8GsENu4GTC2BwY0+9n5PyWq4eAf7+Tu7SAH99B6Sekr5xdZ0md2mISG6mZuma1NywSZucGIMbe/IJAXoWd7Pe9jJQVCBfWQxFwK7iWpvuTwA6f/nKQkTOoXTOjRBV24dTL5ALYHBjb10fA3wjgJsJwIH/yVeO4+uAtLNS183bp8pXDiJyHqYAxVAIFGZXbR/zjOCsuSHnxeDG3jReQN8XpeVf3y7paeBIBj2w601pucdTgNbX8WUgIuej8ZamXwGq3h2coxOTC2Bw4wjt/w2EtgTybwK733X8+f/8GrhxQUoe7PKw489PRM7L3DRVxYH8GNyQC2Bw4whKFXDnK9Ly/k+AG5ccd+6iQuDXt6TlnjOlb2pERCbmpOKq1txw6gVyfgxuHKXJACD2Dqlte/trjjvv0S+kfB+fMKDTQ447LxG5hurODM6cG3IBDG4cRaEA7nxVWj7+DXD1qP3PWVQA/PqOtNxzlpT/Q0RUWnUH8mNXcHIBDG4cKbI90GaktBw/p+pdL2vqj9VA5mWpt1bcRPuei4hcU3WnYGBXcHIBDG4crf8cQKUBLvwKnN1qv/Po80uSl3s9Dah19jsXEbmu6gzkZygC8jOkZTZLkRNjcONoAQ1LxpmJ/680JYI9HF4FZCUB/lFAx/H2OQcRub7qTMGQfxNAcY0zp28hJ8bgRg69npamQEg5ISX82lphLvDbQmn5jmcAD63tz0FE7qE6OTemJimdP6DysF+ZiGqJwY0cPAOBO/4jLe+YDxTm2Pb4h1YA2deAgGig/VjbHpuI3Et1cm7YDZxcBIMbuXR5WGqiykoC9i223XELc4Df3pOWez8LqNS2OzYRuR9Ts1RVam7YDZxcBIMbuXhogf5zpeU9i4Ds67Y57oH/Sd/AAmOBtqNtc0wicl+mWpj8DGmqlsqw5oZcBIMbObUaAUR2kCasM83YXRsFWcCe96XlPs+zTZyIbs0zAFAU/yu4Ve0Np14gF8HgRk5KZcnAfodWAqlnane8/UulauN6TYHW99e+fETk/pSqkp5Ptwxuil9nsxQ5OQY3covtBdx2FyAMwNZ5NT9Ofgaw90NpmbU2RFQdVZ2CIY81N+QaGNw4gwEvS9XC/2wEEn6v2TF+XyIFOCHNgVb32rZ8ROTeqtodPPdG8fYMbsi5yR7cLF68GLGxsdDpdIiLi8Pu3bsr3b6goAAvvvgioqOjodVq0bhxY6xYscJBpbWT0OZAh3HS8pYaTMuQdwPY97G03Od5qZqZiKiqvKsa3DChmFyDrMHN2rVrMWPGDLz44os4cuQIevXqhcGDByMhIaHCfUaOHIlt27Zh+fLlOHXqFL766is0b97cgaW2k74vAGov4PIB4OSG6u2772OgIBMIbQW0uMc+5SMi91XVmht2BScXIWtws3DhQkyePBlTpkxBixYtsGjRIkRFRWHJkiVWt9+8eTN27dqFTZs2YcCAAYiJiUGXLl3QvXt3B5fcDnzDge5PSMtb5wFFhVXbLzddapICgL6zpSRlIqLqqGrODWtuyEXI9p+wsLAQhw8fxsCBAy3WDxw4EHv37rW6z4YNG9CpUye89dZbqF+/Pm677TY888wzyMvLc0SR7a/7E4B3CJB+Xpobqir2fiB1JQ9vCzQfatfiEZGbqsooxUaj1AQOMOeGnJ5sXWpSU1NhMBgQFhZmsT4sLAzJyclW9zl//jx+++036HQ6fP/990hNTcX06dORnp5eYd5NQUEBCgoKzM8zMzNtdxG2pvUF+swGfpoljXvTbpQ0h0tFsq8D+5dJy31fABQKx5STiNxLVZql8m8Cwigts1mKnJzsbRiKMv+QhRDl1pkYjUYoFAp88cUX6NKlC4YMGYKFCxdi1apVFdbeLFiwAP7+/uZHVFSUza/BpjqOl8apyU0rGZCvInvfB/Q50kCAt93lmPIRkfsxBTeVzQxuqrXR+AIeGvuXiagWZAtugoODoVKpytXSpKSklKvNMYmIiED9+vXh719Sm9GiRQsIIXD58mWr+8yePRsZGRnmR2Jiou0uwh5UauDOl6XlfR8DGVesb5d1DTjwqbTc90XW2hBRzVWl5sacbxNo//IQ1ZJswY1Go0FcXBzi4+Mt1sfHx1eYINyjRw9cvXoV2dnZ5nWnT5+GUqlEgwYNrO6j1Wrh5+dn8XB6zYYADbsBRfnSrOHW7FkEFOUBDToDTQY4tHhE5Ga8S02eWdFQFOapF5hMTM5P1mapWbNm4dNPP8WKFStw8uRJzJw5EwkJCZg2bRoAqdZl/Pjx5u3//e9/o169epg0aRJOnDiBX3/9Ff/5z3/w0EMPwdPTU67LsD2FAhj4mrR89Asg+S/L1zOTgIPLpWXm2hBRbZkCFqNeGlbCGnYDJxcia3AzatQoLFq0CK+88grat2+PX3/9FZs2bUJ0dDQAICkpyWLMGx8fH8THx+PmzZvo1KkTxo4di2HDhuGDDz6Q6xLsp0EnoOVwAALYOtfytd8WAoYCqXanUV85SkdE7kTtCai9peWKuoOzGzi5ENknIJo+fTqmT59u9bVVq1aVW9e8efNyTVlua8Bc4J+fgLNbgXM7gMZ9gYzLJd3EWWtDRLbiVQ/IyJGan+o1Lv86ZwQnFyJ7bymqRFAjoPNkaTl+jjTOxO53AUMhENMLiL1D3vIRkfswT8HAmhtyfQxunN0dzwJaPyD5uBTY/LFGWt9ntrzlIiL3cqtRis05N+wtRc6PwY2z864H9JwpLe94TUr4a9QHiOkha7GIyM3cqjs4m6XIhTC4cQVdHwX86pc87/OCfGUhIvd0qykY2BWcXAiDG1eg9gQGFA/s12wI0PB2ectDRO7HVCNjCmLKYldwciGy95aiKmr7ABDWCgiMkbskROSOKsu5EYIJxeRSGNy4krCWcpeAiNxVZTk3BVmAsah4O9bckPNjsxQREVWec2MKeNReUjM5kZNjcENERKVqbqzk3DDfhlwMgxsiIioJbgoygaICy9fYDZxcDIMbIiICdAGAQiUtl827YXBDLobBDRERAUplqe7gZYOb4udsliIXweCGiIgkFXUHz+MAfuRaGNwQEZGkou7gbJYiF8PghoiIJN4VBTccwI9cC4MbIiKSVFRzw67g5GI4QnEFDAYD9Hq93MUgN6PRaKBU8jsFOamKcm7YLEUuhsFNGUIIJCcn4+bNm3IXhdyQUqlEbGwsNBqN3EUhKs9cc8Pghlwbg5syTIFNaGgovLy8oFAo5C4SuQmj0YirV68iKSkJDRs25GeLnI95CoZSoxRz0kxyQQxuSjEYDObApl49/hKT7YWEhODq1asoKiqCWq2WuzhElkzBS+lmKX0uYCgesZg5N+Qi2PhfiinHxsvLS+aSkLsyNUcZDAaZS0JkhbWEYtOySgNovB1fJqIaYHBjBZsLyF742SKnZm6WSgOMxuLlUgP48fNLLoLBDbmdmJgYLFq0SO5iELkeU82NMAAFGdIyu4GTC2Jw4yYmTpwIhUJR7nHXXXdVaf+dO3dCoVC4RS+xgwcP4pFHHrHpMfv06YMZM2bY9JhETsdDC2h8peWc4uYo9pQiF8SEYjdy1113YeXKlRbrtFqtTc9RWFjo9N2YQ0JC5C4CkevyCgIKs4pzbZowuCGXxJobN6LVahEeHm7xCAwMBCDlenz66ae499574eXlhaZNm2LDhg0AgIsXL6Jv374AgMDAQCgUCkycOBGAVGPx+OOPY9asWQgODsadd94JADhx4gSGDBkCHx8fhIWFYdy4cUhNLelh0adPHzz55JN49tlnERQUhPDwcMybN8+ivAsXLkSbNm3g7e2NqKgoTJ8+HdnZ2ebXV61ahYCAAGzcuBHNmjWDl5cX7r//fuTk5OCzzz5DTEwMAgMD8cQTT1gk6JZtlsrIyMAjjzyC0NBQ+Pn5oV+/fvjzzz/Nr8+bNw/t27fHmjVrEBMTA39/f4wePRpZWVkApFqxXbt24f333zfXiF28eBEAsGvXLnTp0gVarRYRERF4/vnnUVRUVIu7SCQzc95N8e8zu4GTC2JwcwtCCOQWFsnyEELY9FpefvlljBw5EseOHcOQIUMwduxYpKenIyoqCuvXrwcAnDp1CklJSXj//ffN+3322Wfw8PDAnj178MknnyApKQm9e/dG+/btcejQIWzevBnXrl3DyJEjLc732WefwdvbG/v378dbb72FV155BfHx8ebXlUolPvjgA/z111/47LPPsH37djz77LMWx8jNzcUHH3yAr7/+Gps3b8bOnTsxYsQIbNq0CZs2bcKaNWuwbNkyfPvtt1avWQiBu+++G8nJydi0aRMOHz6Mjh07on///khPLxnL49y5c/jhhx+wceNGbNy4Ebt27cIbb7wBAHj//ffRrVs3PPzww0hKSkJSUhKioqJw5coVDBkyBJ07d8aff/6JJUuWYPny5Xjttddqd6OI5FS2OzhzbsgFsVnqFvL0BrT87y+ynPvEK4Pgpan6Ldq4cSN8fHws1j333HOYM2cOAKkGYsyYMQCA+fPn48MPP8SBAwdw1113IShI+sMVGhqKgIAAi2M0adIEb731lvn5f//7X3Ts2BHz5883r1uxYgWioqJw+vRp3HbbbQCAtm3bYu7cuQCApk2b4qOPPsK2bdvMtT+lc1hiY2Px6quv4tFHH8XixYvN6/V6PZYsWYLGjRsDAO6//36sWbMG165dg4+PD1q2bIm+fftix44dGDVqVLn3ZMeOHTh+/DhSUlLMTXTvvPMOfvjhB3z77bfm3Byj0YhVq1bB11fKNxg3bhy2bduG119/Hf7+/tBoNPDy8kJ4eLj52IsXL0ZUVBQ++ugjKBQKNG/eHFevXsVzzz2H//73v5xmgVyTV6keU6V/slmKXAiDGzfSt29fLFmyxGKdKWgBpGDDxNvbG76+vkhJSbnlcTt16mTx/PDhw9ixY0e5QAqQakBKBzelRUREWJxvx44dmD9/Pk6cOIHMzEwUFRUhPz8fOTk58PaWxtPw8vIyBzYAEBYWhpiYGItzh4WFVXgdhw8fRnZ2drlBGfPy8nDu3Dnz85iYGHNgY62s1pw8eRLdunWz6N7do0cPZGdn4/Lly2jYsGGl+xM5pbIzg5fuCk7kIhjc3IKnWoUTrwyS7dzV4e3tjSZNmlT4etkRcRUKBYymsSxucdzSjEYjhg0bhjfffLPcthEREVU636VLlzBkyBBMmzYNr776KoKCgvDbb79h8uTJFhOWWjtGda7DaDQiIiICO3fuLPda6Rqqmrw3Qohy49aYmhI5ng25rLID+bFZilwQg5tbUCgU1WoaclXVGTm3Y8eOWL9+PWJiYuDhUbP35tChQygqKsK7775rbr755ptvanSsynTs2BHJycnw8PBATExMjY+j0WjKvTctW7bE+vXrLYKcvXv3wtfXF/Xr169NsYnkU3ZmcNbckAtiUoAbKSgoQHJyssWjdA+mykRHR0OhUGDjxo24fv26Ra+lsh577DGkp6djzJgxOHDgAM6fP48tW7bgoYceqvK0Ao0bN0ZRURE+/PBDnD9/HmvWrMHSpUurtG91DBgwAN26dcPw4cPxyy+/4OLFi9i7dy9eeuklHDp0qMrHiYmJwf79+3Hx4kWkpqbCaDRi+vTpSExMxBNPPIF//vkH//d//4e5c+di1qxZzLch11W25sYc3ATKUx6iGuBfYDeyefNmREREWDx69uxZpX3r16+Pl19+Gc8//zzCwsLw+OOPV7htZGQk9uzZA4PBgEGDBqF169Z46qmn4O/vX+V/6u3bt8fChQvx5ptvonXr1vjiiy+wYMGCKu1bHQqFAps2bcIdd9yBhx56CLfddhtGjx6NixcvIiwsrMrHeeaZZ6BSqdCyZUuEhIQgISEB9evXx6ZNm3DgwAG0a9cO06ZNw+TJk/HSSy/Z/DqIHKZ0V3B9PqDPkZ6z5oZciELYur+xk8vMzIS/vz8yMjLg5+dn8Vp+fj4uXLiA2NhY6HQ6mUpI7oyfMXJ6aeeADzsCGh/g8YPAwhaA0gOYk8q5pUhWlf3/Los1N0REVMJUQ1OYDWRelZY9gxjYkEthcENERCV0/lJNDQCknpZ+cowbcjEMboiIqIRCUVJ7Ywpu2A2cXAyDGyIismTqDp56pvg5gxtyLQxuiIjIkimYYXBDLorBDRERWTJ1B08/L/1kN3ByMQxuiIjIkimYMRZPhcKcG3IxDG6IiMiSKefG/Jw1N+RaGNyQSzh79izmz5+PvLw8uYtC5P7KBjPMuSEXw+CGAAB9+vTBjBkzzM9jYmKwaNGiSvdRKBT44YcfbFaGis6Zn5+PBx54AJGRkfD09LTZ+YioAt5lgxvW3JBrcf/pruuAYcOGIS8vD1u3bi332r59+9C9e3ccPnwYHTt2rPIxDx48CG9vb1sWs8bnnDFjBoYPH46JEyc6tDxEdVbZYIY5N+RiGNy4gcmTJ2PEiBG4dOkSoqOjLV5bsWIF2rdvX63ABgBCQkJsWcRandMes4UTUSXK5dwwuCHXwmYpNzB06FCEhoZi1apVFutzc3Oxdu1aDB8+HGPGjEGDBg3g5eWFNm3a4Kuvvqr0mGWbiM6cOYM77rgDOp0OLVu2RHx8fLl9nnvuOdx2223w8vJCo0aNMGfOHOj1eottNmzYgE6dOkGn0yE4OBgjRoyo8JwJCQm455574OPjAz8/P4wcORLXrl0zvz5v3jy0b98ea9asQUxMDPz9/TF69GhkZWVV4V0jogp5lwpuFEppSgYiF8Lg5laEAApz5HlUccJ2Dw8PjB8/HqtWrULpSd7XrVuHwsJCTJkyBXFxcdi4cSP++usvPPLIIxg3bhz2799fpeMbjUaMGDECKpUKv//+O5YuXYrnnnuu3Ha+vr5YtWoVTpw4gffffx//+9//8N5775lf/+mnnzBixAjcfffdOHLkCLZt24ZOnTpV8LYLDB8+HOnp6di1axfi4+Nx7tw5jBo1ymK7c+fO4YcffsDGjRuxceNG7Nq1C2+88UaVrouIKlC6GUoXAChVshWFqCbYLHUr+lxgfqQ8537hKqCpWt7LQw89hLfffhs7d+5E3759AUhNUiNGjED9+vXxzDPPmLd94oknsHnzZqxbtw633377LY+9detWnDx5EhcvXkSDBg0AAPPnz8fgwYMttnvppZfMyzExMXj66aexdu1aPPvsswCA119/HaNHj8bLL79s3q5du3YVnvPYsWO4cOECoqKiAABr1qxBq1atcPDgQXTu3BmAFHitWrUKvr6+AIBx48Zh27ZteP311295XURUAQ8NoPUHCjKYTEwuiTU3bqJ58+bo3r07VqxYAUCq0di9ezceeughGAwGvP7662jbti3q1asHHx8fbNmyBQkJCVU69smTJ9GwYUNzYAMA3bp1K7fdt99+i549eyI8PBw+Pj6YM2eOxTmOHj2K/v37V/mcUVFR5sAGAFq2bImAgACcPHnSvC4mJsYc2ABAREQEUlJSqnQOIqqEKc+G+TbkglhzcytqL6kGRa5zV8PkyZPx+OOP4+OPP8bKlSsRHR2N/v374+2338Z7772HRYsWoU2bNvD29saMGTNQWFhYpeMKK81jCoXC4vnvv/9urpUZNGgQ/P398fXXX+Pdd981b1OdbtxCiHLnsLZerVaXK5fRaKzyeYioAt7BwI0LrLkhl8Tg5lYUiio3Dclt5MiReOqpp/Dll1/is88+w8MPPwyFQoHdu3fjnnvuwYMPPghAaso5c+YMWrRoUaXjtmzZEgkJCbh69SoiI6Umun379llss2fPHkRHR+PFF180r7t06ZLFNm3btsW2bdswadKkKp8zMTHRXHtz4sQJZGRkVLncRFQLpqCG3cDJBbFZyo34+Phg1KhReOGFF3D16lXzuDBNmjRBfHw89u7di5MnT2Lq1KlITk6u8nEHDBiAZs2aYfz48fjzzz+xe/duiyDGdI6EhAR8/fXXOHfuHD744AN8//33FtvMnTsXX331FebOnYuTJ0/i+PHjeOuttyo8Z9u2bTF27Fj88ccfOHDgAMaPH4/evXtXmIRMRDZk6g7uFShvOYhqgMGNm5k8eTJu3LiBAQMGoGHDhgCAOXPmoGPHjhg0aBD69OmD8PBwDB8+vMrHVCqV+P7771FQUIAuXbpgypQp5RJ277nnHsycOROPP/442rdvj71792LOnDkW2/Tp0wfr1q3Dhg0b0L59e/Tr16/CHlum0Y8DAwNxxx13YMCAAWjUqBHWrl1bvTeEiGqm5b+AgGig2RC5S0JUbQphLaHCjWVmZsLf3x8ZGRnw8/OzeC0/Px8XLlxAbGwsdDqdTCUkd8bPGBFRzVT2/7ss1twQERGRW2FwQ0RERG6FwQ0RERG5FQY3RERE5FZkD24WL15sTq6Mi4vD7t27K9x2586dUCgU5R7//POPA0tMREREzkzW4Gbt2rWYMWMGXnzxRRw5cgS9evXC4MGDbzktwKlTp5CUlGR+NG3a1KblqmMdyMiB+NkiIrI/WYObhQsXYvLkyZgyZQpatGiBRYsWISoqCkuWLKl0v9DQUISHh5sfKpVtZqw1DeWfm5trk+MRlWWa8sJWn1kiIipPtukXCgsLcfjwYTz//PMW6wcOHIi9e/dWum+HDh2Qn5+Pli1b4qWXXjLPgl1bKpUKAQEB5okXvby8rM5vRFQTRqMR169fh5eXFzw8OPMJEZG9yPYXNjU1FQaDAWFhYRbrw8LCKpwaICIiAsuWLUNcXBwKCgqwZs0a9O/fHzt37sQdd9xhdZ+CggIUFBSYn2dmZlZarvDwcADgzNJkF0qlEg0bNmTQTERkR7J/fSz7R76i2aABoFmzZmjWrJn5ebdu3ZCYmIh33nmnwuBmwYIFePnll6tVnoiICISGhkKv11d5P6Kq0Gg0UCplz+MnInJrsgU3wcHBUKlU5WppUlJSytXmVKZr1674/PPPK3x99uzZmDVrlvl5ZmameZbpyqhUKuZFEBERuSDZvkJqNBrExcUhPj7eYn18fDy6d+9e5eMcOXIEERERFb6u1Wrh5+dn8SAiIiL3JWuz1KxZszBu3Dh06tQJ3bp1w7Jly5CQkIBp06YBkGpdrly5gtWrVwMAFi1ahJiYGLRq1QqFhYX4/PPPsX79eqxfv17OyyAiIiInImtwM2rUKKSlpeGVV15BUlISWrdujU2bNiE6OhoAkJSUZDHmTWFhIZ555hlcuXIFnp6eaNWqFX766ScMGTJErksgIiIiJ6MQdWxUsYyMDAQEBCAxMZFNVERERC7ClDN78+ZN+Pv7V7qt7L2lHC0rKwsAqpRUTERERM4lKyvrlsFNnau5MRqNuHr1Knx9fW0+1ogpqqwLtUJ16VqBunW9vFb3VZeul9fqfoQQyMrKQmRk5C2H1KhzNTdKpRINGjSw6znqUq+sunStQN26Xl6r+6pL18trdS+3qrEx4WhiRERE5FYY3BAREZFbYXBjQ1qtFnPnzoVWq5W7KHZXl64VqFvXy2t1X3XpenmtdVudSygmIiIi98aaGyIiInIrDG6IiIjIrTC4ISIiIrfC4IaIiIjcCoObalq8eDFiY2Oh0+kQFxeH3bt3V7r9rl27EBcXB51Oh0aNGmHp0qUOKmnNLViwAJ07d4avry9CQ0MxfPhwnDp1qtJ9du7cCYVCUe7xzz//OKjUNTdv3rxy5Q4PD690H1e8rwAQExNj9T499thjVrd3pfv666+/YtiwYYiMjIRCocAPP/xg8boQAvPmzUNkZCQ8PT3Rp08f/P3337c87vr169GyZUtotVq0bNkS33//vZ2uoHoqu169Xo/nnnsObdq0gbe3NyIjIzF+/HhcvXq10mOuWrXK6v3Oz8+389VU7lb3duLEieXK3LVr11se1xnv7a2u1dr9USgUePvttys8prPeV3ticFMNa9euxYwZM/Diiy/iyJEj6NWrFwYPHmwxc3lpFy5cwJAhQ9CrVy8cOXIEL7zwAp588kmsX7/ewSWvnl27duGxxx7D77//jvj4eBQVFWHgwIHIycm55b6nTp1CUlKS+dG0aVMHlLj2WrVqZVHu48ePV7itq95XADh48KDFdcbHxwMAHnjggUr3c4X7mpOTg3bt2uGjjz6y+vpbb72FhQsX4qOPPsLBgwcRHh6OO++80zzfnDX79u3DqFGjMG7cOPz5558YN24cRo4cif3799vrMqqssuvNzc3FH3/8gTlz5uCPP/7Ad999h9OnT+Nf//rXLY/r5+dnca+TkpKg0+nscQlVdqt7CwB33XWXRZk3bdpU6TGd9d7e6lrL3psVK1ZAoVDgvvvuq/S4znhf7UpQlXXp0kVMmzbNYl3z5s3F888/b3X7Z599VjRv3txi3dSpU0XXrl3tVkZ7SElJEQDErl27Ktxmx44dAoC4ceOG4wpmI3PnzhXt2rWr8vbucl+FEOKpp54SjRs3Fkaj0errrnpfAYjvv//e/NxoNIrw8HDxxhtvmNfl5+cLf39/sXTp0gqPM3LkSHHXXXdZrBs0aJAYPXq0zctcG2Wv15oDBw4IAOLSpUsVbrNy5Urh7+9v28LZmLVrnTBhgrjnnnuqdRxXuLdVua/33HOP6NevX6XbuMJ9tTXW3FRRYWEhDh8+jIEDB1qsHzhwIPbu3Wt1n3379pXbftCgQTh06BD0er3dymprGRkZAICgoKBbbtuhQwdERESgf//+2LFjh72LZjNnzpxBZGQkYmNjMXr0aJw/f77Cbd3lvhYWFuLzzz/HQw89dMtJZF31vppcuHABycnJFvdNq9Wid+/eFf7+AhXf68r2cVYZGRlQKBQICAiodLvs7GxER0ejQYMGGDp0KI4cOeKYAtbSzp07ERoaittuuw0PP/wwUlJSKt3eHe7ttWvX8NNPP2Hy5Mm33NZV72tNMbipotTUVBgMBoSFhVmsDwsLQ3JystV9kpOTrW5fVFSE1NRUu5XVloQQmDVrFnr27InWrVtXuF1ERASWLVuG9evX47vvvkOzZs3Qv39//Prrrw4sbc3cfvvtWL16NX755Rf873//Q3JyMrp37460tDSr27vDfQWAH374ATdv3sTEiRMr3MaV72tppt/R6vz+mvar7j7OKD8/H88//zz+/e9/VzqxYvPmzbFq1Sps2LABX331FXQ6HXr06IEzZ844sLTVN3jwYHzxxRfYvn073n33XRw8eBD9+vVDQUFBhfu4w7397LPP4OvrixEjRlS6nave19qoc7OC11bZb7hCiEq/9Vrb3tp6Z/X444/j2LFj+O233yrdrlmzZmjWrJn5ebdu3ZCYmIh33nkHd9xxh72LWSuDBw82L7dp0wbdunVD48aN8dlnn2HWrFlW93H1+woAy5cvx+DBgxEZGVnhNq58X62p7u9vTfdxJnq9HqNHj4bRaMTixYsr3bZr164Wibg9evRAx44d8eGHH+KDDz6wd1FrbNSoUebl1q1bo1OnToiOjsZPP/1U6T9+V7+3K1aswNixY2+ZO+Oq97U2WHNTRcHBwVCpVOWi+pSUlHLRv0l4eLjV7T08PFCvXj27ldVWnnjiCWzYsAE7duxAgwYNqr1/165dXfKbgbe3N9q0aVNh2V39vgLApUuXsHXrVkyZMqXa+7rifTX1fqvO769pv+ru40z0ej1GjhyJCxcuID4+vtJaG2uUSiU6d+7scvc7IiIC0dHRlZbb1e/t7t27cerUqRr9Drvqfa0OBjdVpNFoEBcXZ+5dYhIfH4/u3btb3adbt27ltt+yZQs6deoEtVptt7LWlhACjz/+OL777jts374dsbGxNTrOkSNHEBERYePS2V9BQQFOnjxZYdld9b6WtnLlSoSGhuLuu++u9r6ueF9jY2MRHh5ucd8KCwuxa9euCn9/gYrvdWX7OAtTYHPmzBls3bq1RoG3EAJHjx51ufudlpaGxMTESsvtyvcWkGpe4+Li0K5du2rv66r3tVrkymR2RV9//bVQq9Vi+fLl4sSJE2LGjBnC29tbXLx4UQghxPPPPy/GjRtn3v78+fPCy8tLzJw5U5w4cUIsX75cqNVq8e2338p1CVXy6KOPCn9/f7Fz506RlJRkfuTm5pq3KXut7733nvj+++/F6dOnxV9//SWef/55AUCsX79ejkuolqefflrs3LlTnD9/Xvz+++9i6NChwtfX1+3uq4nBYBANGzYUzz33XLnXXPm+ZmVliSNHjogjR44IAGLhwoXiyJEj5t5Bb7zxhvD39xffffedOH78uBgzZoyIiIgQmZmZ5mOMGzfOovfjnj17hEqlEm+88YY4efKkeOONN4SHh4f4/fffHX59ZVV2vXq9XvzrX/8SDRo0EEePHrX4PS4oKDAfo+z1zps3T2zevFmcO3dOHDlyREyaNEl4eHiI/fv3y3GJZpVda1ZWlnj66afF3r17xYULF8SOHTtEt27dRP369V3y3t7qcyyEEBkZGcLLy0ssWbLE6jFc5b7aE4Obavr4449FdHS00Gg0omPHjhbdoydMmCB69+5tsf3OnTtFhw4dhEajETExMRV+GJ0JAKuPlStXmrcpe61vvvmmaNy4sdDpdCIwMFD07NlT/PTTT44vfA2MGjVKRERECLVaLSIjI8WIESPE33//bX7dXe6ryS+//CIAiFOnTpV7zZXvq6nbetnHhAkThBBSd/C5c+eK8PBwodVqxR133CGOHz9ucYzevXubtzdZt26daNasmVCr1aJ58+ZOE9hVdr0XLlyo8Pd4x44d5mOUvd4ZM2aIhg0bCo1GI0JCQsTAgQPF3r17HX9xZVR2rbm5uWLgwIEiJCREqNVq0bBhQzFhwgSRkJBgcQxXube3+hwLIcQnn3wiPD09xc2bN60ew1Xuqz0phCjOhCQiIiJyA8y5ISIiIrfC4IaIiIjcCoMbIiIicisMboiIiMitMLghIiIit8LghoiIiNwKgxsiIiJyKwxuiKhOUigU+OGHH+QuBhHZAYMbInK4iRMnQqFQlHvcddddcheNiNyAh9wFIKK66a677sLKlSst1mm1WplKQ0TuhDU3RCQLrVaL8PBwi0dgYCAAqcloyZIlGDx4MDw9PREbG4t169ZZ7H/8+HH069cPnp6eqFevHh555BFkZ2dbbLNixQq0atUKWq0WERERePzxxy1eT01Nxb333gsvLy80bdoUGzZsML9248YNjB07FiEhIfD09ETTpk3LBWNE5JwY3BCRU5ozZw7uu+8+/Pnnn3jwwQcxZswYnDx5EgCQm5uLu+66C4GBgTh48CDWrVuHrVu3WgQvS5YswWOPPYZHHnkEx48fx4YNG9CkSROLc7z88ssYOXIkjh07hiFDhmDs2LFIT083n//EiRP4+eefcfLkSSxZsgTBwcGOewOIqObknrmTiOqeCRMmCJVKJby9vS0er7zyihBCmpl+2rRpFvvcfvvt4tFHHxVCCLFs2TIRGBgosrOzza//9NNPQqlUiuTkZCGEEJGRkeLFF1+ssAwAxEsvvWR+np2dLRQKhfj555+FEEIMGzZMTJo0yTYXTEQOxZwbIpJF3759sWTJEot1QUFB5uVu3bpZvNatWzccPXoUAHDy5Em0a9cO3t7e5td79OgBo9GIU6dOQaFQ4OrVq+jfv3+lZWjbtq152dvbG76+vkhJSQEAPProo7jvvvvwxx9/YODAgRg+fDi6d+9eo2slIsdicENEsvD29i7XTHQrCoUCACCEMC9b28bT07NKx1Or1eX2NRqNAIDBgwfj0qVL+Omnn7B161b0798fjz32GN55551qlZmIHI85N0TklH7//fdyz5s3bw4AaNmyJY4ePYqcnBzz63v27IFSqcRtt90GX19fxMTEYNu2bbUqQ0hICCZOnIjPP/8cixYtwrJly2p1PCJyDNbcEJEsCgoKkJycbLHOw8PDnLS7bt06dOrUCT179sQXX3yBAwcOYPny5QCAsWPHYu7cuZgwYQLmzZuH69ev44knnsC4ceMQFhYGAJg3bx6mTZuG0NBQDB48GFlZWdizZw+eeOKJKpXvv//9L+Li4tCqVSsUFBRg48aNaNGihQ3fASKyFwY3RCSLzZs3IyIiwmJds2bN8M8//wCQejJ9/fXXmD59OsLDw/HFF1+gZcuWAAAvLy/88ssveOqpp9C5c2d4eXnhvvvuw8KFC83HmjBhAvLz8/Hee+/hmWeeQXBwMO6///4ql0+j0WD27Nm4ePEiPD090atXL3z99dc2uHIisjeFEELIXQgiotIUCgW+//57DB8+XO6iEJELYs4NERERuRUGN0RERORWmHNDRE6HreVEVBusuSEiIiK3wuCGiIiI3AqDGyIiInIrDG6IiIjIrTC4ISIiIrfC4IaIiIjcCoMbIiIicisMboiIiMitMLghIiIit/L/p4mcBx9pMPoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directorio_historico = './Historicos/historico_alexnet_arqu_batchsize/hist_alexNet_Simple3_64.csv' # cambiar directorio en caso que se emplee otro csv\n",
    "metrica_entrenamiento = 'auc' \n",
    "metrica_validacion = 'val_auc' \n",
    "\n",
    "graf_mejor_modelo_auc=grafica(directorio_historico, metrica_entrenamiento, metrica_validacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac42feb-ac71-4268-94b0-840dc14244c7",
   "metadata": {},
   "source": [
    "#### Gráfica con la métrica loss para el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a26e038-f31c-4f89-9369-5744bb4d8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHGCAYAAACB5Qr1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpK0lEQVR4nO3dd3wT5eMH8E+apumkAygtUNrKLnvKUpYiUxAFQWT7Y6OAA1AR0K/gRFSW+FWGky8iiOwhoLKXgoIguwqlzJbSnTy/P66XJm1aOpLcXfJ5v1559XK5uzyX6/j0GffohBACRERERBrlpXQBiIiIiEqDYYaIiIg0jWGGiIiINI1hhoiIiDSNYYaIiIg0jWGGiIiINI1hhoiIiDSNYYaIiIg0jWGGiIiINI1hhopt0KBBqF69Oq5du6Z0UagAjz/+OOrVq4ekpCSli0JEdmRlZaFFixZ46KGHkJWVpXRxNI9hxo0dO3YMw4cPR9WqVeHn5wc/Pz9Ur14dI0eOxKFDh0p0zE8++QSbN2/G5s2bUb58+Xyvr1ixAnXq1IGfnx90Oh1+++03zJgxAzqdrrSnoxk6nQ4zZsxw2vGHDBmCmJiYAl+fO3cuDhw4gI0bNyI4ONhp5XCEEydOYMaMGbhw4YLSRXGZmJgYDBkyxKnvsWfPHsyYMQO3b9926vso6cKFC9DpdFi6dKll3dKlS6HT6Yr0/dSuXTu0a9fOaeW71/FffPFFpKWl4fvvv4fBYHBaOTyGILe0aNEi4e3tLerUqSM+/PBDsW3bNrF9+3Yxb9480bp1awFAnDlzpljHPHLkiChXrpw4dOiQ3dcTExOFwWAQPXr0EDt37hR79+4Vd+/eFfHx8WLv3r2OOC1NACCmT5/utOOfOXNGHDlyxO5re/fuFeXKlRPHjx932vs70sqVKwUAsWPHDqWL4jJHjhwp9s9ecb377rsCgDh//rxT30dJ58+fFwDEkiVLLOsSExPF3r17RXp6+j33b9u2rWjbtq3Tyvfnn3+KP//80+5rq1atElWqVBH//vuv097f03grmqTIKXbv3o0xY8agW7du+O677+Dj42N5rUOHDhg7dixWrlwJPz+/Qo+TmpoKf39/y/NGjRoV2rR0+vRpZGVl4emnn0bbtm0t6/39/VG5cuVSnBFZq1q1aoGvtWjRwq2b//J+T2pRo0aNlC6C2ypfvrzdGmMlxMXFFfha79690bt3bxeWxv2xmckNzZo1C3q9Hp988olNkLHWp08fVKxY0fJ8yJAhCAwMxPHjx9GpUycEBQWhY8eOAICtW7eiZ8+eqFy5Mnx9fVGtWjWMHDkS169ft9m/TZs2AIAnn3wSOp3OUsVaUDPT119/jZYtWyIwMBCBgYFo2LAhPvvsM5ttPv/8czRo0AC+vr4ICwvDY489hpMnTxbpc0hISMDIkSNRuXJl+Pj4IDY2FjNnzkR2djYAqc06PDwcAwcOzLfv7du34efnh0mTJlnWXbp0CU8//TTCw8NhNBpRu3ZtvP/++zCbzYWWo6DzL6hK/F6fi71mpvT0dEydOhWxsbHw8fFBpUqVMHbs2HzNDDExMejevTs2bdqExo0bw8/PD7Vq1cLnn39e6DnIMjMz8Z///Ae1atWC0WhE+fLlMXTo0HwBqijvs3TpUvTp0wcA0L59e+h0Optmg3bt2qFu3br4+eef0apVK/j7+2PYsGEAgOTkZLzwwgs25zthwgTcvXvXphw6nQ7jxo3DF198gdq1a8Pf3x8NGjTAunXrbLY7c+YMhg4diurVq8Pf3x+VKlVCjx49cPz4cZvtdu7cCZ1Oh6+//hqTJ09GZGQkAgMD0aNHD1y9ehV37tzBiBEjUK5cOZQrVw5Dhw5FSkpKvs8mbzOTI89nxowZePHFFwEAsbGxls91586dAACz2Yx33nnHcg3Dw8MxaNAg/PPPP3avueyXX36BTqfDN998k++15cuXQ6fT4eDBg3b3/f3336HT6fL9fAPAxo0bodPpsHbtWgBFvxb22PuZEkLgnXfeQXR0NHx9fdG4cWNs3Lgx377p6el4/vnn0bBhQwQHByMsLAwtW7bEDz/8kG9bs9mMjz/+GA0bNoSfnx9CQkLQokULyzkA9puZbt68iTFjxqBSpUrw8fHBfffdh1deeQUZGRk22xX1+5asKF01RI6VnZ0t/Pz8RMuWLYu13+DBg4XBYBAxMTFi9uzZYvv27WLz5s1CCCHmzZsn3njjDbF69Wqxc+dOsWzZMlG/fn1Rs2ZNkZmZKYSQmj7mz58vAIhZs2aJvXv3WqpYp0+fLvJ+q02bNk0AEL179xYrV64UW7ZsEXPmzBHTpk2zbDNr1iwBQPTv31+sX79eLF++XNx3330iODhYnD59utDzuXLlioiKihLR0dHik08+Edu2bRNvvPGGMBqNYsiQIZbtJk6cKPz8/ERSUpLN/gsWLBAAxLFjx4QQUvV1pUqVRPny5cWiRYvEpk2bxLhx4wQAMXr0aJt9kaeZyd75CyHEkiVL8jUFFOVzGTx4sIiOjrY8N5vN4pFHHhHe3t5i2rRpYsuWLeK9994TAQEBolGjRjZV7tHR0aJy5coiLi5OLF++XGzevFn06dNHABC7du0q9DM1mUyic+fOIiAgQMycOVNs3bpV/Pe//xWVKlUScXFxIjU1tVjvk5iYaLnG8+fPF3v37hV79+4ViYmJQgipGSAsLExERUWJjz/+WOzYsUPs2rVL3L17VzRs2FCUK1dOzJkzR2zbtk18+OGHIjg4WHTo0EGYzWabaxETEyOaN28u/ve//4kNGzaIdu3aCW9vb3H27FnLdrt27RLPP/+8+O6778SuXbvE6tWrRa9evYSfn5/466+/LNvt2LFDABDR0dFiyJAhYtOmTWLRokUiMDBQtG/fXjz88MPihRdeEFu2bBFvv/220Ov1Yvz48TafY3R0tBg8eLDluaPPJz4+XowfP14AEN9//73lc5W/x0eMGCEAiHHjxlnKX758eREVFSWuXbtW6PdAo0aNROvWrfOtb9asmWjWrFmJ9u3bt68IDw8XWVlZxboW9pqZ7P1MyT9/w4cPFxs3bhSLFy8WlSpVEhERETbNTLdv3xZDhgwRX3zxhfjpp5/Epk2bxAsvvCC8vLzEsmXLbMo8cOBAodPpxDPPPCN++OEHsXHjRvHmm2+KDz/80LJN3mastLQ0Ub9+fREQECDee+89sWXLFjFt2jTh7e0tunbtanP8on7fUi6GGTeTkJAgAIh+/frley07O1tkZWVZHta/JAcPHiwAiM8//7xI73Pp0iUBQPzwww+WdfIv+pUrV9psm/eP+blz54RerxcDBgwo8Pi3bt0Sfn5++X7IL126JIxGo3jqqacKLd/IkSNFYGCguHjxos369957TwCwBK1jx44JAGLx4sU22zVv3lw0adLE8nzKlCkCgNi/f7/NdqNHjxY6nU6cOnXKsq6kYaYon4sQ+cPMpk2bBADxzjvv2Gy3YsWKfOcWHR0tfH19bT6XtLQ0ERYWJkaOHFno+37zzTcCgFi1apXN+oMHDwoAYsGCBcV+n8L6zLRt21YAENu3b7dZP3v2bOHl5SUOHjxos/67774TAMSGDRss6wCIChUqiOTkZMu6hIQE4eXlJWbPnl3guWZnZ4vMzExRvXp1MXHiRMt6+Xu8R48eNttPmDBBABDPPvuszfpevXqJsLAwm3V5w4wzzqegPjMnT54UAMSYMWNs1u/fv18AEC+//HKBn4kQud+zR48etaw7cOCAAJDvD35eH330kQBg87Ny8+ZNYTQaxfPPP1/gfgVdi6KEmVu3bglfX1/x2GOP2Rxz9+7dAkChfWbk35fDhw8XjRo1sqz/+eefBQDxyiuvFHq+ecPMokWLBADxv//9z2a7t99+WwAQW7Zssawr6fetJ2Mzkwdp0qQJDAaD5fH+++/n2+bxxx/Pt+7mzZuYNGkSatWqhTJlysDX1xfVq1cHgCI3+VjbunUrTCYTxo4dW+A2e/fuRVpaWr7q+KioKHTo0AHbt28v9D3WrVuH9u3bo2LFisjOzrY8unTpAgDYtWsXAKBevXpo0qQJlixZYtn35MmTOHDggKVJAwB++uknxMXFoXnz5jbvM2TIEAgh8NNPPxXp3AtTlM/FHvm9835Wffr0QUBAQL7PqmHDhqhSpYrlua+vL2rUqIGLFy8W+j7r1q1DSEgIevToYfOZNmzYEBEREZZmjNK+j7XQ0FB06NAhXznq1q2Lhg0b2pTjkUcesWlOkbVv3x5BQUGW5xUqVEB4eLhNObKzszFr1izExcXBx8cH3t7e8PHxwd9//233e7x79+42z2vXrg0A6NatW771N2/ezNfU5OzzKciOHTsA5P9ead68OWrXrn3Pn6v+/fsjPDwc8+fPt6z7+OOPUb58eTz55JOF7jtgwAAYjUab0UfffPMNMjIyMHToUMu64l6Lwuzduxfp6ekYMGCAzfpWrVohOjo63/YrV65E69atERgYCG9vbxgMBnz22Wc27ys3UZXk5zQgIABPPPGEzXr5WuT97EtznT0Rw4ybKVeuHPz8/Ox+w3/99dc4ePCgTbuuNX9/f5QpU8ZmnRACnTp1wjfffIMXX3wR27dvx9GjRy1Du9PS0opdRrl/RWGdgm/cuAEAiIyMzPdaxYoVLa8X5OrVq/jxxx9twpvBYECdOnUAwKa/z7Bhw7B371789ddfAIAlS5bAaDSif//+NuUpqCzW5S2Nonwu9ty4cQPe3t75Oj7qdDpERETkK1vZsmXzHcNoNN7zWl69ehW3b9+Gj49Pvs81ISHB5jMtzftYs/eZX716FceOHctXhqCgIAghSlSOSZMmYdq0aejVqxd+/PFH7N+/HwcPHkSDBg3sljcsLMzmudw3raD16enpBZ6jM86nIKX9uTIajRg5ciS+/vpr3L59G9euXcP//vc/PPPMMzAajYXuGxYWhkcffRTLly+HyWQCIPVxad68ueXnEij+tSjK+UZEROR7Le+677//Hn379kWlSpXw5ZdfYu/evTh48CCGDRtmc/2uXbsGvV5v95j3KktERES+/nPh4eHw9vZ22M+pp+JoJjej1+vRoUMHbNmyBVeuXLH5pSX3ri/oHgz2Oqn+8ccfOHz4MJYvX27TUfb06dMlLqP8R/eff/5BVFSU3W3kH+QrV67ke+3y5csoV65coe9Rrlw51K9fH2+++abd1607P/fv3x+TJk3C0qVL8eabb+KLL75Ar169EBoaalOegsoiv19BfH19AQAZGRk2v/Dz/pEqyudiT9myZZGdnY1r167ZBBohBBISEtCsWbMiH6sw5cqVQ9myZbFp0ya7r1v/F+ko9r4n5cBeUKfle31v2PPll19i0KBBmDVrls3669evIyQkpNjHKw5nnE9BrH+u8obmovxcAcDo0aPx1ltv4fPPP0d6ejqys7MxatSoIr3/0KFDsXLlSmzduhVVqlTBwYMHsXDhQpttHHkt5PNNSEjI91pCQoJNR/ovv/wSsbGxWLFihc33Xd7OueXLl4fJZEJCQoLdUFhYWfbv3w8hhM3xExMTkZ2d7dDr7IlYM+OGpk6dCpPJhFGjRpX6zpJCCABSSLK2aNGiEh+zU6dO0Ov1+X6JWWvZsiX8/Pzw5Zdf2qz/559/8NNPP1lGWhWke/fu+OOPP1C1alU0bdo038M6zISGhqJXr15Yvnw51q1bh4SEBJsmJgDo2LEjTpw4gSNHjtisl0dxtG/fvsCyyL8wjx07ZrP+xx9/tHlelM/FHvmzyPtZrVq1Cnfv3r3nZ1VU3bt3x40bN2Aymex+pjVr1iz2MeVwV5z/Nrt3746zZ8+ibNmydstR2A0FC6LT6fLVLKxfvx7//vtvsY9VXM44n4I+V7nJLu/3ysGDB3Hy5Mkifa9ERkaiT58+WLBgARYtWoQePXrYNCcWplOnTqhUqRKWLFmCJUuWwNfX16YGFHDstWjRogV8fX3x1Vdf2azfs2dPvtprnU4HHx8fm6CRkJCQbzST3FRdkp/TlJQUrFmzxmb98uXLLa9TybFmxg21bt0a8+fPx/jx49G4cWOMGDECderUgZeXF65cuYJVq1YBQL4mJXtq166N++67D1OnToUQAmXLlsXatWuxbdu2EpcvJiYGL7/8Mt544w2kpaWhf//+CA4OxokTJ3D9+nXMnDkTISEhmDZtGl5++WUMGjQI/fv3x40bNzBz5kz4+vpi+vTphb7H66+/jq1bt6JVq1Z49tlnUbNmTaSnp+PChQvYsGEDFi1aZPOf6bBhw7BixQqMGzcOlStXxkMPPWRzvIkTJ2L58uXo1q0bXn/9dURHR2P9+vVYsGABRo8ejRo1ahRYlq5duyIsLAzDhw/H66+/Dm9vbyxduhTx8fHF/lzsefjhh/HII49g8uTJSE5ORuvWrXHs2DFMnz4djRo1sjv0vCT69euHr776Cl27dsVzzz2H5s2bw2Aw4J9//sGOHTvQs2dPPPbYY8U6Zt26dQEAixcvRlBQEHx9fREbG2u3il02YcIErFq1Cg8++CAmTpyI+vXrw2w249KlS9iyZQuef/553H///cUqR/fu3bF06VLUqlUL9evXx+HDh/Huu++65P5IzjifevXqAQA+/PBDDB48GAaDATVr1kTNmjUxYsQIfPzxx/Dy8kKXLl1w4cIFTJs2DVFRUZg4cWKRjv/cc89ZymTd3+xe9Ho9Bg0ahDlz5qBMmTLo3bt3vrtUO/JahIaG4oUXXsB//vMfPPPMM+jTpw/i4+MxY8aMfM1E3bt3x/fff48xY8bgiSeeQHx8PN544w1ERkbi77//tmz3wAMPYODAgfjPf/6Dq1evonv37jAajTh69Cj8/f0xfvx4u2UZNGgQ5s+fj8GDB+PChQuoV68efv31V8yaNQtdu3bN9zuHikm5vsfkbL/99psYOnSoiI2NFUajUfj6+opq1aqJQYMG5RshMnjwYBEQEGD3OCdOnBAPP/ywCAoKEqGhoaJPnz6W0UzWo3aKOppJtnz5ctGsWTPh6+srAgMDRaNGjWxGJgghxH//+19Rv3594ePjI4KDg0XPnj0LvKtmXteuXRPPPvusiI2NFQaDQYSFhYkmTZqIV155RaSkpNhsazKZRFRUVKGjFC5evCieeuopUbZsWWEwGETNmjXFu+++K0wmk812eT8XIaQRH61atRIBAQGiUqVKYvr06eK///2v3REn9/pc8o5mEkIaKTR58mQRHR0tDAaDiIyMFKNHjxa3bt2y2S46Olp069Yt37kV9W6oWVlZ4r333hMNGjSwlK9WrVpi5MiR4u+//y7R+8ydO1fExsYKvV5vMzqlbdu2ok6dOnbLkZKSIl599VVRs2ZNy/dGvXr1xMSJE0VCQoJlOwBi7Nix+fbPO6Lo1q1bYvjw4SI8PFz4+/uLNm3aiF9++SVfeQv6HpdH0eQdkSR/71sPec773s44HyGEmDp1qqhYsaLw8vKyGTFmMpnE22+/LWrUqCEMBoMoV66cePrpp0V8fHy+4xYmJiZG1K5du1j7CCHE6dOnBQABQGzdujXf60W9FkUdmm02m8Xs2bNFVFSU8PHxEfXr1xc//vij3e/Ft956S8TExAij0Shq164tPv30U7u/v0wmk/jggw9E3bp1LderZcuW4scff7RsY+/4N27cEKNGjRKRkZHC29tbREdHi6lTp+a7Y3FxrjNJdELktCMQEREVwbFjx9CgQQPMnz8fY8aMUbo4RGCYISKiIjl79iwuXryIl19+GZcuXcKZM2c0P70EuQd2ACYioiJ544038PDDDyMlJQUrV65kkCHVYM0MERERaRprZoiIiEjTGGaIiIhI0xhmiIiISNPc/qZ5ZrMZly9fRlBQkN1boxMREZH6CCFw584dVKxYEV5ehde9uH2YuXz5crHmuSEiIiL1iI+Pv+cdoN0+zMiT38XHxxfp9v1ERESkvOTkZERFRRVpElu3DzNy01KZMmUYZoiIiDSmKF1E2AGYiIiINI1hhoiIiDSNYYaIiIg0ze37zBARUemZTCZkZWUpXQxyIwaDAXq93iHHYpghIqICCSGQkJCA27dvK10UckMhISGIiIgo9X3gGGaIiKhAcpAJDw+Hv78/bz5KDiGEQGpqKhITEwEAkZGRpToewwwREdllMpksQaZs2bJKF4fcjJ+fHwAgMTER4eHhpWpyYgdgIiKyS+4j4+/vr3BJyF3J31ul7Y/FMENERIVi0xI5i6O+txhmiIiISNMYZoiIiNxYTEwM5s6dq3QxnIphhoiI3M6QIUOg0+nyPTp37lyk/Xfu3AmdTucWQ9IPHjyIESNGOPSY7dq1w4QJExx6zNLgaCYiIgLMJsCUBRh8lS6Jw3Tu3BlLliyxWWc0Gh36HpmZmfDx8XHoMR2tfPnyShfB6VgzQ0REwLIewEcNgcxUpUviMEajERERETaP0NBQAFLH0//+97947LHH4O/vj+rVq2Pt2rUAgAsXLqB9+/YAgNDQUOh0OgwZMgSAVCMxbtw4TJo0CeXKlcPDDz8MADhx4gS6du2KwMBAVKhQAQMHDsT169ctZWnXrh2effZZvPTSSwgLC0NERARmzJhhU945c+agXr16CAgIQFRUFMaMGYOUlBTL60uXLkVISAjWrVuHmjVrwt/fH0888QTu3r2LZcuWISYmBqGhoRg/fjxMJpNlv7zNTElJSRgxYgTCw8NRpkwZdOjQAb///rvl9RkzZqBhw4b44osvEBMTg+DgYPTr1w937twBINV67dq1Cx9++KGlxuvChQsAgF27dqF58+YwGo2IjIzElClTkJ2dXYqrWDQMM0REns5sAi7uAe5cAW6dL3RTIQRSM7Nd/hBCOPy0Z86cib59++LYsWPo2rUrBgwYgJs3byIqKgqrVq0CAJw6dQpXrlzBhx9+aNlv2bJl8Pb2xu7du/HJJ5/gypUraNu2LRo2bIhDhw5h06ZNuHr1Kvr27WvzfsuWLUNAQAD279+Pd955B6+//jq2bt1qed3LywsfffQR/vjjDyxbtgw//fQTXnrpJZtjpKam4qOPPsK3336LTZs2YefOnejduzc2bNiADRs24IsvvsDixYvx3Xff2T1nIQS6deuGhIQEbNiwAYcPH0bjxo3RsWNH3Lx507Ld2bNnsWbNGqxbtw7r1q3Drl278NZbbwEAPvzwQ7Rs2RL/93//hytXruDKlSuIiorCv//+i65du6JZs2b4/fffsXDhQnz22Wf4z3/+U7oLVQRsZiIi8nRptwHkhIXUm4VtibQsE+Je2+z0IuV14vVH4O9TvD9Z69atQ2BgoM26yZMnY9q0aQCkGob+/fsDAGbNmoWPP/4YBw4cQOfOnREWFgYACA8PR0hIiM0xqlWrhnfeecfy/LXXXkPjxo0xa9Ysy7rPP/8cUVFROH36NGrUqAEAqF+/PqZPnw4AqF69OubNm4ft27dbanes+6DExsbijTfewOjRo7FgwQLL+qysLCxcuBBVq1YFADzxxBP44osvcPXqVQQGBiIuLg7t27fHjh078OSTT+b7THbs2IHjx48jMTHR0uT23nvvYc2aNfjuu+8sfWvMZjOWLl2KoKAgAMDAgQOxfft2vPnmmwgODoaPjw/8/f0RERFhOfaCBQsQFRWFefPmQafToVatWrh8+TImT56M1157DV5ezqs/YZghIvJ0aVYBJu2WcuVwsPbt22PhwoU26+SQAkjhQhYQEICgoCDL7fUL07RpU5vnhw8fxo4dO/IFJ0Cq4bAOM9YiIyNt3m/Hjh2YNWsWTpw4geTkZGRnZyM9PR13795FQEAAAOkmc3KQAYAKFSogJibG5r0rVKhQ4HkcPnwYKSkp+e7onJaWhrNnz1qex8TEWIKMvbLac/LkSbRs2dLm3jGtW7dGSkoK/vnnH1SpUqXQ/UuDYYaIyNOl3shdTiu8ZsbPoMeJ1x9xcoHsv29xBQQEoFq1agW+bjAYbJ7rdDqYzeYiHdea2WxGjx498Pbbb+fb1nrOocLe7+LFi+jatStGjRqFN954A2FhYfj1118xfPhwm7vj2jtGcc7DbDYjMjISO3fuzPeadQ1UST4bIUS+m+DJzYPOvvEiwwwRkadLLXrNjE6nK3ZzjxbJI5SsO9IWpHHjxli1ahViYmLg7V2yz+bQoUPIzs7G+++/b2mO+d///leiYxWmcePGSEhIgLe3N2JiYkp8HB8fn3yfTVxcHFatWmUTavbs2YOgoCBUqlSpNMW+J3YAJiLydNY1M/foM6MlGRkZSEhIsHlYjzAqTHR0NHQ6HdatW4dr167ZjCrKa+zYsbh58yb69++PAwcO4Ny5c9iyZQuGDRtWpDAEAFWrVkV2djY+/vhjnDt3Dl988QUWLVpUpH2L46GHHkLLli3Rq1cvbN68GRcuXMCePXvw6quv4tChQ0U+TkxMDPbv348LFy7g+vXrMJvNGDNmDOLj4zF+/Hj89ddf+OGHHzB9+nRMmjTJqf1lAIYZIiKy6TPjPmFm06ZNiIyMtHm0adOmSPtWqlQJM2fOxJQpU1ChQgWMGzeuwG0rVqyI3bt3w2Qy4ZFHHkHdunXx3HPPITg4uMh/xBs2bIg5c+bg7bffRt26dfHVV19h9uzZRdq3OHQ6HTZs2IAHH3wQw4YNQ40aNdCvXz9cuHABFSpUKPJxXnjhBej1esTFxaF8+fK4dOkSKlWqhA0bNuDAgQNo0KABRo0aheHDh+PVV191+HnkpRPOGO+mIsnJyQgODkZSUhLKlCmjdHGIiNRn62vA7pyhx7W6A/2+AgCkp6fj/PnziI2Nha+v+9xMj9SjsO+x4vz9Zs0MEZGns25acqNmJvIcDDNERJ4u1T2bmchzMMwQEXk6N73PDHkOhhkiIk+XdzSTe3elJDfEMENE5Omsm5nMWUDmXeXKQlQCDDNERJ7MbM7ftMR+M6QxDDNERJ4sIwkQOTd288uZt4gjmkhjGGaIiDyZHFx8AoGgnBmQ2QmYNEbRMPPzzz+jR48eqFixInQ6HdasWWPzuhACM2bMQMWKFeHn54d27drhzz//VKawRETuSA4zfmGAX6i0zGYm1Ttz5gxmzZqFtLQ0pYuiCoqGmbt376JBgwaYN2+e3dffeecdzJkzB/PmzcPBgwcRERGBhx9+GHfu3HFxSYmI3JQcXPytwgybmdCuXTtMmDDB8jwmJgZz584tdB97/5SXRkHvmZ6ejj59+lj+0SeFZ83u0qULunTpYvc1IQTmzp2LV155Bb179wYALFu2DBUqVMDXX3+NkSNHurKoRETuSR6W7R8mPQAg7bZixXGEHj16IC0tDdu2bcv32t69e9GqVSscPnwYjRs3LvIxDx48iICAAEcWs8TvOWHCBPTq1QtDhgxxaXnUTLXzuJ8/fx4JCQno1KmTZZ3RaETbtm2xZ8+eAsNMRkYGMjIyLM+Tk5OdXlYiIs2Sa2H8y7pNM9Pw4cPRu3dvXLx4EdHR0Tavff7552jYsGGxggwAlC9f3pFFLNV7OmM2ba1TbQfghIQEAMg3i2eFChUsr9kze/ZsBAcHWx5RUVFOLScRkabJNTN+YbmjmTTeAbh79+4IDw/H0qVLbdanpqZixYoV6NWrF/r374/KlSvD398f9erVwzfffFPoMfM2+fz999948MEH4evri7i4OGzdujXfPpMnT0aNGjXg7++P++67D9OmTUNWVpbNNmvXrkXTpk3h6+uLcuXKWVoi7L3npUuX0LNnTwQGBqJMmTLo27cvrl69anl9xowZaNiwIb744gvExMQgODgY/fr184iuGaoNMzKdTmfzXAiRb521qVOnIikpyfKIj493dhGJiLQrzU7NTGF9ZoSQbqrn6kcx7krs7e2NQYMGYenSpRBW+61cuRKZmZl45pln0KRJE6xbtw5//PEHRowYgYEDB2L//v1FOr7ZbEbv3r2h1+uxb98+LFq0CJMnT863XVBQEJYuXYoTJ07gww8/xKeffooPPvjA8vr69evRu3dvdOvWDUePHsX27dvRtGnTAj52gV69euHmzZvYtWsXtm7dirNnz+LJJ5+02e7s2bNYs2YN1q1bh3Xr1mHXrl146623inReWqbaZqaICGmIYEJCAiIjIy3rExMT89XWWDMajTAajU4vHxGRW7DbZ6aQMJOVCsyq6Pxy5fXyZcCn6H1Whg0bhnfffRc7d+5E+/btAUhNTL1790alSpXwwgsvWLYdP348Nm3ahJUrV+L++++/57G3bduGkydP4sKFC6hcuTIAYNasWfn6gL766quW5ZiYGDz//PNYsWIFXnrpJQDAm2++iX79+mHmzJmW7Ro0aFDgex47dgznz5+3tDh88cUXqFOnDg4ePIhmzZoBkILW0qVLERQUBAAYOHAgtm/fjjfffPOe56Vlqq2ZiY2NRUREhE3VXWZmJnbt2oVWrVopWDIiIjeSmtOk5O8+zUwAUKtWLbRq1Qqff/45AKnG4pdffsGwYcNgMpnw5ptvon79+ihbtiwCAwOxZcsWXLp0qUjHPnnyJKpUqWIJMgDQsmXLfNt99913aNOmDSIiIhAYGIhp06bZvMdvv/2Gjh07Fvk9o6KibLpOxMXFISQkBCdPnrSsi4mJsQQZAIiMjERiYmKR3kPLFK2ZSUlJwZkzZyzPz58/j99++w1hYWGoUqUKJkyYgFmzZqF69eqoXr06Zs2aBX9/fzz11FMKlpqIyI3Y9JkpQjOTwV+qJXE1g3+xdxk+fDjGjRuH+fPnY8mSJYiOjkbHjh3x7rvv4oMPPsDcuXNRr149BAQEYMKECcjMzCzScYWdJq+83R/27dtnqXV55JFHEBwcjG+//Rbvv/++ZZviDKsuqItF3vUGgyFfucxmc5HfR6sUDTOHDh2yVP8BwKRJkwAAgwcPxtKlS/HSSy8hLS0NY8aMwa1bt3D//fdjy5YtNqmTiIhKwbrPjNzMlH5bmrPJHp2uWM09Surbty+ee+45fP3111i2bBn+7//+DzqdDr/88gt69uyJp59+GoDUNPP333+jdu3aRTpuXFwcLl26hMuXL6NiRanJbe/evTbb7N69G9HR0XjllVcs6y5evGizTf369bF9+3YMHTq0yO8ZHx9vqZ05ceIEkpKSilxud6ZomGnXrp3dhCvT6XSYMWMGZsyY4bpCERF5CiGshmZb1cwIszRnk07bN2QLDAzEk08+iZdffhlJSUmW+7JUq1YNq1atwp49exAaGoo5c+YgISGhyKHgoYceQs2aNTFo0CC8//77SE5Otgkt8ntcunQJ3377LZo1a4b169dj9erVNttMnz4dHTt2RNWqVdGvXz9kZ2dj48aNlj41ed+zfv36GDBgAObOnYvs7GyMGTMGbdu2LbDTsCdRbZ8ZIiJysow7gDlnqLBfGOBtBAw5tS5uchfg4cOH49atW3jooYdQpUoVAMC0adPQuHFjPPLII2jXrh0iIiLQq1evIh/Ty8sLq1evRkZGBpo3b45nnnkmXwfbnj17YuLEiRg3bhwaNmyIPXv2YNq0aTbbtGvXDitXrsTatWvRsGFDdOjQocARVfLdhUNDQ/Hggw/ioYcewn333YcVK1YU7wNxUzpRWNWIG0hOTkZwcDCSkpJQpkwZpYtDRKQety4AHzYAvP2AV3Pu3/VBXSApHnjmJ6SXq4Pz588jNjYWvr6+ihaV3FN6enqB32PF+fvNmhkiIk9lPSxb5hcifdX4XYDJszDMEBF5Kuth2TJ5eLabNDORZ2CYISLyVNbDsmX+7nOvGfIcDDNERJ7Keli2zE0mmyTPwjBDROSp7PaZyV8z4+bjREhBjvreYpghIvJUqXZqZvxz+8zId5NNTU11ccHIU8jfW3nvXFxcqp1okoiInMxenxmrZia9Xo+QkBDL3D7+/v52b6lPVFxCCKSmpiIxMREhISHQ6/WlOh7DDBGRp7LbZ8a2mSkiIgIAPGKyQnK9kJAQy/dYaTDMEBF5KsvQ7NDcdXkmm9TpdIiMjER4eDiysrJcXEByZwaDodQ1MjKGGSIiT1WModl6vd5hf3iIHI0dgImIPJEQhTczZSQDJtbEkDYwzBAReaKsVCA7XVq2HprtG5y7nHbbpUUiKimGGSIiTyQPy9b7AD6Buev13rmBhncBJo1gmCEi8kTW/WXyDrfmXYBJYxhmiIg8kb3+MjJONkkawzBDROSJLHf/Dcv/GiebJI1hmCEi8kSFhRk2M5HGMMwQEXkie/eYkbGZiTSGYYaIyBMV1meGzUykMQwzRESeiM1M5EYYZoiIPFFRmplYM0MawTBDROSJCh2aLU82yTBD2sAwQ0TkiQodms1mJtIWhhkiIk9UaJ8ZNjORtjDMEBF5mqx0IOuutGy3z0xOzUxWqrQtkcoxzBAReRq5+Uint50lW+YbLL1mvS2RijHMEBF5Gnkkk7+dSSYBaZ1leDabmkj9GGaIiDxNaiEjmWSWEU2smSH1Y5ghIvI0hd1jRsa7AJOGMMwQEXmatEJGMsl4F2DSEIYZIiJPI98Mr9Aww8kmSTsYZoiIPA2bmcjNMMwQEXmawqYykPmF2G5LpGIMM0REnsZ6aHZBLM1MrJkh9WOYISLyNEUZms1mJtIQhhkiIk9TlD4zHM1EGsIwQ0TkaeTalkL7zLBmhrSDYYaIyJNkZwIZydJyUe4zk3oTEML55SIqBYYZIiJPIte06LzsTzIpk4OOOQvITHF+uYhKgWGGiMiTyP1lfEMAL33B2xn8Ab1RWmZTE6kcwwwRkScpyj1mANuZs3kXYFI5hhkiIk9SlHvMyCzDsxlmSN0YZoiIPIlcy1LYsGyZZXg2m5lI3RhmiIg8SVGbmQA2M5FmMMwQEXkSy91/Q++9raWZ6bbTikPkCAwzRESepChTGch4F2DSCIYZIiJPUpSpDGSWySYZZkjdGGaIiDxJcfrMcLJJ0giGGSIiT1KcodlsZiKNYJghIvIkxeozw5oZ0gaGGSIiT2HKBtJvS8vFuc8M+8yQyqk6zGRnZ+PVV19FbGws/Pz8cN999+H111+H2WxWumhERNojBxkgN6gURm6KSr8N8PcuqZi30gUozNtvv41FixZh2bJlqFOnDg4dOoShQ4ciODgYzz33nNLFIyLSFsskk8GAvgi//uXAI8xARlLRAhCRAlQdZvbu3YuePXuiW7duAICYmBh88803OHTokMIlIyLSoOJMZQAA3kbAEABk3ZX2ZZghlVJ1M1ObNm2wfft2nD59GgDw+++/49dff0XXrl0L3CcjIwPJyck2DyIiQvGGZcs4PJs0QNU1M5MnT0ZSUhJq1aoFvV4Pk8mEN998E/379y9wn9mzZ2PmzJkuLCURkUYUZ1i2zC8USIpnmCFVU3XNzIoVK/Dll1/i66+/xpEjR7Bs2TK89957WLZsWYH7TJ06FUlJSZZHfHy8C0tMRKRixRmWLeOIJtIAVdfMvPjii5gyZQr69esHAKhXrx4uXryI2bNnY/DgwXb3MRqNMBqNriwmEZE2FGcqAxmbmUgDVF0zk5qaCi8v2yLq9XoOzSYiKglLn5liNjNZ70ukQqqumenRowfefPNNVKlSBXXq1MHRo0cxZ84cDBs2TOmiERFpT2pJwgwnmyT1U3WY+fjjjzFt2jSMGTMGiYmJqFixIkaOHInXXntN6aIREWlPSfrMsJmJNEDVYSYoKAhz587F3LlzlS4KEZH2laTPDJuZSANU3WeGiIgcqCT3mWEzE2kAwwwRkScwm3ObiorTZ4bNTKQBDDNERJ4g/bY0xxJQwmYmhhlSL4YZIiJPIIcRnyDA26fo+8nBJyMZMGU5vlxEDsAwQ0TkCSxTGRRzskjf4NzltNsOKw6RIzHMEBF5gpIMywYAvXduoOGIJlIphhkiIk9QkmHZMj92AiZ1Y5ghIvIEJRmWLeNkk6RyDDNERJ7A0memBDUzluHZDDOkTgwzRESeoKR9ZgA2M5HqMcwQEXkCS5+ZYo5mst6HzUykUgwzRESewHL33xLUzPAuwKRyDDNERJ6gNH1mONkkqRzDDBGRJ5CbiEozNJvNTKRSDDNERO5OiNINzZbvGsw7AJNKMcwQEbm7jGTAnC0ts5mJ3BDDDBGRu5Obhwz+gMGv+PuzmYlUjmGGiMjdlaa/DJBbM5OdBmSlOaZMRA7EMENE5O4s/WVKGGZ8gwGdPudYHJ5N6sMwQ0Tk7kozLBsAdDqrfjMMM6Q+DDNERO6uNFMZyHgXYFIxhhkiIndnmcqghDUzACebJFVjmCEicneluceMjJNNkooxzBARubvS9pkB2MxEqsYwQ0Tk7ko7NBvgZJOkagwzRETuLrWUQ7MBwC9E+so+M6RCDDNERO6utPeZAazuAsyaGVIfhhkiIncmhGOGZrOZiVSMYYaIyJ1l3gVMGdJyafrMcLJJUjGGGSIidyaHD70R8Ako+XE42SSpGMMMEZE7sx6WrdOV/DjWzUxClL5cRA7EMENE5M4c0V8GyG1mMmcBmSmlOxaRgzHMEBG5M8s9ZkJLdxyDv9RUBbATMKkOwwwRkTtzxFQGgO3M2ew3QyrDMENE5M4cMZWBjJNNkkoxzBARuTNHTGUg42STpFIMM0RE7sxSM1PKZiYgd0oDNjORyjDMEBG5M0dMZSDjXYBJpRhmiIjcmaOGZgNsZiLVYpghInJnDu0zw9FMpE4MM0RE7ozNTOQBGGaIiNxVVhqQlSotOyLMcLJJUimGGSIidyU3B3l5A8YypT8eJ5sklWKYISJyV/KwbL9STjIpYzMTqRTDDBGRu3LUVAYyuZkp/TZgNjvmmEQOwDBDROSuHDmVAZAbZoRZCjREKsEwQ0Tkrhw1Y7bM2wgYAqRlNjWRijDMEBG5K0feME/GfjOkQgwzRETuypH3mJFZhmczzJB6MMwQEbkrR04yKeNdgEmFGGaIiNyVI6cykFmamRhmSD0YZoiI3JWjh2YDnGySVEn1Yebff//F008/jbJly8Lf3x8NGzbE4cOHlS4WEZH6OXpoNsBmJlIlb6ULUJhbt26hdevWaN++PTZu3Ijw8HCcPXsWISEhSheNiEj9UnNqT5wymolhhtRD1WHm7bffRlRUFJYsWWJZFxMTo1yBiIi0IjsTyLwjLTvqPjPWx2IzE6mIqpuZ1q5di6ZNm6JPnz4IDw9Ho0aN8OmnnypdLCIi9ZNrTnRegG+I447LySZJhVQdZs6dO4eFCxeievXq2Lx5M0aNGoVnn30Wy5cvL3CfjIwMJCcn2zyIiDyOZZLJUMDLgb/qedM8UiFVNzOZzWY0bdoUs2bNAgA0atQIf/75JxYuXIhBgwbZ3Wf27NmYOXOmK4tJRKQ+zhiWDbCZiVRJ1TUzkZGRiIuLs1lXu3ZtXLp0qcB9pk6diqSkJMsjPj7e2cUkIlIfZ9wwD8gNRxnJgCnLsccmKiFV18y0bt0ap06dsll3+vRpREdHF7iP0WiE0Wh0dtGIiNTNGVMZAIBfiNV73AYCyzv2+EQloOqamYkTJ2Lfvn2YNWsWzpw5g6+//hqLFy/G2LFjlS4aEZG6OeMeMwDgpQd8g6VlDs8mlVB1mGnWrBlWr16Nb775BnXr1sUbb7yBuXPnYsCAAUoXjYhI3eR7zDi6z4z1MTmiiVRC1c1MANC9e3d0795d6WIQEWmLM6YykPmFArfOsxMwqYaqa2aIiKiEnNXMZH1MNjORSjDMEBG5o1Rn1szwXjOkLgwzRETuyHLTPGf0meFkk6QuDDNERO7ImX1m2MxEKlOiMLNs2TKsX7/e8vyll15CSEgIWrVqhYsXLzqscEREVAKmbCA9SVp2Rp8ZNjORypQozMyaNQt+fn4AgL1792LevHl45513UK5cOUycONGhBSQiomKyDhmOnGRSxmYmUpkSDc2Oj49HtWrVAABr1qzBE088gREjRqB169Zo166dI8tHRETFJfeX8Q0B9E64A4e/PD/Tbccfm6gESlQzExgYiBs3pB+WLVu24KGHHgIA+Pr6Ii0tzXGlIyKi4nPWVAYyy2STrJkhdShRZH/44YfxzDPPoFGjRjh9+jS6desGAPjzzz8RExPjyPIREVFxOWuSSRnvAEwqU6Kamfnz56Nly5a4du0aVq1ahbJlpR+Yw4cPo3///g4tIBERFZMcMpwxLBvIrfHJTgOyWBtPyitRzUxISAjmzZuXb/3MmTNLXSAiIiolZw7LBgBjGUCnB4RJ6mxs8HPO+xAVUYlqZjZt2oRff/3V8nz+/Plo2LAhnnrqKdy6xaF6RESKcuZUBgCg03FEE6lKicLMiy++iOTkZADA8ePH8fzzz6Nr1644d+4cJk2a5NACEhFRMckzZjsrzFgfm/eaIRUoUTPT+fPnERcXBwBYtWoVunfvjlmzZuHIkSPo2rWrQwtIRETF5MypDGQc0UQqUqKaGR8fH6SmpgIAtm3bhk6dOgEAwsLCLDU2RESkEGf3mQF4F2BSlRLVzLRp0waTJk1C69atceDAAaxYsQIAcPr0aVSuXNmhBSQiomJydp8ZgH1mSFVKVDMzb948eHt747vvvsPChQtRqVIlAMDGjRvRuXNnhxaQiIiKydlDswFONkmqUqKamSpVqmDdunX51n/wwQelLhAREZWC2ZTb9OPUZia5zwybmUh5JZ60w2QyYc2aNTh58iR0Oh1q166Nnj17Qq/XO7J8RERUHOlJAIS0LAcOZ7A0MzHMkPJKFGbOnDmDrl274t9//0XNmjUhhMDp06cRFRWF9evXo2rVqo4uJxERFYXcX8ZYBvD2cd77sJmJVKREfWaeffZZVK1aFfHx8Thy5AiOHj2KS5cuITY2Fs8++6yjy0hEREVl6S/jxFoZ6+OzmYlUoEQ1M7t27cK+ffsQFpbbuaxs2bJ466230Lp1a4cVjoiIisnZk0zKONkkqUiJamaMRiPu3LmTb31KSgp8fJxYrUlERIWz3GPGiSOZrI+fdgsQwrnvRXQPJQoz3bt3x4gRI7B//34IISCEwL59+zBq1Cg8+uijji4jEREVVaoLbpgH5DYzmbOAzBTnvhfRPZQozHz00UeoWrUqWrZsCV9fX/j6+qJVq1aoVq0a5s6d6+AiEhFRkbliKgMAMPgDemPOe7KpiZRVoj4zISEh+OGHH3DmzBmcPHkSQgjExcWhWrVqji4fEREVhyumMgCkmbP9w4A7V6SmptBo574fUSGKHGbuNRv2zp07Lctz5swpcYGIiKgULM1MTh7NBEhNTXeucHg2Ka7IYebo0aNF2k6n05W4MEREVEqumMpAxhFNpBJFDjM7duxwZjmIiMgRXDU0GwD8QqSvvNcMKaxEHYCJiEilXDU02/o9GGZIYQwzRETuQgjXDc0GcpuZGGZIYQwzRETuIj0JECZp2SV9ZuTJJtlnhpTFMENE5C7k/jKGAMDg6/z342STpBIMM0RE7kJu7nFFfxmAzUykGgwzRETuItWFnX8BNjORajDMEBG5C1dNZSBjMxOpBMMMEZG7cNVUBjK5ZibtNmA2u+Y9iexgmCEicheWG+a5uM8MBJB+2zXvSWQHwwwRkbtw5VQGAODtA/gESsvsBEwKYpghInIXrpzKQGZpamKYIeUwzBARuQtXD80GOKKJVIFhhojIXbi6z4z1e7FmhhTEMENE5C5c3WcGsGpmYs0MKYdhhojIHQihUJ+ZnODEZiZSEMMMEZE7yEwBzFnSshJ9ZtjMRApimCEicgdyzYi3L2Dwd9378i7ApAIMM0RE7sB6KgOdznXvy8kmSQUYZoiI3IGrpzKQcWg2qQDDDBGRO7DMmB3q2vdlMxOpAMMMEZE7UGJYtvX7pd127fsSWWGYISJyB0oMywZym5kykgFTlmvfmygHwwwRkTuw9Jlxdc1MiFUZbrv2vYlyMMwQEbkDpWpmvPSAb7C0zH4zpBBNhZnZs2dDp9NhwoQJSheFiEhdlOozY/2eHNFECtFMmDl48CAWL16M+vXrK10UIiL1SVVoaDbAySZJcZoIMykpKRgwYAA+/fRThIa6eNghEZEWpCk0NBvgZJOkOE2EmbFjx6Jbt2546KGH7rltRkYGkpOTbR5ERG5PyZoZNjORwryVLsC9fPvttzh8+DAOHTpUpO1nz56NmTNnOrlUREQqkpkKZKdJy4r0meFkk6QsVdfMxMfH47nnnsNXX30FX1/fIu0zdepUJCUlWR7x8fFOLiURkcLk5h0vA2AMcv378y7ApDBV18wcPnwYiYmJaNKkiWWdyWTCzz//jHnz5iEjIwN6vd5mH6PRCKPR6OqiEhEpxzIs28WTTMo42SQpTNVhpmPHjjh+/LjNuqFDh6JWrVqYPHlyviBDROSRlByWDXCySVKcqsNMUFAQ6tata7MuICAAZcuWzbeeiMhjKXXDPJk/+8yQslTdZ4aIiIpADhFKDMsG2MxEilN1zYw9O3fuVLoIRETqonTNDJuZSGGsmSEi0jql+8zIo5my04CsNGXKQB6NYYaISOuUrpkxlgF0OQMy2NRECmCYISLSOstUBgrVzOh0bGoiRTHMEBFpndI1MwAnmyRFMcwQEWldak6AUKrPDMDJJklRDDNERFqndDMTwMkmSVEMM0REWpadAWSmSMtKhhk2M5GCGGaIiLRMrgnReQHGYOXKwWYmUhDDDBGRlsmdf/3CAC8Ff6VbRjOxZoZcj2GGiEjL1NBfBrCqmWGYIddjmCEi0jI1DMsGrPrMsJmJXI9hhohIy5SeykDGySZJQQwzRERalqqyZiYOzSYFMMwQEWmZWvrMWDczCaFsWcjjMMwQEWmZWvrMyM1M5uzc+94QuQjDDBGRlqmlz4zBD9AbpWU2NZGLMcwQEWmZpZlJ4ZoZnY4jmkgxDDNERFpmaWZSuGYG4L1mSDEMM0REWqaGGbNlnGySFMIwQ0SkVaYsICNJWla6mQkA/FkzQ8pgmCEi0ipLaNABfiFKlkTCZiZSCMMMEZFWWSaZDAG89IoWBQCbmUgxDDNERFqllmHZMtbMkEIYZoiItEotN8yTcWg2KYRhhohIq9QylYGMzUykEIYZIiKtUlvNDJuZSCEMM0REWmXpMxOqbDlkbGYihTDMEBFplVwDopqaGTnM3AbMZkWLQp6FYYaISKvUNJUBYFVDJID020qWhDwMwwwRkVapbWi2tw/gEygts98MuRDDDBGRVqmtAzDATsCkCIYZIiKtUtvQbCA3zHB4NrkQwwwRkRaZTVJHW0BdNTOWEU2smSHXYZghItKitNsAhLSslqHZgFUzE2tmyHUYZoiItEjuL2MMBvQGZctijXcBJgUwzBARaZGlv4yKamUANjORIhhmiIi0SI0jmQA2M5EiGGaIiLRIbfeYkbGZiRTAMENEpEWqr5lhMxO5DsMMEZEWqfEeMwAnmyRFMMwQEWmR2puZ5HvgELkAwwwRkRalqrRmRm5mykgGTFnKloU8BsMMEZEWqbWZyS8EgE5aZr8ZchGGGSIiLVJrB2AvPeAbLC0zzJCLMMwQEWmRWvvMAJxsklyOYYaISGvMZqtmJpXVzAAc0UQuxzBDRKQ1GUmAMEvLauszA/BeM+RyDDNERFojN9/4BALeRmXLYg/vAkwuxjBDRKQ1au4vA3CySXI5hhkiIq2xjGRSaZjhZJPkYgwzRERao9Z7zMjYzEQuxjBDRKQ1bGYisqHqMDN79mw0a9YMQUFBCA8PR69evXDq1Cmli0VEpCy13jBP5hcifWWYIRdRdZjZtWsXxo4di3379mHr1q3Izs5Gp06dcPfuXaWLRkSkHDYzEdnwVroAhdm0aZPN8yVLliA8PByHDx/Ggw8+qFCpiIgUpvqaGd5nhlxL1TUzeSUlJQEAwsJU+t+II5nN0n81QihdEiJSm9SckCCHBrWRa4yy04CsNGXLQh5B1TUz1oQQmDRpEtq0aYO6desWuF1GRgYyMjIsz5OTk11RPMdbMxo49i1g8AdCY4Cw+3K/hsVKX8tUBvSauYRE5Chqr5kxlgF0ekCYpNoZg5/SJSI3p5m/hOPGjcOxY8fw66+/Frrd7NmzMXPmTBeVykn+XC0FGQDISgUST0iPvLy8gZDo3HATGpsbdkKiAYOva8tNRK6h9j4zOp1Ua5R6XaphLlNR6RKRm9NEmBk/fjzWrl2Ln3/+GZUrVy5026lTp2LSpEmW58nJyYiKinJ2ER3n7nVg/QvS8gPPAw0HADfPA7fOAzfPScs3zwG3LgCmDODmWemRjw4oUyk36NgEnljAGOTKsyIiRxFC/TUzgBS0Uq/zxnnkEqoOM0IIjB8/HqtXr8bOnTsRGxt7z32MRiOMRhXOVVJUG16QfgGE1wHaTgG8fYCyVfNvZzYDdy7nCThy4LkAZN4Bkv+RHhd+yb9/QHmgakeg10LAS1Ndp4g8W8YdwJwtLav1PjMAOwGTS6k6zIwdOxZff/01fvjhBwQFBSEhIQEAEBwcDD8/N2yD/XON1MSk0wO9FkhBpiBeXkBwZekRm2dklxBSDU++2pycr6k3gLvXpKas2t2B2j2celpE5EByrYy3H+Djr2xZCsPh2eRCqg4zCxcuBAC0a9fOZv2SJUswZMgQ1xfIme7eANY/Ly0/MAmo2LDkx9LpgMDy0iOqef7X05OAHbOB/QuBXz8AanWX9iEi9VN7fxmZ5S7ADDPkfKoOM8KThiVvfDGneSkOePBF576Xb7AUmA59Dvx7GLjwKxD7gHPfk4gcwzIsW+Vhhs1M5ELsLKEGJ9YCf6yyal5yQZ+fwHCg0dPS8u65zn8/InIMtc+YLZPDTCrDDDkfw4zS7t4A1ueMvmozEajYyHXv3Wo8oPMCzmwDEo677n2JqOQ018zEMEPOxzCjtI0vSZ1xy9cG2r7k2vcOiwXieknLuz907XsTUcloYVg2YNXMxD4z5HwMM0o6+SPwx3eubV7Kq80E6esf30v3riEidZNHB6m+zwxHM5HrMMwoJfUmsE5uXpoAVGqsTDkiGwBVO0i3Hd8zT5kyEFHRaa5mhs1M5HwMM0rZ+BJwNxEoXwtoO1nZsrSeIH09+qV0fxoiUi/N9ZnhhLnkfAwzSji5Dji+Uup8q1TzkrXYB6WOx9lpwP5PlC0LERUuVSNhRm5mMmcDmSnKloXcHsOMq6XeBNZNlJZbPwdUaqJseQDphnly7cyBxUAGf/EQqZZW+swY/AB9zj9q7DdDTsYw42qbplg1L01RujS5avcAwqoC6beBI8uULg0R2aOVSSYB6Z8k3gWYXIRhxpX+2gAcWyE1L/VcABh8lS5RLi890PpZaXnvfCA7U9nyEFF+WamAKUNaVnszE5Bbe8ROwORkDDOuknoTWDdBWm71LFBZBc1LedXvBwRWAJL/lYaME5G6yLUyXgbAJ1DZshSF5S7ArJkh52KYcZVNU4GUq0C5GkC7qUqXxj6DL9BitLS8+0PAbFa2PERky9L5t6w2Jof15/Bscg2GGVc4tRE49m3O6KWF6mpeyqvpMMBYBrj2F3B6k9KlISJrWhmWLeO9ZshFGGacLe0W8OMEabnVeKByU0WLc0++wVKgATgBJZHaWNfMaAHvAkwuwjDjbJumAikJOc1LLytdmqJpMRrQ+wDx+4GLe5UuDRHJLMOyQ5UtR1FxsklyEYYZZzq1Cfj9G3WOXipMUATQoL+0zNoZIvXQyrBsGSebJBdhmHGWtFu5o5dajgWimilanGJr/RwAndRv5uoJpUtDRIAG+8ywmYlcg2HGWTa9DNy5ApStDrR/RenSFF/ZqkDco9Ly7g+VLQsRSbRWM8NmJnIRhhlnOL0Z+P1rADpp7iWDn9IlKhl5ioM/vgNuxytaFCKCdqYykLGZqWjMJt6otJQYZhwt7Tbw43PScsuxQFRzRYtTKpUaS5NQmrOluwITkbK0VjNjuQPwbekPNuV34yzwcWNgfnMg5ZrSpdEshhlH2/xKTvNSNaDDq0qXpvTk2pkjy9juTaQ0ublGM31m5FFXAkhPUrQoqnTjLLC0G3DrAnDrPPDDWGn+LSo2hhlHOr0F+O1LADqg53ztNi9Zq9oBiKgvzQlzYLHSpSHybHLNjFaGZnv75E67wH4ztuQgI//zqzcCf28GDn2mdMk0iWHGUfI2L1VpoWhxHEanA9pMkJb3fwJk3lW0OEQeKytd+qcC0E4zE8DJJu2xDjLlawFDNwEPz5Re2/wqcO2UsuXTIIYZR9nyCnDnMhBWVZujlwpTuycQGiN14jv6pdKlIfJMcidanV66U7dW+IVIX9lMLckbZAavAwLLA81HSjXh2WnAqmfYIbiYGGYc4e9tOX/kc5qXfPyVLpFj6b2lqRgAYM88wJSlbHmIPJGl82+YNiaZlFmGZzPMFBhkAMArZ+4+vzAg4Riw4z/KllVjGGZKKz0J+PFZabnFaCC6pbLlcZaGA4CA8kDSJeCP75UuDZHn0dqwbBknm5QUFmRkQRHAox9Ly7s/As7/7PpyahTDTGltfgVI/hcIuw/oME3p0jiPwQ+4f5S0vPtD9rgncjWtDcuW8S7ARQsystrdgcaDAQhg9SiGwCJimCmNM9uAo1/AbZuX8mo2XBqZkPgn8PdWpUtD5Fm0NpWBzNObmYoTZGSdZ0v9L5P/BdZN5D+PRcAwU1LpScDanOal+0cB0a2ULY8r+IUCTYZIy5yAksi1UjUaZjy5menGWWBp9+IFGQDwCQAe/xTw8gb+XA38/q3zy6pxDDMltXW6lJpDY4GObty8lFfLsYCXAbi4G4g/oHRpiDyHZvvMeGgzkyXIXC5ekJFVagK0myotb3gBuHneOeV0EwwzJdXsGaBio5zmpQClS+M6ZSoCDZ6Uln+dq2hRiDyGKRu49pe0rLU+M5442WRpg4yszUSgSisgMwX4foT0fUB2McyUVERd4P92ADGtlS6J67V6DoAOOLWeN3cicrab54AlnYFzO6TnlZooW57i8rTJJh0VZADASw/0/gQwlgH+OQD88r5jy+pGGGZKQ0v3enCk8jWAWt2k5d0fKVsWInclBHD0K2DRA8A/B6U/aL3/q71/oCzNTB5QM+PIICMLqQJ0myMt73obiD9Y+nK6IYYZKhl5AspjK4CkfxUtCpHbSb0JrBwM/DBGamKo0goYvRuo30fpkhWfXDOTece9b7iZL8j8WPogI6vfB6jXBxAm4PtngIw7jjmuG2GYoZKJagZEtwHMWcC+BUqXhsh9nN0BLGwFnPhBGs3S8TVgyDrpP3Qt8gsBkFOL7a79ZuwGmXDHvkfX94DgKGmG7Y1THHtsN8AwQyUnT0B5eKn7/pIicpXsDOkmnF/0yp1JefhW4IHnpb4TWuVlNZeUO45ockWQAaRQ2HsxoPMCfvsS+HON499DwxhmqOSqPQRUqCtVgx/8r9KlIdKuxJPApx2AvfOk502HASN/Bio1VrZcjuKu95pxVZCRRbeSRjgBwI/PsYnfCsMMlZxOB7R+TlretwjISlO2PERaI4T0s/NJW+DqH4B/OaD/t0D3D9zrlg/ueBdgVwcZWbup0m1B0m8Da0YBZrPz31MDGGaodOr0ltryU6/nzBxOREVyJwH48nFg02TAlAFUexgYvQeo2UXpkjmen5vda0apIAMAeoM0qs3gL01EKdfmeThvpQtAGqf3BlqOBza+COz5GGgyVFrnqbLSgJTEnMfVnEcikJJgtS5R2tY3RGoH9wu1euR57mv13CfAc28H4G7+Wg+sHS9NHuntC3T6j3QjTne9vnIzkzv0mVEyyMjKVZPmb/rxOWD768B97YDI+q4tg8p48F8dcphGTwO73gJuXwROrAHqPaF0iRzLbALuXrcKJlfzLFt9zUgq+nGT4otXDi/DvQOP/KjUWHtz+HiCzLvApqnAkWXS84h60n/Z4bWULZezuUszkxqCjKzxYOD0FunmpaueAUbsdP/JjgvBMEOl5+MPNB8J7JwlTXFQ93Ft/odpNgOXjwCnNwGXj+YGlLvXAFGMdmm9EQisAARVkL4Ghtt+DQgHvLykKve023m+Wj3Sc9al3pSGwJuzgLuJ0uNevLyBqh2ka1GzK+BbpoQfCjnMv4eBVf8H3DwLQAe0Gg90eBXwNipdMudzhw7AagoygPQ79tGPgYWHgOungK2vAd3eU648CmOYIcdo/n/A7g+Bq8eBs9ulkU5akHkXOLcTOLUROL25kKCgAwLK2w8nlq85y77Bjg1zQgBZqQWHHuvgk3YLSL4M3DgD/L1FeuiNQPWHpWBTo7NH//emCLMJ+HUOsPMtwJwNlKkEPLYIiH1Q6ZK5jtYnm7zyO/B1P/UEGVlAWaDXAqnv1cFPgeqdgBqdlC6VIhhmyDH8w4Amg6Ub6P06V91hJvmyVPtyaqPUgS47Pfc1nyCgWgepDTo4Kjeo+JdTri+QTif1l/EJAIIrF22fa6eBP78H/lgFXD8N/LVOehgCgJqdpWBT7SF11QoIAdy+JHUmD8j53L19lC5V6dy6CKweCVzaKz2v85g0UkmuqfAUWpxs8k4CcPw76S7nCcekdWoKMrJqDwH3jwb2L5TuGD16r+PuPKwhOiGEULoQzpScnIzg4GAkJSWhTBnHVbUf/ycJe85eR+VQf0SF+aFyqD9C/Q3QabF5xVGS/gE+bCD99/l/P6lnQjwhgCu/Aac2Aac3Sv9lWQupAtToIv2Rj26j/T+g1oSQhvz+kRNsbl/Mfc0YDNTuLo1Iu6+tNErCldKTpWa9fw5JTTD/HMpfM+ZfFgiMAIJyHoEVrJYjcpryIgCDr2vLfi9CAMf+B2x4AchIlkJy13eBBv202QRbWme2SbUH/mWBtlOk2oPQGKVLlV/GHeDkOinAnN+V27zsZZBGmXV7X11BRpaVDnzaHkg8AVR/BHhqhVt8nxXn7zfDTAkt3HkWb2/6y2adv48elUOlYCN99UNUqL/leYgnhJ3Vo4DfvwFqPwo8+YVy5chKk2pdTm2UamHuXLF6UQdUbio1udTsAoTHucUP/j0JAfx7JKfG5nupylzmFwbE9ZRqbKJbOf6Os6Zs6Rftv4eAfw5LX6+dApDn14+Xt1Qrc/ea1EeoqHxDrMJOZG7ICcp5LocgV9y7Je02sH6SFB4BIKqFNPOxGv94u8rteOCjRrbXtHwtoMYj0s9h5ebK1XyasqQpJI6tkEaZZVvdLyuqBVC/r1SjpvYO9Ql/SIHGlCmFrmbPKF2iUmOYseKsMLP1xFWsO3YZ/9xKwz+3UnE1OeOe+wT46G2DTpi/TfgJ9nODsJN4EljQAoAOGHcQKFfdde9956oUXE5vkn45Wf9SMgQAVdtL4aX6Ix5ZDWvDbAbi90mh5sQaKTzIAitIv7zrPg5UblayoJf0b05wOSiFlyu/Sf1+8gqpAlRqKoXLSk2l4aUGP6l8abekEJqSIF3blASp6v9OgtQ5W1423ftnz8InSBoN5u0rPQy+eZb9pKY3g1/+9Tbb5myXd/3Nc8DaZ4HkfwCdXrrBWZuJnn27AtnNc1Ktx+nNUrObMOW+5hsiNZfU6AxU6+j84CAH+2MrpNCZej33tbLVgPr9pFGZYbHOLYej7V0AbJ4qfV+O3AWUr6l0iUqFYcaKs8JMXulZJlxJSsc/t1IRf1MKOHLQ+edWGhLv3PsXbqDR2xJ0Kof6o2KIL4L9DAj2M6CMrwFl5GU/A4KM3vDyUmnw+bqf1JwTGCH18fAtAxiDAGMZ6WHzPCjneRnb5wb/e/8RlZtQ5Oajfw/bvl6mUm7tS8wD6muKUAtTNnDhF+mX+skfpc7EsuAqQJ1eUrCJbGD/mmSkSKO//j2U22RkUxOWw1hGGjJuCS9NSl9lL4RU3sLCjhyGsu6W7r2KI+w+oPen0nlSfmm3gDPbczupW/el0XkBUffn1tqUr+W4mtOb54BjK6UQc/Ns7vqA8kDdJ6RamIqNtFtTazYDX/YGzu0AIuoDz2zXdLM5w4wVV4WZe0nPMuHy7TTE37IOOrnL14oQdqzpdECQ0Ts34PgaUMbP27Ishx7pa/71vgYnTlz3zyHgs4eLN5w5L50+N/DYCz/mbKn2Je+9Wio2lsJLjc7SPTy0+ktJKdmZ0i/CP1YBf20AMu/kvhZWFajbWxryfeNMbq3LtZP5r7VOD1SIs611KVdDGpKulIw7UrjJSJYmdcxKkzp/Z6VJz7PTpL4H2elW6+Xl9DzL9rbNkD6HBk8Cnd4EjIHKnauWmE3S99LpTdJ9UxL/tH09pIpUm1qjMxDTpvj/lNy9ITWtHvsf8M+B3PUGf6BWd6D+k1KHf3epPUu+Is26nnZTmm7m4deVLlGJMcxYUUuYuZf0LBP+vZ2G+Ju5QSchKQ3J6dlITstCUloWktOlr+lZpZ+Lw8fbC0FGb/gb9Qjw8Ya/jx4BxpyvPtbrvRFg1Nt89ffR293eR++V20x264LUTp6RLP0RSU/OWbZ+fsf+68UJQd5+0i+imp2lX3ZBEaX+bChHVhrw91Yp2JzebNtsl1eZykDlJrnhJbKBe80tRK5z+5L0/fb3FuDcLttmRIO/9PNe4xEp4JSJtH+MrDSpv9yx/wFntkr//ABSrc997aUAU6ub+wbOkz8CK54GoAMGr9XsbQAYZqxoJcwUR0a2Cclp2ZZwkxt2pOCTbBV8ktOybYJQcloWzE664t5eOkvI8fORwo2XTge9lw5eXjrodZCWc9ZZL0tfAb0O8EUGAkQqAkQq/HMefua78BN34W++C19zKgzIQkJwA1wNux/evv4weuth9PaC0eCVu+yth6/83OBlWWe9nV6tTXVqk5Ei/ef8xyqpGalcDamZSK51KeiPClFpZN6VOvLLtTbWndYBKTTLtTaRDYCLv0oB5sRa21rFyIZSgKn7uNQp3BOsHQ8cWS41t4/ercnbATDMWHHHMFMaQgjczTQhKS0LKenZuJuZjdQMk/Q1Mxt3M0xIy5Sfm3A3I89Xm+2l9RnZ2p211aDXWYUfLxgN0rKPtxf0Xjp4e+UGL72Xl+W5d05As36u9/KC3gvw9rK3b+42ln30Onh7ecFbr4MhZ1n+qtfrYMjzms328nPrZctXnfY7kpNmZJvMSMnIxp10+ZGV+zwj53l6NlIysuGl0yHQ6I0AozcCjdI/PtJy7rpAowEBOTXDNv0ChQASjufU2myWmrOtR8N5GWxHSwVXkfrA1O+r+Y6wJZKRAnzygNRPqM5jwBNLNNfszjBjhWHG+bJNZqRmmXJDTs7XbJOASQiYzQIms9WykJ6bhYDJDDvr8ryeb530yMg25zxM0tesnOUsq3XZZmRk5S6nZ5mQ7ayqKRWxDVC2y95eXvDKE7q8dFIwyv/cK/e5lw56vQ76nNo0nQ7Q66TXvLwgfbV6zcvedjrAy8vOdrqc7fLU3Om9pNe89bllkEOkJUzm3T7POUv75Z6zsyvjBKTvWbOQvreFAARyngsBIXKXzWbpNSGs9rHaJnd9znEK+NbN+zfK7inaWanLszLLZMad9GykZGRZhZM8z60Cyp30bKRlmfIf2EHkml4p7EgBRw4+4fo7qJ+2H7WS9yLm9j74mO4iw1AGlyIewYVK3XEtpCGg87J8voBV9MlZIayeCjvrrJ/rIP3zY9B7wVvvZVk25Fn21uvgk2fZ2862Lvmn49/DwGedpGa22j2kfoeWk7P+hrrXsrDdz95yXE8pODpQcf5+a6LH04IFC/Duu+/iypUrqFOnDubOnYsHHnhA6WJRDm+9F8rovVDG18U3XSuhbJMZmSY5/OQGn/Ss3FCUaTLBZAZMZjOyc8KTHM5MZiGtM0mvmYX8XFi2tWxnEpZjmIX0PDtn/+yc/eWvWSYzsk0CWfI6k0CW2Ww5Tlae7bLNZmSZ7P91kwNfpos/W/JcvgYvBBoNKOPrjSBfbwT6eiPIaJC++kohxGQWuJuRjZQMqVb3bqZUY3M3Q6oVlpflfzhSM01IzTQVMkAiDkAcDBiMGF0CLqZXQOYdA/A3APxZwD7qYR1s5PBjqaHNsz63NtYLhpywnn8f2/0NXoFoEfV/aHVxodSPxonSQ6rBV8GJu1UfZlasWIEJEyZgwYIFaN26NT755BN06dIFJ06cQJUqVZQuHmmQd85/Vv7aHbFoIazClRyMskxWgSon9MjPs035w5YljJnNeZ5bBbecr+acr/L75tYwSMsmYftavu1Ebo1bvu2sajMs7yes39cMsxnS+QgpaMqBUy6rfM7y+eUtt8ks8t6m756fb7GuB2CpgdLJX5FTI5VT+yTXTEk1RLmvWfbJqeXSwWqfnJote//I5y2ivTO0dxr2zszbS4cgX28E+RosAUReDrKEktzXyuS8FmD0ho+3Y0aqCSHVutoEHJvQkxuGUjJy16dmVkJ0zknJn5P8cel0ubVQltcs2+RunLu9Lt/+ZgHLz5f0j4UZWdkCmVbLWWYzskzScrbZjMzs3H9A7P3jIR3LeTVbADAPrfG43oRySAYgXXcBXW4NFHQQOWcqcs7a+nne13OXbb/WvFMPg5x6JoVTfTPT/fffj8aNG2PhwoWWdbVr10avXr0we/bse+7PZiYiIlKayAnmWVaBSK5lzciWAnmWVW1tVs4/IoXVylpqd+3uY7udba2ybS2z/M+CvfCf95+a3GWzzfORbati0sM1HPqZuU0zU2ZmJg4fPowpU6bYrO/UqRP27Nljd5+MjAxkZORWSSYnJzu1jERERPei0+kszUrkeKr+VK9fvw6TyYQKFWyH0lWoUAEJCQl295k9ezaCg4Mtj6ioKFcUlYiIiBSi6jAjy9vjWwhRYC/wqVOnIikpyfKIj4+3ux0RERG5B1U3M5UrVw56vT5fLUxiYmK+2hqZ0WiE0Wh0RfGIiIhIBVRdM+Pj44MmTZpg69atNuu3bt2KVq1aKVQqIiIiUhNV18wAwKRJkzBw4EA0bdoULVu2xOLFi3Hp0iWMGjVK6aIRERGRCqg+zDz55JO4ceMGXn/9dVy5cgV169bFhg0bEB0drXTRiIiISAVUf5+Z0uJ9ZoiIiLSnOH+/Vd1nhoiIiOheGGaIiIhI0xhmiIiISNMYZoiIiEjTGGaIiIhI0xhmiIiISNMYZoiIiEjTVH/TvNKSb6OTnJyscEmIiIioqOS/20W5HZ7bh5k7d+4AAKKiohQuCRERERXXnTt3EBwcXOg2bn8HYLPZjMuXLyMoKAg6nc6hx05OTkZUVBTi4+Pd/u7CPFf35Unny3N1X550vp5yrkII3LlzBxUrVoSXV+G9Yty+ZsbLywuVK1d26nuUKVPGrb+hrPFc3ZcnnS/P1X150vl6wrneq0ZGxg7AREREpGkMM0RERKRpDDOlYDQaMX36dBiNRqWL4nQ8V/flSefLc3VfnnS+nnSuReX2HYCJiIjIvbFmhoiIiDSNYYaIiIg0jWGGiIiINI1hhoiIiDSNYaYQCxYsQGxsLHx9fdGkSRP88ssvhW6/a9cuNGnSBL6+vrjvvvuwaNEiF5W0dGbPno1mzZohKCgI4eHh6NWrF06dOlXoPjt37oROp8v3+Ouvv1xU6pKZMWNGvjJHREQUuo9WrysAxMTE2L1OY8eOtbu9lq7rzz//jB49eqBixYrQ6XRYs2aNzetCCMyYMQMVK1aEn58f2rVrhz///POex121ahXi4uJgNBoRFxeH1atXO+kMiq6wc83KysLkyZNRr149BAQEoGLFihg0aBAuX75c6DGXLl1q91qnp6c7+Wzu7V7XdsiQIfnK3aJFi3seV2vXFoDda6TT6fDuu+8WeEw1X1tnYZgpwIoVKzBhwgS88sorOHr0KB544AF06dIFly5dsrv9+fPn0bVrVzzwwAM4evQoXn75ZTz77LNYtWqVi0tefLt27cLYsWOxb98+bN26FdnZ2ejUqRPu3r17z31PnTqFK1euWB7Vq1d3QYlLp06dOjZlPn78eIHbavm6AsDBgwdtznXr1q0AgD59+hS6nxau6927d9GgQQPMmzfP7uvvvPMO5syZg3nz5uHgwYOIiIjAww8/bJmvzZ69e/fiySefxMCBA/H7779j4MCB6Nu3L/bv3++s0yiSws41NTUVR44cwbRp03DkyBF8//33OH36NB599NF7HrdMmTI21/nKlSvw9fV1xikUy72uLQB07tzZptwbNmwo9JhavLYA8l2fzz//HDqdDo8//nihx1XrtXUaQXY1b95cjBo1ymZdrVq1xJQpU+xu/9JLL4latWrZrBs5cqRo0aKF08roLImJiQKA2LVrV4Hb7NixQwAQt27dcl3BHGD69OmiQYMGRd7ena6rEEI899xzomrVqsJsNtt9XavXFYBYvXq15bnZbBYRERHirbfesqxLT08XwcHBYtGiRQUep2/fvqJz58426x555BHRr18/h5e5pPKeqz0HDhwQAMTFixcL3GbJkiUiODjYsYVzAnvnO3jwYNGzZ89iHcddrm3Pnj1Fhw4dCt1GK9fWkVgzY0dmZiYOHz6MTp062azv1KkT9uzZY3efvXv35tv+kUcewaFDh5CVleW0sjpDUlISACAsLOye2zZq1AiRkZHo2LEjduzY4eyiOcTff/+NihUrIjY2Fv369cO5c+cK3NadrmtmZia+/PJLDBs27J6Trmrxulo7f/48EhISbK6d0WhE27ZtC/wZBgq+3oXto0ZJSUnQ6XQICQkpdLuUlBRER0ejcuXK6N69O44ePeqaAjrAzp07ER4ejho1auD//u//kJiYWOj27nBtr169ivXr12P48OH33FbL17YkGGbsuH79OkwmEypUqGCzvkKFCkhISLC7T0JCgt3ts7Ozcf36daeV1dGEEJg0aRLatGmDunXrFrhdZGQkFi9ejFWrVuH7779HzZo10bFjR/z8888uLG3x3X///Vi+fDk2b96MTz/9FAkJCWjVqhVu3Lhhd3t3ua4AsGbNGty+fRtDhgwpcButXte85J/T4vwMy/sVdx+1SU9Px5QpU/DUU08VOglhrVq1sHTpUqxduxbffPMNfH190bp1a/z9998uLG3JdOnSBV999RV++uknvP/++zh48CA6dOiAjIyMAvdxh2u7bNkyBAUFoXfv3oVup+VrW1JuP2t2aeT971UIUeh/tPa2t7dezcaNG4djx47h119/LXS7mjVrombNmpbnLVu2RHx8PN577z08+OCDzi5miXXp0sWyXK9ePbRs2RJVq1bFsmXLMGnSJLv7uMN1BYDPPvsMXbp0QcWKFQvcRqvXtSDF/Rku6T5qkZWVhX79+sFsNmPBggWFbtuiRQubTrOtW7dG48aN8fHHH+Ojjz5ydlFL5cknn7Qs161bF02bNkV0dDTWr19f6B96LV9bAPj8888xYMCAe/Z90fK1LSnWzNhRrlw56PX6fIk9MTExX7KXRURE2N3e29sbZcuWdVpZHWn8+PFYu3YtduzYgcqVKxd7/xYtWmgu+QcEBKBevXoFltsdrisAXLx4Edu2bcMzzzxT7H21eF3lEWrF+RmW9yvuPmqRlZWFvn374vz589i6dWuhtTL2eHl5oVmzZpq71oBUoxgdHV1o2bV8bQHgl19+walTp0r0M6zla1tUDDN2+Pj4oEmTJpaRH7KtW7eiVatWdvdp2bJlvu23bNmCpk2bwmAwOK2sjiCEwLhx4/D999/jp59+QmxsbImOc/ToUURGRjq4dM6VkZGBkydPFlhuLV9Xa0uWLEF4eDi6detW7H21eF1jY2MRERFhc+0yMzOxa9euAn+GgYKvd2H7qIEcZP7++29s27atREFbCIHffvtNc9caAG7cuIH4+PhCy67Vayv77LPP0KRJEzRo0KDY+2r52haZUj2P1e7bb78VBoNBfPbZZ+LEiRNiwoQJIiAgQFy4cEEIIcSUKVPEwIEDLdufO3dO+Pv7i4kTJ4oTJ06Izz77TBgMBvHdd98pdQpFNnr0aBEcHCx27twprly5YnmkpqZatsl7vh988IFYvXq1OH36tPjjjz/ElClTBACxatUqJU6hyJ5//nmxc+dOce7cObFv3z7RvXt3ERQU5JbXVWYymUSVKlXE5MmT872m5et6584dcfToUXH06FEBQMyZM0ccPXrUMoLnrbfeEsHBweL7778Xx48fF/379xeRkZEiOTnZcoyBAwfajFDcvXu30Ov14q233hInT54Ub731lvD29hb79u1z+flZK+xcs7KyxKOPPioqV64sfvvtN5uf4YyMDMsx8p7rjBkzxKZNm8TZs2fF0aNHxdChQ4W3t7fYv3+/Eqdoo7DzvXPnjnj++efFnj17xPnz58WOHTtEy5YtRaVKldzu2sqSkpKEv7+/WLhwod1jaOnaOgvDTCHmz58voqOjhY+Pj2jcuLHNUOXBgweLtm3b2my/c+dO0ahRI+Hj4yNiYmIK/MZTGwB2H0uWLLFsk/d83377bVG1alXh6+srQkNDRZs2bcT69etdX/hievLJJ0VkZKQwGAyiYsWKonfv3uLPP/+0vO5O11W2efNmAUCcOnUq32tavq7yMPK8j8GDBwshpOHZ06dPFxEREcJoNIoHH3xQHD9+3OYYbdu2tWwvW7lypahZs6YwGAyiVq1aqghyhZ3r+fPnC/wZ3rFjh+UYec91woQJokqVKsLHx0eUL19edOrUSezZs8f1J2dHYeebmpoqOnXqJMqXLy8MBoOoUqWKGDx4sLh06ZLNMdzh2so++eQT4efnJ27fvm33GFq6ts6iEyKnNyMRERGRBrHPDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwReQSdToc1a9YoXQwicgKGGSJyuiFDhkCn0+V7dO7cWemiEZEb8Fa6AETkGTp37owlS5bYrDMajQqVhojcCWtmiMgljEYjIiIibB6hoaEApCaghQsXokuXLvDz80NsbCxWrlxps//x48fRoUMH+Pn5oWzZshgxYgRSUlJstvn8889Rp04dGI1GREZGYty4cTavX79+HY899hj8/f1RvXp1rF271vLarVu3MGDAAJQvXx5+fn6oXr16vvBFROrEMENEqjBt2jQ8/vjj+P333/H000+jf//+OHnyJAAgNTUVnTt3RmhoKA4ePIiVK1di27ZtNmFl4cKFGDt2LEaMGIHjx49j7dq1qFatms17zJw5E3379sWxY8fQtWtXDBgwADdv3rS8/4kTJ7Bx40acPHkSCxcuRLly5Vz3ARBRySk90yURub/BgwcLvV4vAgICbB6vv/66EEKauX3UqFE2+9x///1i9OjRQgghFi9eLEJDQ0VKSorl9fXr1wsvLy+RkJAghBCiYsWK4pVXXimwDADEq6++anmekpIidDqd2LhxoxBCiB49eoihQ4c65oSJyKXYZ4aIXKJ9+/ZYuHChzbqwsDDLcsuWLW1ea9myJX777TcAwMmTJ9GgQQMEBARYXm/dujXMZjNOnToFnU6Hy5cvo2PHjoWWoX79+pblgIAABAUFITExEQAwevRoPP744zhy5Ag6deqEXr16oVWrViU6VyJyLYYZInKJgICAfM0+96LT6QAAQgjLsr1t/Pz8inQ8g8GQb1+z2QwA6NKlCy5evIj169dj27Zt6NixI8aOHYv33nuvWGUmItdjnxkiUoV9+/ble16rVi0AQFxcHH777TfcvXvX8vru3bvh5eWFGjVqICgoCDExMdi+fXupylC+fHkMGTIEX375JebOnYvFixeX6nhE5BqsmSEil8jIyEBCQoLNOm9vb0sn25UrV6Jp06Zo06YNvvrqKxw4cACfffYZAGDAgAGYPn06Bg8ejBkzZuDatWsYP348Bg4ciAoVKgAAZsyYgVGjRiE8PBxdunTBnTt3sHv3bowfP75I5XvttdfQpEkT1KlTBxkZGVi3bh1q167twE+AiJyFYYaIXGLTpk2IjIy0WVezZk389ddfAKSRRt9++y3GjBmDiIgIfPXVV4iLiwMA+Pv7Y/PmzXjuuefQrFkz+Pv74/HHH8ecOXMsxxo8eDDS09PxwQcf4IUXXkC5cuXwxBNPFLl8Pj4+mDp1Ki5cuAA/Pz888MAD+Pbbbx1w5kTkbDohhFC6EETk2XQ6HVavXo1evXopXRQi0iD2mSEiIiJNY5ghIiIiTWOfGSJSHFu7iag0WDNDREREmsYwQ0RERJrGMENERESaxjBDREREmsYwQ0RERJrGMENERESaxjBDREREmsYwQ0RERJrGMENERESa9v8SS8X9bHaykAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directorio_historico = './Historicos/historico_alexnet_arqu_batchsize/hist_alexNet_Simple3_64.csv' # cambiar directorio en caso que se emplee otro csv\n",
    "metrica_entrenamiento = 'loss' \n",
    "metrica_validacion = 'val_loss' \n",
    "\n",
    "graf_mejor_modelo_loss=grafica(directorio_historico, metrica_entrenamiento, metrica_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0861be5-63bc-4386-83a9-bd839eb78501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec70ad44-41bf-4c21-897f-5dfa8f83fe0d",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como evoluciona del modelo más simple inicial al modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0aa3-f29f-4b6a-bd79-4aec32a7e8dd",
   "metadata": {},
   "source": [
    "Finalmente, se obtiene la matriz de confusión para el modelo inicial (más simple) y el modelo final obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6667ac05-148b-4795-a802-6f326e9b6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def matriz_conf(ruta, batch_size, target_size, epochs, modelo, titulo):\n",
    "    \n",
    "    '''\n",
    "    Función que crea una matriz de confusión a partir de la carga de un modelo dentro de la carpeta ''Modelos''.\n",
    "    ----------------------------------------------------------------\n",
    "    Parámetros:\n",
    "    - ruta: str. Ruta base donde se encuentran las imágenes organizadas en subcarpetas (train, val, test). Ruta data_nuevo\n",
    "    - batchsize: int. Tamaño del lote que se utiliza en una única iteración del algoritmo de aprendizaje\n",
    "    - target_size: tupla de números enteros que representa el alto y ancho al que se van a redimensionar todas las imágenes. \n",
    "    - epochs: int. Número de épocas a entrenar\n",
    "    - modelo: modelo previamente entrenado y almacenado dentro de la carpeta ''Modelos'' del cual se quiere obtener la matriz de confusión.\n",
    "    - titulo: str. Título que se quiere asignar a la matriz de confusión\n",
    "    -----------------------------------------------------------\n",
    "    Return:\n",
    "    - nada\n",
    "    '''\n",
    "\n",
    "    #se genera los datos\n",
    "    train_generator, validation_generator, test_generator = preparar_modelo(ruta, batch_size, target_size)\n",
    "    \n",
    "    # se calcula y_test e y_pred del modelo pasado como parámetro para obtener la matriz de confusion\n",
    "    y_test=test_generator.labels\n",
    "    y_pred=modelo.predict(test_generator)\n",
    "    y_pred_bin=np.where(y_pred>=0.5,1,0) #para convertirlo en un problema binario\n",
    "    \n",
    "        \n",
    "    # matriz de confusión visualmente\n",
    "    labels=np.unique(y_test)\n",
    "        \n",
    "    matriz_conf = metrics.confusion_matrix(y_test, y_pred_bin,labels=labels)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matriz_conf, display_labels = [\"NORMAL\" , \"PNEUMONIA\"])\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    cm_display.plot(ax=ax)\n",
    "    plt.title(titulo)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef68307-5f21-48be-8a2c-cd536b2550fb",
   "metadata": {},
   "source": [
    "#### Matriz de confusión inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfc9fb8c-2f27-4e9a-83e6-829cfa632023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "147/147 [==============================] - 30s 205ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' \n",
    "batch_size=8 \n",
    "target_size=(150,150) #porque se emplea la CNN propia\n",
    "epochs=20\n",
    "modelo=keras.models.load_model('./Modelos/modelo_propia_arqu_batchsize/modelo_propia_Simple1_8.h5') \n",
    "titulo=\"Matriz inicial PNEUMONIA-NORMAL\"\n",
    "\n",
    "matriz_conf(ruta, batch_size, target_size, epochs, modelo, titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d901d-4d08-4f3b-ad30-dd2a7021db0b",
   "metadata": {},
   "source": [
    "#### Matriz de confusión final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d216db73-ce27-479e-add8-5c2a7d951d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3747 images belonging to 2 classes.\n",
      "Found 937 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "19/19 [==============================] - 38s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ruta='C:/Users/nuria/Downloads/TFG/data_nuevo' #directorio donde se encuentra la nueva carpeta creada con las imágenes\n",
    "batch_size=64 \n",
    "target_size=(340,340) #porque se emplea la CNN de AlexNet\n",
    "epochs=20\n",
    "#se indica la ruta donde está el modelo que se quiere emplear (CAMBIAR EN CASO DE MODIFICAR LA RUTA)\n",
    "modelo=keras.models.load_model('./Modelos/modelo_alexnet_arqu_batchsize/modelo_alexnet_Simple3_64.h5') \n",
    "titulo=\"Matriz final PNEUMONIA-NORMAL\"\n",
    "\n",
    "matriz_conf(ruta, batch_size, target_size, epochs, modelo, titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115865-dddc-4ec1-bb3a-efa3419117a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39577e-3dcd-4b3f-8f6c-2008ba038885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
